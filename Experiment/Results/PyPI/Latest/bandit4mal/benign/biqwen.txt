Run started:2025-05-25 16:00:23.530980

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/latest/unzip_benign/biqwen/biqwen-0.1.0/src/billm/modeling_qwen2.py:297
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
296	
297	QWEN2_START_DOCSTRING = r"""
298	    This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the
299	    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
300	    etc.)
301	
302	    This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.
303	    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
304	    and behavior.
305	
306	    Parameters:
307	        config ([`Qwen2Config`]):
308	            Model configuration class with all the parameters of the model. Initializing with a config file does not
309	            load the weights associated with the model, only the configuration. Check out the
310	            [`~PreTrainedModel.from_pretrained`] method to load the model weights.
311	"""
312	
313	
314	@add_start_docstrings(
315	    "The bare Qwen2 Model outputting raw hidden-states without any specific head on top.",
316	    QWEN2_START_DOCSTRING,
317	)
318	class Qwen2PreTrainedModel(PreTrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/latest/unzip_benign/biqwen/biqwen-0.1.0/src/billm/modeling_qwen2.py:380
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
379	
380	QWEN2_INPUTS_DOCSTRING = r"""
381	    Args:
382	        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):
383	            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide
384	            it.
385	
386	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
387	            [`PreTrainedTokenizer.__call__`] for details.
388	
389	            [What are input IDs?](../glossary#input-ids)
390	        attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length) or `BlockMask`, *optional*):
391	            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:
392	
393	            - 1 for tokens that are **not masked**,
394	            - 0 for tokens that are **masked**.
395	
396	            If the model is configured to use flex_attention, it will attempt to convert the mask Tensor into a BlockMask,
397	            but you can also pass a `BlockMask` object directly here.
398	
399	            [What are attention masks?](../glossary#attention-mask)
400	
401	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
402	            [`PreTrainedTokenizer.__call__`] for details.
403	
404	            If `past_key_values` is used, optionally only the last `input_ids` have to be input (see
405	            `past_key_values`).
406	
407	            If you want to change padding behavior, you should read [`modeling_opt._prepare_decoder_attention_mask`]
408	            and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more
409	            information on the default strategy.
410	
411	            - 1 indicates the head is **not masked**,
412	            - 0 indicates the head is **masked**.
413	        position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):
414	            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,
415	            config.n_positions - 1]`.
416	
417	            [What are position IDs?](../glossary#position-ids)
418	        past_key_values (`Cache`, *optional*):
419	            Pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
420	            blocks) that can be used to speed up sequential decoding. This typically consists in the `past_key_values`
421	            returned by the model at a previous stage of decoding, when `use_cache=True` or `config.use_cache=True`.
422	
423	            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).
424	
425	            If `past_key_values` are used, the user can optionally input only the last `input_ids` (those that don't
426	            have their past key value states given to this model) of shape `(batch_size, 1)` instead of all `input_ids`
427	            of shape `(batch_size, sequence_length)`.
428	        inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):
429	            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
430	            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the
431	            model's internal embedding lookup matrix.
432	        use_cache (`bool`, *optional*):
433	            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see
434	            `past_key_values`).
435	        output_attentions (`bool`, *optional*):
436	            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned
437	            tensors for more detail.
438	        output_hidden_states (`bool`, *optional*):
439	            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for
440	            more detail.
441	        return_dict (`bool`, *optional*):
442	            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.
443	        cache_position (`torch.LongTensor` of shape `(sequence_length)`, *optional*):
444	            Indices depicting the position of the input sequence tokens in the sequence. Contrarily to `position_ids`,
445	            this tensor is not affected by padding. It is used to update the cache in the correct position and to infer
446	            the complete sequence length.
447	"""
448	
449	
450	@add_start_docstrings(
451	    "The bare Qwen2 Model outputting raw hidden-states without any specific head on top.",
452	    QWEN2_START_DOCSTRING,
453	)
454	class Qwen2Model(Qwen2PreTrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/latest/unzip_benign/biqwen/biqwen-0.1.0/src/billm/modeling_qwen3.py:323
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
322	
323	QWEN3_START_DOCSTRING = r"""
324	    This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the
325	    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
326	    etc.)
327	
328	    This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.
329	    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
330	    and behavior.
331	
332	    Parameters:
333	        config ([`Qwen3Config`]):
334	            Model configuration class with all the parameters of the model. Initializing with a config file does not
335	            load the weights associated with the model, only the configuration. Check out the
336	            [`~PreTrainedModel.from_pretrained`] method to load the model weights.
337	"""
338	
339	
340	@add_start_docstrings(
341	    "The bare Qwen3 Model outputting raw hidden-states without any specific head on top.",
342	    QWEN3_START_DOCSTRING,
343	)
344	class Qwen3PreTrainedModel(PreTrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/latest/unzip_benign/biqwen/biqwen-0.1.0/src/billm/modeling_qwen3.py:406
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
405	
406	QWEN3_INPUTS_DOCSTRING = r"""
407	    Args:
408	        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):
409	            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide
410	            it.
411	
412	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
413	            [`PreTrainedTokenizer.__call__`] for details.
414	
415	            [What are input IDs?](../glossary#input-ids)
416	        attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length) or `BlockMask`, *optional*):
417	            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:
418	
419	            - 1 for tokens that are **not masked**,
420	            - 0 for tokens that are **masked**.
421	
422	            If the model is configured to use flex_attention, it will attempt to convert the mask Tensor into a BlockMask,
423	            but you can also pass a `BlockMask` object directly here.
424	
425	            [What are attention masks?](../glossary#attention-mask)
426	
427	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
428	            [`PreTrainedTokenizer.__call__`] for details.
429	
430	            If `past_key_values` is used, optionally only the last `input_ids` have to be input (see
431	            `past_key_values`).
432	
433	            If you want to change padding behavior, you should read [`modeling_opt._prepare_decoder_attention_mask`]
434	            and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more
435	            information on the default strategy.
436	
437	            - 1 indicates the head is **not masked**,
438	            - 0 indicates the head is **masked**.
439	        position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):
440	            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,
441	            config.n_positions - 1]`.
442	
443	            [What are position IDs?](../glossary#position-ids)
444	        past_key_values (`Cache`, *optional*):
445	            Pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
446	            blocks) that can be used to speed up sequential decoding. This typically consists in the `past_key_values`
447	            returned by the model at a previous stage of decoding, when `use_cache=True` or `config.use_cache=True`.
448	
449	            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).
450	
451	            If `past_key_values` are used, the user can optionally input only the last `input_ids` (those that don't
452	            have their past key value states given to this model) of shape `(batch_size, 1)` instead of all `input_ids`
453	            of shape `(batch_size, sequence_length)`.
454	        inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):
455	            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
456	            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the
457	            model's internal embedding lookup matrix.
458	        use_cache (`bool`, *optional*):
459	            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see
460	            `past_key_values`).
461	        output_attentions (`bool`, *optional*):
462	            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned
463	            tensors for more detail.
464	        output_hidden_states (`bool`, *optional*):
465	            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for
466	            more detail.
467	        return_dict (`bool`, *optional*):
468	            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.
469	        cache_position (`torch.LongTensor` of shape `(sequence_length)`, *optional*):
470	            Indices depicting the position of the input sequence tokens in the sequence. Contrarily to `position_ids`,
471	            this tensor is not affected by padding. It is used to update the cache in the correct position and to infer
472	            the complete sequence length.
473	"""
474	
475	
476	@add_start_docstrings(
477	    "The bare Qwen3 Model outputting raw hidden-states without any specific head on top.",
478	    QWEN3_START_DOCSTRING,
479	)
480	class Qwen3Model(Qwen3PreTrainedModel):

--------------------------------------------------

Code scanned:
	Total lines of code: 1866
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 4.0
		High: 0.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 4.0
		High: 0.0
Files skipped (0):
