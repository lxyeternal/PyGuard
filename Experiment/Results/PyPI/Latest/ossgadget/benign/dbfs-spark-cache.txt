[31m--[ [0m[34mMatch #[0m[33m1[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache-0.4.6.dist-info/METADATA[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m  | [0m[35mng the same dataframe. This tradeoff can be tuned be a parameter which controlles when caching is tr[0m
[30;1m  | [0m[35m[0m
[30;1m  | [0m[35m## Features[0m
[30;1m  | [0m[35m[0m
[30;1m  | [0m[35m- **DataFrame caching**: Intelligent caching system using DBFS (Databricks File System).[0m
[30;1m  | [0m[35m- **Query complexity estimation**: Tools to analyze and estimate Spark query complexity and trigger [0m
[30;1m  | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m2[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache-0.4.6.dist-info/METADATA[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m  | [0m[35mhile the `dbfs_cache_multiplier_threshold` checks the multiplier component directly. Both conditions[0m
[30;1m  | [0m[35m[0m
[30;1m  | [0m[35m[0m
[30;1m  | [0m[35m### Configuration[0m
[30;1m  | [0m[35m[0m
[30;1m  | [0m[35mConfiguration is handled through environment variables (can be read from .env file):[0m
[30;1m  | [0m[35m[0m
[30;1m  | [0m[35m- `SPARK_CACHE_DIR`: Directory for cached data (default: "/dbfs/FileStore/tables/cache/").[0m

[31m--[ [0m[34mMatch #[0m[33m3[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache-0.4.6.dist-info/METADATA[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m  | [0m[35m JSON ()[0m
[30;1m  | [0m[35m[0m
[30;1m  | [0m[35mIf you want to disable all calls to the extensions you can do:[0m
[30;1m  | [0m[35m```python[0m
[30;1m  | [0m[35m    dbfs_cache.extend_dataframe_methods(disable_cache_and_display=True)[0m
[30;1m  | [0m[35m```[0m
[30;1m  | [0m[35mand it will keep the DataFrame unchanged.[0m
[30;1m  | [0m[35m[0m
[30;1m  | [0m[35m#### What is "Total compute complexity" anyway?[0m
[30;1m  | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m4[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache-0.4.6.dist-info/METADATA[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m46 | [0m[35m[0m
[30;1m47 | [0m[35mRequires Python 3.10 or higher. Install using pip:[0m
[30;1m48 | [0m[35m```sh[0m
[30;1m49 | [0m[35m    pip install dbfs-spark-cache # todo: assumes published to PyPI[0m
[30;1m50 | [0m[35m```[0m
[30;1m51 | [0m[35m[0m
[30;1m52 | [0m[35m## Usage[0m

[31m--[ [0m[34mMatch #[0m[33m5[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/caching.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m909 | [0m[35m            return write_dbfs_cache([0m
[30;1m910 | [0m[35m                self, replace=True, query_plan=current_query_plan,[0m
[30;1m911 | [0m[35m                input_dir_mod_datetime=input_dir_mod_datetime_casted, hash_name=None,[0m
[30;1m912 | [0m[35m                cache_path=config.SPARK_CACHE_DIR, verbose=kwargs.get('verbose', False)[0m
[30;1m913 | [0m[35m            )[0m
[30;1m914 | [0m[35m        else:[0m
[30;1m915 | [0m[35m            log.info(f"Skip cache: {reason}")[0m

[31m--[ [0m[34mMatch #[0m[33m6[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/caching.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m858 | [0m[35m            return self[0m
[30;1m859 | [0m[35m[0m
[30;1m860 | [0m[35m        input_dir_mod_datetime_casted: Dict[str, datetime][0m
[30;1m861 | [0m[35m        if isinstance(input_info, dict) and not input_info.get("<direct_data_cache>", False):[0m
[30;1m862 | [0m[35m            input_dir_mod_datetime_casted = input_info # type: ignore[0m
[30;1m863 | [0m[35m        else:[0m
[30;1m864 | [0m[35m            log.warning("cacheToDbfs: Unexpected input_info. Defaulting to empty dict.")[0m

[31m--[ [0m[34mMatch #[0m[33m7[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/caching.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m852 | [0m[35m[0m
[30;1m853 | [0m[35m        if input_info == {"<direct_data_cache>": True}:[0m
[30;1m854 | [0m[35m            log.info("Direct data cache source. Skipping standard cache.")[0m
[30;1m855 | [0m[35m            if kwargs.get('eager_spark_cache', False) and is_spark_cached(self):[0m
[30;1m856 | [0m[35m                 log.info("Triggering spark cache.")[0m
[30;1m857 | [0m[35m                 return self.cache() # Separate return[0m
[30;1m858 | [0m[35m            return self[0m

[31m--[ [0m[34mMatch #[0m[33m8[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/caching.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m357 | [0m[35m    input_dir_mod_datetime_raw: Union[Dict[str, datetime], Dict[str, bool]] = get_input_dir_mod_date[0m
[30;1m358 | [0m[35m    # Only keep items where value is a datetime[0m
[30;1m359 | [0m[35m    input_dir_mod_datetime: Dict[str, datetime][0m
[30;1m360 | [0m[35m    if isinstance(input_dir_mod_datetime_raw, dict) and not input_dir_mod_datetime_raw.get("<direct_[0m
[30;1m361 | [0m[35m        input_dir_mod_datetime = input_dir_mod_datetime_raw # type: ignore[0m
[30;1m362 | [0m[35m    else:[0m
[30;1m363 | [0m[35m        input_dir_mod_datetime = {}[0m

[31m--[ [0m[34mMatch #[0m[33m9[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/caching.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m470 | [0m[35m    """[0m
[30;1m471 | [0m[35m    def last_mod_datetime_from_s3_dir(dir_path: str) -> Optional[datetime]:[0m
[30;1m472 | [0m[35m        if dbutils is None:[0m
[30;1m473 | [0m[35m             log.warning("dbutils not available, cannot get modification time for %s", dir_path)[0m
[30;1m474 | [0m[35m             return None[0m
[30;1m475 | [0m[35m[0m
[30;1m476 | [0m[35m        if "dbfs:/" in dir_path:[0m

[31m--[ [0m[34mMatch #[0m[33m10[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/caching.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m5 | [0m[35mimport os[0m
[30;1m6 | [0m[35mimport re[0m
[30;1m7 | [0m[35mimport shutil[0m
[30;1m8 | [0m[35mimport time[0m
[30;1m9 | [0m[35mimport types  # Added for attaching method[0m
[30;1m10 | [0m[35mfrom concurrent.futures import ThreadPoolExecutor[0m
[30;1m11 | [0m[35mfrom datetime import datetime, timedelta[0m
[30;1m12 | [0m[35mfrom glob import glob[0m

[31m--[ [0m[34mMatch #[0m[33m11[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/caching.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m689 | [0m[35m    local_metadata_file_path = metadata_file_path.replace("dbfs:/", "/dbfs/")[0m
[30;1m690 | [0m[35m[0m
[30;1m691 | [0m[35m    if not os.path.exists(local_metadata_file_path):[0m
[30;1m692 | [0m[35m        log.info(f"No cache metadata found at {local_metadata_file_path}")[0m
[30;1m693 | [0m[35m        return None[0m
[30;1m694 | [0m[35m[0m
[30;1m695 | [0m[35m    try:[0m

[31m--[ [0m[34mMatch #[0m[33m12[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/query_complexity_estimation.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m148 | [0m[35m    The complexity is estimated as the sum of input file sizes in GB[0m
[30;1m149 | [0m[35m    multiplied by a factor derived from the operations in the logical query plan.[0m
[30;1m150 | [0m[35m    A simple count() operation on 1 GB of data should result in a complexity of 1.0[0m
[30;1m151 | [0m[35m    and a multiplier of 1.0. Simpler operations (like projections) start at a baseline[0m
[30;1m152 | [0m[35m    multiplier of 0.6.[0m
[30;1m153 | [0m[35m[0m
[30;1m154 | [0m[35m    This function retrieves the input size and query plan, then delegates[0m

[31m--[ [0m[34mMatch #[0m[33m13[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/query_complexity_estimation.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m12 | [0m[35m        try:[0m
[30;1m13 | [0m[35m            # Ensure SparkContext is available[0m
[30;1m14 | [0m[35m            jsc = df.sparkSession._jsc[0m
[30;1m15 | [0m[35m            if jsc is None:[0m
[30;1m16 | [0m[35m                raise Exception("Java SparkContext not available")[0m
[30;1m17 | [0m[35m[0m
[30;1m18 | [0m[35m            path = df.sparkSession._jvm.org.apache.hadoop.fs.Path(file_path)  # type: ignore[union-a[0m

[31m--[ [0m[34mMatch #[0m[33m14[0m[34m of [0m[33m14[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/dbfs_spark_cache/query_complexity_estimation.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m11 | [0m[35m    for file_path in input_files:[0m
[30;1m12 | [0m[35m        try:[0m
[30;1m13 | [0m[35m            # Ensure SparkContext is available[0m
[30;1m14 | [0m[35m            jsc = df.sparkSession._jsc[0m
[30;1m15 | [0m[35m            if jsc is None:[0m
[30;1m16 | [0m[35m                raise Exception("Java SparkContext not available")[0m
[30;1m17 | [0m[35m[0m

14 matches found.
