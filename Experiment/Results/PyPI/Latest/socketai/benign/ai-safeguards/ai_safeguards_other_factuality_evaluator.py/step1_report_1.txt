{
  "purpose": "The code defines prompts for a language model to evaluate the factuality and groundness of claims based on a given context, specifically for verifying the supportiveness of claims and correcting responses to align strictly with a provided document.",
  "sources": "The prompt strings themselves, which are used as instructions for a language model during evaluation and correction tasks.",
  "sinks": "The prompts are designed to guide the model's output; no direct data sinks or external data transmission are present within this code snippet.",
  "flows": "The flow involves receiving a context and claims or responses, then processing these prompts to generate supported, unsupported, or corrected answersâ€”entirely within the language model's response process; no external data flow is indicated.",
  "anomalies": "No anomalies or suspicious code behaviors are evident; the code consists solely of string templates with instructions. There are no code injections, dynamic code execution, or hidden operations.",
  "analysis": "The code provides prompt templates for factuality and groundness evaluation tasks, involving structured JSON responses for clarity. The prompts are straightforward and contain no executable code or suspicious constructs. There are no signs of obfuscated code, hidden backdoors, or malicious behavior. The content is purely instructional text for language model guidance.",
  "conclusion": "The code is a benign set of prompt templates for language model tasks related to factuality and correction. It does not contain malware, malicious intent, or security risks. No malicious behavior or sabotage is evident.",
  "confidence": 1,
  "obfuscated": 0,
  "malware": 0,
  "securityRisk": 0,
  "report_number": 1
}