Run started:2025-05-25 13:25:51.935519

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyctcdecode-0.5.0/pyctcdecode-0.5.0/pyctcdecode/decoder.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
55	    logger.warning(
56	        "kenlm python bindings are not installed. Most likely you want to install it using: "
57	        "pip install https://github.com/kpu/kenlm/archive/master.zip"
58	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyctcdecode-0.5.0/pyctcdecode-0.5.0/pyctcdecode/decoder.py:106
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
105	        logger.warning(
106	            "Specified pool object has a spawn context, which is not currently supported. "
107	            "See https://github.com/kensho-technologies/pyctcdecode/issues/65."
108	            "\nFalling back to sequential decoding."

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyctcdecode-0.5.0/pyctcdecode-0.5.0/pyctcdecode/decoder.py:784
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
783	        with open(alphabet_path, "w") as fi:
784	            fi.write(self._alphabet.dumps())
785	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyctcdecode-0.5.0/pyctcdecode-0.5.0/pyctcdecode/decoder.py:831
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
830	        with open(filenames["alphabet"], "r") as fi:  # type: ignore
831	            alphabet = Alphabet.loads(fi.read())
832	        if filenames["language_model"] is None:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyctcdecode-0.5.0/pyctcdecode-0.5.0/pyctcdecode/decoder.py:868
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
867	            raise ImportError(
868	                "You need to install huggingface_hub to use `load_from_hf_hub`. "
869	                "See https://pypi.org/project/huggingface-hub/ for installation."
870	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyctcdecode-0.5.0/pyctcdecode-0.5.0/pyctcdecode/language_model.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	    logger.warning(
32	        "kenlm python bindings are not installed. Most likely you want to install it using: "
33	        "pip install https://github.com/kpu/kenlm/archive/master.zip"
34	    )

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyctcdecode-0.5.0/pyctcdecode-0.5.0/pyctcdecode/language_model.py:361
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
360	            for unigram in sorted(self._unigram_set):
361	                fi.write(unigram + "\n")
362	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyctcdecode-0.5.0/pyctcdecode-0.5.0/pyctcdecode/language_model.py:415
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
414	        with open(filenames["unigrams"], "r", encoding=unigram_encoding) as fi:
415	            unigrams = fi.read().splitlines()
416	

--------------------------------------------------

Code scanned:
	Total lines of code: 1311
	Total lines skipped (#nosec): 3

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 4.0
		High: 4.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 8.0
		High: 0.0
Files skipped (0):
