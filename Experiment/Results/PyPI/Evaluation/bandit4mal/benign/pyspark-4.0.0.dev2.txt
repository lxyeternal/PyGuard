Run started:2025-05-25 13:18:26.296902

Test results:
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/deps/examples/ml/dataframe_example.py:75
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
74	    newDF.printSchema()
75	    shutil.rmtree(tempdir)
76	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/deps/examples/mllib/naive_bayes_example.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
55	    output_dir = 'target/tmp/myNaiveBayesModel'
56	    shutil.rmtree(output_dir, ignore_errors=True)
57	    model.save(sc, output_dir)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/deps/examples/streaming/recoverable_network_wordcount.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
94	        with open(outputPath, 'a') as f:
95	            f.write(counts + "\n")
96	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/accumulators.py:321
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
320	        SocketServer.TCPServer.shutdown(self)
321	        self.server_close()
322	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/context.py:387
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
386	        if isinstance(
387	            threading.current_thread(), threading._MainThread  # type: ignore[attr-defined]
388	        ):

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/context.py:389
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
388	        ):
389	            signal.signal(signal.SIGINT, signal_handler)
390	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/context.py:389
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
388	        ):
389	            signal.signal(signal.SIGINT, signal_handler)
390	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/context.py:857
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
856	            serializer.dump_stream(data, chunked_out)
857	            chunked_out.close()
858	            # this call will block until the server has read all the data and processed it (or

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/context.py:870
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
869	                finally:
870	                    tempFile.close()
871	                return reader_func(tempFile.name)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/rdd.py:560
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
559	
560	        return checkpointFile.get() if checkpointFile.isDefined() else None
561	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/rdd.py:1575
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1574	                    s = str(obj).rstrip("\n") + "\n"
1575	                    out.write(s.encode("utf-8"))
1576	                out.close()

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/rdd.py:1576
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
1575	                    out.write(s.encode("utf-8"))
1576	                out.close()
1577	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/rdd.py:1578
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1577	
1578	            Thread(target=pipe_objs, args=[pipe.stdin]).start()
1579	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/rdd.py:3978
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
3977	    def _memory_limit(self) -> int:
3978	        return _parse_memory(self.ctx._conf.get("spark.python.worker.memory", "512m"))
3979	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/core/rdd.py:5334
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
5333	            self.ctx.profiler_collector
5334	            and self.ctx._conf.get("spark.python.profile", "false") == "true"
5335	        ):

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:54
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
53	    """
54	    signal.signal(SIGHUP, SIG_DFL)
55	    signal.signal(SIGCHLD, SIG_DFL)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:54
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
53	    """
54	    signal.signal(SIGHUP, SIG_DFL)
55	    signal.signal(SIGCHLD, SIG_DFL)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
54	    signal.signal(SIGHUP, SIG_DFL)
55	    signal.signal(SIGCHLD, SIG_DFL)
56	    signal.signal(SIGTERM, SIG_DFL)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:55
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
54	    signal.signal(SIGHUP, SIG_DFL)
55	    signal.signal(SIGCHLD, SIG_DFL)
56	    signal.signal(SIGTERM, SIG_DFL)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
55	    signal.signal(SIGCHLD, SIG_DFL)
56	    signal.signal(SIGTERM, SIG_DFL)
57	    # restore the handler for SIGINT,

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:56
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
55	    signal.signal(SIGCHLD, SIG_DFL)
56	    signal.signal(SIGTERM, SIG_DFL)
57	    # restore the handler for SIGINT,

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
58	    # it's useful for debugging (show the stacktrace before exit)
59	    signal.signal(SIGINT, signal.default_int_handler)
60	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:59
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
58	    # it's useful for debugging (show the stacktrace before exit)
59	    signal.signal(SIGINT, signal.default_int_handler)
60	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
75	            outfile.flush()
76	            sock.close()
77	            return 1

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:98
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
97	    if os.environ.get("SPARK_PREFER_IPV6", "false").lower() == "true":
98	        listen_sock = socket.socket(AF_INET6, SOCK_STREAM)
99	        listen_sock.bind(("::1", 0, 0, 0))

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:103
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
102	    else:
103	        listen_sock = socket.socket(AF_INET, SOCK_STREAM)
104	        listen_sock.bind(("127.0.0.1", 0))

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:104
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
103	        listen_sock = socket.socket(AF_INET, SOCK_STREAM)
104	        listen_sock.bind(("127.0.0.1", 0))
105	        listen_sock.listen(max(1024, SOMAXCONN))

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:115
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
114	    def shutdown(code):
115	        signal.signal(SIGTERM, SIG_DFL)
116	        # Send SIGHUP to notify workers of shutdown

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:115
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
114	    def shutdown(code):
115	        signal.signal(SIGTERM, SIG_DFL)
116	        # Send SIGHUP to notify workers of shutdown

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:123
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
122	
123	    signal.signal(SIGTERM, handle_sigterm)  # Gracefully exit on SIGTERM
124	    signal.signal(SIGHUP, SIG_IGN)  # Don't die on SIGHUP

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:123
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
122	
123	    signal.signal(SIGTERM, handle_sigterm)  # Gracefully exit on SIGTERM
124	    signal.signal(SIGHUP, SIG_IGN)  # Don't die on SIGHUP

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:124
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
123	    signal.signal(SIGTERM, handle_sigterm)  # Gracefully exit on SIGTERM
124	    signal.signal(SIGHUP, SIG_IGN)  # Don't die on SIGHUP
125	    signal.signal(SIGCHLD, SIG_IGN)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:124
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
123	    signal.signal(SIGTERM, handle_sigterm)  # Gracefully exit on SIGTERM
124	    signal.signal(SIGHUP, SIG_IGN)  # Don't die on SIGHUP
125	    signal.signal(SIGCHLD, SIG_IGN)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:125
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
124	    signal.signal(SIGHUP, SIG_IGN)  # Don't die on SIGHUP
125	    signal.signal(SIGCHLD, SIG_IGN)
126	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:125
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
124	    signal.signal(SIGHUP, SIG_IGN)  # Don't die on SIGHUP
125	    signal.signal(SIGCHLD, SIG_IGN)
126	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
169	                        outfile.flush()
170	                        outfile.close()
171	                        sock.close()

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:171
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
170	                        outfile.close()
171	                        sock.close()
172	                        continue

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:176
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
175	                    # in child process
176	                    listen_sock.close()
177	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
189	                    os.dup2(devnull.fileno(), 0)
190	                    devnull.close()
191	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:197
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
196	                        outfile.flush()
197	                        outfile.close()
198	                        authenticated = False

--------------------------------------------------
>> Issue: [B809:recv] socket.socket.recv
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:206
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b809_recv.html
205	                                try:
206	                                    while sock.recv(1024):
207	                                        pass

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/daemon.py:218
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
217	                else:
218	                    sock.close()
219	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/errors_doc_gen.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
22	    """
23	    header = """..  Licensed to the Apache Software Foundation (ASF) under one
24	    or more contributor license agreements.  See the NOTICE file
25	    distributed with this work for additional information
26	    regarding copyright ownership.  The ASF licenses this file
27	    to you under the Apache License, Version 2.0 (the
28	    "License"); you may not use this file except in compliance
29	    with the License.  You may obtain a copy of the License at
30	
31	..    http://www.apache.org/licenses/LICENSE-2.0
32	
33	..  Unless required by applicable law or agreed to in writing,
34	    software distributed under the License is distributed on an
35	    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
36	    KIND, either express or implied.  See the License for the
37	    specific language governing permissions and limitations
38	    under the License.
39	
40	========================
41	Error classes in PySpark
42	========================
43	
44	This is a list of common, named error classes returned by PySpark which are defined at `error-conditions.json <https://github.com/apache/spark/blob/master/python/pyspark/errors/error-conditions.json>`_.
45	
46	When writing PySpark errors, developers must use an error class from the list. If an appropriate error class is not available, add a new one into the list. For more information, please refer to `Contributing Error and Exception <contributing.rst#contributing-error-and-exception>`_.
47	"""  # noqa
48	    with open(output_rst_file_path, "w") as f:

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:146
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
145	            print("Downloading %s from:\n- %s" % (pretty_pkg_name, url))
146	            download_to_file(urllib.request.urlopen(url), package_local_path)
147	

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:146
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
145	            print("Downloading %s from:\n- %s" % (pretty_pkg_name, url))
146	            download_to_file(urllib.request.urlopen(url), package_local_path)
147	

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:149
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
148	            print("Installing to %s" % dest)
149	            tar = tarfile.open(package_local_path, "r:gz")
150	            for member in tar.getmembers():

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:160
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
159	            traceback.print_exc()
160	            rmtree(dest, ignore_errors=True)
161	        finally:

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:173
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
172	        try:
173	            response = urllib.request.urlopen(
174	                "https://www.apache.org/dyn/closer.lua?preferred=true"
175	            )

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:173
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
172	        try:
173	            response = urllib.request.urlopen(
174	                "https://www.apache.org/dyn/closer.lua?preferred=true"
175	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:174
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
173	            response = urllib.request.urlopen(
174	                "https://www.apache.org/dyn/closer.lua?preferred=true"
175	            )
176	            mirror_urls.append(response.read().decode("utf-8"))

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:176
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
175	            )
176	            mirror_urls.append(response.read().decode("utf-8"))
177	        except Exception:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:182
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
181	    default_sites = [
182	        "https://dlcdn.apache.org/",
183	        "https://archive.apache.org/dist",
184	        "https://dist.apache.org/repos/dist/release",
185	    ]
186	    return list(set(mirror_urls)) + [x for x in default_sites if x not in mirror_urls]

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:183
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
182	        "https://dlcdn.apache.org/",
183	        "https://archive.apache.org/dist",
184	        "https://dist.apache.org/repos/dist/release",
185	    ]
186	    return list(set(mirror_urls)) + [x for x in default_sites if x not in mirror_urls]
187	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:184
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
183	        "https://archive.apache.org/dist",
184	        "https://dist.apache.org/repos/dist/release",
185	    ]
186	    return list(set(mirror_urls)) + [x for x in default_sites if x not in mirror_urls]
187	
188	

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:193
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
192	
193	    with open(path, mode="wb") as dest:
194	        while True:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:195
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
194	        while True:
195	            chunk = response.read(chunk_size)
196	            bytes_so_far += len(chunk)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/install.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
198	                break
199	            dest.write(chunk)
200	            print(

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/java_gateway.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
65	        # proper classpath and settings from spark-env.sh
66	        on_windows = platform.system() == "Windows"
67	        script = "./bin/spark-submit.cmd" if on_windows else "./bin/spark-submit"

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/java_gateway.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
65	        # proper classpath and settings from spark-env.sh
66	        on_windows = platform.system() == "Windows"
67	        script = "./bin/spark-submit.cmd" if on_windows else "./bin/spark-submit"

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/java_gateway.py:66
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
65	        # proper classpath and settings from spark-env.sh
66	        on_windows = platform.system() == "Windows"
67	        script = "./bin/spark-submit.cmd" if on_windows else "./bin/spark-submit"

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/java_gateway.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
96	                def preexec_func():
97	                    signal.signal(signal.SIGINT, signal.SIG_IGN)
98	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/java_gateway.py:97
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
96	                def preexec_func():
97	                    signal.signal(signal.SIGINT, signal.SIG_IGN)
98	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/java_gateway.py:119
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
118	        finally:
119	            shutil.rmtree(conn_info_dir)
120	

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/classification.py:3585
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
3584	
3585	        pool = ThreadPool(processes=min(self.getParallelism(), numClasses))
3586	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/classification.py:4342
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
4341	        try:
4342	            rmtree(temp_path)
4343	        except OSError:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/clustering.py:2184
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
2183	        try:
2184	            rmtree(temp_path)
2185	        except OSError:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/connect/io_utils.py:145
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
144	                if os.path.isdir(path):
145	                    shutil.rmtree(path)
146	                else:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/connect/io_utils.py:249
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
248	        finally:
249	            shutil.rmtree(tmp_local_dir, ignore_errors=True)
250	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/connect/io_utils.py:268
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
267	                with open(os.path.join(tmp_local_dir, file_name), "wb") as f:
268	                    f.write(file_content)
269	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/connect/io_utils.py:268
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
267	                with open(os.path.join(tmp_local_dir, file_name), "wb") as f:
268	                    f.write(file_content)
269	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/connect/io_utils.py:272
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
271	        finally:
272	            shutil.rmtree(tmp_local_dir, ignore_errors=True)
273	

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/connect/tuning.py:424
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
423	
424	        pool = ThreadPool(processes=min(self.getParallelism(), numModels))
425	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/dl_util.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
125	            if prefix_code != "":
126	                f.write(prefix_code)
127	            f.write(code_snippet)

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/dl_util.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
125	            if prefix_code != "":
126	                f.write(prefix_code)
127	            f.write(code_snippet)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/dl_util.py:127
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
126	                f.write(prefix_code)
127	            f.write(code_snippet)
128	            if suffix_code != "":

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/dl_util.py:127
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
126	                f.write(prefix_code)
127	            f.write(code_snippet)
128	            if suffix_code != "":

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/dl_util.py:129
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
128	            if suffix_code != "":
129	                f.write(suffix_code)
130	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/dl_util.py:129
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
128	            if suffix_code != "":
129	                f.write(suffix_code)
130	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/evaluation.py:1161
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
1160	        try:
1161	            rmtree(temp_path)
1162	        except OSError:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/feature.py:7476
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
7475	        try:
7476	            rmtree(temp_path)
7477	        except OSError:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/fpm.py:539
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
538	        try:
539	            rmtree(temp_path)
540	        except OSError:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/param/_shared_params_code_gen.py:20
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
19	
20	header = """#
21	# Licensed to the Apache Software Foundation (ASF) under one or more
22	# contributor license agreements.  See the NOTICE file distributed with
23	# this work for additional information regarding copyright ownership.
24	# The ASF licenses this file to You under the Apache License, Version 2.0
25	# (the "License"); you may not use this file except in compliance with
26	# the License.  You may obtain a copy of the License at
27	#
28	#    http://www.apache.org/licenses/LICENSE-2.0
29	#
30	# Unless required by applicable law or agreed to in writing, software
31	# distributed under the License is distributed on an "AS IS" BASIS,
32	# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
33	# See the License for the specific language governing permissions and
34	# limitations under the License.
35	#"""
36	
37	# Code generator for shared params (shared.py). Run under this folder with:
38	# python _shared_params_code_gen.py > shared.py
39	
40	_type_for_type_converter = {

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/pipeline.py:420
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
419	        for index, stage in enumerate(stages):
420	            cast(MLWritable, stage).write().save(
421	                PipelineSharedReadWrite.getStagePath(stage.uid, index, len(stages), stagesDir)

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/recommendation.py:744
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
743	        try:
744	            rmtree(temp_path)
745	        except OSError:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/regression.py:3329
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
3328	        try:
3329	            rmtree(temp_path)
3330	        except OSError:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/distributor.py:494
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
493	                    else:
494	                        sys.stdout.write(decoded)
495	                if log_streaming_client:

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/distributor.py:494
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
493	                    else:
494	                        sys.stdout.write(decoded)
495	                if log_streaming_client:

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/distributor.py:666
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
665	
666	                        sock = socket.socket()
667	                        sock.bind((address, 0))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/distributor.py:878
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
877	            with open(schema_file_path, "w") as f:
878	                f.write(schema_json_string)
879	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/distributor.py:878
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
877	            with open(schema_file_path, "w") as f:
878	                f.write(schema_json_string)
879	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/distributor.py:925
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
924	    def _cleanup_files(save_dir: str) -> None:
925	        shutil.rmtree(save_dir, ignore_errors=True)
926	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
43	        while self.server.is_active:
44	            packed_number_bytes = self.rfile.read(4)
45	            if not packed_number_bytes:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
48	            number_bytes = unpack(">i", packed_number_bytes)[0]
49	            message = self.rfile.read(number_bytes)
50	            yield message

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
55	            with _get_log_print_lock():
56	                sys.stderr.write(bline.decode("utf-8") + "\n")
57	                sys.stderr.flush()

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:69
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
68	    def _get_free_port(spark_host_address: str = "") -> int:
69	        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as tcp:
70	            tcp.bind((spark_host_address, 0))

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:79
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
78	        def serve_task(port: int) -> None:
79	            with socketserver.ThreadingTCPServer(("0.0.0.0", port), WriteLogToStdout) as server:
80	                self.server = server

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
84	        self.port = LogStreamingServer._get_free_port(spark_host_address)
85	        self.serve_thread = threading.Thread(target=serve_task, args=(self.port,))
86	        self.serve_thread.daemon = True

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:136
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
135	        if LogStreamingClient._log_callback_client is not None:
136	            LogStreamingClient._log_callback_client.close()
137	

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:163
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
162	        try:
163	            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
164	            sock.settimeout(self.timeout)

--------------------------------------------------
>> Issue: [B808:settimeout] settimeout
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:164
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b808_settimeout.html
163	            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
164	            sock.settimeout(self.timeout)
165	            sock.connect((self.address, self.port))

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:165
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
164	            sock.settimeout(self.timeout)
165	            sock.connect((self.address, self.port))
166	            sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:178
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
177	            if self.sock is None:
178	                self._connect()
179	            if not self.failed:

--------------------------------------------------
>> Issue: [B806:sendall] socket.socket.sendall
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:188
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b806_sendall.html
187	                    packed_number_bytes = pack(">i", len(binary_message))
188	                    self.sock.sendall(packed_number_bytes + binary_message)
189	                except Exception:  # pylint: disable=broad-except

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/log_communication.py:197
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
196	        if self.sock:
197	            self.sock.close()
198	            self.sock = None

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/torch_run_process_wrapper.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
59	    )
60	    t = threading.Thread(target=check_parent_alive, args=(task,), daemon=True)
61	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/torch_run_process_wrapper.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
65	
66	    signal.signal(signal.SIGTERM, sigterm_handler)
67	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/torch/torch_run_process_wrapper.py:66
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
65	
66	    signal.signal(signal.SIGTERM, sigterm_handler)
67	

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/tuning.py:836
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
835	
836	        pool = ThreadPool(processes=min(self.getParallelism(), numModels))
837	        subModels = None

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/tuning.py:1469
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
1468	        )
1469	        pool = ThreadPool(processes=min(self.getParallelism(), numModels))
1470	        metrics = [None] * numModels

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/util.py:157
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
156	        if self.shouldOverwrite:
157	            self._handleOverwrite(path)
158	        self.saveImpl(path)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/util.py:209
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
208	        _java_obj = instance._to_java()  # type: ignore[attr-defined]
209	        self._jwrite = _java_obj.write()
210	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/util.py:219
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
218	        """Overwrites if the output path already exists."""
219	        self._jwrite.overwrite()
220	        return self

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/util.py:264
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
263	        """Save this ML instance to the given path, a shortcut of 'write().save(path)'."""
264	        self.write().save(path)
265	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/util.py:314
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
313	        self._clazz = clazz
314	        self._jread = self._load_java_obj(clazz).read()
315	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/ml/util.py:371
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
370	        """Reads an ML instance from the input path, a shortcut of `read().load(path)`."""
371	        return cls.read().load(path)
372	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/mllib/fpm.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
224	        try:
225	            rmtree(temp_path)
226	        except OSError:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/pandas/frame.py:13806
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
13805	
13806	    shutil.rmtree(path, ignore_errors=True)
13807	    spark.sql("DROP DATABASE IF EXISTS %s CASCADE" % db_name)

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/pandas/generic.py:3642
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
3641	
3642	    shutil.rmtree(path, ignore_errors=True)
3643	    spark.stop()

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/pandas/namespace.py:3844
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
3843	
3844	    shutil.rmtree(path, ignore_errors=True)
3845	    spark.sql("DROP DATABASE IF EXISTS %s CASCADE" % db_name)

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/pandas/spark/accessors.py:1266
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
1265	
1266	    shutil.rmtree(path, ignore_errors=True)
1267	    spark.sql("DROP DATABASE IF EXISTS %s CASCADE" % db_name)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/pandas/supported_api_gen.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	
43	RST_HEADER = """
44	=====================
45	Supported pandas API
46	=====================
47	
48	.. currentmodule:: pyspark.pandas
49	
50	The following table shows the pandas APIs that implemented or non-implemented from pandas API on
51	Spark. Some pandas API do not implement full parameters, so the third column shows missing
52	parameters for each API.
53	
54	* 'Y' in the second column means it's implemented including its whole parameter.
55	* 'N' means it's not implemented yet.
56	* 'P' means it's partially implemented with the missing of some parameters.
57	
58	All API in the list below computes the data with distributed execution except the ones that require
59	the local execution by design. For example, `DataFrame.to_numpy() <https://spark.apache.org/docs/
60	latest/api/python/reference/pyspark.pandas/api/pyspark.pandas.DataFrame.to_numpy.html>`__
61	requires to collect the data to the driver side.
62	
63	If there is non-implemented pandas API or parameter you want, you can create an `Apache Spark
64	JIRA <https://issues.apache.org/jira/projects/SPARK/summary>`__ to request or to contribute by
65	your own.
66	
67	The API list is updated based on the `latest pandas official API reference
68	<https://pandas.pydata.org/docs/reference/index.html#>`__.
69	
70	"""
71	
72	
73	@unique
74	class Implemented(Enum):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/pandas/supported_api_gen.py:318
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
317	            + "`%s.%s " % (pd_module_path, module_dot_func)
318	            + "<https://pandas.pydata.org/docs/reference/api/"
319	            + "%s.%s.html>`__ and " % (pd_module_path, module_dot_func)
320	            + "`%s.%s " % (ps_module_path, module_dot_func)
321	            + "<https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/api/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/pandas/supported_api_gen.py:321
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
320	            + "`%s.%s " % (ps_module_path, module_dot_func)
321	            + "<https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/api/"
322	            + "%s.%s.html>`__ for detail." % (ps_module_path, module_dot_func)
323	        )
324	        missing_str += additional_str
325	    return missing_str
326	
327	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/pandas/supported_api_gen.py:418
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
417	    with open(output_rst_file_path, "w") as w_fd:
418	        w_fd.write(RST_HEADER)
419	        for module_info, supported_status in all_supported_status.items():

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/pandas/supported_api_gen.py:423
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
422	                _write_table(module, module_path, supported_status, w_fd)
423	                w_fd.write("\n")
424	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/profiler.py:471
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
470	
471	            stream.write("Filename: " + filename + "\n\n")
472	            stream.write(header + "\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/profiler.py:472
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
471	            stream.write("Filename: " + filename + "\n\n")
472	            stream.write(header + "\n")
473	            stream.write("=" * len(header) + "\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/profiler.py:473
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
472	            stream.write(header + "\n")
473	            stream.write("=" * len(header) + "\n")
474	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/profiler.py:498
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
497	                tmp = template.format(lineno, total_mem, inc, occurrences, all_lines[lineno - 1])
498	                stream.write(tmp)
499	            stream.write("\n\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/profiler.py:499
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
498	                stream.write(tmp)
499	            stream.write("\n\n")
500	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/python/pyspark/shell.py:141
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
140	    with open(_pythonstartup) as f:
141	        code = compile(f.read(), _pythonstartup, "exec")
142	        exec(code)

--------------------------------------------------
>> Issue: [B800:exec_used] exec
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/python/pyspark/shell.py:142
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b800_exec_used.html
141	        code = compile(f.read(), _pythonstartup, "exec")
142	        exec(code)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:162
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
161	        write_int(len(serialized), stream)
162	        stream.write(serialized)
163	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
169	            return None
170	        obj = stream.read(length)
171	        if len(obj) < length:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:279
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
278	            write_int(len(bytes), stream)
279	            stream.write(bytes)
280	

--------------------------------------------------
>> Issue: [B816:decompress] zlib.decompress
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:542
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b816_decompress.html
541	    def loads(self, obj):
542	        return self.serializer.loads(zlib.decompress(obj))
543	

--------------------------------------------------
>> Issue: [B306:blacklist] zlib.decompress
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:542
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b306-zlib-decompress
541	    def loads(self, obj):
542	        return self.serializer.loads(zlib.decompress(obj))
543	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:563
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
562	            return None
563	        s = stream.read(length)
564	        return s.decode("utf-8") if self.use_unicode else s

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:580
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
579	def read_long(stream):
580	    length = stream.read(8)
581	    if not length:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:587
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
586	def write_long(value, stream):
587	    stream.write(struct.pack("!q", value))
588	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:595
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
594	def read_int(stream):
595	    length = stream.read(4)
596	    if not length:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:602
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
601	def write_int(value, stream):
602	    stream.write(struct.pack("!i", value))
603	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:606
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
605	def read_bool(stream):
606	    length = stream.read(1)
607	    if not length:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:614
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
613	    write_int(len(obj), stream)
614	    stream.write(obj)
615	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:653
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
652	                write_int(self.buffer_size, self.wrapped)
653	                self.wrapped.write(self.buffer)
654	                byte_remaining -= space_left

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/serializers.py:662
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
661	            write_int(self.current_pos, self.wrapped)
662	            self.wrapped.write(self.buffer[: self.current_pos])
663	        # -1 length indicates to the receiving end that we're done.

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shell.py:141
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
140	    with open(_pythonstartup) as f:
141	        code = compile(f.read(), _pythonstartup, "exec")
142	        exec(code)

--------------------------------------------------
>> Issue: [B800:exec_used] exec
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shell.py:142
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b800_exec_used.html
141	        code = compile(f.read(), _pythonstartup, "exec")
142	        exec(code)

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shuffle.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
58	        """Return the used memory in MiB"""
59	        if platform.system() == "Linux":
60	            for line in open("/proc/self/status"):

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shuffle.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
58	        """Return the used memory in MiB"""
59	        if platform.system() == "Linux":
60	            for line in open("/proc/self/status"):

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shuffle.py:59
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
58	        """Return the used memory in MiB"""
59	        if platform.system() == "Linux":
60	            for line in open("/proc/self/status"):

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shuffle.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
65	            warnings.warn("Please install psutil to have better " "support with spilling")
66	            if platform.system() == "Darwin":
67	                import resource

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shuffle.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
65	            warnings.warn("Please install psutil to have better " "support with spilling")
66	            if platform.system() == "Darwin":
67	                import resource

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shuffle.py:66
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
65	            warnings.warn("Please install psutil to have better " "support with spilling")
66	            if platform.system() == "Darwin":
67	                import resource

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shuffle.py:440
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
439	        for d in self.localdirs:
440	            shutil.rmtree(d, True)
441	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shuffle.py:571
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
570	                f.seek(0)
571	                serialized = f.read()
572	        else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/shuffle.py:580
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
579	            self._open_file()
580	            self._file.write(serialized)
581	        else:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/connect/client/artifact.py:363
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
362	            with artifact.storage.stream() as stream:
363	                binary = stream.read()
364	            crc32 = zlib.crc32(binary)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/connect/client/artifact.py:390
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
389	        with artifact.storage.stream() as stream:
390	            for chunk in iter(lambda: stream.read(ArtifactManager.CHUNK_SIZE), b""):
391	                if initial_batch:

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/connect/client/reattach.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
70	            if cls._release_thread_pool_instance is None:
71	                cls._release_thread_pool_instance = ThreadPool(
72	                    os.cpu_count() if os.cpu_count() else 8
73	                )

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/streaming/stateful_processor_api_client.py:41
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
40	        self.key_schema = key_schema
41	        self._client_socket = socket.socket()
42	        self._client_socket.connect(("localhost", state_server_port))

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/streaming/stateful_processor_api_client.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
41	        self._client_socket = socket.socket()
42	        self._client_socket.connect(("localhost", state_server_port))
43	        self.sockfile = self._client_socket.makefile(

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/streaming/stateful_processor_api_client.py:132
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
131	        write_int(len(message), self.sockfile)
132	        self.sockfile.write(message)
133	        self.sockfile.flush()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/streaming/stateful_processor_api_client.py:139
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
138	        length = read_int(self.sockfile)
139	        bytes = self.sockfile.read(length)
140	        message = stateMessage.StateResponse()

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/types.py:1679
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
1678	                "pyClass": "%s.%s" % (self.module(), type(self).__name__),
1679	                "serializedClass": base64.b64encode(b).decode("utf8"),
1680	                "sqlType": self.sqlType().jsonValue(),

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/types.py:1679
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
1678	                "pyClass": "%s.%s" % (self.module(), type(self).__name__),
1679	                "serializedClass": base64.b64encode(b).decode("utf8"),
1680	                "sqlType": self.sqlType().jsonValue(),

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/types.py:1692
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
1691	        if not hasattr(m, pyClass):
1692	            s = base64.b64decode(json["serializedClass"].encode("utf-8"))
1693	            UDT = CloudPickleSerializer().loads(s)

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/types.py:1692
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
1691	        if not hasattr(m, pyClass):
1692	            s = base64.b64decode(json["serializedClass"].encode("utf-8"))
1693	            UDT = CloudPickleSerializer().loads(s)

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/variant_utils.py:608
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
607	                # decoding simply converts byte array to string
608	                return '"' + base64.b64encode(value).decode("utf-8") + '"'
609	            if type(value) == datetime.date or type(value) == datetime.datetime:

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/variant_utils.py:608
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
607	                # decoding simply converts byte array to string
608	                return '"' + base64.b64encode(value).decode("utf-8") + '"'
609	            if type(value) == datetime.date or type(value) == datetime.datetime:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/worker/plan_data_source_read.py:297
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
296	
297	            output_iter = reader.read(partition)  # type: ignore[arg-type]
298	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/sql/worker/write_into_data_source.py:197
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
196	
197	            res = writer.write(batch_to_rows())
198	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/testing/connectutils.py:208
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
207	    def tearDownClass(cls):
208	        shutil.rmtree(cls.tempdir.name, ignore_errors=True)
209	        cls.spark.stop()

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/testing/pandasutils.py:509
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
508	        finally:
509	            shutil.rmtree(tmp)
510	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/testing/sqlutils.py:295
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
294	        cls.spark.stop()
295	        shutil.rmtree(cls.tempdir.name, ignore_errors=True)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/testing/utils.py:239
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
238	        script = "$(test $(tput colors)) && $(test $(tput colors) -ge 8) && echo true || echo false"
239	        return os.popen(script).read()
240	    except Exception:

--------------------------------------------------
>> Issue: [B813:popen] os.popen
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/testing/utils.py:239
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b813_popen.html
238	        script = "$(test $(tput colors)) && $(test $(tput colors) -ge 8) && echo true || echo false"
239	        return os.popen(script).read()
240	    except Exception:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/util.py:294
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
293	    print(
294	        """
295	________________________________________________________________________________________________
296	
297	  Spark %(lib_name)s libraries not found in class path. Try one of the following.
298	
299	  1. Include the %(lib_name)s library and its dependencies with in the
300	     spark-submit command as
301	
302	     $ bin/spark-submit --packages org.apache.spark:spark-%(pkg_name)s:%(spark_version)s ...
303	
304	  2. Download the JAR of the artifact from Maven Central http://search.maven.org/,
305	     Group Id = org.apache.spark, Artifact Id = spark-%(jar_name)s, Version = %(spark_version)s.
306	     Then, include the jar in the spark-submit command as
307	
308	     $ bin/spark-submit --jars <spark-%(jar_name)s.jar> ...
309	
310	________________________________________________________________________________________________
311	
312	"""
313	        % {
314	            "lib_name": lib_name,
315	            "pkg_name": pkg_name,
316	            "jar_name": jar_name,
317	            "spark_version": spark_version,
318	        }

--------------------------------------------------
>> Issue: [B808:settimeout] settimeout
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/util.py:611
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b808_settimeout.html
610	    # operation, it will very possibly fail. See SPARK-18281.
611	    sock.settimeout(None)
612	    return sockfile

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/util.py:703
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
702	    # Support for both IPv4 and IPv6.
703	    addr = "127.0.0.1"
704	    if os.environ.get("SPARK_PREFER_IPV6", "false").lower() == "true":

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/util.py:709
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
708	        try:
709	            sock = socket.socket(af, socktype, proto)
710	            sock.settimeout(int(os.environ.get("SPARK_AUTH_SOCKET_TIMEOUT", 15)))

--------------------------------------------------
>> Issue: [B808:settimeout] settimeout
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/util.py:710
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b808_settimeout.html
709	            sock = socket.socket(af, socktype, proto)
710	            sock.settimeout(int(os.environ.get("SPARK_AUTH_SOCKET_TIMEOUT", 15)))
711	            sock.connect(sa)

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/util.py:711
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
710	            sock.settimeout(int(os.environ.get("SPARK_AUTH_SOCKET_TIMEOUT", 15)))
711	            sock.connect(sa)
712	            sockfile = sock.makefile("rwb", int(os.environ.get("SPARK_BUFFER_SIZE", 65536)))

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/util.py:719
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
718	            if sock is not None:
719	                sock.close()
720	                sock = None

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/util.py:738
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
737	    if reply != "ok":
738	        conn.close()
739	        raise PySparkRuntimeError(

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/pyspark/worker_util.py:179
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
178	    if needs_broadcast_decryption_server:
179	        broadcast_sock_file.write(b"1")
180	        broadcast_sock_file.close()

--------------------------------------------------
>> Issue: [B800:exec_used] exec
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b800_exec_used.html
47	try:
48	    exec(open("pyspark/version.py").read())
49	except IOError:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
47	try:
48	    exec(open("pyspark/version.py").read())
49	except IOError:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:168
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
167	        spark_dist = os.path.join(self.install_lib, "pyspark", "spark-distribution")
168	        rmtree(spark_dist, ignore_errors=True)
169	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:252
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
251	    with open("README.md") as f:
252	        long_description = f.read()
253	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:262
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
261	        author_email="dev@spark.apache.org",
262	        url="https://github.com/apache/spark/tree/master/python",
263	        packages=[

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:342
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
341	        scripts=scripts,
342	        license="http://www.apache.org/licenses/LICENSE-2.0",
343	        # Don't forget to update python/docs/source/getting_started/install.rst
344	        # if you're updating the versions or dependencies.
345	        install_requires=["py4j==0.10.9.7"],

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:399
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
398	        else:
399	            rmtree(os.path.join(TEMP_PATH, "jars"))
400	            rmtree(os.path.join(TEMP_PATH, "bin"))

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:400
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
399	            rmtree(os.path.join(TEMP_PATH, "jars"))
400	            rmtree(os.path.join(TEMP_PATH, "bin"))
401	            rmtree(os.path.join(TEMP_PATH, "sbin"))

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:401
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
400	            rmtree(os.path.join(TEMP_PATH, "bin"))
401	            rmtree(os.path.join(TEMP_PATH, "sbin"))
402	            rmtree(os.path.join(TEMP_PATH, "examples"))

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:402
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
401	            rmtree(os.path.join(TEMP_PATH, "sbin"))
402	            rmtree(os.path.join(TEMP_PATH, "examples"))
403	            rmtree(os.path.join(TEMP_PATH, "data"))

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:403
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
402	            rmtree(os.path.join(TEMP_PATH, "examples"))
403	            rmtree(os.path.join(TEMP_PATH, "data"))
404	            rmtree(os.path.join(TEMP_PATH, "licenses"))

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:404
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
403	            rmtree(os.path.join(TEMP_PATH, "data"))
404	            rmtree(os.path.join(TEMP_PATH, "licenses"))
405	        os.rmdir(TEMP_PATH)

--------------------------------------------------
>> Issue: [B837:rmdir] pathlib.Path.rmdir
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/pyspark-4.0.0.dev2/pyspark-4.0.0.dev2/setup.py:405
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b837_rmdir.html
404	            rmtree(os.path.join(TEMP_PATH, "licenses"))
405	        os.rmdir(TEMP_PATH)

--------------------------------------------------

Code scanned:
	Total lines of code: 183473
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 43.0
		High: 156.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 171.0
		High: 28.0
Files skipped (0):
