Run started:2025-05-25 12:35:17.668080

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/datasets/pascal_voc/segmentation.py:52
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
51	
52	VOC_URL = "https://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar"  # noqa: E501
53	
54	"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/datasets/pascal_voc/segmentation.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
60	"""  # noqa: E501
61	SBD_URL = "https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz"  # noqa: E501
62	
63	
64	# Note that this list doesn't contain the background class. In the
65	# classification use case, the label is 0 based (aeroplane -> 0), whereas in
66	# segmentation use case, the 0 is reserved for background, so aeroplane maps to
67	# 1.
68	CLASSES = [

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/datasets/pascal_voc/segmentation.py:170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
169	    logging.info("Extract data into %s", data_directory)
170	    with tarfile.open(data_file_path) as f:
171	        f.extractall(data_directory)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/datasets/pascal_voc/segmentation.py:229
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
228	    ) as f:
229	        image_ids = f.read().splitlines()
230	        logging.info(f"Received {len(image_ids)} images for {split} dataset.")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/datasets/pascal_voc/segmentation.py:240
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
239	    ) as f:
240	        image_ids = f.read().splitlines()
241	        logging.info(f"Received {len(image_ids)} images for {split} dataset.")

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/datasets/pascal_voc/segmentation.py:298
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
297	    pool_size = 10 if len(image_ids) > 10 else len(image_ids)
298	    with multiprocessing.Pool(pool_size) as p:
299	        metadata = p.map(_parse_single_image, image_file_paths)

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/datasets/pascal_voc/segmentation.py:298
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
297	    pool_size = 10 if len(image_ids) > 10 else len(image_ids)
298	    with multiprocessing.Pool(pool_size) as p:
299	        metadata = p.map(_parse_single_image, image_file_paths)

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/datasets/pascal_voc/segmentation.py:332
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
331	    pool_size = 10 if len(image_ids) > 10 else len(image_ids)
332	    with multiprocessing.Pool(pool_size) as p:
333	        metadata = p.map(_parse_single_sbd_image, image_file_paths)

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/datasets/pascal_voc/segmentation.py:332
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
331	    pool_size = 10 if len(image_ids) > 10 else len(image_ids)
332	    with multiprocessing.Pool(pool_size) as p:
333	        metadata = p.map(_parse_single_sbd_image, image_file_paths)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/csp_darknet/csp_darknet_aliases.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	ALIAS_DOCSTRING = """CSPDarkNetBackbone model with {stackwise_channels} channels
27	    and {stackwise_depth} depths.
28	
29	    Reference:
30	        - [YoloV4 Paper](https://arxiv.org/abs/1804.02767)
31	        - [CSPNet Paper](https://arxiv.org/pdf/1911.11929)
32	        - [YoloX Paper](https://arxiv.org/abs/2107.08430)
33	
34	    For transfer learning use cases, make sure to read the
35	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
36	
37	    Args:
38	        include_rescaling: bool, whether or not to rescale the inputs. If set to
39	            True, inputs will be passed through a `Rescaling(1/255.0)` layer.
40	        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
41	            to use as image input for the model.
42	        input_shape: optional shape tuple, defaults to (None, None, 3).
43	
44	    Example:
45	    ```python
46	    input_data = tf.ones(shape=(8, 224, 224, 3))
47	
48	    # Randomly initialized backbone
49	    model = CSPDarkNet{name}Backbone()
50	    output = model(input_data)
51	    ```
52	"""  # noqa: E501
53	
54	
55	@keras_cv_export("keras_cv.models.CSPDarkNetTinyBackbone")
56	class CSPDarkNetTinyBackbone(CSPDarkNetBackbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/densenet/densenet_aliases.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	ALIAS_DOCSTRING = """DenseNetBackbone model with {num_layers} layers.
27	
28	    Reference:
29	        - [Densely Connected Convolutional Networks (CVPR 2017)](https://arxiv.org/abs/1608.06993)
30	
31	    For transfer learning use cases, make sure to read the
32	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
33	
34	    Args:
35	        include_rescaling: bool, whether to rescale the inputs. If set
36	            to `True`, inputs will be passed through a `Rescaling(1/255.0)`
37	            layer.
38	        input_shape: optional shape tuple, defaults to (None, None, 3).
39	        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
40	            to use as image input for the model.
41	
42	    Example:
43	    ```python
44	    input_data = tf.ones(shape=(8, 224, 224, 3))
45	
46	    # Randomly initialized backbone
47	    model = DenseNet{num_layers}Backbone()
48	    output = model(input_data)
49	    ```
50	"""  # noqa: E501
51	
52	
53	@keras_cv_export("keras_cv.models.DenseNet121Backbone")
54	class DenseNet121Backbone(DenseNetBackbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/efficientnet_lite/efficientnet_lite_aliases.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
20	
21	ALIAS_DOCSTRING = """Instantiates the {name} architecture.
22	
23	    Reference:
24	    - [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)
25	      (ICML 2019)
26	
27	    Args:
28	        include_rescaling: bool, whether to rescale the inputs. If set
29	            to `True`, inputs will be passed through a `Rescaling(1/255.0)`
30	            layer.
31	        input_shape: optional shape tuple, defaults to (None, None, 3).
32	        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
33	            to use as image input for the model.
34	    Example:
35	    ```python
36	    input_data = np.ones(shape=(8, 224, 224, 3))
37	
38	    # Randomly initialized backbone
39	    model = {name}Backbone()
40	    output = model(input_data)
41	    ```
42	"""  # noqa: E501
43	
44	
45	@keras_cv_export("keras_cv.models.EfficientNetLiteB0Backbone")
46	class EfficientNetLiteB0Backbone(EfficientNetLiteBackbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/efficientnet_v1/efficientnet_v1_aliases.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
20	
21	ALIAS_DOCSTRING = """Instantiates the {name} architecture.
22	
23	    Reference:
24	    - [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)
25	      (ICML 2019)
26	
27	    Args:
28	        include_rescaling: bool, whether to rescale the inputs. If set
29	            to `True`, inputs will be passed through a `Rescaling(1/255.0)`
30	            layer.
31	        input_shape: optional shape tuple, defaults to (None, None, 3).
32	        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
33	            to use as image input for the model.
34	"""  # noqa: E501
35	
36	
37	@keras_cv_export("keras_cv.models.EfficientNetV1B0Backbone")
38	class EfficientNetV1B0Backbone(EfficientNetV1Backbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/efficientnet_v2/efficientnet_v2_aliases.py:25
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
24	
25	ALIAS_DOCSTRING = """Instantiates the {name} architecture.
26	
27	    Reference:
28	    - [EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/abs/2104.00298)
29	      (ICML 2021)
30	
31	    Args:
32	        include_rescaling: bool, whether to rescale the inputs. If set
33	            to `True`, inputs will be passed through a `Rescaling(1/255.0)`
34	            layer.
35	        input_shape: optional shape tuple, defaults to (None, None, 3).
36	        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
37	            to use as image input for the model.
38	"""  # noqa: E501
39	
40	
41	@keras_cv_export("keras_cv.models.EfficientNetV2SBackbone")
42	class EfficientNetV2SBackbone(EfficientNetV2Backbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/mix_transformer/mix_transformer_aliases.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	ALIAS_DOCSTRING = """MiT model.
27	
28	    For transfer learning use cases, make sure to read the
29	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
30	
31	    Args:
32	        include_rescaling: bool, whether to rescale the inputs. If set to
33	            True, inputs will be passed through a `Rescaling(scale=1 / 255)`
34	            layer. Defaults to True.
35	        input_shape: optional shape tuple, defaults to (None, None, 3).
36	        input_tensor: optional Keras tensor (i.e., output of `layers.Input()`)
37	            to use as image input for the model.
38	
39	    Example:
40	    ```python
41	    input_data = tf.ones(shape=(8, 224, 224, 3))
42	
43	    # Randomly initialized backbone
44	    model = {name}Backbone()
45	    output = model(input_data)
46	    ```
47	"""  # noqa: E501
48	
49	
50	@keras_cv_export("keras_cv.models.MiTB0Backbone")
51	class MiTB0Backbone(MiTBackbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/mobilenet_v3/mobilenet_v3_aliases.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	ALIAS_DOCSTRING = """MobileNetV3Backbone model with {num_layers} layers.
27	
28	    References:
29	        - [Searching for MobileNetV3](https://arxiv.org/abs/1905.02244)
30	        - [Based on the Original keras.applications MobileNetv3](https://github.com/keras-team/keras/blob/master/keras/applications/mobilenet_v3.py)
31	
32	    For transfer learning use cases, make sure to read the
33	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
34	
35	    Args:
36	        include_rescaling: bool, whether to rescale the inputs. If set to
37	            True, inputs will be passed through a `Rescaling(scale=1 / 255)`
38	            layer. Defaults to True.
39	        input_shape: optional shape tuple, defaults to (None, None, 3).
40	        input_tensor: optional Keras tensor (i.e., output of `layers.Input()`)
41	            to use as image input for the model.
42	
43	    Example:
44	    ```python
45	    input_data = tf.ones(shape=(8, 224, 224, 3))
46	
47	    # Randomly initialized backbone
48	    model = {name}Backbone()
49	    output = model(input_data)
50	    ```
51	"""  # noqa: E501
52	
53	
54	@keras_cv_export("keras_cv.models.MobileNetV3SmallBackbone")
55	class MobileNetV3SmallBackbone(MobileNetV3Backbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/resnet_v1/resnet_v1_aliases.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	ALIAS_DOCSTRING = """ResNetBackbone (V1) model with {num_layers} layers.
27	
28	    Reference:
29	        - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
30	
31	    The difference in ResNetV1 and ResNetV2 rests in the structure of their
32	    individual building blocks. In ResNetV2, the batch normalization and
33	    ReLU activation precede the convolution layers, as opposed to ResNetV1 where
34	    the batch normalization and ReLU activation are applied after the
35	    convolution layers.
36	
37	    For transfer learning use cases, make sure to read the
38	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
39	
40	    Args:
41	        include_rescaling: bool, whether to rescale the inputs. If set
42	            to `True`, inputs will be passed through a `Rescaling(1/255.0)`
43	            layer.
44	        input_shape: optional shape tuple, defaults to (None, None, 3).
45	        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
46	            to use as image input for the model.
47	
48	    Example:
49	    ```python
50	    input_data = tf.ones(shape=(8, 224, 224, 3))
51	
52	    # Randomly initialized backbone
53	    model = ResNet{num_layers}Backbone()
54	    output = model(input_data)
55	    ```
56	"""  # noqa: E501
57	
58	
59	@keras_cv_export("keras_cv.models.ResNet18Backbone")
60	class ResNet18Backbone(ResNetBackbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/resnet_v2/resnet_v2_aliases.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	ALIAS_DOCSTRING = """ResNetV2Backbone model with {num_layers} layers.
27	
28	    Reference:
29	        - [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027) (ECCV 2016)
30	
31	    The difference in ResNet and ResNetV2 rests in the structure of their
32	    individual building blocks. In ResNetV2, the batch normalization and
33	    ReLU activation precede the convolution layers, as opposed to ResNetV1 where
34	    the batch normalization and ReLU activation are applied after the
35	    convolution layers.
36	
37	    For transfer learning use cases, make sure to read the
38	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
39	
40	    Args:
41	        include_rescaling: bool, whether to rescale the inputs. If set
42	            to `True`, inputs will be passed through a `Rescaling(1/255.0)`
43	            layer.
44	        input_shape: optional shape tuple, defaults to (None, None, 3).
45	        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
46	            to use as image input for the model.
47	
48	    Example:
49	    ```python
50	    input_data = tf.ones(shape=(8, 224, 224, 3))
51	
52	    # Randomly initialized backbone
53	    model = ResNet{num_layers}V2Backbone()
54	    output = model(input_data)
55	    ```
56	"""  # noqa: E501
57	
58	
59	@keras_cv_export("keras_cv.models.ResNet18V2Backbone")
60	class ResNet18V2Backbone(ResNetV2Backbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/video_swin/video_swin_aliases.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	ALIAS_DOCSTRING = """VideoSwin{size}Backbone model.
27	
28	    Reference:
29	        - [Video Swin Transformer](https://arxiv.org/abs/2106.13230)
30	        - [Video Swin Transformer GitHub](https://github.com/SwinTransformer/Video-Swin-Transformer)
31	
32	    For transfer learning use cases, make sure to read the
33	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
34	
35	    Examples:
36	    ```python
37	    input_data = np.ones(shape=(1, 32, 224, 224, 3))
38	
39	    # Randomly initialized backbone
40	    model = VideoSwin{size}Backbone()
41	    output = model(input_data)
42	    ```
43	"""  # noqa: E501
44	
45	
46	@keras_cv_export("keras_cv.models.VideoSwinTBackbone")
47	class VideoSwinTBackbone(VideoSwinBackbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/backbones/vit_det/vit_det_aliases.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	ALIAS_DOCSTRING = """VitDet{size}Backbone model.
27	
28	    Reference:
29	        - [Detectron2](https://github.com/facebookresearch/detectron2)
30	        - [Segment Anything paper](https://arxiv.org/abs/2304.02643)
31	        - [Segment Anything GitHub](https://github.com/facebookresearch/segment-anything)
32	
33	    For transfer learning use cases, make sure to read the
34	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
35	
36	    Example:
37	    ```python
38	    input_data = np.ones(shape=(1, 1024, 1024, 3))
39	
40	    # Randomly initialized backbone
41	    model = VitDet{size}Backbone()
42	    output = model(input_data)
43	    ```
44	"""  # noqa: E501
45	
46	
47	@keras_cv_export("keras_cv.models.ViTDetBBackbone")
48	class ViTDetBBackbone(ViTDetBackbone):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/legacy/convmixer.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
61	
62	BASE_DOCSTRING = """Instantiates the {name} architecture.
63	
64	    Reference:
65	        - [Patches Are All You Need?](https://arxiv.org/abs/2201.09792)
66	
67	    This class represents a Keras {name} model.
68	
69	    For transfer learning use cases, make sure to read the [guide to transfer
70	        learning & fine-tuning](https://keras.io/guides/transfer_learning/).
71	
72	    Args:
73	        include_rescaling: bool, whether to rescale the inputs. If set to
74	            True, inputs will be passed through a `Rescaling(1/255.0)` layer.
75	        include_top: bool, whether to include the fully-connected layer at the
76	            top of the network. If provided, num_classes must be provided.
77	        num_classes: integer, optional number of classes to classify images
78	            into. Only to be specified if `include_top` is True.
79	        weights: one of `None` (random initialization), a pretrained weight file
80	            path, or a reference to pre-trained weights (e.g.
81	            'imagenet/classification')(see available pre-trained weights in
82	            weights.py)
83	        input_shape: optional shape tuple, defaults to (None, None, 3).
84	        input_tensor: optional Keras tensor (i.e., output of `layers.Input()`)
85	            to use as image input for the model.
86	        pooling: optional pooling mode for feature extraction
87	            when `include_top` is `False`.
88	            - `None` means that the output of the model will be the 4D tensor
89	                output of the last convolutional block.
90	            - `avg` means that global average pooling will be applied to the
91	                output of the last convolutional block, and thus the output of
92	                the model will be a 2D tensor.
93	            - `max` means that global max pooling will be applied.
94	        name: string, optional name to pass to the model, defaults to "{name}".
95	
96	    Returns:
97	      A `keras.Model` instance.
98	"""
99	
100	
101	def apply_conv_mixer_layer(x, dim, kernel_size):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/legacy/convnext.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	BASE_DOCSTRING = """Instantiates the {name} architecture.
58	    - [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545) (CVPR 2022)
59	
60	    This function returns a Keras {name} model.
61	    Args:
62	        include_rescaling: bool, whether to rescale the inputs. If set
63	            to `True`, inputs will be passed through a `Rescaling(1/255.0)`
64	            layer.
65	        include_top: bool, whether to include the fully-connected layer at the
66	            top of the network. If provided, `num_classes` must be provided.
67	        depths: an iterable containing depths for each individual stages.
68	        projection_dims: An iterable containing output number of channels of
69	            each individual stages.
70	        drop_path_rate: stochastic depth probability, if 0.0, then stochastic
71	            depth won't be used.
72	        layer_scale_init_value: layer scale coefficient, if 0.0, layer scaling
73	            won't be used.
74	        weights: one of `None` (random initialization), a pretrained weight file
75	            path, or a reference to pre-trained weights (e.g.
76	            'imagenet/classification')(see available pre-trained weights in
77	            weights.py)
78	        input_shape: optional shape tuple, defaults to (None, None, 3).
79	        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
80	            to use as image input for the model.
81	        pooling: optional pooling mode for feature extraction
82	            when `include_top` is `False`.
83	            - `None` means that the output of the model will be the 4D tensor
84	                output of the last convolutional block.
85	            - `avg` means that global average pooling will be applied to the
86	                output of the last convolutional block, and thus the output of
87	                the model will be a 2D tensor.
88	            - `max` means that global max pooling will be applied.
89	        num_classes: optional int, number of classes to classify images into
90	            (only to be specified if `include_top` is `True`).
91	        classifier_activation: A `str` or callable. The activation function to
92	            use on the "top" layer. Ignored unless `include_top=True`. Set
93	            `classifier_activation=None` to return the logits of the "top"
94	            layer.
95	        name: (Optional) name to pass to the model, defaults to "{name}".
96	
97	    Returns:
98	      A `keras.Model` instance.
99	"""
100	
101	
102	@keras.utils.register_keras_serializable(package="keras_cv")
103	class LayerScale(layers.Layer):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/legacy/darknet.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	
37	BASE_DOCSTRING = """Represents the {name} architecture.
38	
39	    Although the {name} architecture is commonly used for detection tasks, it is
40	    possible to extract the intermediate dark2 to dark5 layers from the model
41	    for creating a feature pyramid Network.
42	
43	    Reference:
44	        - [YoloV3 Paper](https://arxiv.org/abs/1804.02767)
45	        - [YoloV3 implementation](https://github.com/ultralytics/yolov3)
46	
47	    For transfer learning use cases, make sure to read the
48	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
49	
50	    Args:
51	        include_rescaling: bool, whether to rescale the inputs. If set to
52	            True, inputs will be passed through a `Rescaling(1/255.0)` layer.
53	        include_top: bool, whether to include the fully-connected layer at the
54	            top of the network. If provided, `num_classes` must be provided.
55	        num_classes: integer, optional number of classes to classify images
56	            into. Only to be specified if `include_top` is True.
57	        weights: one of `None` (random initialization), or a pretrained weight
58	            file path.
59	        input_shape: optional shape tuple, defaults to (None, None, 3).
60	        input_tensor: optional Keras tensor (i.e., output of `layers.Input()`)
61	            to use as image input for the model.
62	        pooling: optional pooling mode for feature extraction when `include_top`
63	            is `False`.
64	            - `None` means that the output of the model will be the 4D tensor
65	                output of the last convolutional block.
66	            - `avg` means that global average pooling will be applied to the
67	                output of the last convolutional block, and thus the output of
68	                the model will be a 2D tensor.
69	            - `max` means that global max pooling will be applied.
70	        name: string, optional name to pass to the model, defaults to "{name}".
71	
72	    Returns:
73	        A `keras.Model` instance.
74	"""  # noqa: E501
75	
76	
77	@keras.utils.register_keras_serializable(package="keras_cv.models")
78	class DarkNet(keras.Model):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/legacy/mlp_mixer.py:52
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
51	
52	BASE_DOCSTRING = """Instantiates the {name} architecture.
53	
54	    Reference:
55	        - [MLP-Mixer: An all-MLP Architecture for Vision](https://arxiv.org/abs/2105.01601)
56	
57	    This class represents a Keras {name} model.
58	
59	    For transfer learning use cases, make sure to read the [guide to transfer
60	        learning & fine-tuning](https://keras.io/guides/transfer_learning/).
61	
62	    Args:
63	        include_rescaling: bool, whether to rescale the inputs. If set to
64	            True, inputs will be passed through a `Rescaling(1/255.0)` layer.
65	        include_top: bool, whether to include the fully-connected layer at the
66	            top of the network. If provided, num_classes must be provided.
67	        num_classes: integer, optional number of classes to classify images
68	            into. Only to be specified if `include_top` is True.
69	        weights: one of `None` (random initialization), a pretrained weight file
70	            path, or a reference to pre-trained weights (e.g.
71	            'imagenet/classification')(see available pre-trained weights in
72	            weights.py)
73	        input_shape: optional shape tuple, defaults to (None, None, 3).
74	        input_tensor: optional Keras tensor (i.e., output of `layers.Input()`)
75	            to use as image input for the model.
76	        pooling: optional pooling mode for feature extraction
77	            when `include_top` is `False`.
78	            - `None` means that the output of the model will be the 4D tensor
79	                output of the last convolutional block.
80	            - `avg` means that global average pooling will be applied to the
81	                output of the last convolutional block, and thus the output of
82	                the model will be a 2D tensor.
83	            - `max` means that global max pooling will be applied.
84	        name: string, optional name to pass to the model, defaults to "{name}".
85	        classifier_activation: A `str` or callable. The activation function to
86	            use on the "top" layer. Ignored unless `include_top=True`. Set
87	            `classifier_activation=None` to return the logits of the "top"
88	            layer.
89	
90	    Returns:
91	      A `keras.Model` instance.
92	"""  # noqa: E501
93	
94	
95	def apply_mlp_block(x, mlp_dim, name=None):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/legacy/regnet.py:206
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
205	
206	BASE_DOCSTRING = """This class represents the {name} architecture.
207	
208	  Reference:
209	    - [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)
210	    (CVPR 2020)
211	
212	  For image classification use cases, see
213	  [this page for detailed examples](https://keras.io/api/applications/#usage-examples-for-image-classification-models).
214	
215	  For transfer learning use cases, make sure to read the
216	  [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
217	
218	
219	  The naming of models is as follows: `RegNet<block_type><flops>` where
220	  `block_type` is one of `(X, Y)` and `flops` signifies hundred million
221	  floating point operations. For example RegNetY064 corresponds to RegNet with
222	  Y block and 6.4 giga flops (64 hundred million flops).
223	
224	  Args:
225	    include_rescaling: whether to rescale the inputs. If set to True,
226	        inputs will be passed through a `Rescaling(1/255.0)` layer.
227	    include_top: Whether to include the fully-connected
228	        layer at the top of the network.
229	    num_classes: Optional number of classes to classify images
230	        into, only to be specified if `include_top` is True.
231	    weights: One of `None` (random initialization), or the path to the weights
232	          file to be loaded, defaults to `None`.
233	    input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`)
234	        to use as image input for the model.
235	    input_shape: Optional shape tuple, defaults to (None, None, 3).
236	        It should have exactly 3 inputs channels.
237	    pooling: Optional pooling mode for feature extraction
238	        when `include_top` is `False`, defaults to None.
239	        - `None` means that the output of the model will be
240	            the 4D tensor output of the
241	            last convolutional layer.
242	        - `avg` means that global average pooling
243	            will be applied to the output of the
244	            last convolutional layer, and thus
245	            the output of the model will be a 2D tensor.
246	        - `max` means that global max pooling will
247	            be applied.
248	    classifier_activation: A `str` or callable. The activation function to use
249	        on the "top" layer. Ignored unless `include_top=True`. Set
250	        `classifier_activation=None` to return the logits of the "top" layer.
251	        Defaults to `"softmax"`.
252	        When loading pretrained weights, `classifier_activation` can only
253	        be `None` or `"softmax"`.
254	
255	  Returns:
256	    A `keras.Model` instance.
257	"""  # noqa: E501
258	
259	
260	def apply_conv2d_bn(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/legacy/vit.py:124
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
123	
124	BASE_DOCSTRING = """Instantiates the {name} architecture.
125	    Reference:
126	        - [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929v2)
127	        (ICLR 2021)
128	    This function returns a Keras {name} model.
129	
130	    The naming convention of ViT models follows: ViTSize_Patch-size
131	        (i.e. ViTS16).
132	    The following sizes were released in the original paper:
133	        - S (Small)
134	        - B (Base)
135	        - L (Large)
136	    But subsequent work from the same authors introduced:
137	        - Ti (Tiny)
138	        - H (Huge)
139	
140	    The parameter configurations for all of these sizes, at patch sizes 16 and
141	    32 are made available, following the naming convention laid out above.
142	
143	    For transfer learning use cases, make sure to read the
144	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
145	    Args:
146	        include_rescaling: bool, whether to rescale the inputs. If set to
147	            True, inputs will be passed through a `Rescaling(scale=1./255.0)`
148	            layer. Note that ViTs expect an input range of `[0..1]` if rescaling
149	            isn't used. Regardless of whether you supply `[0..1]` or the input
150	            is rescaled to `[0..1]`, the inputs will further be rescaled to
151	            `[-1..1]`.
152	        include_top: bool, whether to include the fully-connected layer at the
153	            top of the network. If provided, num_classes must be provided.
154	        num_classes: optional int, number of classes to classify images into,
155	            only to be specified if `include_top` is True.
156	        weights: one of `None` (random initialization), a pretrained weight file
157	            path, or a reference to pre-trained weights
158	            (e.g. 'imagenet/classification') (see available pre-trained weights
159	            in weights.py). Note that the 'imagenet' weights only work on an
160	            input shape of (224, 224, 3) due to the input shape dependent
161	            patching and flattening logic.
162	        input_shape: optional shape tuple, defaults to (None, None, 3).
163	        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
164	            to use as image input for the model.
165	        pooling: optional pooling mode for feature extraction
166	            when `include_top` is `False`.
167	            - `None` means that the output of the model will be the 4D tensor
168	                output of the last convolutional block.
169	            - `avg` means that global average pooling will be applied to the
170	                output of the last convolutional block, and thus the output of
171	                the model will be a 2D tensor.
172	            - `max` means that global max pooling will be applied.
173	            - `token_pooling`, default, means that the token at the start of the
174	                sequences is used instead of regular pooling.
175	        name: (Optional) name to pass to the model, defaults to "{name}".
176	        classifier_activation: A `str` or callable. The activation function to
177	            use on the "top" layer. Ignored unless `include_top=True`. Set
178	            `classifier_activation=None` to return the logits of the "top"
179	            layer.
180	    Returns:
181	      A `keras.Model` instance.
182	"""  # noqa: E501
183	
184	
185	@keras.utils.register_keras_serializable(package="keras_cv.models")
186	class ViT(keras.Model):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/legacy/weights.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
20	    if weights.startswith("gs://"):
21	        weights = weights.replace("gs://", "https://storage.googleapis.com/")
22	        return utils.get_file(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/legacy/weights.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	    raise ValueError(
40	        "The `weights` argument should be either `None`, a the path to the "
41	        "weights file to be loaded, or the name of pre-trained weights from "
42	        "https://github.com/keras-team/keras-cv/blob/master/keras_cv/models/weights.py. "  # noqa: E501
43	        f"Invalid `weights` argument: {weights}"
44	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/legacy/weights.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	
47	BASE_PATH = "https://storage.googleapis.com/keras-cv/models"
48	
49	ALIASES = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/segmentation/segformer/segformer_aliases.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
21	
22	ALIAS_DOCSTRING = """SegFormer model.
23	
24	    For transfer learning use cases, make sure to read the
25	    [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).
26	
27	    Args:
28	        backbone: a KerasCV backbone for feature extraction.
29	        num_classes: the number of classes for segmentation, including the background class.
30	
31	    Example:
32	    ```python
33	    input_data = tf.ones(shape=(8, 224, 224, 3))
34	
35	    # Randomly initialized backbone
36	    backbone = keras_cv.models.MiTBackbone.from_preset("mit_b0_imagenet")
37	    segformer = keras_cv.models.SegFormer(backbone=backbone, num_classes=19)
38	    output = model(input_data)
39	    ```
40	"""  # noqa: E501
41	
42	
43	@keras_cv_export("keras_cv.models.SegFormerB0")
44	class SegFormerB0(SegFormer):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/stable_diffusion/clip_tokenizer.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
84	            "bpe_simple_vocab_16e6.txt.gz",
85	            "https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true",  # noqa: E501
86	            file_hash="924691ac288e54409236115652ad4aa250f48203de50a9e4722a6ecd48d6804a",  # noqa: E501
87	        )
88	        self.byte_encoder = bytes_to_unicode()
89	        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/stable_diffusion/decoder.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
62	            decoder_weights_fpath = keras.utils.get_file(
63	                origin="https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_decoder.h5",  # noqa: E501
64	                file_hash="ad350a65cc8bc4a80c8103367e039a3329b4231c2469a1093869a345f55b1962",  # noqa: E501

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/stable_diffusion/diffusion_model.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
111	            diffusion_model_weights_fpath = keras.utils.get_file(
112	                origin="https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5",  # noqa: E501
113	                file_hash="8799ff9763de13d7f30a683d653018e114ed24a6a819667da4f5ee10f9e805fe",  # noqa: E501

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/stable_diffusion/diffusion_model.py:208
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
207	            diffusion_model_weights_fpath = keras.utils.get_file(
208	                origin="https://huggingface.co/ianstenbit/keras-sd2.1/resolve/main/diffusion_model_v2_1.h5",  # noqa: E501
209	                file_hash="c31730e91111f98fe0e2dbde4475d381b5287ebb9672b1821796146a25c5132d",  # noqa: E501

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/stable_diffusion/image_encoder.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
60	            image_encoder_weights_fpath = keras.utils.get_file(
61	                origin="https://huggingface.co/fchollet/stable-diffusion/resolve/main/vae_encoder.h5",  # noqa: E501
62	                file_hash="c60fb220a40d090e0f86a6ab4c312d113e115c87c40ff75d11ffcf380aab7ebb",  # noqa: E501

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/stable_diffusion/stable_diffusion.py:415
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
414	        print(
415	            "By using this model checkpoint, you acknowledge that its usage is "
416	            "subject to the terms of the CreativeML Open RAIL-M license at "
417	            "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE"  # noqa: E501

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/stable_diffusion/stable_diffusion.py:501
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
500	        print(
501	            "By using this model checkpoint, you acknowledge that its usage is "
502	            "subject to the terms of the CreativeML Open RAIL++-M license at "
503	            "https://github.com/Stability-AI/stablediffusion/blob/main/LICENSE-MODEL"  # noqa: E501

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/stable_diffusion/text_encoder.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	            text_encoder_weights_fpath = keras.utils.get_file(
39	                origin="https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5",  # noqa: E501
40	                file_hash="4789e63e07c0e54d6a34a29b45ce81ece27060c499a709d556c7755b42bb0dc4",  # noqa: E501

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/models/stable_diffusion/text_encoder.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
63	            text_encoder_weights_fpath = keras.utils.get_file(
64	                origin="https://huggingface.co/ianstenbit/keras-sd2.1/resolve/main/text_encoder_v2_1.h5",  # noqa: E501
65	                file_hash="985002e68704e1c5c3549de332218e99c5b9b745db7171d5f31fcd9a6089f25b",  # noqa: E501

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/utils/conditional_imports.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
57	        raise ImportError(
58	            f"{symbol_name} requires the `waymo-open-dataset-tf` package. "
59	            "Please install the package from source. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/utils/preset_utils.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
57	        url = os.path.join(preset, path)
58	        url = url.replace(GS_PREFIX, "https://storage.googleapis.com/")
59	        subdir = preset.replace(GS_PREFIX, "gs_")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/utils/preset_utils.py:119
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
118	    with open(config_path, "w") as config_file:
119	        config_file.write(json.dumps(config, indent=4))
120	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/keras_cv/src/utils/preset_utils.py:135
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
134	        with open(metadata_path, "w") as metadata_file:
135	            metadata_file.write(json.dumps(metadata, indent=4))
136	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/setup.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
27	    with open(os.path.join(here, rel_path)) as fp:
28	        return fp.read()
29	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/setup.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
31	def get_version(rel_path):
32	    for line in read(rel_path).splitlines():
33	        if line.startswith("__version__"):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/keras_cv-0.9.0/keras_cv-0.9.0/setup.py:68
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
67	    version=VERSION,
68	    url="https://github.com/keras-team/keras-cv",
69	    author="Keras team",

--------------------------------------------------

Code scanned:
	Total lines of code: 43439
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 37.0
		High: 9.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 44.0
		High: 2.0
Files skipped (0):
