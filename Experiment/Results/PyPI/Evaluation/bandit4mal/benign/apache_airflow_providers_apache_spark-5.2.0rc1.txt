Run started:2025-05-25 12:49:53.370106

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/src/airflow/providers/apache/spark/get_provider_info.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
27	        "name": "Apache Spark",
28	        "description": "`Apache Spark <https://spark.apache.org/>`__\n",
29	        "integrations": [
30	            {
31	                "integration-name": "Apache Spark",
32	                "external-doc-url": "https://spark.apache.org/",
33	                "how-to-guide": ["/docs/apache-airflow-providers-apache-spark/operators.rst"],
34	                "logo": "/docs/integration-logos/spark.png",
35	                "tags": ["apache"],
36	            }
37	        ],
38	        "operators": [
39	            {
40	                "integration-name": "Apache Spark",
41	                "python-modules": [
42	                    "airflow.providers.apache.spark.operators.spark_jdbc",
43	                    "airflow.providers.apache.spark.operators.spark_sql",
44	                    "airflow.providers.apache.spark.operators.spark_submit",
45	                ],
46	            }
47	        ],
48	        "hooks": [
49	            {
50	                "integration-name": "Apache Spark",
51	                "python-modules": [
52	                    "airflow.providers.apache.spark.hooks.spark_connect",
53	                    "airflow.providers.apache.spark.hooks.spark_jdbc",
54	                    "airflow.providers.apache.spark.hooks.spark_jdbc_script",
55	                    "airflow.providers.apache.spark.hooks.spark_sql",
56	                    "airflow.providers.apache.spark.hooks.spark_submit",
57	                ],
58	            }
59	        ],
60	        "connection-types": [
61	            {
62	                "hook-class-name": "airflow.providers.apache.spark.hooks.spark_connect.SparkConnectHook",
63	                "connection-type": "spark_connect",
64	            },
65	            {
66	                "hook-class-name": "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook",
67	                "connection-type": "spark_jdbc",
68	            },
69	            {
70	                "hook-class-name": "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook",
71	                "connection-type": "spark_sql",
72	            },
73	            {
74	                "hook-class-name": "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook",
75	                "connection-type": "spark",
76	            },
77	        ],
78	        "task-decorators": [
79	            {
80	                "class-name": "airflow.providers.apache.spark.decorators.pyspark.pyspark_task",
81	                "name": "pyspark",
82	            }
83	        ],
84	    }

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/src/airflow/providers/apache/spark/get_provider_info.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	                "integration-name": "Apache Spark",
32	                "external-doc-url": "https://spark.apache.org/",
33	                "how-to-guide": ["/docs/apache-airflow-providers-apache-spark/operators.rst"],
34	                "logo": "/docs/integration-logos/spark.png",
35	                "tags": ["apache"],
36	            }
37	        ],
38	        "operators": [

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/src/airflow/providers/apache/spark/hooks/spark_submit.py:326
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
325	        try:
326	            keytab = base64.b64decode(base64_keytab)
327	        except Exception as err:

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/src/airflow/providers/apache/spark/hooks/spark_submit.py:326
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
325	        try:
326	            keytab = base64.b64decode(base64_keytab)
327	        except Exception as err:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/src/airflow/providers/apache/spark/hooks/spark_submit.py:334
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
333	            with open(keytab_path, "rb") as f:
334	                existing_keytab = f.read()
335	            if existing_keytab == keytab:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/src/airflow/providers/apache/spark/hooks/spark_submit.py:343
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
342	                self.log.info("Saving keytab to %s", staging_path)
343	                f.write(keytab)
344	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/src/airflow/providers/apache/spark/hooks/spark_submit.py:343
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
342	                self.log.info("Saving keytab to %s", staging_path)
343	                f.write(keytab)
344	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	        "exclude_packages": "org.bad.dependency:1.0.0",
47	        "repositories": "http://myrepo.org",
48	        "total_executor_cores": 4,
49	        "executor_cores": 4,
50	        "executor_memory": "22g",
51	        "keytab": "privileged_user.keytab",
52	        "principal": "user/spark@airflow.org",
53	        "proxy_user": "sample_user",
54	        "name": "spark-job",
55	        "num_executors": 10,
56	        "verbose": True,
57	        "driver_memory": "3g",
58	        "java_class": "com.foo.bar.AppMain",
59	        "application_args": [
60	            "-f",
61	            "foo",
62	            "--bar",
63	            "bar",
64	            "--with-spaces",
65	            "args should keep embedded spaces",
66	            "baz",
67	        ],
68	        "use_krb5ccache": True,
69	    }
70	
71	    @staticmethod
72	    def cmd_args_to_dict(list_cmd):
73	        return_dict = {}
74	        for arg1, arg2 in zip(list_cmd, list_cmd[1:]):
75	            if arg1.startswith("--"):
76	                return_dict[arg1] = arg2
77	        return return_dict
78	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:92
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
91	                conn_type="spark",
92	                host="k8s://https://k8s-master",
93	                extra='{"deploy-mode": "cluster", "namespace": "mynamespace"}',

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
99	                conn_type="spark",
100	                host="k8s://https://k8s-master",
101	                extra='{"deploy-mode": "client", "namespace": "mynamespace"}',

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:203
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
202	            "--repositories",
203	            "http://myrepo.org",
204	            "--num-executors",
205	            "10",
206	            "--total-executor-cores",
207	            "4",
208	            "--executor-cores",
209	            "4",
210	            "--executor-memory",
211	            "22g",
212	            "--driver-memory",
213	            "3g",
214	            "--keytab",
215	            "privileged_user.keytab",
216	            "--principal",
217	            "user/spark@airflow.org",
218	            "--conf",
219	            "spark.kerberos.renewal.credentials=ccache",
220	            "--proxy-user",
221	            "sample_user",
222	            "--name",
223	            "spark-job",
224	            "--class",
225	            "com.foo.bar.AppMain",
226	            "--verbose",
227	            "test_application.py",
228	            "-f",
229	            "foo",
230	            "--bar",
231	            "bar",
232	            "--with-spaces",
233	            "args should keep embedded spaces",
234	            "baz",
235	        ]
236	        assert expected_build_cmd == cmd
237	        mock_get_env.assert_called_with("KRB5CCNAME")
238	
239	    @patch("airflow.configuration.conf.get_mandatory_value")
240	    def test_resolve_spark_submit_env_vars_use_krb5ccache_missing_principal(self, mock_get_madantory_value):
241	        mock_principal = "airflow"
242	        mock_get_madantory_value.return_value = mock_principal
243	        hook = SparkSubmitHook(conn_id="spark_yarn_cluster", principal=None, use_krb5ccache=True)
244	        mock_get_madantory_value.assert_called_with("kerberos", "principal")
245	        assert hook._principal == mock_principal
246	
247	    def test_resolve_spark_submit_env_vars_use_krb5ccache_missing_KRB5CCNAME_env(self):
248	        hook = SparkSubmitHook(
249	            conn_id="spark_yarn_cluster", principal="user/spark@airflow.org", use_krb5ccache=True
250	        )
251	        with pytest.raises(
252	            AirflowException,
253	            match="KRB5CCNAME environment variable required to use ticket ccache is missing.",
254	        ):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:280
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
279	            "30",
280	            "http://spark-standalone-master:6066/v1/submissions/status/driver-20171128111416-0001",
281	        ]
282	        expected_spark_yarn_cluster = [
283	            "spark-submit",
284	            "--master",
285	            "yarn://yarn-master",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:452
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
451	            "spark_binary": "spark-submit",
452	            "master": "k8s://https://k8s-master",
453	            "deploy_mode": "cluster",
454	            "namespace": "mynamespace",
455	            "principal": None,
456	            "keytab": None,
457	        }
458	        assert connection == expected_spark_connection
459	        assert dict_cmd["--master"] == "k8s://https://k8s-master"
460	        assert dict_cmd["--deploy-mode"] == "cluster"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:459
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
458	        assert connection == expected_spark_connection
459	        assert dict_cmd["--master"] == "k8s://https://k8s-master"
460	        assert dict_cmd["--deploy-mode"] == "cluster"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:478
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
477	            "spark_binary": "spark-submit",
478	            "master": "k8s://https://k8s-master",
479	            "deploy_mode": "cluster",
480	            "namespace": "airflow",
481	            "principal": None,
482	            "keytab": None,
483	        }
484	        assert connection == expected_spark_connection
485	        assert dict_cmd["--master"] == "k8s://https://k8s-master"
486	        assert dict_cmd["--deploy-mode"] == "cluster"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:485
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
484	        assert connection == expected_spark_connection
485	        assert dict_cmd["--master"] == "k8s://https://k8s-master"
486	        assert dict_cmd["--deploy-mode"] == "cluster"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:875
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
874	        log_lines = [
875	            "curl: Failed to connect to http://spark-standalone-master:6066This is an invalid Spark response",
876	            "Timed out",
877	        ]
878	        # When

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1075
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
1074	        keytab_value = b"abcd"
1075	        base64_keytab = base64.b64encode(keytab_value).decode("UTF-8")
1076	        _mock_open = mock_open()

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1075
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
1074	        keytab_value = b"abcd"
1075	        base64_keytab = base64.b64encode(keytab_value).decode("UTF-8")
1076	        _mock_open = mock_open()

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
1099	        keytab_value = b"abcd"
1100	        base64_keytab = base64.b64encode(keytab_value).decode("UTF-8")
1101	        mock_exists.return_value = False

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1100
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
1099	        keytab_value = b"abcd"
1100	        base64_keytab = base64.b64encode(keytab_value).decode("UTF-8")
1101	        mock_exists.return_value = False

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
1129	        keytab_value = b"abcd"
1130	        base64_keytab = base64.b64encode(keytab_value).decode("UTF-8")
1131	        mock_uuid4.return_value = "uuid"

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1130
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
1129	        keytab_value = b"abcd"
1130	        base64_keytab = base64.b64encode(keytab_value).decode("UTF-8")
1131	        mock_uuid4.return_value = "uuid"

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1159
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
1158	        keytab_value = b"abcd"
1159	        base64_keytab = base64.b64encode(keytab_value).decode("UTF-8")
1160	        mock_resolve.return_value = Path("resolved_path")

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1159
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
1158	        keytab_value = b"abcd"
1159	        base64_keytab = base64.b64encode(keytab_value).decode("UTF-8")
1160	        mock_resolve.return_value = Path("resolved_path")

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1185
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
1184	        keytab_value = b"abcd"
1185	        base64_keytab = base64.b64encode(keytab_value)
1186	        mock_resolve.return_value = Path("resolved_path")

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/hooks/test_spark_submit.py:1185
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
1184	        keytab_value = b"abcd"
1185	        base64_keytab = base64.b64encode(keytab_value)
1186	        mock_resolve.return_value = Path("resolved_path")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/operators/test_spark_submit.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
47	        "exclude_packages": "org.bad.dependency:1.0.0",
48	        "repositories": "http://myrepo.org",
49	        "total_executor_cores": 4,
50	        "executor_cores": 4,
51	        "executor_memory": "22g",
52	        "keytab": "privileged_user.keytab",
53	        "principal": "user/spark@airflow.org",
54	        "proxy_user": "sample_user",
55	        "name": "{{ task_instance.task_id }}",
56	        "num_executors": 10,
57	        "status_poll_interval": 30,
58	        "verbose": True,
59	        "application": "test_application.py",
60	        "driver_memory": "3g",
61	        "java_class": "com.foo.bar.AppMain",
62	        "properties_file": "conf/spark-custom.conf",
63	        "application_args": [
64	            "-f",
65	            "foo",
66	            "--bar",
67	            "bar",
68	            "--start",
69	            "{{ macros.ds_add(ds, -1)}}",
70	            "--end",
71	            "{{ ds }}",
72	            "--with-spaces",
73	            "args should keep embedded spaces",
74	        ],
75	        "use_krb5ccache": True,
76	        "yarn_queue": "yarn_dev_queue2",
77	        "deploy_mode": "client2",
78	        "queue": "airflow_custom_queue",
79	    }
80	
81	    def setup_method(self):
82	        args = {"owner": "airflow", "start_date": DEFAULT_DATE}
83	        self.dag = DAG("test_dag_id", schedule=None, default_args=args)
84	
85	    def test_execute(self):
86	        # Given / When
87	        conn_id = "spark_default"
88	        operator = SparkSubmitOperator(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/operators/test_spark_submit.py:105
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
104	            "exclude_packages": "org.bad.dependency:1.0.0",
105	            "repositories": "http://myrepo.org",
106	            "total_executor_cores": 4,
107	            "executor_cores": 4,
108	            "executor_memory": "22g",
109	            "keytab": "privileged_user.keytab",
110	            "principal": "user/spark@airflow.org",
111	            "proxy_user": "sample_user",
112	            "name": "{{ task_instance.task_id }}",
113	            "num_executors": 10,
114	            "status_poll_interval": 30,
115	            "verbose": True,
116	            "application": "test_application.py",
117	            "driver_memory": "3g",
118	            "java_class": "com.foo.bar.AppMain",
119	            "application_args": [
120	                "-f",
121	                "foo",
122	                "--bar",
123	                "bar",
124	                "--start",
125	                "{{ macros.ds_add(ds, -1)}}",
126	                "--end",
127	                "{{ ds }}",
128	                "--with-spaces",
129	                "args should keep embedded spaces",
130	            ],
131	            "spark_binary": "sparky",
132	            "yarn_queue": "yarn_dev_queue2",
133	            "deploy_mode": "client2",
134	            "use_krb5ccache": True,
135	            "properties_file": "conf/spark-custom.conf",
136	            "queue": "airflow_custom_queue",
137	        }
138	
139	        assert conn_id == operator._conn_id
140	        assert expected_dict["application"] == operator.application
141	        assert expected_dict["conf"] == operator.conf
142	        assert expected_dict["files"] == operator.files
143	        assert expected_dict["py_files"] == operator.py_files
144	        assert expected_dict["archives"] == operator._archives
145	        assert expected_dict["driver_class_path"] == operator.driver_class_path
146	        assert expected_dict["jars"] == operator.jars

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/operators/test_spark_submit.py:301
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
300	            config=HttpConfig(
301	                url="http://localhost:5000",
302	                endpoint="api/v2/lineage",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/operators/test_spark_submit.py:322
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
321	            "spark.openlineage.transport.type": "http",
322	            "spark.openlineage.transport.url": "http://localhost:5000",
323	            "spark.openlineage.transport.endpoint": "api/v2/lineage",
324	            "spark.openlineage.transport.timeoutInMillis": "5050000",
325	            "spark.openlineage.transport.compression": "gzip",
326	            "spark.openlineage.transport.auth.type": "api_key",
327	            "spark.openlineage.transport.auth.apiKey": "Bearer 12345",
328	            "spark.openlineage.transport.headers.X-OpenLineage-Custom-Header": "airflow",
329	        }
330	
331	    @mock.patch.object(SparkSubmitOperator, "_get_hook")
332	    @mock.patch("airflow.providers.openlineage.utils.spark.get_openlineage_listener")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/operators/test_spark_submit.py:343
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
342	                            "type": "http",
343	                            "url": "http://localhost:5000",
344	                            "endpoint": "api/v2/lineage",
345	                            "timeout": "5050",
346	                            "auth": {
347	                                "type": "api_key",
348	                                "api_key": "12345",
349	                            },
350	                            "compression": "gzip",
351	                            "custom_headers": {
352	                                "X-OpenLineage-Custom-Header": "airflow",
353	                            },
354	                        },
355	                        "test2": {
356	                            "type": "http",
357	                            "url": "https://example.com:1234",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/operators/test_spark_submit.py:357
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
356	                            "type": "http",
357	                            "url": "https://example.com:1234",
358	                        },
359	                        "test3": {"type": "console"},
360	                    }
361	                }

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/operators/test_spark_submit.py:392
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
391	            "spark.openlineage.transport.transports.test1.type": "http",
392	            "spark.openlineage.transport.transports.test1.url": "http://localhost:5000",
393	            "spark.openlineage.transport.transports.test1.endpoint": "api/v2/lineage",
394	            "spark.openlineage.transport.transports.test1.timeoutInMillis": "5050000",
395	            "spark.openlineage.transport.transports.test1.auth.type": "api_key",
396	            "spark.openlineage.transport.transports.test1.auth.apiKey": "Bearer 12345",
397	            "spark.openlineage.transport.transports.test1.compression": "gzip",
398	            "spark.openlineage.transport.transports.test1.headers.X-OpenLineage-Custom-Header": "airflow",
399	            "spark.openlineage.transport.transports.test2.type": "http",
400	            "spark.openlineage.transport.transports.test2.url": "https://example.com:1234",
401	            "spark.openlineage.transport.transports.test2.endpoint": "api/v1/lineage",
402	            "spark.openlineage.transport.transports.test2.timeoutInMillis": "5000",
403	        }
404	
405	    @mock.patch.object(SparkSubmitOperator, "_get_hook")
406	    @mock.patch("airflow.providers.openlineage.utils.spark.get_openlineage_listener")
407	    def test_inject_openlineage_composite_config_wrong_transport_to_spark(
408	        self, mock_get_openlineage_listener, mock_get_hook, caplog
409	    ):
410	        # Given / When
411	        from openlineage.client.transport.composite import CompositeConfig, CompositeTransport

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/apache_airflow_providers_apache_spark-5.2.0rc1/apache_airflow_providers_apache_spark-5.2.0rc1/tests/unit/apache/spark/operators/test_spark_submit.py:400
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
399	            "spark.openlineage.transport.transports.test2.type": "http",
400	            "spark.openlineage.transport.transports.test2.url": "https://example.com:1234",
401	            "spark.openlineage.transport.transports.test2.endpoint": "api/v1/lineage",
402	            "spark.openlineage.transport.transports.test2.timeoutInMillis": "5000",
403	        }
404	
405	    @mock.patch.object(SparkSubmitOperator, "_get_hook")
406	    @mock.patch("airflow.providers.openlineage.utils.spark.get_openlineage_listener")
407	    def test_inject_openlineage_composite_config_wrong_transport_to_spark(
408	        self, mock_get_openlineage_listener, mock_get_hook, caplog
409	    ):
410	        # Given / When
411	        from openlineage.client.transport.composite import CompositeConfig, CompositeTransport
412	
413	        mock_get_openlineage_listener.return_value.adapter.get_or_create_openlineage_client.return_value.transport = CompositeTransport(
414	            CompositeConfig.from_dict({"transports": {"test1": {"type": "console"}}})
415	        )
416	
417	        with caplog.at_level(logging.INFO):
418	            operator = SparkSubmitOperator(
419	                task_id="spark_submit_job",

--------------------------------------------------

Code scanned:
	Total lines of code: 4152
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 26.0
		High: 9.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 29.0
		High: 6.0
Files skipped (0):
