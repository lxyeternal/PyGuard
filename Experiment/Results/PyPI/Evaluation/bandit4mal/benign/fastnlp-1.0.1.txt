Run started:2025-05-25 13:30:20.909716

Test results:
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/callbacks/load_best_model_callback.py:138
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
137	            logger.info(f"Deleting {self.real_save_folder}...")
138	            shutil.rmtree(self.real_save_folder, ignore_errors=True)
139	            try:

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/dataset/dataset.py:720
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
719	                queue = ctx.SimpleQueue()
720	                proc = ctx.Process(target=_multi_proc, args=(shard_data[i], _apply_field, func, counter, queue))
721	                proc.start()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/driver.py:418
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
417	            }
418	            sys.stderr.write("\nException info:\n")
419	            sys.stderr.write(json.dumps(_write_exc_info, indent=2) + "\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/driver.py:419
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
418	            sys.stderr.write("\nException info:\n")
419	            sys.stderr.write(json.dumps(_write_exc_info, indent=2) + "\n")
420	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/driver.py:421
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
420	
421	            sys.stderr.write(f"Start to stop these pids:{self._pids}, please wait several seconds.\n")
422	            for pid in self._pids:

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/jittor_driver/mpi.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
72	            print("[RUN CMD]:", cmd)
73	            os.system(cmd)
74	            exit(0)

--------------------------------------------------
>> Issue: [B316:blacklist] os.system
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/jittor_driver/mpi.py:73
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b313-b320-os-system
72	            print("[RUN CMD]:", cmd)
73	            os.system(cmd)
74	            exit(0)

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/paddle_driver/fleet_launcher.py:163
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
162	        """
163	        self.node_ip = "127.0.0.1"
164	
165	        free_ports = None

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/paddle_driver/utils.py:141
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
140	    def __free_port():
141	        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
142	            s.setsockopt(socket.SOL_SOCKET, socket.SO_LINGER,

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/torch_driver/ddp.py:462
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
461	        """
462	        return os.environ.get("MASTER_ADDR", "127.0.0.1")
463	

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/torch_driver/ddp.py:729
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
728	    """
729	    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
730	    s.bind(("", 0))

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/torch_driver/ddp.py:733
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
732	    port = s.getsockname()[1]
733	    s.close()
734	    return str(port)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/torch_driver/torch_fsdp.py:277
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
276	    def save_checkpoint(self, folder: Path, states: Dict, dataloader, only_state_dict: bool = True, should_save_model: bool = True, **kwargs):
277	        raise RuntimeError("``TorchFSDPDriver`` does not support ``save_checkpoint`` function for now, there is some "
278	                           "technical issues that needs to solve. You can implement your own breakpoint retraining "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/core/drivers/torch_driver/torch_fsdp.py:283
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
282	    def load_checkpoint(self, folder: Path, dataloader, only_state_dict: bool = True, should_load_model: bool = True, **kwargs) -> Dict:
283	        raise RuntimeError("``TorchFSDPDriver`` does not support ``load_checkpoint`` function for now, there is some "
284	                           "technical issues that needs to solve. You can implement your own breakpoint retraining "

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/embeddings/torch/static_embedding.py:369
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
368	        with open(os.path.join(folder, STATIC_EMBED_FILENAME), 'w', encoding='utf-8') as f:
369	            f.write('{}\n'.format(' '*30))  # 留白之后再来填写
370	            word_count = 0

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/embeddings/torch/static_embedding.py:387
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
386	                    vec_str = ' '.join(map(str, vec))
387	                    f.write(f'{word} {vec_str}\n')
388	                    valid_word_count += 1

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/embeddings/torch/static_embedding.py:390
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
389	            f.seek(0)
390	            f.write('{} {}'.format(valid_word_count, self.embedding_dim))
391	        logger.debug(f"StaticEmbedding has been saved to {folder}.")

--------------------------------------------------
>> Issue: [B837:rmdir] pathlib.Path.rmdir
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/envs/distributed.py:135
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b837_rmdir.html
134	        _recursive_rm(sub_path)
135	    path.rmdir()

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/envs/imports.py:20
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
19	
20	_IS_WINDOWS = platform.system() == "Windows"
21	_NEED_IMPORT_FAIRSCALE = not _IS_WINDOWS and _module_available("fairscale") and 'torch' in need_import

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/envs/imports.py:20
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
19	
20	_IS_WINDOWS = platform.system() == "Windows"
21	_NEED_IMPORT_FAIRSCALE = not _IS_WINDOWS and _module_available("fairscale") and 'torch' in need_import

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/envs/imports.py:20
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
19	
20	_IS_WINDOWS = platform.system() == "Windows"
21	_NEED_IMPORT_FAIRSCALE = not _IS_WINDOWS and _module_available("fairscale") and 'torch' in need_import

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:221
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
220	    if 'FASTNLP_CACHE_DIR' in os.environ:
221	        fastnlp_cache_dir = os.environ.get('FASTNLP_CACHE_DIR')
222	        if os.path.isdir(fastnlp_cache_dir):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:248
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
247	        URLS = {
248	            'embedding': "http://download.fastnlp.top/embedding/",
249	            "dataset": "http://download.fastnlp.top/dataset/"
250	        }
251	        if name.lower() not in URLS:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:249
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
248	            'embedding': "http://download.fastnlp.top/embedding/",
249	            "dataset": "http://download.fastnlp.top/dataset/"
250	        }
251	        if name.lower() not in URLS:
252	            raise KeyError(f"{name} is not recognized.")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:265
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
264	    #  从扩展中寻找下载的url
265	    _filename = FASTNLP_EXTEND_EMBEDDING_URL.get(embed_type, None)
266	    if _filename:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:270
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
269	            return url
270	    embed_map = PRETRAIN_MAP.get(embed_type, None)
271	    if embed_map:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:272
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
271	    if embed_map:
272	        filename = embed_map.get(name, None)
273	        if filename:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:316
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
315	    dataset_dir = DATASET_DIR if dataset_dir is None else dataset_dir
316	    filename = dataset_dir.get(name, None)
317	    if filename:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:377
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
376	        # GET file object
377	        req = requests.get(url, stream=True, headers={"User-Agent": "fastNLP"})
378	        if req.status_code == 200:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:383
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
382	            try:
383	                content_length = req.headers.get("Content-Length")
384	                total = int(content_length) if content_length is not None else None

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:401
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
400	                            progress.update(task, advance=len(chunk))
401	                            temp_file.write(chunk)
402	                progress.stop()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:401
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
400	                            progress.update(task, advance=len(chunk))
401	                            temp_file.write(chunk)
402	                progress.stop()

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:447
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
446	                        else:
447	                            shutil.rmtree(cache_path)
448	                os.close(fd)

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:453
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
452	                elif os.path.isdir(uncompress_temp_dir):
453	                    shutil.rmtree(uncompress_temp_dir)
454	                elif os.path.isfile(uncompress_temp_dir):

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:473
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
472	
473	    with tarfile.open(file, 'r:gz') as tar:
474	        def is_within_directory(directory, target):

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:500
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
499	    g_file = gzip.GzipFile(file)
500	    with open(os.path.join(to, filename), 'wb+') as f:
501	        f.write(g_file.read())

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:501
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
500	    with open(os.path.join(to, filename), 'wb+') as f:
501	        f.write(g_file.read())
502	    g_file.close()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:501
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
500	    with open(os.path.join(to, filename), 'wb+') as f:
501	        f.write(g_file.read())
502	    g_file.close()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/file_utils.py:501
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
500	    with open(os.path.join(to, filename), 'wb+') as f:
501	        f.write(g_file.read())
502	    g_file.close()

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/classification.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
95	    if time.time() - modify_time > 1 and re_download:  # 通过这种比较丑陋的方式判断一下文件是否是才下载的
96	        shutil.rmtree(data_dir)
97	        data_dir = Loader()._get_dataset_path(dataset_name=dataset_name)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/classification.py:108
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
107	                        if random.random() < dev_ratio:
108	                            f2.write(line)
109	                        else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/classification.py:110
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
109	                        else:
110	                            f1.write(line)
111	                os.remove(os.path.join(data_dir, f'train.{suffix}'))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/conll.py:280
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
279	    def download(self):
280	        raise RuntimeError("Ontonotes cannot be downloaded automatically, you can refer "
281	                           "https://github.com/yhcc/OntoNotes-5.0-NER to download and preprocess.")

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/conll.py:435
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
434	        if time.time() - modify_time > 1 and re_download:  # 通过这种比较丑陋的方式判断一下文件是否是才下载的
435	            shutil.rmtree(data_dir)
436	            data_dir = self._get_dataset_path(dataset_name=dataset_name)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/conll.py:452
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
451	                                if random.random() < dev_ratio:
452	                                    f2.write('\n'.join(lines) + '\n\n')
453	                                else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/conll.py:454
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
453	                                else:
454	                                    f1.write('\n'.join(lines) + '\n\n')
455	                                lines.clear()

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/cws.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
70	        if time.time() - modify_time > 1 and re_download:  # 通过这种比较丑陋的方式判断一下文件是否是才下载的
71	            shutil.rmtree(data_dir)
72	            data_dir = self._get_dataset_path(dataset_name=self.dataset_name)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/cws.py:83
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
82	                            if random.random() < dev_ratio:
83	                                f2.write(line)
84	                            else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/io/loader/cws.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
84	                            else:
85	                                f1.write(line)
86	                    os.remove(os.path.join(data_dir, 'train.txt'))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/configuration_utils.py:548
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
547	            msg = (
548	                f"Can't load config for '{pretrained_model_name_or_path}'. Make sure that:\n\n"
549	                f"- '{pretrained_model_name_or_path}' is a correct model identifier listed on 'https://huggingface.co/models'\n\n"
550	                f"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\n\n"
551	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/configuration_utils.py:554
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
553	            if revision is not None:
554	                msg += f"- or '{revision}' is a valid git identifier (branch name, a tag name, or a commit id) that exists for this model name as listed on its model page on 'https://huggingface.co/models'\n\n"
555	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/configuration_utils.py:631
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
630	        with open(json_file, "r", encoding="utf-8") as reader:
631	            text = reader.read()
632	        return json.loads(text)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/configuration_utils.py:720
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
719	        with open(json_file_path, "w", encoding="utf-8") as writer:
720	            writer.write(self.to_json_string(use_diff=use_diff))
721	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
59	
60	_staging_mode = os.environ.get("HUGGINGFACE_CO_STAGING", "NO").upper() in ENV_VARS_TRUE_VALUES
61	_default_endpoint = "https://moon-staging.huggingface.co" if _staging_mode else "https://huggingface.co"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
60	_staging_mode = os.environ.get("HUGGINGFACE_CO_STAGING", "NO").upper() in ENV_VARS_TRUE_VALUES
61	_default_endpoint = "https://moon-staging.huggingface.co" if _staging_mode else "https://huggingface.co"
62	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
60	_staging_mode = os.environ.get("HUGGINGFACE_CO_STAGING", "NO").upper() in ENV_VARS_TRUE_VALUES
61	_default_endpoint = "https://moon-staging.huggingface.co" if _staging_mode else "https://huggingface.co"
62	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
62	
63	HUGGINGFACE_CO_RESOLVE_ENDPOINT = os.environ.get("HUGGINGFACE_CO_RESOLVE_ENDPOINT", _default_endpoint)
64	HUGGINGFACE_CO_PREFIX = HUGGINGFACE_CO_RESOLVE_ENDPOINT + "/{model_id}/resolve/{revision}/{filename}"

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:68
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
67	
68	_is_offline_mode = True if os.environ.get("TRANSFORMERS_OFFLINE", "0").upper() in ENV_VARS_TRUE_VALUES else False
69	

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:75
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
74	        open_mode = os.O_RDWR | os.O_CREAT | os.O_TRUNC
75	        fd = os.open(path, open_mode)
76	        fcntl.flock(fd, fcntl.LOCK_EX | fcntl.LOCK_NB)

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:105
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
104	        os.makedirs(os.path.dirname(cls.path_token), exist_ok=True)
105	        with open(cls.path_token, "w+") as f:
106	            f.write(token)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:106
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
105	        with open(cls.path_token, "w+") as f:
106	            f.write(token)
107	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:106
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
105	        with open(cls.path_token, "w+") as f:
106	            f.write(token)
107	

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
117	        try:
118	            with open(cls.path_token, "r") as f:
119	                return f.read()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:119
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
118	            with open(cls.path_token, "r") as f:
119	                return f.read()
120	        except FileNotFoundError:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:561
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
560	        with filelock(lock_path):
561	            shutil.rmtree(output_path_extracted, ignore_errors=True)
562	            os.makedirs(output_path_extracted)

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:568
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
567	            elif tarfile.is_tarfile(output_path):
568	                tar_file = tarfile.open(output_path)
569	                tar_file.extractall(output_path_extracted)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:580
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
579	    try:
580	        instance_data = requests.get(os.environ["ECS_CONTAINER_METADATA_URI"]).json()
581	        dlc_container_used = instance_data["Image"]

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:615
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
614	    # CI will set this value to True
615	    if os.environ.get("TRANSFORMERS_IS_CI", "").upper() in ENV_VARS_TRUE_VALUES:
616	        ua += "; is_ci/true"

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:630
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
629	        headers["Range"] = f"bytes={resume_size}-"
630	    r = requests.get(url, stream=True, proxies=proxies, headers=headers)
631	    r.raise_for_status()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:632
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
631	    r.raise_for_status()
632	    content_length = r.headers.get("Content-Length")
633	    total = resume_size + int(content_length) if content_length is not None else None

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:646
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
645	            # progress.update(len(chunk))
646	            temp_file.write(chunk)
647	    # progress.close()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:646
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
645	            # progress.update(len(chunk))
646	            temp_file.write(chunk)
647	    # progress.close()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:692
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
691	            r.raise_for_status()
692	            etag = r.headers.get("X-Linked-Etag") or r.headers.get("ETag")
693	            # We favor a custom header indicating the etag of the linked resource, and

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:692
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
691	            r.raise_for_status()
692	            etag = r.headers.get("X-Linked-Etag") or r.headers.get("ETag")
693	            # We favor a custom header indicating the etag of the linked resource, and

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:766
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
765	            def _resumable_file_manager() -> "io.BufferedWriter":
766	                with open(incomplete_path, "ab") as f:
767	                    yield f

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:783
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
782	
783	            http_get(url_to_download, temp_file, proxies=proxies, resume_size=resume_size, headers=headers)
784	

--------------------------------------------------
>> Issue: [B810:chmod] os.chmod
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:791
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b810_chmod.html
790	        os.umask(umask)
791	        os.chmod(cache_path, 0o666 & ~umask)
792	

--------------------------------------------------
>> Issue: [B315:blacklist] os.chmod
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:791
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b313-b320-os-chmod
790	        os.umask(umask)
791	        os.chmod(cache_path, 0o666 & ~umask)
792	

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:796
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
795	        meta_path = cache_path + ".json"
796	        with open(meta_path, "w") as meta_file:
797	            json.dump(meta, meta_file)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:856
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
855	    status_query_param = None
856	    r = requests.get(
857	        path, headers=headers, timeout=None, params=status_query_param
858	    )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/file_utils.py:861
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
860	    d = r.json()
861	    siblings = d.get("siblings", None)
862	    rfilenames = (

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/modeling_utils.py:1252
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1251	                msg = (
1252	                    f"Can't load weights for '{pretrained_model_name_or_path}'. Make sure that:\n\n"
1253	                    f"- '{pretrained_model_name_or_path}' is a correct model identifier listed on 'https://huggingface.co/models'\n\n"
1254	                    f"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a file named one of {WEIGHTS_NAME}\n\n"
1255	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/modeling_utils.py:1258
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1257	                if revision is not None:
1258	                    msg += f"- or '{revision}' is a valid git identifier (branch name, a tag name, or a commit id) that exists for this model name as listed on its model page on 'https://huggingface.co/models'\n\n"
1259	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/modeling_utils.py:1276
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1275	                    with open(resolved_archive_file) as f:
1276	                        if f.read().startswith("version"):
1277	                            raise OSError(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/auto/auto_factory.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
55	
56	FROM_PRETRAINED_TORCH_DOCSTRING = """
57	        Instantiate one of the model classes of the library from a pretrained model.
58	
59	        The model class to instantiate is selected based on the :obj:`model_type` property of the config object (either
60	        passed as an argument or loaded from :obj:`pretrained_model_name_or_path` if possible), or when it's missing,
61	        by falling back to using pattern matching on :obj:`pretrained_model_name_or_path`:
62	
63	        List options
64	
65	        The model is set in evaluation mode by default using ``model.eval()`` (so for instance, dropout modules are
66	        deactivated). To train the model, you should first set it back in training mode with ``model.train()``
67	
68	        Args:
69	            pretrained_model_name_or_path (:obj:`str` or :obj:`os.PathLike`):
70	                Can be either:
71	
72	                    - A string, the `model id` of a pretrained model hosted inside a model repo on huggingface.co.
73	                      Valid model ids can be located at the root-level, like ``bert-base-uncased``, or namespaced under
74	                      a user or organization name, like ``dbmdz/bert-base-german-cased``.
75	                    - A path to a `directory` containing model weights saved using
76	                      :func:`~transformers.PreTrainedModel.save_pretrained`, e.g., ``./my_model_directory/``.
77	                    - A path or url to a `tensorflow index checkpoint file` (e.g, ``./tf_model/model.ckpt.index``). In
78	                      this case, ``from_tf`` should be set to :obj:`True` and a configuration object should be provided
79	                      as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in
80	                      a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.
81	            model_args (additional positional arguments, `optional`):
82	                Will be passed along to the underlying model ``__init__()`` method.
83	            config (:class:`~transformers.PretrainedConfig`, `optional`):
84	                Configuration for the model to use instead of an automatically loaded configuration. Configuration can
85	                be automatically loaded when:
86	
87	                    - The model is a model provided by the library (loaded with the `model id` string of a pretrained
88	                      model).
89	                    - The model was saved using :meth:`~transformers.PreTrainedModel.save_pretrained` and is reloaded
90	                      by supplying the save directory.
91	                    - The model is loaded by supplying a local directory as ``pretrained_model_name_or_path`` and a
92	                      configuration JSON file named `config.json` is found in the directory.
93	            state_dict (`Dict[str, torch.Tensor]`, `optional`):
94	                A state dictionary to use instead of a state dictionary loaded from saved weights file.
95	
96	                This option can be used if you want to create a model from a pretrained configuration but load your own
97	                weights. In this case though, you should check if using
98	                :func:`~transformers.PreTrainedModel.save_pretrained` and
99	                :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.
100	            cache_dir (:obj:`str` or :obj:`os.PathLike`, `optional`):
101	                Path to a directory in which a downloaded pretrained model configuration should be cached if the
102	                standard cache should not be used.
103	            from_tf (:obj:`bool`, `optional`, defaults to :obj:`False`):
104	                Load the model weights from a TensorFlow checkpoint save file (see docstring of
105	                ``pretrained_model_name_or_path`` argument).
106	            force_download (:obj:`bool`, `optional`, defaults to :obj:`False`):
107	                Whether or not to force the (re-)download of the model weights and configuration files, overriding the
108	                cached versions if they exist.
109	            resume_download (:obj:`bool`, `optional`, defaults to :obj:`False`):
110	                Whether or not to delete incompletely received files. Will attempt to resume the download if such a
111	                file exists.
112	            proxies (:obj:`Dict[str, str], `optional`):
113	                A dictionary of proxy servers to use by protocol or endpoint, e.g., :obj:`{'http': 'foo.bar:3128',
114	                'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.
115	            output_loading_info(:obj:`bool`, `optional`, defaults to :obj:`False`):
116	                Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.
117	            local_files_only(:obj:`bool`, `optional`, defaults to :obj:`False`):
118	                Whether or not to only look at local files (e.g., not try downloading the model).
119	            revision(:obj:`str`, `optional`, defaults to :obj:`"main"`):
120	                The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
121	                git-based system for storing models and other artifacts on huggingface.co, so ``revision`` can be any
122	                identifier allowed by git.
123	            trust_remote_code (:obj:`bool`, `optional`, defaults to :obj:`False`):
124	                Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
125	                should only be set to :obj:`True` for repositories you trust and in which you have read the code, as it
126	                will execute code present on the Hub on your local machine.
127	            kwargs (additional keyword arguments, `optional`):
128	                Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
129	                :obj:`output_attentions=True`). Behaves differently depending on whether a ``config`` is provided or
130	                automatically loaded:
131	
132	                    - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the
133	                      underlying model's ``__init__`` method (we assume all relevant updates to the configuration have
134	                      already been done)
135	                    - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class
136	                      initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of
137	                      ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute
138	                      with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration
139	                      attribute will be passed to the underlying model's ``__init__`` function.
140	
141	        Examples::
142	
143	            >>> from transformers import AutoConfig, BaseAutoModelClass
144	
145	            >>> # Download model and configuration from huggingface.co and cache.
146	            >>> model = BaseAutoModelClass.from_pretrained('checkpoint_placeholder')
147	
148	            >>> # Update configuration during loading
149	            >>> model = BaseAutoModelClass.from_pretrained('checkpoint_placeholder', output_attentions=True)
150	            >>> model.config.output_attentions
151	            True
152	
153	            >>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)
154	            >>> config = AutoConfig.from_pretrained('./tf_model/shortcut_placeholder_tf_model_config.json')
155	            >>> model = BaseAutoModelClass.from_pretrained('./tf_model/shortcut_placeholder_tf_checkpoint.ckpt.index', from_tf=True, config=config)
156	"""
157	
158	FROM_PRETRAINED_TF_DOCSTRING = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/auto/auto_factory.py:158
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
157	
158	FROM_PRETRAINED_TF_DOCSTRING = """
159	        Instantiate one of the model classes of the library from a pretrained model.
160	
161	        The model class to instantiate is selected based on the :obj:`model_type` property of the config object (either
162	        passed as an argument or loaded from :obj:`pretrained_model_name_or_path` if possible), or when it's missing,
163	        by falling back to using pattern matching on :obj:`pretrained_model_name_or_path`:
164	
165	        List options
166	
167	        Args:
168	            pretrained_model_name_or_path (:obj:`str` or :obj:`os.PathLike`):
169	                Can be either:
170	
171	                    - A string, the `model id` of a pretrained model hosted inside a model repo on huggingface.co.
172	                      Valid model ids can be located at the root-level, like ``bert-base-uncased``, or namespaced under
173	                      a user or organization name, like ``dbmdz/bert-base-german-cased``.
174	                    - A path to a `directory` containing model weights saved using
175	                      :func:`~transformers.PreTrainedModel.save_pretrained`, e.g., ``./my_model_directory/``.
176	                    - A path or url to a `PyTorch state_dict save file` (e.g, ``./pt_model/pytorch_model.bin``). In
177	                      this case, ``from_pt`` should be set to :obj:`True` and a configuration object should be provided
178	                      as ``config`` argument. This loading path is slower than converting the PyTorch model in a
179	                      TensorFlow model using the provided conversion scripts and loading the TensorFlow model
180	                      afterwards.
181	            model_args (additional positional arguments, `optional`):
182	                Will be passed along to the underlying model ``__init__()`` method.
183	            config (:class:`~transformers.PretrainedConfig`, `optional`):
184	                Configuration for the model to use instead of an automatically loaded configuration. Configuration can
185	                be automatically loaded when:
186	
187	                    - The model is a model provided by the library (loaded with the `model id` string of a pretrained
188	                      model).
189	                    - The model was saved using :meth:`~transformers.PreTrainedModel.save_pretrained` and is reloaded
190	                      by supplying the save directory.
191	                    - The model is loaded by supplying a local directory as ``pretrained_model_name_or_path`` and a
192	                      configuration JSON file named `config.json` is found in the directory.
193	            cache_dir (:obj:`str` or :obj:`os.PathLike`, `optional`):
194	                Path to a directory in which a downloaded pretrained model configuration should be cached if the
195	                standard cache should not be used.
196	            from_pt (:obj:`bool`, `optional`, defaults to :obj:`False`):
197	                Load the model weights from a PyTorch checkpoint save file (see docstring of
198	                ``pretrained_model_name_or_path`` argument).
199	            force_download (:obj:`bool`, `optional`, defaults to :obj:`False`):
200	                Whether or not to force the (re-)download of the model weights and configuration files, overriding the
201	                cached versions if they exist.
202	            resume_download (:obj:`bool`, `optional`, defaults to :obj:`False`):
203	                Whether or not to delete incompletely received files. Will attempt to resume the download if such a
204	                file exists.
205	            proxies (:obj:`Dict[str, str], `optional`):
206	                A dictionary of proxy servers to use by protocol or endpoint, e.g., :obj:`{'http': 'foo.bar:3128',
207	                'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.
208	            output_loading_info(:obj:`bool`, `optional`, defaults to :obj:`False`):
209	                Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.
210	            local_files_only(:obj:`bool`, `optional`, defaults to :obj:`False`):
211	                Whether or not to only look at local files (e.g., not try downloading the model).
212	            revision(:obj:`str`, `optional`, defaults to :obj:`"main"`):
213	                The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
214	                git-based system for storing models and other artifacts on huggingface.co, so ``revision`` can be any
215	                identifier allowed by git.
216	            trust_remote_code (:obj:`bool`, `optional`, defaults to :obj:`False`):
217	                Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
218	                should only be set to :obj:`True` for repositories you trust and in which you have read the code, as it
219	                will execute code present on the Hub on your local machine.
220	            kwargs (additional keyword arguments, `optional`):
221	                Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
222	                :obj:`output_attentions=True`). Behaves differently depending on whether a ``config`` is provided or
223	                automatically loaded:
224	
225	                    - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the
226	                      underlying model's ``__init__`` method (we assume all relevant updates to the configuration have
227	                      already been done)
228	                    - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class
229	                      initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of
230	                      ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute
231	                      with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration
232	                      attribute will be passed to the underlying model's ``__init__`` function.
233	
234	        Examples::
235	
236	            >>> from transformers import AutoConfig, BaseAutoModelClass
237	
238	            >>> # Download model and configuration from huggingface.co and cache.
239	            >>> model = BaseAutoModelClass.from_pretrained('checkpoint_placeholder')
240	
241	            >>> # Update configuration during loading
242	            >>> model = BaseAutoModelClass.from_pretrained('checkpoint_placeholder', output_attentions=True)
243	            >>> model.config.output_attentions
244	            True
245	
246	            >>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
247	            >>> config = AutoConfig.from_pretrained('./pt_model/shortcut_placeholder_pt_model_config.json')
248	            >>> model = BaseAutoModelClass.from_pretrained('./pt_model/shortcut_placeholder_pytorch_model.bin', from_pt=True, config=config)
249	"""
250	
251	FROM_PRETRAINED_FLAX_DOCSTRING = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/auto/auto_factory.py:251
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
250	
251	FROM_PRETRAINED_FLAX_DOCSTRING = """
252	        Instantiate one of the model classes of the library from a pretrained model.
253	
254	        The model class to instantiate is selected based on the :obj:`model_type` property of the config object (either
255	        passed as an argument or loaded from :obj:`pretrained_model_name_or_path` if possible), or when it's missing,
256	        by falling back to using pattern matching on :obj:`pretrained_model_name_or_path`:
257	
258	        List options
259	
260	        Args:
261	            pretrained_model_name_or_path (:obj:`str` or :obj:`os.PathLike`):
262	                Can be either:
263	
264	                    - A string, the `model id` of a pretrained model hosted inside a model repo on huggingface.co.
265	                      Valid model ids can be located at the root-level, like ``bert-base-uncased``, or namespaced under
266	                      a user or organization name, like ``dbmdz/bert-base-german-cased``.
267	                    - A path to a `directory` containing model weights saved using
268	                      :func:`~transformers.PreTrainedModel.save_pretrained`, e.g., ``./my_model_directory/``.
269	                    - A path or url to a `PyTorch state_dict save file` (e.g, ``./pt_model/pytorch_model.bin``). In
270	                      this case, ``from_pt`` should be set to :obj:`True` and a configuration object should be provided
271	                      as ``config`` argument. This loading path is slower than converting the PyTorch model in a
272	                      TensorFlow model using the provided conversion scripts and loading the TensorFlow model
273	                      afterwards.
274	            model_args (additional positional arguments, `optional`):
275	                Will be passed along to the underlying model ``__init__()`` method.
276	            config (:class:`~transformers.PretrainedConfig`, `optional`):
277	                Configuration for the model to use instead of an automatically loaded configuration. Configuration can
278	                be automatically loaded when:
279	
280	                    - The model is a model provided by the library (loaded with the `model id` string of a pretrained
281	                      model).
282	                    - The model was saved using :meth:`~transformers.PreTrainedModel.save_pretrained` and is reloaded
283	                      by supplying the save directory.
284	                    - The model is loaded by supplying a local directory as ``pretrained_model_name_or_path`` and a
285	                      configuration JSON file named `config.json` is found in the directory.
286	            cache_dir (:obj:`str` or :obj:`os.PathLike`, `optional`):
287	                Path to a directory in which a downloaded pretrained model configuration should be cached if the
288	                standard cache should not be used.
289	            from_pt (:obj:`bool`, `optional`, defaults to :obj:`False`):
290	                Load the model weights from a PyTorch checkpoint save file (see docstring of
291	                ``pretrained_model_name_or_path`` argument).
292	            force_download (:obj:`bool`, `optional`, defaults to :obj:`False`):
293	                Whether or not to force the (re-)download of the model weights and configuration files, overriding the
294	                cached versions if they exist.
295	            resume_download (:obj:`bool`, `optional`, defaults to :obj:`False`):
296	                Whether or not to delete incompletely received files. Will attempt to resume the download if such a
297	                file exists.
298	            proxies (:obj:`Dict[str, str], `optional`):
299	                A dictionary of proxy servers to use by protocol or endpoint, e.g., :obj:`{'http': 'foo.bar:3128',
300	                'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.
301	            output_loading_info(:obj:`bool`, `optional`, defaults to :obj:`False`):
302	                Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.
303	            local_files_only(:obj:`bool`, `optional`, defaults to :obj:`False`):
304	                Whether or not to only look at local files (e.g., not try downloading the model).
305	            revision(:obj:`str`, `optional`, defaults to :obj:`"main"`):
306	                The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
307	                git-based system for storing models and other artifacts on huggingface.co, so ``revision`` can be any
308	                identifier allowed by git.
309	            trust_remote_code (:obj:`bool`, `optional`, defaults to :obj:`False`):
310	                Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
311	                should only be set to :obj:`True` for repositories you trust and in which you have read the code, as it
312	                will execute code present on the Hub on your local machine.
313	            kwargs (additional keyword arguments, `optional`):
314	                Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
315	                :obj:`output_attentions=True`). Behaves differently depending on whether a ``config`` is provided or
316	                automatically loaded:
317	
318	                    - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the
319	                      underlying model's ``__init__`` method (we assume all relevant updates to the configuration have
320	                      already been done)
321	                    - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class
322	                      initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of
323	                      ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute
324	                      with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration
325	                      attribute will be passed to the underlying model's ``__init__`` function.
326	
327	        Examples::
328	
329	            >>> from transformers import AutoConfig, BaseAutoModelClass
330	
331	            >>> # Download model and configuration from huggingface.co and cache.
332	            >>> model = BaseAutoModelClass.from_pretrained('checkpoint_placeholder')
333	
334	            >>> # Update configuration during loading
335	            >>> model = BaseAutoModelClass.from_pretrained('checkpoint_placeholder', output_attentions=True)
336	            >>> model.config.output_attentions
337	            True
338	
339	            >>> # Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
340	            >>> config = AutoConfig.from_pretrained('./pt_model/shortcut_placeholder_pt_model_config.json')
341	            >>> model = BaseAutoModelClass.from_pretrained('./pt_model/shortcut_placeholder_pytorch_model.bin', from_pt=True, config=config)
342	"""
343	
344	
345	def _get_model_class(config, model_mapping):

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/auto/dynamic.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
50	    with open(filename, "r", encoding="utf-8") as f:
51	        content = f.read()
52	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/configuration_bart.py:25
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
24	BART_PRETRAINED_CONFIG_ARCHIVE_MAP = {
25	    "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/config.json",
26	    # See all BART models at https://huggingface.co/models?filter=bart
27	}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/modeling_bart.py:522
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
521	
522	BART_START_DOCSTRING = r"""
523	    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic
524	    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
525	    pruning heads etc.)
526	
527	    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__
528	    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
529	    general usage and behavior.
530	
531	    Parameters:
532	        config (:class:`~transformers.BartConfig`):
533	            Model configuration class with all the parameters of the model. Initializing with a config file does not
534	            load the weights associated with the model, only the configuration. Check out the
535	            :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model weights.
536	"""
537	
538	BART_GENERATION_EXAMPLE = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/modeling_bart.py:570
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
569	
570	BART_INPUTS_DOCSTRING = r"""
571	    Args:
572	        input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`):
573	            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide
574	            it.
575	
576	            Indices can be obtained using :class:`~transformers.BartTokenizer`. See
577	            :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__` for
578	            details.
579	
580	            `What are input IDs? <../glossary.html#input-ids>`__
581	        attention_mask (:obj:`torch.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):
582	            Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:
583	
584	            - 1 for tokens that are **not masked**,
585	            - 0 for tokens that are **masked**.
586	
587	            `What are attention masks? <../glossary.html#attention-mask>`__
588	        decoder_input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, target_sequence_length)`, `optional`):
589	            Indices of decoder input sequence tokens in the vocabulary.
590	
591	            Indices can be obtained using :class:`~transformers.BartTokenizer`. See
592	            :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__` for
593	            details.
594	
595	            `What are decoder input IDs? <../glossary.html#decoder-input-ids>`__
596	
597	            Bart uses the :obj:`eos_token_id` as the starting token for :obj:`decoder_input_ids` generation. If
598	            :obj:`past_key_values` is used, optionally only the last :obj:`decoder_input_ids` have to be input (see
599	            :obj:`past_key_values`).
600	
601	            For translation and summarization training, :obj:`decoder_input_ids` should be provided. If no
602	            :obj:`decoder_input_ids` is provided, the model will create this tensor by shifting the :obj:`input_ids` to
603	            the right for denoising pre-training following the paper.
604	        decoder_attention_mask (:obj:`torch.LongTensor` of shape :obj:`(batch_size, target_sequence_length)`, `optional`):
605	            Default behavior: generate a tensor that ignores pad tokens in :obj:`decoder_input_ids`. Causal mask will
606	            also be used by default.
607	
608	            If you want to change padding behavior, you should read :func:`modeling_bart._prepare_decoder_inputs` and
609	            modify to your needs. See diagram 1 in `the paper <https://arxiv.org/abs/1910.13461>`__ for more
610	            information on the default strategy.
611	        head_mask (:obj:`torch.Tensor` of shape :obj:`(encoder_layers, encoder_attention_heads)`, `optional`):
612	            Mask to nullify selected heads of the attention modules in the encoder. Mask values selected in ``[0, 1]``:
613	
614	            - 1 indicates the head is **not masked**,
615	            - 0 indicates the head is **masked**.
616	
617	        decoder_head_mask (:obj:`torch.Tensor` of shape :obj:`(decoder_layers, decoder_attention_heads)`, `optional`):
618	            Mask to nullify selected heads of the attention modules in the decoder. Mask values selected in ``[0, 1]``:
619	
620	            - 1 indicates the head is **not masked**,
621	            - 0 indicates the head is **masked**.
622	
623	        cross_attn_head_mask (:obj:`torch.Tensor` of shape :obj:`(decoder_layers, decoder_attention_heads)`, `optional`):
624	            Mask to nullify selected heads of the cross-attention modules in the decoder. Mask values selected in ``[0,
625	            1]``:
626	
627	            - 1 indicates the head is **not masked**,
628	            - 0 indicates the head is **masked**.
629	
630	        encoder_outputs (:obj:`tuple(tuple(torch.FloatTensor)`, `optional`):
631	            Tuple consists of (:obj:`last_hidden_state`, `optional`: :obj:`hidden_states`, `optional`:
632	            :obj:`attentions`) :obj:`last_hidden_state` of shape :obj:`(batch_size, sequence_length, hidden_size)`,
633	            `optional`) is a sequence of hidden-states at the output of the last layer of the encoder. Used in the
634	            cross-attention of the decoder.
635	        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))`, `optional`, returned when ``use_cache=True`` is passed or when ``config.use_cache=True``):
636	            Tuple of :obj:`tuple(torch.FloatTensor)` of length :obj:`config.n_layers`, with each tuple having 2 tensors
637	            of shape :obj:`(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of
638	            shape :obj:`(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.
639	
640	            Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
641	            blocks) that can be used (see :obj:`past_key_values` input) to speed up sequential decoding.
642	
643	            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`
644	            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`
645	            instead of all :obj:`decoder_input_ids`` of shape :obj:`(batch_size, sequence_length)`.
646	        inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):
647	            Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.
648	            This is useful if you want more control over how to convert :obj:`input_ids` indices into associated
649	            vectors than the model's internal embedding lookup matrix.
650	        decoder_inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, target_sequence_length, hidden_size)`, `optional`):
651	            Optionally, instead of passing :obj:`decoder_input_ids` you can choose to directly pass an embedded
652	            representation. If :obj:`past_key_values` is used, optionally only the last :obj:`decoder_inputs_embeds`
653	            have to be input (see :obj:`past_key_values`). This is useful if you want more control over how to convert
654	            :obj:`decoder_input_ids` indices into associated vectors than the model's internal embedding lookup matrix.
655	
656	            If :obj:`decoder_input_ids` and :obj:`decoder_inputs_embeds` are both unset, :obj:`decoder_inputs_embeds`
657	            takes the value of :obj:`inputs_embeds`.
658	        use_cache (:obj:`bool`, `optional`):
659	            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up
660	            decoding (see :obj:`past_key_values`).
661	        output_attentions (:obj:`bool`, `optional`):
662	            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned
663	            tensors for more detail.
664	        output_hidden_states (:obj:`bool`, `optional`):
665	            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for
666	            more detail.
667	        return_dict (:obj:`bool`, `optional`):
668	            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.
669	"""
670	
671	
672	class BartEncoder(BartPretrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
27	    "vocab_file": {
28	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/vocab.json",
29	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/vocab.json",
30	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/vocab.json",
31	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json",
32	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/vocab.json",
33	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/vocab.json",
34	    },
35	    "merges_file": {
36	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/vocab.json",
29	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/vocab.json",
30	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/vocab.json",
31	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json",
32	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/vocab.json",
33	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/vocab.json",
34	    },
35	    "merges_file": {
36	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/merges.txt",
37	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
29	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/vocab.json",
30	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/vocab.json",
31	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json",
32	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/vocab.json",
33	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/vocab.json",
34	    },
35	    "merges_file": {
36	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/merges.txt",
37	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/merges.txt",
38	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
30	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/vocab.json",
31	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json",
32	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/vocab.json",
33	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/vocab.json",
34	    },
35	    "merges_file": {
36	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/merges.txt",
37	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/merges.txt",
38	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/merges.txt",
39	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json",
32	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/vocab.json",
33	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/vocab.json",
34	    },
35	    "merges_file": {
36	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/merges.txt",
37	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/merges.txt",
38	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/merges.txt",
39	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt",
40	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
32	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/vocab.json",
33	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/vocab.json",
34	    },
35	    "merges_file": {
36	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/merges.txt",
37	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/merges.txt",
38	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/merges.txt",
39	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt",
40	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/merges.txt",
41	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	    "merges_file": {
36	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/merges.txt",
37	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/merges.txt",
38	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/merges.txt",
39	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt",
40	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/merges.txt",
41	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/merges.txt",
42	    },
43	}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	        "facebook/bart-base": "https://huggingface.co/facebook/bart-base/resolve/main/merges.txt",
37	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/merges.txt",
38	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/merges.txt",
39	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt",
40	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/merges.txt",
41	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/merges.txt",
42	    },
43	}
44	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
37	        "facebook/bart-large": "https://huggingface.co/facebook/bart-large/resolve/main/merges.txt",
38	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/merges.txt",
39	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt",
40	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/merges.txt",
41	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/merges.txt",
42	    },
43	}
44	
45	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	        "facebook/bart-large-mnli": "https://huggingface.co/facebook/bart-large-mnli/resolve/main/merges.txt",
39	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt",
40	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/merges.txt",
41	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/merges.txt",
42	    },
43	}
44	
45	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
46	    "facebook/bart-base": 1024,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	        "facebook/bart-large-cnn": "https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt",
40	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/merges.txt",
41	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/merges.txt",
42	    },
43	}
44	
45	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
46	    "facebook/bart-base": 1024,
47	    "facebook/bart-large": 1024,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bart/tokenization_bart.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	        "facebook/bart-large-xsum": "https://huggingface.co/facebook/bart-large-xsum/resolve/main/merges.txt",
41	        "yjernite/bart_eli5": "https://huggingface.co/yjernite/bart_eli5/resolve/main/merges.txt",
42	    },
43	}
44	
45	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
46	    "facebook/bart-base": 1024,
47	    "facebook/bart-large": 1024,
48	    "facebook/bart-large-mnli": 1024,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
26	BERT_PRETRAINED_CONFIG_ARCHIVE_MAP = {
27	    "bert-base-uncased": "https://huggingface.co/bert-base-uncased/resolve/main/config.json",
28	    "bert-large-uncased": "https://huggingface.co/bert-large-uncased/resolve/main/config.json",
29	    "bert-base-cased": "https://huggingface.co/bert-base-cased/resolve/main/config.json",
30	    "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/config.json",
31	    "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json",
32	    "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json",
33	    "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/config.json",
34	    "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/config.json",
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
27	    "bert-base-uncased": "https://huggingface.co/bert-base-uncased/resolve/main/config.json",
28	    "bert-large-uncased": "https://huggingface.co/bert-large-uncased/resolve/main/config.json",
29	    "bert-base-cased": "https://huggingface.co/bert-base-cased/resolve/main/config.json",
30	    "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/config.json",
31	    "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json",
32	    "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json",
33	    "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/config.json",
34	    "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/config.json",
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	    "bert-large-uncased": "https://huggingface.co/bert-large-uncased/resolve/main/config.json",
29	    "bert-base-cased": "https://huggingface.co/bert-base-cased/resolve/main/config.json",
30	    "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/config.json",
31	    "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json",
32	    "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json",
33	    "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/config.json",
34	    "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/config.json",
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
29	    "bert-base-cased": "https://huggingface.co/bert-base-cased/resolve/main/config.json",
30	    "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/config.json",
31	    "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json",
32	    "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json",
33	    "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/config.json",
34	    "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/config.json",
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
30	    "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/config.json",
31	    "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json",
32	    "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json",
33	    "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/config.json",
34	    "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/config.json",
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	    "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json",
32	    "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json",
33	    "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/config.json",
34	    "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/config.json",
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
32	    "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json",
33	    "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/config.json",
34	    "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/config.json",
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
33	    "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/config.json",
34	    "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/config.json",
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
34	    "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/config.json",
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	    "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/config.json",
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	    "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/config.json",
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
37	    "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json",
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	    "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/config.json",
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	    "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/config.json",
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	
63	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	    "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/config.json",
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	
63	
64	    Args:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
41	    "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/config.json",
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	
63	
64	    Args:
65	        vocab_size (:obj:`int`, `optional`, defaults to 30522):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	    "cl-tohoku/bert-base-japanese": "https://huggingface.co/cl-tohoku/bert-base-japanese/resolve/main/config.json",
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	
63	
64	    Args:
65	        vocab_size (:obj:`int`, `optional`, defaults to 30522):
66	            Vocabulary size of the BERT model. Defines the number of different tokens that can be represented by the

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
43	    "cl-tohoku/bert-base-japanese-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json",
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	
63	
64	    Args:
65	        vocab_size (:obj:`int`, `optional`, defaults to 30522):
66	            Vocabulary size of the BERT model. Defines the number of different tokens that can be represented by the
67	            :obj:`inputs_ids` passed when calling :class:`~transformers.BertModel` or

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	    "cl-tohoku/bert-base-japanese-char": "https://huggingface.co/cl-tohoku/bert-base-japanese-char/resolve/main/config.json",
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	
63	
64	    Args:
65	        vocab_size (:obj:`int`, `optional`, defaults to 30522):
66	            Vocabulary size of the BERT model. Defines the number of different tokens that can be represented by the
67	            :obj:`inputs_ids` passed when calling :class:`~transformers.BertModel` or
68	            :class:`~transformers.TFBertModel`.

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	    "cl-tohoku/bert-base-japanese-char-whole-word-masking": "https://huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/resolve/main/config.json",
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	
63	
64	    Args:
65	        vocab_size (:obj:`int`, `optional`, defaults to 30522):
66	            Vocabulary size of the BERT model. Defines the number of different tokens that can be represented by the
67	            :obj:`inputs_ids` passed when calling :class:`~transformers.BertModel` or
68	            :class:`~transformers.TFBertModel`.
69	        hidden_size (:obj:`int`, `optional`, defaults to 768):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	    "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/config.json",
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	
63	
64	    Args:
65	        vocab_size (:obj:`int`, `optional`, defaults to 30522):
66	            Vocabulary size of the BERT model. Defines the number of different tokens that can be represented by the
67	            :obj:`inputs_ids` passed when calling :class:`~transformers.BertModel` or
68	            :class:`~transformers.TFBertModel`.
69	        hidden_size (:obj:`int`, `optional`, defaults to 768):
70	            Dimensionality of the encoder layers and the pooler layer.

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/configuration_bert.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
47	    "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/config.json",
48	    "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/config.json",
49	    # See all BERT models at https://huggingface.co/models?filter=bert
50	}
51	
52	
53	class BertConfig(PretrainedConfig):
54	    r"""
55	    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a
56	    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,
57	    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration
58	    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.
59	
60	    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
61	    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.
62	
63	
64	    Args:
65	        vocab_size (:obj:`int`, `optional`, defaults to 30522):
66	            Vocabulary size of the BERT model. Defines the number of different tokens that can be represented by the
67	            :obj:`inputs_ids` passed when calling :class:`~transformers.BertModel` or
68	            :class:`~transformers.TFBertModel`.
69	        hidden_size (:obj:`int`, `optional`, defaults to 768):
70	            Dimensionality of the encoder layers and the pooler layer.
71	        num_hidden_layers (:obj:`int`, `optional`, defaults to 12):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/modeling_bert.py:714
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
713	
714	BERT_START_DOCSTRING = r"""
715	
716	    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic
717	    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
718	    pruning heads etc.)
719	
720	    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__
721	    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
722	    general usage and behavior.
723	
724	    Parameters:
725	        config (:class:`~transformers.BertConfig`): Model configuration class with all the parameters of the model.
726	            Initializing with a config file does not load the weights associated with the model, only the
727	            configuration. Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model
728	            weights.
729	"""
730	
731	BERT_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	    "vocab_file": {
36	        "bert-base-uncased": "https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt",
37	        "bert-large-uncased": "https://huggingface.co/bert-large-uncased/resolve/main/vocab.txt",
38	        "bert-base-cased": "https://huggingface.co/bert-base-cased/resolve/main/vocab.txt",
39	        "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/vocab.txt",
40	        "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt",
41	        "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt",
42	        "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt",
43	        "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt",
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	        "bert-base-uncased": "https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt",
37	        "bert-large-uncased": "https://huggingface.co/bert-large-uncased/resolve/main/vocab.txt",
38	        "bert-base-cased": "https://huggingface.co/bert-base-cased/resolve/main/vocab.txt",
39	        "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/vocab.txt",
40	        "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt",
41	        "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt",
42	        "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt",
43	        "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt",
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
37	        "bert-large-uncased": "https://huggingface.co/bert-large-uncased/resolve/main/vocab.txt",
38	        "bert-base-cased": "https://huggingface.co/bert-base-cased/resolve/main/vocab.txt",
39	        "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/vocab.txt",
40	        "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt",
41	        "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt",
42	        "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt",
43	        "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt",
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	        "bert-base-cased": "https://huggingface.co/bert-base-cased/resolve/main/vocab.txt",
39	        "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/vocab.txt",
40	        "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt",
41	        "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt",
42	        "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt",
43	        "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt",
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	        "bert-large-cased": "https://huggingface.co/bert-large-cased/resolve/main/vocab.txt",
40	        "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt",
41	        "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt",
42	        "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt",
43	        "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt",
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	        "bert-base-multilingual-uncased": "https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt",
41	        "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt",
42	        "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt",
43	        "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt",
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
41	        "bert-base-multilingual-cased": "https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt",
42	        "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt",
43	        "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt",
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	        "bert-base-chinese": "https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt",
43	        "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt",
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
43	        "bert-base-german-cased": "https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt",
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	        "bert-large-uncased-whole-word-masking": "https://huggingface.co/bert-large-uncased-whole-word-masking/resolve/main/vocab.txt",
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,
64	    "bert-base-chinese": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	        "bert-large-cased-whole-word-masking": "https://huggingface.co/bert-large-cased-whole-word-masking/resolve/main/vocab.txt",
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,
64	    "bert-base-chinese": 512,
65	    "bert-base-german-cased": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	        "bert-large-uncased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,
64	    "bert-base-chinese": 512,
65	    "bert-base-german-cased": 512,
66	    "bert-large-uncased-whole-word-masking": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
47	        "bert-large-cased-whole-word-masking-finetuned-squad": "https://huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt",
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,
64	    "bert-base-chinese": 512,
65	    "bert-base-german-cased": 512,
66	    "bert-large-uncased-whole-word-masking": 512,
67	    "bert-large-cased-whole-word-masking": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
48	        "bert-base-cased-finetuned-mrpc": "https://huggingface.co/bert-base-cased-finetuned-mrpc/resolve/main/vocab.txt",
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,
64	    "bert-base-chinese": 512,
65	    "bert-base-german-cased": 512,
66	    "bert-large-uncased-whole-word-masking": 512,
67	    "bert-large-cased-whole-word-masking": 512,
68	    "bert-large-uncased-whole-word-masking-finetuned-squad": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	        "bert-base-german-dbmdz-cased": "https://huggingface.co/bert-base-german-dbmdz-cased/resolve/main/vocab.txt",
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,
64	    "bert-base-chinese": 512,
65	    "bert-base-german-cased": 512,
66	    "bert-large-uncased-whole-word-masking": 512,
67	    "bert-large-cased-whole-word-masking": 512,
68	    "bert-large-uncased-whole-word-masking-finetuned-squad": 512,
69	    "bert-large-cased-whole-word-masking-finetuned-squad": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
50	        "bert-base-german-dbmdz-uncased": "https://huggingface.co/bert-base-german-dbmdz-uncased/resolve/main/vocab.txt",
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,
64	    "bert-base-chinese": 512,
65	    "bert-base-german-cased": 512,
66	    "bert-large-uncased-whole-word-masking": 512,
67	    "bert-large-cased-whole-word-masking": 512,
68	    "bert-large-uncased-whole-word-masking-finetuned-squad": 512,
69	    "bert-large-cased-whole-word-masking-finetuned-squad": 512,
70	    "bert-base-cased-finetuned-mrpc": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:52
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
51	        "TurkuNLP/bert-base-finnish-cased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/resolve/main/vocab.txt",
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,
64	    "bert-base-chinese": 512,
65	    "bert-base-german-cased": 512,
66	    "bert-large-uncased-whole-word-masking": 512,
67	    "bert-large-cased-whole-word-masking": 512,
68	    "bert-large-uncased-whole-word-masking-finetuned-squad": 512,
69	    "bert-large-cased-whole-word-masking-finetuned-squad": 512,
70	    "bert-base-cased-finetuned-mrpc": 512,
71	    "bert-base-german-dbmdz-cased": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
52	        "TurkuNLP/bert-base-finnish-uncased-v1": "https://huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/resolve/main/vocab.txt",
53	        "wietsedv/bert-base-dutch-cased": "https://huggingface.co/wietsedv/bert-base-dutch-cased/resolve/main/vocab.txt",
54	    }
55	}
56	
57	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
58	    "bert-base-uncased": 512,
59	    "bert-large-uncased": 512,
60	    "bert-base-cased": 512,
61	    "bert-large-cased": 512,
62	    "bert-base-multilingual-uncased": 512,
63	    "bert-base-multilingual-cased": 512,
64	    "bert-base-chinese": 512,
65	    "bert-base-german-cased": 512,
66	    "bert-large-uncased-whole-word-masking": 512,
67	    "bert-large-cased-whole-word-masking": 512,
68	    "bert-large-uncased-whole-word-masking-finetuned-squad": 512,
69	    "bert-large-cased-whole-word-masking-finetuned-squad": 512,
70	    "bert-base-cased-finetuned-mrpc": 512,
71	    "bert-base-german-dbmdz-cased": 512,
72	    "bert-base-german-dbmdz-uncased": 512,

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/bert/tokenization_bert.py:350
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
349	                    index = token_index
350	                writer.write(token + "\n")
351	                index += 1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/cpt/modeling_cpt.py:453
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
452	
453	CPT_START_DOCSTRING = r"""
454	    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic
455	    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
456	    pruning heads etc.)
457	    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__
458	    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
459	    general usage and behavior.
460	    Parameters:
461	        config (:class:`~transformers.CPTConfig`):
462	            Model configuration class with all the parameters of the model. Initializing with a config file does not
463	            load the weights associated with the model, only the configuration. Check out the
464	            :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model weights.
465	"""
466	
467	CPT_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/cpt/modeling_cpt.py:467
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
466	
467	CPT_INPUTS_DOCSTRING = r"""
468	    Args:
469	        input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`):
470	            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide
471	            it.
472	            Indices can be obtained using :class:`~transformers.CPTTokenizer`. See
473	            :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__` for
474	            details.
475	            `What are input IDs? <../glossary.html#input-ids>`__
476	        attention_mask (:obj:`torch.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):
477	            Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:
478	            - 1 for tokens that are **not masked**,
479	            - 0 for tokens that are **masked**.
480	            `What are attention masks? <../glossary.html#attention-mask>`__
481	        decoder_input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, target_sequence_length)`, `optional`):
482	            Indices of decoder input sequence tokens in the vocabulary.
483	            Indices can be obtained using :class:`~transformers.CPTTokenizer`. See
484	            :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__` for
485	            details.
486	            `What are input IDs? <../glossary.html#input-ids>`__
487	            CPT uses the :obj:`eos_token_id` as the starting token for :obj:`decoder_input_ids` generation. If
488	            :obj:`past_key_values` is used, optionally only the last :obj:`decoder_input_ids` have to be input (see
489	            :obj:`past_key_values`).
490	            For translation and summarization training, :obj:`decoder_input_ids` should be provided. If no
491	            :obj:`decoder_input_ids` is provided, the model will create this tensor by shifting the :obj:`input_ids` to
492	            the right for denoising pre-training following the paper.
493	        decoder_attention_mask (:obj:`torch.LongTensor` of shape :obj:`(batch_size, target_sequence_length)`, `optional`):
494	            Default behavior: generate a tensor that ignores pad tokens in :obj:`decoder_input_ids`. Causal mask will
495	            also be used by default.
496	            If you want to change padding behavior, you should read :func:`modeling_cpt._prepare_decoder_inputs` and
497	            modify to your needs. See diagram 1 in `the paper <https://arxiv.org/abs/1910.13461>`__ for more
498	            information on the default strategy.
499	        head_mask (:obj:`torch.Tensor` of shape :obj:`(num_layers, num_heads)`, `optional`):
500	            Mask to nullify selected heads of the attention modules in the encoder. Mask values selected in ``[0, 1]``:
501	            - 1 indicates the head is **not masked**,
502	            - 0 indicates the heas is **masked**.
503	        decoder_head_mask (:obj:`torch.Tensor` of shape :obj:`(num_layers, num_heads)`, `optional`):
504	            Mask to nullify selected heads of the attention modules in the decoder. Mask values selected in ``[0, 1]``:
505	            - 1 indicates the head is **not masked**,
506	            - 0 indicates the head is **masked**.
507	        encoder_outputs (:obj:`tuple(tuple(torch.FloatTensor)`, `optional`):
508	            Tuple consists of (:obj:`last_hidden_state`, `optional`: :obj:`hidden_states`, `optional`:
509	            :obj:`attentions`) :obj:`last_hidden_state` of shape :obj:`(batch_size, sequence_length, hidden_size)`,
510	            `optional`) is a sequence of hidden-states at the output of the last layer of the encoder. Used in the
511	            cross-attention of the decoder.
512	        past_key_values (:obj:`Tuple[Tuple[torch.Tensor]]` of length :obj:`config.n_layers` with each tuple having 2 tuples each of which has 2 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):
513	            Contains precomputed key and value hidden-states of the attention blocks. Can be used to speed up decoding.
514	            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`
515	            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`
516	            instead of all :obj:`decoder_input_ids`` of shape :obj:`(batch_size, sequence_length)`.
517	        inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):
518	            Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.
519	            This is useful if you want more control over how to convert :obj:`input_ids` indices into associated
520	            vectors than the model's internal embedding lookup matrix.
521	        decoder_inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, target_sequence_length, hidden_size)`, `optional`):
522	            Optionally, instead of passing :obj:`decoder_input_ids` you can choose to directly pass an embedded
523	            representation. If :obj:`past_key_values` is used, optionally only the last :obj:`decoder_inputs_embeds`
524	            have to be input (see :obj:`past_key_values`). This is useful if you want more control over how to convert
525	            :obj:`decoder_input_ids` indices into associated vectors than the model's internal embedding lookup matrix.
526	            If :obj:`decoder_input_ids` and :obj:`decoder_inputs_embeds` are both unset, :obj:`decoder_inputs_embeds`
527	            takes the value of :obj:`inputs_embeds`.
528	        use_cache (:obj:`bool`, `optional`):
529	            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up
530	            decoding (see :obj:`past_key_values`).
531	        output_attentions (:obj:`bool`, `optional`):
532	            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned
533	            tensors for more detail.
534	        output_hidden_states (:obj:`bool`, `optional`):
535	            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for
536	            more detail.
537	        return_dict (:obj:`bool`, `optional`):
538	            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.
539	"""
540	
541	class CPTDecoder(CPTPretrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/configuration_gpt2.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP = {
26	    "gpt2": "https://huggingface.co/gpt2/resolve/main/config.json",
27	    "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/config.json",
28	    "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/config.json",
29	    "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/config.json",
30	    "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/config.json",
31	}
32	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/configuration_gpt2.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
26	    "gpt2": "https://huggingface.co/gpt2/resolve/main/config.json",
27	    "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/config.json",
28	    "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/config.json",
29	    "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/config.json",
30	    "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/config.json",
31	}
32	
33	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/configuration_gpt2.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
27	    "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/config.json",
28	    "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/config.json",
29	    "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/config.json",
30	    "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/config.json",
31	}
32	
33	
34	class GPT2Config(PretrainedConfig):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/configuration_gpt2.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	    "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/config.json",
29	    "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/config.json",
30	    "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/config.json",
31	}
32	
33	
34	class GPT2Config(PretrainedConfig):
35	    """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/configuration_gpt2.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
29	    "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/config.json",
30	    "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/config.json",
31	}
32	
33	
34	class GPT2Config(PretrainedConfig):
35	    """
36	    This is the configuration class to store the configuration of a :class:`~transformers.GPT2Model` or a

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/modeling_gpt2.py:397
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
396	
397	GPT2_START_DOCSTRING = r"""
398	
399	    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic
400	    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
401	    pruning heads etc.)
402	
403	    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__
404	    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
405	    general usage and behavior.
406	
407	    Parameters:
408	        config (:class:`~transformers.GPT2Config`): Model configuration class with all the parameters of the model.
409	            Initializing with a config file does not load the weights associated with the model, only the
410	            configuration. Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model
411	            weights.
412	"""
413	
414	GPT2_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	    "vocab_file": {
40	        "gpt2": "https://huggingface.co/gpt2/resolve/main/vocab.json",
41	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/vocab.json",
42	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/vocab.json",
43	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/vocab.json",
44	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/vocab.json",
45	    },
46	    "merges_file": {
47	        "gpt2": "https://huggingface.co/gpt2/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	        "gpt2": "https://huggingface.co/gpt2/resolve/main/vocab.json",
41	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/vocab.json",
42	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/vocab.json",
43	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/vocab.json",
44	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/vocab.json",
45	    },
46	    "merges_file": {
47	        "gpt2": "https://huggingface.co/gpt2/resolve/main/merges.txt",
48	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
41	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/vocab.json",
42	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/vocab.json",
43	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/vocab.json",
44	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/vocab.json",
45	    },
46	    "merges_file": {
47	        "gpt2": "https://huggingface.co/gpt2/resolve/main/merges.txt",
48	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/merges.txt",
49	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/vocab.json",
43	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/vocab.json",
44	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/vocab.json",
45	    },
46	    "merges_file": {
47	        "gpt2": "https://huggingface.co/gpt2/resolve/main/merges.txt",
48	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/merges.txt",
49	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/merges.txt",
50	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
43	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/vocab.json",
44	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/vocab.json",
45	    },
46	    "merges_file": {
47	        "gpt2": "https://huggingface.co/gpt2/resolve/main/merges.txt",
48	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/merges.txt",
49	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/merges.txt",
50	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/merges.txt",
51	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	    "merges_file": {
47	        "gpt2": "https://huggingface.co/gpt2/resolve/main/merges.txt",
48	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/merges.txt",
49	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/merges.txt",
50	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/merges.txt",
51	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/merges.txt",
52	    },
53	}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
47	        "gpt2": "https://huggingface.co/gpt2/resolve/main/merges.txt",
48	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/merges.txt",
49	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/merges.txt",
50	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/merges.txt",
51	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/merges.txt",
52	    },
53	}
54	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
48	        "gpt2-medium": "https://huggingface.co/gpt2-medium/resolve/main/merges.txt",
49	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/merges.txt",
50	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/merges.txt",
51	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/merges.txt",
52	    },
53	}
54	
55	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	        "gpt2-large": "https://huggingface.co/gpt2-large/resolve/main/merges.txt",
50	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/merges.txt",
51	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/merges.txt",
52	    },
53	}
54	
55	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
56	    "gpt2": 1024,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
50	        "gpt2-xl": "https://huggingface.co/gpt2-xl/resolve/main/merges.txt",
51	        "distilgpt2": "https://huggingface.co/distilgpt2/resolve/main/merges.txt",
52	    },
53	}
54	
55	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
56	    "gpt2": 1024,
57	    "gpt2-medium": 1024,

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:185
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
184	        with open(merges_file, encoding="utf-8") as merges_handle:
185	            bpe_merges = merges_handle.read().split("\n")[1:-1]
186	        bpe_merges = [tuple(merge.split()) for merge in bpe_merges]

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:279
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
278	        with open(vocab_file, "w", encoding="utf-8") as f:
279	            f.write(json.dumps(self.encoder, ensure_ascii=False))
280	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:283
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
282	        with open(merge_file, "w", encoding="utf-8") as writer:
283	            writer.write("#version: 0.2\n")
284	            for bpe_tokens, token_index in sorted(self.bpe_ranks.items(), key=lambda kv: kv[1]):

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/gpt2/tokenization_gpt2.py:291
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
290	                    index = token_index
291	                writer.write(" ".join(bpe_tokens) + "\n")
292	                index += 1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/configuration_roberta.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP = {
26	    "roberta-base": "https://huggingface.co/roberta-base/resolve/main/config.json",
27	    "roberta-large": "https://huggingface.co/roberta-large/resolve/main/config.json",
28	    "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/config.json",
29	    "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/config.json",
30	    "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/config.json",
31	    "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/config.json",
32	}
33	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/configuration_roberta.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
26	    "roberta-base": "https://huggingface.co/roberta-base/resolve/main/config.json",
27	    "roberta-large": "https://huggingface.co/roberta-large/resolve/main/config.json",
28	    "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/config.json",
29	    "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/config.json",
30	    "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/config.json",
31	    "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/config.json",
32	}
33	
34	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/configuration_roberta.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
27	    "roberta-large": "https://huggingface.co/roberta-large/resolve/main/config.json",
28	    "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/config.json",
29	    "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/config.json",
30	    "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/config.json",
31	    "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/config.json",
32	}
33	
34	
35	class RobertaConfig(BertConfig):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/configuration_roberta.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	    "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/config.json",
29	    "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/config.json",
30	    "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/config.json",
31	    "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/config.json",
32	}
33	
34	
35	class RobertaConfig(BertConfig):
36	    r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/configuration_roberta.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
29	    "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/config.json",
30	    "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/config.json",
31	    "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/config.json",
32	}
33	
34	
35	class RobertaConfig(BertConfig):
36	    r"""
37	    This is the configuration class to store the configuration of a :class:`~transformers.RobertaModel` or a

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/configuration_roberta.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
30	    "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/config.json",
31	    "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/config.json",
32	}
33	
34	
35	class RobertaConfig(BertConfig):
36	    r"""
37	    This is the configuration class to store the configuration of a :class:`~transformers.RobertaModel` or a
38	    :class:`~transformers.TFRobertaModel`. It is used to instantiate a RoBERTa model according to the specified

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/modeling_roberta.py:635
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
634	
635	ROBERTA_START_DOCSTRING = r"""
636	
637	    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic
638	    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
639	    pruning heads etc.)
640	
641	    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__
642	    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
643	    general usage and behavior.
644	
645	    Parameters:
646	        config (:class:`~transformers.RobertaConfig`): Model configuration class with all the parameters of the
647	            model. Initializing with a config file does not load the weights associated with the model, only the
648	            configuration. Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model
649	            weights.
650	"""
651	
652	ROBERTA_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
33	    "vocab_file": {
34	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/vocab.json",
35	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/vocab.json",
36	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/vocab.json",
37	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/vocab.json",
38	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/vocab.json",
39	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/vocab.json",
40	    },
41	    "merges_file": {
42	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
34	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/vocab.json",
35	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/vocab.json",
36	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/vocab.json",
37	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/vocab.json",
38	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/vocab.json",
39	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/vocab.json",
40	    },
41	    "merges_file": {
42	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/merges.txt",
43	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/vocab.json",
36	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/vocab.json",
37	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/vocab.json",
38	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/vocab.json",
39	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/vocab.json",
40	    },
41	    "merges_file": {
42	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/merges.txt",
43	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/merges.txt",
44	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/vocab.json",
37	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/vocab.json",
38	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/vocab.json",
39	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/vocab.json",
40	    },
41	    "merges_file": {
42	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/merges.txt",
43	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/merges.txt",
44	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/merges.txt",
45	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
37	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/vocab.json",
38	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/vocab.json",
39	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/vocab.json",
40	    },
41	    "merges_file": {
42	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/merges.txt",
43	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/merges.txt",
44	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/merges.txt",
45	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/merges.txt",
46	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/vocab.json",
39	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/vocab.json",
40	    },
41	    "merges_file": {
42	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/merges.txt",
43	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/merges.txt",
44	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/merges.txt",
45	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/merges.txt",
46	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/merges.txt",
47	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/merges.txt",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
41	    "merges_file": {
42	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/merges.txt",
43	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/merges.txt",
44	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/merges.txt",
45	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/merges.txt",
46	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/merges.txt",
47	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/merges.txt",
48	    },
49	}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	        "roberta-base": "https://huggingface.co/roberta-base/resolve/main/merges.txt",
43	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/merges.txt",
44	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/merges.txt",
45	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/merges.txt",
46	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/merges.txt",
47	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/merges.txt",
48	    },
49	}
50	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
43	        "roberta-large": "https://huggingface.co/roberta-large/resolve/main/merges.txt",
44	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/merges.txt",
45	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/merges.txt",
46	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/merges.txt",
47	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/merges.txt",
48	    },
49	}
50	
51	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	        "roberta-large-mnli": "https://huggingface.co/roberta-large-mnli/resolve/main/merges.txt",
45	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/merges.txt",
46	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/merges.txt",
47	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/merges.txt",
48	    },
49	}
50	
51	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
52	    "roberta-base": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	        "distilroberta-base": "https://huggingface.co/distilroberta-base/resolve/main/merges.txt",
46	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/merges.txt",
47	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/merges.txt",
48	    },
49	}
50	
51	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
52	    "roberta-base": 512,
53	    "roberta-large": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/models/roberta/tokenization_roberta.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	        "roberta-base-openai-detector": "https://huggingface.co/roberta-base-openai-detector/resolve/main/merges.txt",
47	        "roberta-large-openai-detector": "https://huggingface.co/roberta-large-openai-detector/resolve/main/merges.txt",
48	    },
49	}
50	
51	PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
52	    "roberta-base": 512,
53	    "roberta-large": 512,
54	    "roberta-large-mnli": 512,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils.py:597
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
596	            raise NotImplementedError(
597	                "return_offset_mapping is not available when using Python tokenizers."
598	                "To use this feature, change your tokenizer to one deriving from "
599	                "transformers.PreTrainedTokenizerFast."

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1456
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1455	        if value == self.model_max_length - self.num_special_tokens_to_add(pair=False) and self.verbose:
1456	            if not self.deprecation_warnings.get("max_len_single_sentence", False):
1457	                logger.warning(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1470
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1469	        if value == self.model_max_length - self.num_special_tokens_to_add(pair=True) and self.verbose:
1470	            if not self.deprecation_warnings.get("max_len_sentences_pair", False):
1471	                logger.warning(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1688
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1687	            msg = (
1688	                f"Can't load tokenizer for '{pretrained_model_name_or_path}'. Make sure that:\n\n"
1689	                f"- '{pretrained_model_name_or_path}' is a correct model identifier listed on 'https://huggingface.co/models'\n\n"
1690	                f"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing relevant tokenizer files\n\n"
1691	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1694
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1693	            if revision is not None:
1694	                msg += f"- or '{revision}' is a valid git identifier (branch name, a tag name, or a commit id) that exists for this model name as listed on its model page on 'https://huggingface.co/models'\n\n"
1695	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1728
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1727	        # file or if `from_slow` is set to True.
1728	        from_slow = kwargs.get("from_slow", False)
1729	        has_tokenizer_file = resolved_vocab_files.get("tokenizer_file", None) is not None

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1729
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1728	        from_slow = kwargs.get("from_slow", False)
1729	        has_tokenizer_file = resolved_vocab_files.get("tokenizer_file", None) is not None
1730	        if (from_slow or not has_tokenizer_file) and cls.slow_tokenizer_class is not None:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1748
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1747	            # First attempt. We get tokenizer_class from tokenizer_config to check mismatch between tokenizers.
1748	            config_tokenizer_class = init_kwargs.get("tokenizer_class")
1749	            init_kwargs.pop("tokenizer_class", None)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1783
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1782	                if model_type is not None:
1783	                    config_tokenizer_class, config_tokenizer_class_fast = TOKENIZER_MAPPING_NAMES.get(
1784	                        model_type, (None, None)
1785	                    )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1820
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1819	            if model_max_length is not None and isinstance(model_max_length, (int, float)):
1820	                init_kwargs["model_max_length"] = min(init_kwargs.get("model_max_length", int(1e30)), model_max_length)
1821	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1991
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1990	        with open(tokenizer_config_file, "w", encoding="utf-8") as f:
1991	            f.write(json.dumps(tokenizer_config, ensure_ascii=False))
1992	        logger.info(f"tokenizer config file saved in {tokenizer_config_file}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:1997
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1996	        with open(special_tokens_map_file, "w", encoding="utf-8") as f:
1997	            f.write(json.dumps(write_dict, ensure_ascii=False))
1998	        logger.info(f"Special tokens file saved in {special_tokens_map_file}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:2038
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
2037	                out_str = json.dumps(added_vocab, ensure_ascii=False)
2038	                f.write(out_str)
2039	                logger.info(f"added tokens file saved in {added_tokens_file}")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:2152
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
2151	            if verbose:
2152	                if not self.deprecation_warnings.get("Truncation-not-explicitly-activated", False):
2153	                    logger.warning(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:2228
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
2227	                    if verbose:
2228	                        if not self.deprecation_warnings.get("Asking-to-pad-to-max_length", False):
2229	                            logger.warning(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:2241
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
2240	                    if verbose:
2241	                        if not self.deprecation_warnings.get("Asking-to-truncate-to-max_length", False):
2242	                            logger.warning(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/fastNLP/transformers/torch/tokenization_utils_base.py:3253
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
3252	        if max_length is None and len(ids) > self.model_max_length and verbose:
3253	            if not self.deprecation_warnings.get("sequence-length-is-longer-than-the-specified-maximum", False):
3254	                logger.warning(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/fastnlp-1.0.1/FastNLP-1.0.1/setup.py:20
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
19	    version='1.0.1',
20	    url='https://gitee.com/fastnlp/fastNLP',
21	    description='fastNLP: Deep Learning Toolkit for NLP, developed by Fudan FastNLP Team',

--------------------------------------------------

Code scanned:
	Total lines of code: 52389
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 118.0
		High: 86.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 199.0
		High: 5.0
Files skipped (0):
