Run started:2025-05-25 12:44:36.747153

Test results:
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/.buildkite/generate_index.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
23	    # cloudfront requires escaping the '+' character
24	    f.write(
25	        template.format(wheel=filename,
26	                        wheel_html_escaped=filename.replace("+", "%2B")))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/.buildkite/nightly-benchmarks/scripts/get-lmdeploy-modelname.py:5
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4	
5	api_client = APIClient("http://localhost:8000")
6	model_name = api_client.available_models[0]

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/.buildkite/nightly-benchmarks/scripts/summary-nightly-results.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
41	        with open(test_file) as f:
42	            raw_result = json.loads(f.read())
43	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/.buildkite/nightly-benchmarks/scripts/summary-nightly-results.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
45	        with open(test_file.with_suffix(".commands")) as f:
46	            command = json.loads(f.read())
47	        raw_result.update(command)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/.buildkite/nightly-benchmarks/scripts/summary-nightly-results.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
77	        # for those who wants to reproduce our benchmark.
78	        f.write(serving_md_table_with_headers)
79	        f.write('\n')

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/.buildkite/nightly-benchmarks/scripts/summary-nightly-results.py:79
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
78	        f.write(serving_md_table_with_headers)
79	        f.write('\n')
80	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/.buildkite/nightly-benchmarks/scripts/summary-nightly-results.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
84	        results = serving_results.to_dict(orient='records')
85	        f.write(json.dumps(results))

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/backend_request_func.py:448
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
447	        with get_lock(pretrained_model_name_or_path):
448	            model_path = snapshot_download(
449	                model_id=pretrained_model_name_or_path,
450	                local_files_only=huggingface_hub.constants.HF_HUB_OFFLINE,
451	                ignore_file_pattern=[".*.pt", ".*.safetensors", ".*.bin"])
452	

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/benchmark_dataset.py:265
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
264	            image.save(image_data, format="JPEG")
265	            image_base64 = base64.b64encode(
266	                image_data.getvalue()).decode("utf-8")
267	        return {

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/benchmark_dataset.py:265
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
264	            image.save(image_data, format="JPEG")
265	            image_base64 = base64.b64encode(
266	                image_data.getvalue()).decode("utf-8")
267	        return {

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/benchmark_serving.py:754
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
753	    # Use 127.0.0.1 here instead of localhost to force the use of ipv4
754	    parser.add_argument("--host", type=str, default="127.0.0.1")
755	    parser.add_argument("--port", type=int, default=8000)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/benchmark_serving.py:915
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
914	        required=False,
915	        help="Specify service level objectives for goodput as \"KEY:VALUE\" "
916	        "pairs, where the key is a metric name, and the value is in "

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/benchmark_serving_structured_output.py:837
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
836	    # Use 127.0.0.1 here instead of localhost to force the use of ipv4
837	    parser.add_argument("--host", type=str, default="127.0.0.1")
838	    parser.add_argument("--port", type=int, default=8000)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/benchmark_serving_structured_output.py:983
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
982	        required=False,
983	        help="Specify service level objectives for goodput as \"KEY:VALUE\" "
984	        "pairs, where the key is a metric name, and the value is in "

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/disagg_benchmarks/disagg_prefill_proxy_server.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
26	                else:
27	                    content = await response.read()
28	                    yield content

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/disagg_benchmarks/disagg_prefill_proxy_server.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
40	        # finish prefill
41	        async for _ in forward_request('http://localhost:8100/v1/completions',
42	                                       prefill_request):
43	            continue

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/disagg_benchmarks/disagg_prefill_proxy_server.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	        # finish prefill
41	        async for _ in forward_request('http://localhost:8100/v1/completions',
42	                                       prefill_request):
43	            continue

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/disagg_benchmarks/disagg_prefill_proxy_server.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
45	        # return decode
46	        generator = forward_request('http://localhost:8200/v1/completions',
47	                                    original_request_data)
48	        response = await make_response(generator)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/disagg_benchmarks/disagg_prefill_proxy_server.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	        # return decode
46	        generator = forward_request('http://localhost:8200/v1/completions',
47	                                    original_request_data)
48	        response = await make_response(generator)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/disagg_benchmarks/round_robin_proxy.py:18
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
17	        target_port = next(self.port_cycle)
18	        target_url = f"http://localhost:{target_port}{request.path_qs}"
19	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/disagg_benchmarks/round_robin_proxy.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
22	                # Forward the request
23	                async with session.request(
24	                        method=request.method,
25	                        url=target_url,
26	                        headers=request.headers,
27	                        data=request.content,
28	                ) as response:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/disagg_benchmarks/round_robin_proxy.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
54	
55	    print("Proxy server started on http://localhost:8000")
56	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/kernels/benchmark_w8a8_block_fp8.py:277
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
276	        json.dump(configs, f, indent=4)
277	        f.write("\n")
278	

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/benchmarks/kernels/benchmark_w8a8_block_fp8.py:388
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
387	    ctx = mp.get_context("spawn")
388	    with ctx.Pool(num_gpus) as pool:
389	        pool.map(tune_on_gpu, process_args)

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/csrc/quantization/machete/generate.py:647
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
646	    if os.path.exists(output_dir):
647	        shutil.rmtree(output_dir)
648	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/csrc/quantization/machete/generate.py:656
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
655	        with open(filepath, "w") as output_file:
656	            output_file.write(code)
657	        print(f"Rendered template to {filepath}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:77
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
76	    'path_to_docs': 'docs/source',
77	    'repository_url': 'https://github.com/vllm-project/vllm',
78	    'use_repository_button': True,
79	    'use_edit_page_button': True,
80	}
81	# Add any paths that contain custom static files (such as style sheets) here,
82	# relative to this directory. They are copied after the builtin static files,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
95	        "url":
96	        "https://github.com/vllm-project/vllm/issues/{{path}}#{{fragment}}",
97	        "title": "Issue #{{path}}",
98	        "classes": ["github"],
99	    },
100	    "gh-pr": {
101	        "url":
102	        "https://github.com/vllm-project/vllm/pull/{{path}}#{{fragment}}",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:102
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
101	        "url":
102	        "https://github.com/vllm-project/vllm/pull/{{path}}#{{fragment}}",
103	        "title": "Pull Request #{{path}}",
104	        "classes": ["github"],
105	    },
106	    "gh-project": {
107	        "url": "https://github.com/orgs/vllm-project/projects/{{path}}",
108	        "title": "Project #{{path}}",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:107
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
106	    "gh-project": {
107	        "url": "https://github.com/orgs/vllm-project/projects/{{path}}",
108	        "title": "Project #{{path}}",
109	        "classes": ["github"],
110	    },
111	    "gh-dir": {
112	        "url": "https://github.com/vllm-project/vllm/tree/main/{{path}}",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
111	    "gh-dir": {
112	        "url": "https://github.com/vllm-project/vllm/tree/main/{{path}}",
113	        "title": "{{path}}",
114	        "classes": ["github"],
115	    },
116	    "gh-file": {
117	        "url": "https://github.com/vllm-project/vllm/blob/main/{{path}}",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
116	    "gh-file": {
117	        "url": "https://github.com/vllm-project/vllm/blob/main/{{path}}",
118	        "title": "{{path}}",
119	        "classes": ["github"],
120	    },
121	}

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:124
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
123	# see https://docs.readthedocs.io/en/stable/reference/environment-variables.html # noqa
124	READTHEDOCS_VERSION_TYPE = os.environ.get('READTHEDOCS_VERSION_TYPE')
125	if READTHEDOCS_VERSION_TYPE == "tag":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:150
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
149	
150	    url = f"https://api.github.com/repos/vllm-project/vllm/pulls/{pr_number}"
151	    response = requests.get(url)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:151
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
150	    url = f"https://api.github.com/repos/vllm-project/vllm/pulls/{pr_number}"
151	    response = requests.get(url)
152	    if response.status_code == 200:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:198
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
197	        if base and branch:
198	            return f"https://github.com/{base}/blob/{branch}/{filename}#L{lineno}"
199	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
200	    # Otherwise, link to the source file on the main branch
201	    return f"https://github.com/vllm-project/vllm/blob/main/{filename}#L{lineno}"
202	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:252
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
251	intersphinx_mapping = {
252	    "python": ("https://docs.python.org/3", None),
253	    "typing_extensions":
254	    ("https://typing-extensions.readthedocs.io/en/latest", None),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:254
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
253	    "typing_extensions":
254	    ("https://typing-extensions.readthedocs.io/en/latest", None),
255	    "aiohttp": ("https://docs.aiohttp.org/en/stable", None),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:255
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
254	    ("https://typing-extensions.readthedocs.io/en/latest", None),
255	    "aiohttp": ("https://docs.aiohttp.org/en/stable", None),
256	    "pillow": ("https://pillow.readthedocs.io/en/stable", None),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:256
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
255	    "aiohttp": ("https://docs.aiohttp.org/en/stable", None),
256	    "pillow": ("https://pillow.readthedocs.io/en/stable", None),
257	    "numpy": ("https://numpy.org/doc/stable", None),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:257
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
256	    "pillow": ("https://pillow.readthedocs.io/en/stable", None),
257	    "numpy": ("https://numpy.org/doc/stable", None),
258	    "torch": ("https://pytorch.org/docs/stable", None),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:258
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
257	    "numpy": ("https://numpy.org/doc/stable", None),
258	    "torch": ("https://pytorch.org/docs/stable", None),
259	    "psutil": ("https://psutil.readthedocs.io/en/stable", None),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/docs/source/conf.py:259
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
258	    "torch": ("https://pytorch.org/docs/stable", None),
259	    "psutil": ("https://psutil.readthedocs.io/en/stable", None),
260	}

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/data_parallel.py:136
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
135	    if node_size == 1:
136	        dp_master_ip = "127.0.0.1"
137	        dp_master_port = get_open_port()

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/data_parallel.py:150
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
149	            range(node_rank * dp_per_node, (node_rank + 1) * dp_per_node)):
150	        proc = Process(target=main,
151	                       args=(args.model, dp_size, local_dp_rank,
152	                             global_dp_rank, dp_master_ip, dp_master_port,
153	                             tp_size))
154	        proc.start()

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/disaggregated_prefill.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
99	    prefill_done = Event()
100	    prefill_process = Process(target=run_prefill, args=(prefill_done, ))
101	    decode_process = Process(target=run_decode, args=(prefill_done, ))

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/disaggregated_prefill.py:101
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
100	    prefill_process = Process(target=run_prefill, args=(prefill_done, ))
101	    decode_process = Process(target=run_decode, args=(prefill_done, ))
102	

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/disaggregated_prefill_lmcache.py:116
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
115	    prefill_done = Event()
116	    prefill_process = Process(target=run_prefill, args=(prefill_done, prompts))
117	    decode_process = Process(target=run_decode, args=(prefill_done, prompts))

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/disaggregated_prefill_lmcache.py:117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
116	    prefill_process = Process(target=run_prefill, args=(prefill_done, prompts))
117	    decode_process = Process(target=run_decode, args=(prefill_done, prompts))
118	    lmcache_server_process = run_lmcache_server(port)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/eagle.py:16
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
15	    default="./examples/data/gsm8k.jsonl",
16	    help="downloaded from the eagle repo " \
17	    "https://github.com/SafeAILab/EAGLE/blob/main/eagle/data/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/mistral-small.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
63	    prompt = "Describe this image in one sentence."
64	    image_url = "https://picsum.photos/id/237/200/300"
65	
66	    messages = [

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/mistral-small.py:107
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
106	
107	    url_1 = "https://huggingface.co/datasets/patrickvonplaten/random_img/resolve/main/yosemite.png"
108	    url_2 = "https://picsum.photos/seed/picsum/200/300"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/mistral-small.py:108
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
107	    url_1 = "https://huggingface.co/datasets/patrickvonplaten/random_img/resolve/main/yosemite.png"
108	    url_2 = "https://picsum.photos/seed/picsum/200/300"
109	    url_3 = "https://picsum.photos/id/32/512/512"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/mistral-small.py:109
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
108	    url_2 = "https://picsum.photos/seed/picsum/200/300"
109	    url_3 = "https://picsum.photos/id/32/512/512"
110	
111	    messages = [

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/prithvi_geospatial_mae.py:115
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
114	          'w') as config_file:
115	    config_file.write(model_config)
116	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/prithvi_geospatial_mae.py:228
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
227	    with rasterio.open(file_path) as src:
228	        img = src.read()
229	        meta = src.meta

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/prithvi_geospatial_mae.py:250
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
249	        for i in range(image.shape[0]):
250	            dest.write(image[i, :, :], i + 1)
251	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/profiling_tpu/profiling.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
94	        help=
95	        ('path to save the pytorch profiler output. Can be visualized '
96	         'with ui.perfetto.dev or Tensorboard '
97	         '(https://cloud.google.com/tpu/docs/pytorch-xla-performance-profiling-tpu-vm).'

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/vision_language_embedding.py:113
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
112	            image=fetch_image(
113	                "https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/American_Eskimo_Dog.jpg/360px-American_Eskimo_Dog.jpg"  # noqa: E501
114	            ),
115	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/vision_language_embedding.py:122
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
121	            image=fetch_image(
122	                "https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Felis_catus-cat_on_snow.jpg/179px-Felis_catus-cat_on_snow.jpg"  # noqa: E501
123	            ),
124	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/vision_language_multi_image.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
22	IMAGE_URLS = [
23	    "https://upload.wikimedia.org/wikipedia/commons/d/da/2015_Kaczka_krzy%C5%BCowka_w_wodzie_%28samiec%29.jpg",
24	    "https://upload.wikimedia.org/wikipedia/commons/7/77/002_The_lion_king_Snyggve_in_the_Serengeti_National_Park_Photo_by_Giles_Laurent.jpg",
25	]
26	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/offline_inference/vision_language_multi_image.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
23	    "https://upload.wikimedia.org/wikipedia/commons/d/da/2015_Kaczka_krzy%C5%BCowka_w_wodzie_%28samiec%29.jpg",
24	    "https://upload.wikimedia.org/wikipedia/commons/7/77/002_The_lion_king_Snyggve_in_the_Serengeti_National_Park_Photo_by_Giles_Laurent.jpg",
25	]
26	
27	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/api_client.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
34	    }
35	    response = requests.post(api_url,
36	                             headers=headers,
37	                             json=pload,
38	                             stream=stream)
39	    return response

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/api_client.py:72
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
71	    print(f"Prompt: {prompt!r}\n", flush=True)
72	    response = post_http_request(prompt, api_url, n, stream)
73	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/cohere_rerank_client.py:11
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
10	# cohere v1 client
11	co = cohere.Client(base_url="http://localhost:8000", api_key="sk-fake-key")
12	rerank_v1_result = co.rerank(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/cohere_rerank_client.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
22	# or the v2
23	co2 = cohere.ClientV2("sk-fake-key", base_url="http://localhost:8000")
24	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
69	    def setup_routes(self):
70	        self.router.post(
71	            "/v1/completions",
72	            dependencies=[
73	                Depends(self.validate_json_request)
74	            ])(self.custom_create_completion if self.

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
75	               custom_create_completion else self.create_completion)
76	        self.router.post(
77	            "/v1/chat/completions",
78	            dependencies=[
79	                Depends(self.validate_json_request)
80	            ])(self.custom_create_chat_completion if self.

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:82
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
81	               custom_create_chat_completion else self.create_chat_completion)
82	        self.router.get("/status",
83	                        response_class=JSONResponse)(self.get_status)
84	        self.router.post("/instances/add",

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:84
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
83	                        response_class=JSONResponse)(self.get_status)
84	        self.router.post("/instances/add",
85	                         dependencies=[Depends(self.api_key_authenticate)
86	                                       ])(self.add_instance_endpoint)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
88	    async def validate_json_request(self, raw_request: Request):
89	        content_type = raw_request.headers.get("content-type", "").lower()
90	        if content_type != "application/json":

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:98
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
97	    def api_key_authenticate(self, x_api_key: str = Header(...)):
98	        expected_api_key = os.environ.get("ADMIN_API_KEY")
99	        if not expected_api_key:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:119
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
118	                logger.info("Verifying %s ...", instance)
119	                async with client.get(url) as response:
120	                    if response.status == 200:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:123
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
122	                        if "data" in data and len(data["data"]) > 0:
123	                            model_cur = data["data"][0].get("id", "")
124	                            if model_cur == self.model:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:147
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
146	            logger.warning(str(data))
147	            instance_type = data.get("type")
148	            instance = data.get("instance")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:148
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
147	            instance_type = data.get("type")
148	            instance = data.get("instance")
149	            if instance_type not in ["prefill", "decode"]:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
200	            headers = {
201	                "Authorization": f"Bearer {os.environ.get('OPENAI_API_KEY')}"
202	            }

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:204
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
203	            try:
204	                async with session.post(url=url, json=data,
205	                                        headers=headers) as response:
206	                    if 200 <= response.status < 300 or 400 <= response.status < 500:  # noqa: E501

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:212
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
211	                        else:
212	                            content = await response.read()
213	                            yield content

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:260
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
259	            try:
260	                async for _ in self.forward_request(
261	                        f"http://{prefill_instance}/v1/completions",
262	                        kv_prepare_request):
263	                    continue

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:260
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
259	            try:
260	                async for _ in self.forward_request(
261	                        f"http://{prefill_instance}/v1/completions",
262	                        kv_prepare_request):
263	                    continue

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:272
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
271	            try:
272	                generator = self.forward_request(
273	                    f"http://{decode_instance}/v1/completions", request)
274	            except HTTPException as http_exc:

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:272
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
271	            try:
272	                generator = self.forward_request(
273	                    f"http://{decode_instance}/v1/completions", request)
274	            except HTTPException as http_exc:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:297
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
296	            try:
297	                async for _ in self.forward_request(
298	                        f"http://{prefill_instance}/v1/chat/completions",
299	                        kv_prepare_request):
300	                    continue

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:297
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
296	            try:
297	                async for _ in self.forward_request(
298	                        f"http://{prefill_instance}/v1/chat/completions",
299	                        kv_prepare_request):
300	                    continue

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:308
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
307	            try:
308	                generator = self.forward_request(
309	                    "http://" + decode_instance + "/v1/chat/completions",
310	                    request)
311	            except HTTPException as http_exc:

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:308
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
307	            try:
308	                generator = self.forward_request(
309	                    "http://" + decode_instance + "/v1/chat/completions",
310	                    request)
311	            except HTTPException as http_exc:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/disagg_examples/disagg_proxy_demo.py:395
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
394	            try:
395	                response = requests.get(f"http://{instance}/v1/models")
396	                if response.status_code == 200:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/gradio_openai_chatbot_webserver.py:13
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
12	                    type=str,
13	                    default='http://localhost:8000/v1',
14	                    help='Model URL')

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/gradio_webserver.py:17
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
16	    }
17	    response = requests.post(args.model_url,
18	                             headers=headers,
19	                             json=pload,
20	                             stream=True)
21	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/gradio_webserver.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
47	                        type=str,
48	                        default="http://localhost:8000/generate")
49	    args = parser.parse_args()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/jinaai_rerank_client.py:12
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
11	
12	url = "http://127.0.0.1:8000/rerank"
13	
14	headers = {"accept": "application/json", "Content-Type": "application/json"}

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/jinaai_rerank_client.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
25	}
26	response = requests.post(url, headers=headers, json=data)
27	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client.py:7
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
6	openai_api_key = "EMPTY"
7	openai_api_base = "http://localhost:8000/v1"
8	
9	client = OpenAI(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_for_multimodal.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	openai_api_key = "EMPTY"
26	openai_api_base = "http://localhost:8000/v1"
27	
28	client = OpenAI(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_for_multimodal.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
40	
41	    with requests.get(content_url) as response:
42	        response.raise_for_status()

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_for_multimodal.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
42	        response.raise_for_status()
43	        result = base64.b64encode(response.content).decode('utf-8')
44	

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_for_multimodal.py:43
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
42	        response.raise_for_status()
43	        result = base64.b64encode(response.content).decode('utf-8')
44	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_for_multimodal.py:67
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
66	    ## Use image url in the payload
67	    image_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
68	    chat_completion_from_url = client.chat.completions.create(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_for_multimodal.py:121
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
120	def run_multi_image() -> None:
121	    image_url_duck = "https://upload.wikimedia.org/wikipedia/commons/d/da/2015_Kaczka_krzy%C5%BCowka_w_wodzie_%28samiec%29.jpg"
122	    image_url_lion = "https://upload.wikimedia.org/wikipedia/commons/7/77/002_The_lion_king_Snyggve_in_the_Serengeti_National_Park_Photo_by_Giles_Laurent.jpg"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_for_multimodal.py:122
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
121	    image_url_duck = "https://upload.wikimedia.org/wikipedia/commons/d/da/2015_Kaczka_krzy%C5%BCowka_w_wodzie_%28samiec%29.jpg"
122	    image_url_lion = "https://upload.wikimedia.org/wikipedia/commons/7/77/002_The_lion_king_Snyggve_in_the_Serengeti_National_Park_Photo_by_Giles_Laurent.jpg"
123	    chat_completion_from_url = client.chat.completions.create(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_for_multimodal.py:156
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
155	def run_video() -> None:
156	    video_url = "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerFun.mp4"
157	    video_base64 = encode_base64_content_from_url(video_url)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_with_tools.py:25
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
24	openai_api_key = "EMPTY"
25	openai_api_base = "http://localhost:8000/v1"
26	
27	client = OpenAI(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_client_with_tools_required.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
18	openai_api_key = "EMPTY"
19	openai_api_base = "http://localhost:8000/v1"
20	
21	client = OpenAI(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_structured_outputs.py:9
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
8	client = OpenAI(
9	    base_url="http://localhost:8000/v1",
10	    api_key="-",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_structured_outputs_with_reasoning.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	openai_api_key = "EMPTY"
26	openai_api_base = "http://localhost:8000/v1"
27	
28	client = OpenAI(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_tool_calls_with_reasoning.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	openai_api_key = "EMPTY"
32	openai_api_base = "http://localhost:8000/v1"
33	
34	client = OpenAI(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_with_reasoning.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
21	openai_api_key = "EMPTY"
22	openai_api_base = "http://localhost:8000/v1"
23	
24	client = OpenAI(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_completion_with_reasoning_streaming.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
29	openai_api_key = "EMPTY"
30	openai_api_base = "http://localhost:8000/v1"
31	
32	client = OpenAI(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_embedding_client_for_multimodal.py:10
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
9	
10	image_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
11	
12	
13	def vlm2vec():

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_embedding_client_for_multimodal.py:14
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
13	def vlm2vec():
14	    response = requests.post(
15	        "http://localhost:8000/v1/embeddings",
16	        json={
17	            "model":
18	            "TIGER-Lab/VLM2Vec-Full",
19	            "messages": [{
20	                "role":
21	                "user",
22	                "content": [
23	                    {
24	                        "type": "image_url",
25	                        "image_url": {
26	                            "url": image_url
27	                        }
28	                    },
29	                    {
30	                        "type": "text",
31	                        "text": "Represent the given image."
32	                    },
33	                ],
34	            }],
35	            "encoding_format":
36	            "float",
37	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_embedding_client_for_multimodal.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
14	    response = requests.post(
15	        "http://localhost:8000/v1/embeddings",
16	        json={
17	            "model":
18	            "TIGER-Lab/VLM2Vec-Full",
19	            "messages": [{
20	                "role":
21	                "user",
22	                "content": [
23	                    {
24	                        "type": "image_url",
25	                        "image_url": {
26	                            "url": image_url
27	                        }
28	                    },
29	                    {
30	                        "type": "text",
31	                        "text": "Represent the given image."
32	                    },
33	                ],
34	            }],
35	            "encoding_format":
36	            "float",
37	        },
38	    )

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_embedding_client_for_multimodal.py:69
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
68	        buffer.seek(0)
69	        image_placeholder = base64.b64encode(buffer.read()).decode('utf-8')
70	        messages = [{

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_embedding_client_for_multimodal.py:69
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
68	        buffer.seek(0)
69	        image_placeholder = base64.b64encode(buffer.read()).decode('utf-8')
70	        messages = [{

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_embedding_client_for_multimodal.py:87
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
86	
87	    response = requests.post(
88	        "http://localhost:8000/v1/embeddings",
89	        json={
90	            "model": "MrLight/dse-qwen2-2b-mrl-v1",
91	            "messages": messages,
92	            "encoding_format": "float",
93	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_chat_embedding_client_for_multimodal.py:88
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
87	    response = requests.post(
88	        "http://localhost:8000/v1/embeddings",
89	        json={
90	            "model": "MrLight/dse-qwen2-2b-mrl-v1",
91	            "messages": messages,
92	            "encoding_format": "float",
93	        },
94	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_completion_client.py:7
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
6	openai_api_key = "EMPTY"
7	openai_api_base = "http://localhost:8000/v1"
8	
9	client = OpenAI(

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_cross_encoder_score.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
14	    headers = {"User-Agent": "Test Client"}
15	    response = requests.post(api_url, headers=headers, json=prompt)
16	    return response

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_cross_encoder_score.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
31	    prompt = {"model": model_name, "text_1": text_1, "text_2": text_2}
32	    score_response = post_http_request(prompt=prompt, api_url=api_url)
33	    print("Prompt when text_1 and text_2 are both strings:")

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_cross_encoder_score.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
42	    prompt = {"model": model_name, "text_1": text_1, "text_2": text_2}
43	    score_response = post_http_request(prompt=prompt, api_url=api_url)
44	    print("Prompt when text_1 is string and text_2 is a list:")

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_cross_encoder_score.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
55	    prompt = {"model": model_name, "text_1": text_1, "text_2": text_2}
56	    score_response = post_http_request(prompt=prompt, api_url=api_url)
57	    print("Prompt when text_1 and text_2 are both lists:")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_embedding_client.py:7
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
6	openai_api_key = "EMPTY"
7	openai_api_base = "http://localhost:8000/v1"
8	
9	client = OpenAI(

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_pooling_client.py:16
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
15	    headers = {"User-Agent": "Test Client"}
16	    response = requests.post(api_url, headers=headers, json=prompt)
17	    return response

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_pooling_client.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
33	    prompt = {"model": model_name, "input": "vLLM is great!"}
34	    pooling_response = post_http_request(prompt=prompt, api_url=api_url)
35	    print("Pooling Response:")

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_pooling_client.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
49	    }
50	    pooling_response = post_http_request(prompt=prompt, api_url=api_url)
51	    print("Pooling Response:")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/openai_transcription_client.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
14	openai_api_key = "EMPTY"
15	openai_api_base = "http://localhost:8000/v1"
16	client = OpenAI(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/opentelemetry/dummy_client.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
20	
21	url = "http://localhost:8000/v1/completions"
22	with tracer.start_as_current_span("client-span", kind=SpanKind.CLIENT) as span:

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/examples/online_serving/opentelemetry/dummy_client.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
35	    }
36	    response = requests.post(url, headers=headers, json=payload)

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/setup.py:77
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
76	    try:
77	        with urlopen(url) as f:
78	            status = f.status

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/setup.py:296
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
295	                "curl", "-s",
296	                "https://api.github.com/repos/vllm-project/vllm/commits/main"
297	            ]).decode("utf-8")
298	            upstream_main_commit = json.loads(resp_json)["sha"]
299	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/setup.py:310
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
309	                subprocess.check_call([
310	                    "git", "fetch", "https://github.com/vllm-project/vllm",
311	                    "main"
312	                ])
313	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/setup.py:339
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
338	            base_commit = self.get_base_commit_in_main_branch()
339	            wheel_location = f"https://wheels.vllm.ai/{base_commit}/vllm-1.0.0.dev-cp38-abi3-manylinux1_x86_64.whl"
340	            # Fallback to nightly wheel if latest commit wheel is unavailable,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/setup.py:343
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
342	            if not is_url_available(wheel_location):
343	                wheel_location = "https://wheels.vllm.ai/nightly/vllm-1.0.0.dev-cp38-abi3-manylinux1_x86_64.whl"
344	

--------------------------------------------------
>> Issue: [B819:urlretrieve] urllib.request.urlretrieve
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/setup.py:366
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b819_urlretrieve.html
365	            try:
366	                urlretrieve(wheel_location, filename=wheel_path)
367	            except Exception as e:

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/setup.py:470
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
469	            return None
470	        librocm_core = ctypes.CDLL(librocm_core_file)
471	        VerErrors = ctypes.c_uint32

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/setup.py:499
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
498	    with open(version_file) as fp:
499	        content = fp.read()
500	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/setup.py:593
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
592	        with open(requirements_dir / filename) as f:
593	            requirements = f.read().strip().split("\n")
594	        resolved_requirements = []

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
14	def _query_server(prompt: str, max_tokens: int = 5) -> dict:
15	    response = requests.post("http://localhost:8000/generate",
16	                             json={
17	                                 "prompt": prompt,
18	                                 "max_tokens": max_tokens,
19	                                 "temperature": 0,
20	                                 "ignore_eos": True
21	                             })

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
14	def _query_server(prompt: str, max_tokens: int = 5) -> dict:
15	    response = requests.post("http://localhost:8000/generate",
16	                             json={
17	                                 "prompt": prompt,
18	                                 "max_tokens": max_tokens,
19	                                 "temperature": 0,
20	                                 "ignore_eos": True
21	                             })

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
40	        "--host",
41	        "127.0.0.1",
42	        "--tokenizer-pool-size",
43	        str(tokenizer_pool_size),
44	        "--distributed-executor-backend",
45	        distributed_executor_backend,
46	    ]
47	
48	    # API Server Test Requires V0.
49	    my_env = os.environ.copy()
50	    my_env["VLLM_USE_V1"] = "0"
51	    uvicorn_process = subprocess.Popen(commands, env=my_env)
52	    yield
53	    uvicorn_process.terminate()

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:69
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
68	    """
69	    with Pool(32) as pool:
70	        # Wait until the server is ready

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:69
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
68	    """
69	    with Pool(32) as pool:
70	        # Wait until the server is ready

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:86
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
85	
86	        num_aborted_requests = requests.get(
87	            "http://localhost:8000/stats").json()["num_aborted_requests"]
88	        assert num_aborted_requests == 0

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:87
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
86	        num_aborted_requests = requests.get(
87	            "http://localhost:8000/stats").json()["num_aborted_requests"]
88	        assert num_aborted_requests == 0
89	

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
94	
95	    with Pool(32) as pool:
96	        # Cancel requests

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:95
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
94	
95	    with Pool(32) as pool:
96	        # Cancel requests

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:107
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
106	
107	        num_aborted_requests = requests.get(
108	            "http://localhost:8000/stats").json()["num_aborted_requests"]
109	        assert num_aborted_requests > 0

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:108
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
107	        num_aborted_requests = requests.get(
108	            "http://localhost:8000/stats").json()["num_aborted_requests"]
109	        assert num_aborted_requests > 0
110	

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
111	    # check that server still runs after cancellations
112	    with Pool(32) as pool:
113	        # Try with 100 prompts

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/async_engine/test_api_server.py:112
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
111	    # check that server still runs after cancellations
112	    with Pool(32) as pool:
113	        # Try with 100 prompts

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/conftest.py:206
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
205	    with open(_SYS_MSG) as f:
206	        return f.read()
207	

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/conftest.py:1050
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
1049	    if not os.path.exists(_dummy_opt_path):
1050	        snapshot_download(repo_id="facebook/opt-125m",
1051	                          local_dir=_dummy_opt_path,
1052	                          ignore_patterns=[
1053	                              "*.bin", "*.bin.index.json", "*.pt", "*.h5",
1054	                              "*.msgpack"
1055	                          ])

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/conftest.py:1058
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
1057	        with open(json_path) as f:
1058	            config = json.load(f)
1059	        config["architectures"] = ["MyOPTForCausalLM"]

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/conftest.py:1069
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
1068	    if not os.path.exists(_dummy_llava_path):
1069	        snapshot_download(repo_id="llava-hf/llava-1.5-7b-hf",
1070	                          local_dir=_dummy_llava_path,
1071	                          ignore_patterns=[
1072	                              "*.bin", "*.bin.index.json", "*.pt", "*.h5",
1073	                              "*.msgpack"
1074	                          ])

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/conftest.py:1077
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
1076	        with open(json_path) as f:
1077	            config = json.load(f)
1078	        config["architectures"] = ["MyLlava"]

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/conftest.py:1088
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
1087	    if not os.path.exists(_dummy_gemma2_embedding_path):
1088	        snapshot_download(repo_id="BAAI/bge-multilingual-gemma2",
1089	                          local_dir=_dummy_gemma2_embedding_path,
1090	                          ignore_patterns=[
1091	                              "*.bin", "*.bin.index.json", "*.pt", "*.h5",
1092	                              "*.msgpack"
1093	                          ])

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/conftest.py:1096
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
1095	        with open(json_path) as f:
1096	            config = json.load(f)
1097	        config["architectures"] = ["MyGemma2Embedding"]

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_pynccl.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
30	        env['MASTER_PORT'] = '12345'
31	        p = multiprocessing.Process(target=fn, args=(env, ))
32	        processes.append(p)

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_shm_broadcast.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
33	        env['MASTER_PORT'] = '12345'
34	        p = multiprocessing.Process(target=fn, args=(env, ))
35	        processes.append(p)

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_utils.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
47	def cpu_worker(rank, WORLD_SIZE, port1, port2):
48	    pg1 = StatelessProcessGroup.create(host="127.0.0.1",
49	                                       port=port1,

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_utils.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
52	    if rank <= 2:
53	        pg2 = StatelessProcessGroup.create(host="127.0.0.1",
54	                                           port=port2,

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_utils.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
69	    torch.cuda.set_device(rank)
70	    pg1 = StatelessProcessGroup.create(host="127.0.0.1",
71	                                       port=port1,

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_utils.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
75	    if rank <= 2:
76	        pg2 = StatelessProcessGroup.create(host="127.0.0.1",
77	                                           port=port2,

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_utils.py:98
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
97	def broadcast_worker(rank, WORLD_SIZE, port1, port2):
98	    pg1 = StatelessProcessGroup.create(host="127.0.0.1",
99	                                       port=port1,

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_utils.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
110	def allgather_worker(rank, WORLD_SIZE, port1, port2):
111	    pg1 = StatelessProcessGroup.create(host="127.0.0.1",
112	                                       port=port1,

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_utils.py:126
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
125	    port1 = get_open_port()
126	    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
127	        s.bind(("", port1))

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/distributed/test_utils.py:136
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
135	        processes.append(
136	            ctx.Process(target=worker, args=(rank, WORLD_SIZE, port1, port2)))
137	    for p in processes:

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/engine/test_multiproc_workers.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
61	
62	    executor = ThreadPoolExecutor(max_workers=4)
63	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/correctness/test_transcription_api_correctness.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
26	    buffer = io.BytesIO()
27	    soundfile.write(buffer, y, sr, format="WAV")
28	    buffer.seek(0)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_async_tokenization.py:123
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
122	        start_time = time.monotonic()
123	        res = requests.get(url)
124	        end_time = time.monotonic()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_basic.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
88	async def test_show_version(server: RemoteOpenAIServer):
89	    response = requests.get(server.url_for("version"))
90	    response.raise_for_status()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_basic.py:106
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
105	async def test_check_health(server: RemoteOpenAIServer):
106	    response = requests.get(server.url_for("health"))
107	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_basic.py:187
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
186	    # Check initial server load
187	    response = requests.get(server.url_for("load"))
188	    assert response.status_code == HTTPStatus.OK

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_basic.py:189
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
188	    assert response.status_code == HTTPStatus.OK
189	    assert response.json().get("server_load") == 0
190	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_basic.py:192
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
191	    def make_long_completion_request():
192	        return requests.post(
193	            server.url_for("v1/completions"),
194	            headers={"Content-Type": "application/json"},
195	            json={
196	                "prompt": "Give me a long story",
197	                "max_tokens": 1000,
198	                "temperature": 0,
199	            },

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_basic.py:210
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
209	    # Check server load while the completion request is running.
210	    response = requests.get(server.url_for("load"))
211	    assert response.status_code == HTTPStatus.OK

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_basic.py:212
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
211	    assert response.status_code == HTTPStatus.OK
212	    assert response.json().get("server_load") == 1
213	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_basic.py:219
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
218	    # Check server load after the completion request has finished.
219	    response = requests.get(server.url_for("load"))
220	    assert response.status_code == HTTPStatus.OK

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_basic.py:221
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
220	    assert response.status_code == HTTPStatus.OK
221	    assert response.json().get("server_load") == 0

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_chat.py:1137
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1136	async def test_http_chat_no_model_name_with_curl(server: RemoteOpenAIServer):
1137	    url = f"http://localhost:{server.port}/v1/chat/completions"
1138	    headers = {

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_chat.py:1154
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
1153	
1154	    response = requests.post(url, headers=headers, json=data)
1155	    response_data = response.json()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_chat.py:1157
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1156	    print(response_data)
1157	    assert response_data.get("model") == MODEL_NAME
1158	    choice = response_data.get("choices")[0]

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_chat.py:1158
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1157	    assert response_data.get("model") == MODEL_NAME
1158	    choice = response_data.get("choices")[0]
1159	    message = choice.get("message")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_chat.py:1159
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1158	    choice = response_data.get("choices")[0]
1159	    message = choice.get("message")
1160	    assert message is not None

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_chat.py:1161
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1160	    assert message is not None
1161	    content = message.get("content")
1162	    assert content is not None

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_chat.py:1172
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1171	    openai_api_key = "EMPTY"
1172	    openai_api_base = f"http://localhost:{server.port}/v1"
1173	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_embedding.py:144
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
143	
144	    chat_response = requests.post(
145	        server.url_for("v1/embeddings"),
146	        json={
147	            "model": model_name,
148	            "messages": messages,
149	            "encoding_format": "float",
150	        },

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_embedding.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
200	        decoded_responses_base64_data.append(
201	            np.frombuffer(base64.b64decode(data.embedding),
202	                          dtype="float32").tolist())

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_embedding.py:201
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
200	        decoded_responses_base64_data.append(
201	            np.frombuffer(base64.b64decode(data.embedding),
202	                          dtype="float32").tolist())

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_metrics.py:130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
129	
130	    response = requests.get(server.url_for("metrics"))
131	    print(response.text)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_metrics.py:292
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
291	
292	    response = requests.get(server.url_for("metrics"))
293	    assert response.status_code == HTTPStatus.OK

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_metrics.py:306
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
305	
306	    base_url = "0.0.0.0"
307	    port = "8001"

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_metrics.py:313
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
312	                "r") as output_file:
313	        input_file.write(input_batch)
314	        input_file.flush()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_metrics.py:334
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
333	            try:
334	                response = requests.get(url)
335	                return response.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_metrics.py:342
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
341	
342	        response = requests.get(server_url + "/metrics")
343	        assert response.status_code == HTTPStatus.OK

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
44	    # test single pooling
45	    response = requests.post(
46	        server.url_for("pooling"),
47	        json={
48	            "model": model_name,
49	            "input": input_texts,
50	            "encoding_format": "float"
51	        },

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:65
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
64	    input_tokens = [1, 1, 1, 1, 1]
65	    response = requests.post(
66	        server.url_for("pooling"),
67	        json={
68	            "model": model_name,
69	            "input": input_tokens,
70	            "encoding_format": "float"
71	        },

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:92
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
91	    ]
92	    response = requests.post(
93	        server.url_for("pooling"),
94	        json={
95	            "model": model_name,
96	            "input": input_texts,
97	            "encoding_format": "float"
98	        },

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:113
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
112	                    [25, 32, 64, 77]]
113	    response = requests.post(
114	        server.url_for("pooling"),
115	        json={
116	            "model": model_name,
117	            "input": input_tokens,
118	            "encoding_format": "float"
119	        },

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:147
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
146	
147	    chat_response = requests.post(
148	        server.url_for("pooling"),
149	        json={
150	            "model": model_name,
151	            "messages": messages,
152	            "encoding_format": "float",
153	        },

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:166
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
165	    )
166	    completions_response = requests.post(
167	        server.url_for("pooling"),
168	        json={
169	            "model": model_name,
170	            "input": prompt,
171	            "encoding_format": "float",
172	            # To be consistent with chat
173	            "add_special_tokens": False,
174	        },

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:197
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
196	
197	    float_response = requests.post(
198	        server.url_for("pooling"),
199	        json={
200	            "input": input_texts,
201	            "model": model_name,
202	            "encoding_format": "float",
203	        },

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:208
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
207	
208	    base64_response = requests.post(
209	        server.url_for("pooling"),
210	        json={
211	            "input": input_texts,
212	            "model": model_name,
213	            "encoding_format": "base64",
214	        },

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:222
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
221	        decoded_responses_base64_data.append(
222	            np.frombuffer(base64.b64decode(data.data),
223	                          dtype="float32").tolist())

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:222
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
221	        decoded_responses_base64_data.append(
222	            np.frombuffer(base64.b64decode(data.data),
223	                          dtype="float32").tolist())

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_pooling.py:229
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
228	    # Default response is float32 decoded from base64 by OpenAI Client
229	    default_response = requests.post(
230	        server.url_for("pooling"),
231	        json={
232	            "input": input_texts,
233	            "model": model_name,
234	        },

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_rerank.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
28	
29	    rerank_response = requests.post(server.url_for("rerank"),
30	                                    json={
31	                                        "model": model_name,
32	                                        "query": query,
33	                                        "documents": documents,
34	                                    })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_rerank.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
52	
53	    rerank_response = requests.post(server.url_for("rerank"),
54	                                    json={
55	                                        "model": model_name,
56	                                        "query": query,
57	                                        "documents": documents,
58	                                        "top_n": 2
59	                                    })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_rerank.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
77	
78	    rerank_response = requests.post(server.url_for("rerank"),
79	                                    json={
80	                                        "model": model_name,
81	                                        "query": query,
82	                                        "documents": documents
83	                                    })

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_run_batch.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
34	                "r") as output_file:
35	        input_file.write("")
36	        input_file.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_run_batch.py:54
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
53	                "r") as output_file:
54	        input_file.write(INPUT_BATCH)
55	        input_file.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_run_batch.py:79
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
78	                "r") as output_file:
79	        input_file.write(INVALID_INPUT_BATCH)
80	        input_file.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_run_batch.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
94	                "r") as output_file:
95	        input_file.write(INPUT_EMBEDDING_BATCH)
96	        input_file.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_run_batch.py:117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
116	                "r") as output_file:
117	        input_file.write(INPUT_SCORE_BATCH)
118	        input_file.flush()

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_score.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
75	
76	        score_response = requests.post(server.url_for("score"),
77	                                       json={
78	                                           "model": model["name"],
79	                                           "text_1": text_1,
80	                                           "text_2": text_2,
81	                                       })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_score.py:108
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
107	
108	        score_response = requests.post(server.url_for("score"),
109	                                       json={
110	                                           "model": model["name"],
111	                                           "text_1": text_1,
112	                                           "text_2": text_2,
113	                                       })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_score.py:134
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
133	
134	        score_response = requests.post(server.url_for("score"),
135	                                       json={
136	                                           "model": model["name"],
137	                                           "text_1": text_1,
138	                                           "text_2": text_2,
139	                                       })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_score.py:164
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
163	
164	        score_response = requests.post(server.url_for("score"),
165	                                       json={
166	                                           "model": model["name"],
167	                                           "text_1": text_1,
168	                                           "text_2": text_2,
169	                                       })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_score.py:176
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
175	        # Test truncation
176	        score_response = requests.post(server.url_for("score"),
177	                                       json={
178	                                           "model": model["name"],
179	                                           "text_1": text_1,
180	                                           "text_2": text_2,
181	                                           "truncate_prompt_tokens": 101
182	                                       })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
27	                            }) as remote_server:
28	        response = requests.post(remote_server.url_for("sleep"),
29	                                 params={"level": "1"})
30	        assert response.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
30	        assert response.status_code == 200
31	        response = requests.get(remote_server.url_for("is_sleeping"))
32	        assert response.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
32	        assert response.status_code == 200
33	        assert response.json().get("is_sleeping") is True
34	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
34	
35	        response = requests.post(remote_server.url_for("wake_up"))
36	        assert response.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
36	        assert response.status_code == 200
37	        response = requests.get(remote_server.url_for("is_sleeping"))
38	        assert response.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
38	        assert response.status_code == 200
39	        assert response.json().get("is_sleeping") is False
40	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
41	        # test wake up with tags
42	        response = requests.post(remote_server.url_for("sleep"),
43	                                 params={"level": "1"})
44	        assert response.status_code == 200

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
45	
46	        response = requests.post(remote_server.url_for("wake_up"),
47	                                 params={"tags": ["weights"]})
48	        assert response.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
50	        # is sleeping should be false after waking up any part of the engine
51	        response = requests.get(remote_server.url_for("is_sleeping"))
52	        assert response.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
52	        assert response.status_code == 200
53	        assert response.json().get("is_sleeping") is True
54	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
54	
55	        response = requests.post(remote_server.url_for("wake_up"),
56	                                 params={"tags": ["kv_cache"]})
57	        assert response.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
58	
59	        response = requests.get(remote_server.url_for("is_sleeping"))
60	        assert response.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_sleep.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
60	        assert response.status_code == 200
61	        assert response.json().get("is_sleeping") is False

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_tokenization.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
70	
71	        response = requests.post(server.url_for("tokenize"),
72	                                 json={
73	                                     "add_special_tokens": add_special,
74	                                     "model": model_name,
75	                                     "prompt": prompt
76	                                 })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_tokenization.py:129
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
128	
129	                response = requests.post(server.url_for("tokenize"),
130	                                         json={
131	                                             "add_generation_prompt":
132	                                             add_generation,
133	                                             "continue_final_message":
134	                                             continue_final,
135	                                             "add_special_tokens": add_special,
136	                                             "messages": conversation,
137	                                             "model": model_name
138	                                         })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_tokenization.py:165
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
164	
165	    response = requests.post(server.url_for("detokenize"),
166	                             json={
167	                                 "model": model_name,
168	                                 "tokens": tokens
169	                             })

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_transcription_validation.py:82
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
81	        buffer = io.BytesIO()
82	        sf.write(buffer, repeated_audio, sr, format='WAV')
83	        buffer.seek(0)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_video.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
14	TEST_VIDEO_URLS = [
15	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4",
16	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4",
17	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4",
18	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerFun.mp4",
19	]
20	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_video.py:16
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
15	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4",
16	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4",
17	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4",
18	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerFun.mp4",
19	]
20	
21	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_video.py:17
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
16	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4",
17	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4",
18	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerFun.mp4",
19	]
20	
21	
22	@pytest.fixture(scope="module")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_video.py:18
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
17	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4",
18	    "http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerFun.mp4",
19	]
20	
21	
22	@pytest.fixture(scope="module")
23	def server():

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
18	TEST_IMAGE_URLS = [
19	    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
20	    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
21	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
22	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
23	]
24	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision.py:20
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
19	    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
20	    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
21	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
22	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
23	]
24	
25	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
20	    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
21	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
22	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
23	]
24	
25	
26	@pytest.fixture(scope="module")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
21	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
22	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
23	]
24	
25	
26	@pytest.fixture(scope="module")
27	def server():

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision.py:69
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
68	    }]
69	    images = [Image.open(requests.get(image_url, stream=True).raw)]
70	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision_embedding.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
20	TEST_IMAGE_URLS = [
21	    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
22	    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
23	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
24	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
25	]
26	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision_embedding.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
21	    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
22	    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
23	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
24	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
25	]
26	
27	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision_embedding.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
22	    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
23	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
24	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
25	]
26	
27	
28	@pytest.fixture(scope="module")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision_embedding.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
23	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
24	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
25	]
26	
27	
28	@pytest.fixture(scope="module")
29	def server():

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision_embedding.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
63	    prompt = f"{placeholder}{content}"
64	    images = [Image.open(requests.get(image_url, stream=True).raw)]
65	    inputs = processor(prompt, images, return_tensors="pt")

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/entrypoints/openai/test_vision_embedding.py:92
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
91	
92	    response = requests.post(
93	        server.url_for("v1/embeddings"),
94	        json={
95	            "model": model_name,
96	            "messages": messages,
97	            "encoding_format": "float"
98	        },

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/kv_transfer/test_disagg.py:88
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
87	        try:
88	            response = requests.get(f"http://localhost:{port}/v1/completions")
89	            if response.status_code in [200, 405]:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/kv_transfer/test_disagg.py:88
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
87	        try:
88	            response = requests.get(f"http://localhost:{port}/v1/completions")
89	            if response.status_code in [200, 405]:

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/kv_transfer/test_disagg.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
99	    # Send to prefill
100	    response = requests.post("http://localhost:8100/v1/completions",
101	                             headers={"Content-Type": "application/json"},
102	                             json={
103	                                 "model": "meta-llama/Llama-3.2-1B-Instruct",
104	                                 "prompt": prompt,
105	                                 "max_tokens": 1,
106	                                 "temperature": 0
107	                             })

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/kv_transfer/test_disagg.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
99	    # Send to prefill
100	    response = requests.post("http://localhost:8100/v1/completions",
101	                             headers={"Content-Type": "application/json"},
102	                             json={
103	                                 "model": "meta-llama/Llama-3.2-1B-Instruct",
104	                                 "prompt": prompt,
105	                                 "max_tokens": 1,
106	                                 "temperature": 0
107	                             })

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/kv_transfer/test_disagg.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
110	    # Send to decode
111	    response = requests.post("http://localhost:8200/v1/completions",
112	                             headers={"Content-Type": "application/json"},
113	                             json={
114	                                 "model": "meta-llama/Llama-3.2-1B-Instruct",
115	                                 "prompt": prompt,
116	                                 "max_tokens": 10,
117	                                 "temperature": 0
118	                             })

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/kv_transfer/test_disagg.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
110	    # Send to decode
111	    response = requests.post("http://localhost:8200/v1/completions",
112	                             headers={"Content-Type": "application/json"},
113	                             json={
114	                                 "model": "meta-llama/Llama-3.2-1B-Instruct",
115	                                 "prompt": prompt,
116	                                 "max_tokens": 10,
117	                                 "temperature": 0
118	                             })

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/kv_transfer/test_lookup_buffer.py:136
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
135	        kv_parallel_size=2,
136	        kv_ip="127.0.0.1",
137	        kv_port=12345,

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/kv_transfer/test_send_recv.py:145
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
144	        kv_parallel_size=2,
145	        kv_ip="127.0.0.1",
146	        kv_port=12345,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/models/decoder_only/vision_language/test_pixtral.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
34	IMG_URLS = [
35	    "https://picsum.photos/id/237/400/300",
36	    "https://picsum.photos/id/231/200/300",
37	    "https://picsum.photos/id/27/500/500",
38	    "https://picsum.photos/id/17/150/600",
39	]
40	PROMPT = "Describe each image in one short sentence."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/models/decoder_only/vision_language/test_pixtral.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	    "https://picsum.photos/id/237/400/300",
36	    "https://picsum.photos/id/231/200/300",
37	    "https://picsum.photos/id/27/500/500",
38	    "https://picsum.photos/id/17/150/600",
39	]
40	PROMPT = "Describe each image in one short sentence."
41	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/models/decoder_only/vision_language/test_pixtral.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	    "https://picsum.photos/id/231/200/300",
37	    "https://picsum.photos/id/27/500/500",
38	    "https://picsum.photos/id/17/150/600",
39	]
40	PROMPT = "Describe each image in one short sentence."
41	
42	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/models/decoder_only/vision_language/test_pixtral.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
37	    "https://picsum.photos/id/27/500/500",
38	    "https://picsum.photos/id/17/150/600",
39	]
40	PROMPT = "Describe each image in one short sentence."
41	
42	
43	def _create_msg_format(urls: list[str]) -> list[dict[str, Any]]:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/models/decoder_only/vision_language/vlm_utils/custom_inputs.py:113
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
112	    # image from regression issue: https://github.com/vllm-project/vllm/issues/15122
113	    image_url = "https://aomediacodec.github.io/av1-avif/testFiles/Link-U/hato.jpg"
114	    image = Image.open(BytesIO(requests.get(image_url).content))

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/models/decoder_only/vision_language/vlm_utils/custom_inputs.py:114
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
113	    image_url = "https://aomediacodec.github.io/av1-avif/testFiles/Link-U/hato.jpg"
114	    image = Image.open(BytesIO(requests.get(image_url).content))
115	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/models/embedding/language/test_gritlm.py:128
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
127	        "A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.",
128	        "All text-based language problems can be reduced to either generation or embedding. Current models only perform well at one or the other. We introduce generative representational instruction tuning (GRIT) whereby a large language model is trained to handle both generative and embedding tasks by distinguishing between them through instructions. Compared to other open models, our resulting GritLM 7B sets a new state of the art on the Massive Text Embedding Benchmark (MTEB) and outperforms all models up to its size on a range of generative tasks. By scaling up further, GritLM 8X7B outperforms all open generative language models that we tried while still being among the best embedding models. Notably, we find that GRIT matches training on only generative or embedding data, thus we can unify both at no performance loss. Among other benefits, the unification via GRIT speeds up Retrieval-Augmented Generation (RAG) by > 60% for long documents, by no longer requiring separate retrieval and generation models. Models, code, etc. are freely available at https://github.com/ContextualAI/gritlm.",
129	    ]
130	
131	    return queries, q_instruction, documents, d_instruction
132	

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/mq_llm_engine/utils.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
60	        context = multiprocessing.get_context("spawn")
61	        self.proc = context.Process(target=run_fn,
62	                                    args=(engine_args, ipc_path))
63	        self.proc.start()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/multimodal/test_utils.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
22	TEST_IMAGE_URLS = [
23	    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
24	    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
25	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
26	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
27	]
28	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/multimodal/test_utils.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
23	    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
24	    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
25	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
26	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
27	]
28	
29	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/multimodal/test_utils.py:25
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
24	    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
25	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
26	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
27	]
28	
29	
30	@pytest.fixture(scope="module")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/multimodal/test_utils.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Venn_diagram_rgb.svg/1280px-Venn_diagram_rgb.svg.png",
26	    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png",
27	]
28	
29	
30	@pytest.fixture(scope="module")
31	def url_images() -> dict[str, Image.Image]:

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/multimodal/test_utils.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
88	
89	        base64_image = base64.b64encode(f.read()).decode("utf-8")
90	        data_url = f"data:{mime_type};base64,{base64_image}"

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/multimodal/test_utils.py:89
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
88	
89	        base64_image = base64.b64encode(f.read()).decode("utf-8")
90	        data_url = f"data:{mime_type};base64,{base64_image}"

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/multimodal/test_utils.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
88	
89	        base64_image = base64.b64encode(f.read()).decode("utf-8")
90	        data_url = f"data:{mime_type};base64,{base64_image}"

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/neuron/2_core/test_comm_ops.py:93
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
92	        distributed_init_method = get_distributed_init_method(
93	            "127.0.0.1", get_open_port())
94	
95	        monkeypatch.setenv("VLLM_USE_V1", "1")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/tensorizer_loader/test_tensorizer.py:67
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
66	    with open(keyfile_path, 'wb') as f:
67	        f.write(encryption_params.key)
68	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_logger.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
34	    with open(path) as f:
35	        content = f.read()
36	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_logger.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
125	    with NamedTemporaryFile(encoding="utf-8", mode="w") as logging_config_file:
126	        logging_config_file.write("---\nloggers: []\nversion: 1")
127	        logging_config_file.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_logger.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
125	    with NamedTemporaryFile(encoding="utf-8", mode="w") as logging_config_file:
126	        logging_config_file.write("---\nloggers: []\nversion: 1")
127	        logging_config_file.flush()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_logger.py:151
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
150	    with NamedTemporaryFile(encoding="utf-8", mode="w") as logging_config_file:
151	        logging_config_file.write(json.dumps(unexpected_config))
152	        logging_config_file.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_logger.py:151
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
150	    with NamedTemporaryFile(encoding="utf-8", mode="w") as logging_config_file:
151	        logging_config_file.write(json.dumps(unexpected_config))
152	        logging_config_file.flush()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_logger.py:176
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
175	    with NamedTemporaryFile(encoding="utf-8", mode="w") as logging_config_file:
176	        logging_config_file.write(json.dumps(valid_logging_config))
177	        logging_config_file.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_logger.py:176
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
175	    with NamedTemporaryFile(encoding="utf-8", mode="w") as logging_config_file:
176	        logging_config_file.write(json.dumps(valid_logging_config))
177	        logging_config_file.flush()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_logger.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
198	    with NamedTemporaryFile(encoding="utf-8", mode="w") as logging_config_file:
199	        logging_config_file.write(json.dumps(valid_logging_config))
200	        logging_config_file.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_logger.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
198	    with NamedTemporaryFile(encoding="utf-8", mode="w") as logging_config_file:
199	        logging_config_file.write(json.dumps(valid_logging_config))
200	        logging_config_file.flush()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_sharded_state_loader.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
77	    queue.close()
78	    queue.join_thread()
79	

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_sharded_state_loader.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
94	    with TemporaryDirectory() as output_dir:
95	        p = ctx.Process(target=_run_writer,
96	                        args=(input_dir, output_dir, weights_patterns),
97	                        kwargs=dict(
98	                            tensor_parallel_size=tp_size,
99	                            distributed_executor_backend="mp",
100	                            gpu_memory_utilization=gpu_memory_utilization,
101	                            enforce_eager=True,
102	                        ))

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_sharded_state_loader.py:108
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
107	
108	        p = ctx.Process(target=_run_generate,
109	                        args=(input_dir, queue),
110	                        kwargs=dict(
111	                            distributed_executor_backend="mp",
112	                            enable_lora=enable_lora,
113	                            gpu_memory_utilization=gpu_memory_utilization,
114	                            tensor_parallel_size=tp_size,
115	                        ))

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_sharded_state_loader.py:120
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
119	
120	        p = ctx.Process(target=_run_generate,
121	                        args=(output_dir, queue),
122	                        kwargs=dict(
123	                            distributed_executor_backend="mp",
124	                            enable_lora=enable_lora,
125	                            gpu_memory_utilization=gpu_memory_utilization,
126	                            tensor_parallel_size=tp_size,
127	                            load_format="sharded_state",
128	                        ))

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_utils.py:122
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
121	        # make sure we can get multiple ports, even if the env var is set
122	        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s1:
123	            s1.bind(("localhost", get_open_port()))

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_utils.py:124
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
123	            s1.bind(("localhost", get_open_port()))
124	            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s2:
125	                s2.bind(("localhost", get_open_port()))

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/test_utils.py:126
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
125	                s2.bind(("localhost", get_open_port()))
126	                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s3:
127	                    s3.bind(("localhost", get_open_port()))

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/tpu/test_compilation.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
69	    with open(compiled_fns[0]) as f:
70	        content = f.read()
71	        assert kv_cache_prefix not in content

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/tpu/test_compilation.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
75	    with open(compiled_fns[1]) as f:
76	        content = f.read()
77	        assert (kv_cache_prefix in content and attn_prefix in content)

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/tracing/test_tracing.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
75	    """Fixture to set up a fake gRPC trace service"""
76	    server = grpc.server(futures.ThreadPoolExecutor(max_workers=1))
77	    service = FakeTraceService()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/utils.py:152
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
151	            try:
152	                if requests.get(url).status_code == 200:
153	                    break

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/utils.py:554
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
553	                    client, model,
554	                    "https://upload.wikimedia.org/wikipedia/commons/0/0b/RGBA_comp.png"
555	                )
556	            elif method == "encode":
557	                results += _test_embeddings(client, model, prompt)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/utils.py:640
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
639	            ), )
640	    ray.get(refs)
641	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/utils.py:658
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
657	def get_physical_device_indices(devices):
658	    visible_devices = os.environ.get("CUDA_VISIBLE_DEVICES")
659	    if visible_devices is None:

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/utils.py:742
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
741	            # ignore SIGTERM signal itself
742	            old_signal_handler = signal.signal(signal.SIGTERM, signal.SIG_IGN)
743	            # kill all child processes

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/utils.py:742
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
741	            # ignore SIGTERM signal itself
742	            old_signal_handler = signal.signal(signal.SIGTERM, signal.SIG_IGN)
743	            # kill all child processes

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/utils.py:746
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
745	            # restore the signal handler
746	            signal.signal(signal.SIGTERM, old_signal_handler)
747	            assert _exitcode == 0, (f"function {f} failed when called with"

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/utils.py:746
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
745	            # restore the signal handler
746	            signal.signal(signal.SIGTERM, old_signal_handler)
747	            assert _exitcode == 0, (f"function {f} failed when called with"

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/tests/utils.py:761
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
760	        # Check if we're already in a subprocess
761	        if os.environ.get('RUNNING_IN_SUBPROCESS') == '1':
762	            # If we are, just run the function directly

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/assets/base.py:10
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
9	
10	VLLM_S3_BUCKET_URL = "https://vllm-public-assets.s3.us-west-2.amazonaws.com"
11	
12	
13	def get_cache_dir() -> Path:

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/benchmarks/serve.py:587
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
586	    # Use 127.0.0.1 here instead of localhost to force the use of ipv4
587	    parser.add_argument("--host", type=str, default="127.0.0.1")
588	    parser.add_argument("--port", type=int, default=8000)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/benchmarks/serve.py:742
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
741	        required=False,
742	        help="Specify service level objectives for goodput as \"KEY:VALUE\" "
743	        "pairs, where the key is a metric name, and the value is in "

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/compilation/backends.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
62	                # do not use eval(), it is unsafe.
63	                self.cache = ast.literal_eval(f.read())
64	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/compilation/backends.py:74
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
73	            data = printer.pformat(self.cache)
74	            f.write(data)
75	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/compilation/backends.py:382
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
381	                with open(filepath) as f:
382	                    hash_content.append(f.read())
383	            import hashlib

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/compilation/backends.py:467
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
466	            with open(graph_path, "w") as f:
467	                f.write(src)
468	

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/compilation/compiler_interface.py:138
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
137	        from torch._inductor.codecache import CacheBase
138	        system_factors = CacheBase.get_system()
139	        factors.append(system_factors)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/compilation/wrapper.py:103
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
102	                    with open(decompiled_file, "w") as f:
103	                        f.write(src)
104	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/config.py:319
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
318	            raise ValueError(
319	                "VLLM_ATTENTION_BACKEND is set to FLASHINFER, but flashinfer "
320	                "module was not found. See "
321	                "https://github.com/vllm-project/vllm/blob/main/docker/Dockerfile "  # noqa: E501

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/config.py:1439
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
1438	    # IP of the data parallel master.
1439	    data_parallel_master_ip: str = "127.0.0.1"
1440	    data_parallel_master_port: int = 29500  # Port of the data parallel master.

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/config.py:2984
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
2983	    # The KV connector ip, used to build distributed connection
2984	    kv_ip: str = "127.0.0.1"
2985	
2986	    # The KV connector port, used to build distributed connection
2987	    kv_port: int = 14579

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/connections.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
61	
62	        return client.get(url,
63	                          headers=self._headers(**extra_headers),
64	                          stream=stream,
65	                          timeout=timeout)
66	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/connections.py:79
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
78	
79	        return client.get(url,
80	                          headers=self._headers(**extra_headers),
81	                          timeout=timeout)
82	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/device_allocator/cumem.py:147
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
146	        assert "expandable_segments:True" not in conf, \
147	            ("Expandable segments are not compatible with memory pool. "
148	            "Please track https://github.com/pytorch/pytorch/issues/147851 "
149	            "for the latest updates.")
150	
151	        self.pointer_to_data: Dict[int, AllocationData] = {}
152	        self.current_tag: str = CuMemAllocator.default_tag

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/cuda_wrapper.py:117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
116	        if so_file not in CudaRTLibrary.path_to_library_cache:
117	            lib = ctypes.CDLL(so_file)
118	            CudaRTLibrary.path_to_library_cache[so_file] = lib

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/custom_all_reduce_utils.py:141
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
140	    result_queue = smp.Queue()
141	    p_src = smp.Process(target=producer,
142	                        args=(batch_src, producer_queue, consumer_queue,
143	                              result_queue, cuda_visible_devices))
144	    p_tgt = smp.Process(target=consumer,

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/custom_all_reduce_utils.py:144
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
143	                              result_queue, cuda_visible_devices))
144	    p_tgt = smp.Process(target=consumer,
145	                        args=(batch_tgt, producer_queue, consumer_queue,
146	                              result_queue, cuda_visible_devices))
147	    p_src.start()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/custom_all_reduce_utils.py:254
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
253	if __name__ == "__main__":
254	    batch_src, batch_tgt, output_file = pickle.loads(sys.stdin.buffer.read())
255	    result = can_actually_p2p(batch_src, batch_tgt)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/custom_all_reduce_utils.py:257
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
256	    with open(output_file, "wb") as f:
257	        f.write(pickle.dumps(result))

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/custom_all_reduce_utils.py:257
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
256	    with open(output_file, "wb") as f:
257	        f.write(pickle.dumps(result))

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/pynccl_wrapper.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
224	            if so_file not in NCCLLibrary.path_to_dict_mapping:
225	                lib = ctypes.CDLL(so_file)
226	                NCCLLibrary.path_to_library_cache[so_file] = lib

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/shm_broadcast.py:457
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
456	            if len(serialized_obj) >= self.buffer.max_chunk_bytes:
457	                with self.acquire_write(timeout) as buf:
458	                    buf[0] = 1  # overflow

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/shm_broadcast.py:461
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
460	            else:
461	                with self.acquire_write(timeout) as buf:
462	                    buf[0] = 0  # not overflow

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/device_communicators/shm_broadcast.py:470
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
469	        if self._is_local_reader:
470	            with self.acquire_read(timeout) as buf:
471	                overflow = buf[0] == 1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
75	            raise ImportError(
76	                "Please install mooncake by following the instructions at "
77	                "https://github.com/kvcache-ai/Mooncake/blob/main/doc/en/build.md "  # noqa: E501
78	                "to run vLLM with MooncakeConnector.") from e

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
62	            raise ImportError(
63	                "Please install mooncake by following the instructions at "
64	                "https://github.com/kvcache-ai/Mooncake/blob/main/doc/en/build.md "  # noqa: E501
65	                "to run vLLM with MooncakeConnector.") from e

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py:107
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
106	
107	        self.buffer_cleaner = ThreadPoolExecutor(max_workers=1)
108	        self._setup_metadata_sockets(kv_rank, prefill_host, base_prefill_port,

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py:252
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
251	        if self.transport_thread is None:
252	            self.transport_thread = ThreadPoolExecutor(max_workers=1)
253	        tensor = tensor if tensor is not None else self.none_tensor

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py:260
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
259	        if self.transport_thread is None:
260	            self.transport_thread = ThreadPoolExecutor(max_workers=1)
261	        tensor = self.transport_thread.submit(self._recv_impl).result()

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py:234
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
233	        if self.transport_thread is None:
234	            self.transport_thread = ThreadPoolExecutor(max_workers=1)
235	

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py:257
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
256	        if self.transport_thread is None:
257	            self.transport_thread = ThreadPoolExecutor(max_workers=1)
258	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/engine/arg_utils.py:316
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
315	            choices=[f.value for f in LoadFormat],
316	            help='The format of the model weights to load.\n\n'
317	            '* "auto" will try to load the weights in the safetensors format '

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/engine/arg_utils.py:378
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
377	            default='xgrammar',
378	            help='Which engine will be used for guided decoding'
379	            ' (JSON schema / regex etc) by default. Currently support '

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/engine/multiprocessing/client.py:134
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
133	        self.health_loop: Optional[asyncio.Task] = None
134	        self._engine_process = psutil.Process(engine_pid)
135	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/engine/multiprocessing/engine.py:443
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
442	
443	        signal.signal(signal.SIGTERM, signal_handler)
444	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/engine/multiprocessing/engine.py:443
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
442	
443	        signal.signal(signal.SIGTERM, signal_handler)
444	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/chat_utils.py:404
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
403	        logger.warning(
404	            "You specified `--chat-template-content-format %s` "
405	            "which is different from the detected format '%s'. "
406	            "If our automatic detection is incorrect, please consider "
407	            "opening a GitHub issue so that we can improve it: "
408	            "https://github.com/vllm-project/vllm/issues/new/choose",
409	            given_format,
410	            detected_format,
411	        )
412	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/main.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
25	
26	    signal.signal(signal.SIGINT, signal_handler)
27	    signal.signal(signal.SIGTSTP, signal_handler)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/main.py:26
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
25	
26	    signal.signal(signal.SIGINT, signal_handler)
27	    signal.signal(signal.SIGTSTP, signal_handler)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/main.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
26	    signal.signal(signal.SIGINT, signal_handler)
27	    signal.signal(signal.SIGTSTP, signal_handler)
28	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/main.py:27
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
26	    signal.signal(signal.SIGINT, signal_handler)
27	    signal.signal(signal.SIGTSTP, signal_handler)
28	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/openai.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
21	
22	    signal.signal(signal.SIGINT, signal_handler)
23	    signal.signal(signal.SIGTSTP, signal_handler)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/openai.py:22
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
21	
22	    signal.signal(signal.SIGINT, signal_handler)
23	    signal.signal(signal.SIGTSTP, signal_handler)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/openai.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
22	    signal.signal(signal.SIGINT, signal_handler)
23	    signal.signal(signal.SIGTSTP, signal_handler)
24	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/openai.py:23
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
22	    signal.signal(signal.SIGINT, signal_handler)
23	    signal.signal(signal.SIGTSTP, signal_handler)
24	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/openai.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
72	        type=str,
73	        default="http://localhost:8000/v1",
74	        help="url of the running OpenAI-Compatible RESTful API server")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/cli/serve.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
48	            required=False,
49	            help="Read CLI options from a config file."
50	            "Must be a YAML with the following options:"

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/launcher.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
36	    config = uvicorn.Config(app, **uvicorn_kwargs)
37	    config.load()
38	    server = uvicorn.Server(config)

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/api_server.py:238
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
237	        engine_alive = multiprocessing.Value('b', True, lock=False)
238	        engine_process = context.Process(
239	            target=run_mp_engine,
240	            args=(vllm_config, UsageContext.OPENAI_API_SERVER, ipc_path,
241	                  engine_args.disable_log_stats,
242	                  engine_args.disable_log_requests, engine_alive))
243	        engine_process.start()

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/api_server.py:279
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
278	            # Close all open connections to the backend
279	            mq_engine_client.close()
280	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/api_server.py:614
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
613	
614	    audio_data = await request.file.read()
615	    generator = await handler.create_transcription(audio_data, request,

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/api_server.py:1025
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
1024	
1025	    sock = socket.socket(family=family, type=socket.SOCK_STREAM)
1026	    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/api_server.py:1067
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
1066	
1067	    signal.signal(signal.SIGTERM, signal_handler)
1068	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/api_server.py:1067
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
1066	
1067	    signal.signal(signal.SIGTERM, signal_handler)
1068	

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/api_server.py:1078
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
1077	                return '[' + a + ']'
1078	            return a or "0.0.0.0"
1079	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/api_server.py:1107
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
1106	    finally:
1107	        sock.close()
1108	

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/run_batch.py:84
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
83	        type=str,
84	        default="0.0.0.0",
85	        help="URL to the Prometheus metrics server "

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/run_batch.py:380
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
379	            response_futures.append(
380	                run_request(chat_handler_fn, request, tracker))
381	            tracker.submitted()

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/run_batch.py:394
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
393	            response_futures.append(
394	                run_request(embed_handler_fn, request, tracker))
395	            tracker.submitted()

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/run_batch.py:408
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
407	            response_futures.append(
408	                run_request(score_handler_fn, request, tracker))
409	            tracker.submitted()

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/serving_embedding.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
41	        embedding_bytes = np.array(output.embedding, dtype="float32").tobytes()
42	        return base64.b64encode(embedding_bytes).decode("utf-8")
43	

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/serving_embedding.py:42
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
41	        embedding_bytes = np.array(output.embedding, dtype="float32").tobytes()
42	        return base64.b64encode(embedding_bytes).decode("utf-8")
43	

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/serving_engine.py:94
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
93	
94	        self._tokenizer_executor = ThreadPoolExecutor(max_workers=1)
95	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/serving_engine.py:435
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
434	
435	            request = tool_parser(tokenizer).adjust_request(  # type: ignore
436	                request=request)
437	

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/serving_models.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
75	                                  "adapter_config.json").open() as f:
76	                    adapter_config = json.load(f)
77	                    num_virtual_tokens = adapter_config["num_virtual_tokens"]

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/serving_models.py:146
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
145	    ) -> Union[ErrorResponse, str]:
146	        error_check_ret = await self._check_load_lora_adapter_request(request)
147	        if error_check_ret is not None:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/serving_models.py:181
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
180	            request: UnloadLoRAAdapterRequest) -> Union[ErrorResponse, str]:
181	        error_check_ret = await self._check_unload_lora_adapter_request(request
182	                                                                        )

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/serving_pooling.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
40	        pooling_bytes = np.array(output.data, dtype="float32").tobytes()
41	        return base64.b64encode(pooling_bytes).decode("utf-8")
42	

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/entrypoints/openai/serving_pooling.py:41
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
40	        pooling_bytes = np.array(output.data, dtype="float32").tobytes()
41	        return base64.b64encode(pooling_bytes).decode("utf-8")
42	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/envs.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	    VLLM_CONFIG_ROOT: str = os.path.expanduser("~/.config/vllm")
29	    VLLM_USAGE_STATS_SERVER: str = "https://stats.vllm.ai"
30	    VLLM_NO_USAGE_STATS: bool = False

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/envs.py:292
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
291	    "VLLM_USAGE_STATS_SERVER":
292	    lambda: os.environ.get("VLLM_USAGE_STATS_SERVER", "https://stats.vllm.ai"),
293	    "VLLM_NO_USAGE_STATS":

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/envs.py:657
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
656	    "VLLM_DP_MASTER_IP":
657	    lambda: os.getenv("VLLM_DP_MASTER_IP", "127.0.0.1"),
658	

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/executor/mp_distributed_executor.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
72	        distributed_init_method = get_distributed_init_method(
73	            "127.0.0.1", get_open_port())
74	
75	        self.workers: List[ProcessWorkerWrapper] = []

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/executor/multiproc_worker_utils.py:155
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
154	        self.tasks = result_handler.tasks
155	        self.process: BaseProcess = self.mp.Process(  # type: ignore[attr-defined]
156	            target=_run_worker_process,
157	            name="VllmWorkerProcess",
158	            kwargs=dict(
159	                worker_factory=worker_factory,
160	                task_queue=self._task_queue,
161	                result_queue=self.result_queue,
162	                vllm_config=vllm_config,
163	                rank=rank,
164	            ),
165	            daemon=True)
166	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/executor/multiproc_worker_utils.py:272
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
271	        if file.start_new_line:  # type: ignore[attr-defined]
272	            file_write(prefix)
273	        idx = 0

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/executor/multiproc_worker_utils.py:276
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
275	            next_idx += 1
276	            file_write(s[idx:next_idx])
277	            if next_idx == len(s):

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/executor/multiproc_worker_utils.py:280
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
279	                return
280	            file_write(prefix)
281	            idx = next_idx

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/executor/multiproc_worker_utils.py:282
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
281	            idx = next_idx
282	        file_write(s[idx:])
283	        file.start_new_line = False  # type: ignore[attr-defined]

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/executor/ray_distributed_executor.py:376
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
375	            # the node.
376	            driver_ip = "127.0.0.1"
377	        distributed_init_method = get_distributed_init_method(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/inputs/preprocess.py:240
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
239	                logger.warning_once(
240	                    "Your model uses the legacy input pipeline, which will be "
241	                    "removed in an upcoming release. "
242	                    "Please upgrade to the new multi-modal processing pipeline "

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/logger.py:109
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
108	        with open(VLLM_LOGGING_CONFIG_PATH, encoding="utf-8") as file:
109	            custom_config = json.loads(file.read())
110	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/logger.py:175
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
174	                if event == 'call':
175	                    f.write(f"{ts} Call to"
176	                            f" {func_name} in {filename}:{lineno}"
177	                            f" from {last_func_name} in {last_filename}:"
178	                            f"{last_lineno}\n")
179	                else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/logger.py:180
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
179	                else:
180	                    f.write(f"{ts} Return from"
181	                            f" {func_name} in {filename}:{lineno}"
182	                            f" to {last_func_name} in {last_filename}:"
183	                            f"{last_lineno}\n")
184	        except NameError:

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/guided_decoding/outlines_decoding.py:82
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
81	            max_workers = _MAX_THREADPOOL_WORKERS
82	        global_thread_pool = concurrent.futures.ThreadPoolExecutor(
83	            max_workers=max_workers)
84	    loop = asyncio.get_running_loop()

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/layers/logits_processor.py:20
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
19	if envs.VLLM_LOGITS_PROCESSOR_THREADS is not None:
20	    _logits_processor_threadpool = ThreadPoolExecutor(
21	        envs.VLLM_LOGITS_PROCESSOR_THREADS)
22	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/layers/quantization/tpu_int8.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
110	            raise ImportError(
111	                "Please install torch_xla by following the instructions at "
112	                "https://docs.vllm.ai/en/latest/getting_started/tpu-installation.html "  # noqa: E501
113	                "to run vLLM on TPU.") from err

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/model_loader/loader.py:129
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
128	
129	    msg = ("vLLM model class should accept `vllm_config` and `prefix` as "
130	           "input arguments. Possibly you have an old-style model class"
131	           " registered from out of tree and it is used for new vLLM version. "
132	           "Check https://docs.vllm.ai/en/latest/design/arch_overview.html "
133	           "for the design and update the model class accordingly.")
134	    warnings.warn(msg, DeprecationWarning, stacklevel=2)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/model_loader/tensorizer.py:192
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
191	            ) as stream:
192	                key = stream.read()
193	                decryption_params = DecryptionParams.from_key(key)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/model_loader/tensorizer.py:423
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
422	        with open(keyfile, "rb") as f:
423	            key = f.read()
424	        encryption_params = EncryptionParams(key=key)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/model_loader/tensorizer.py:462
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
461	        ) as stream:
462	            stream.write(encryption_params.key)
463	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/models/gemma.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
60	            logger.warning(
61	                "Gemma's activation function was incorrectly set to exact GeLU "
62	                "in the config JSON file when it was initially released. "
63	                "Changing the activation function to approximate GeLU "
64	                "(`gelu_pytorch_tanh`). If you want to use the legacy "
65	                "`%s`, edit the config JSON to set "
66	                "`hidden_activation=%s` instead of `hidden_act`. "
67	                "See https://github.com/huggingface/transformers/pull/29402 "
68	                "for more details.", hidden_act, hidden_act)
69	        return GeluAndMul(approximate="tanh")
70	    elif hidden_activation == "gelu_pytorch_tanh":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/models/pixtral.py:141
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
140	            raise ValueError(
141	                "You've passed text inputs instead of token inputs. "
142	                "Make sure to process your input via `mistral_common`'s "
143	                "tokenizer or pass a chat completion request. "

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/models/registry.py:588
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
587	
588	    fn, output_file = pickle.loads(sys.stdin.buffer.read())
589	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/models/registry.py:593
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
592	    with open(output_file, "wb") as f:
593	        f.write(pickle.dumps(result))
594	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/model_executor/models/registry.py:593
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
592	    with open(output_file, "wb") as f:
593	        f.write(pickle.dumps(result))
594	

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/audio.py:65
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
64	    ) -> tuple[npt.NDArray, float]:
65	        return self.load_bytes(base64.b64decode(data))
66	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/audio.py:65
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
64	    ) -> tuple[npt.NDArray, float]:
65	        return self.load_bytes(base64.b64decode(data))
66	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/audio.py:74
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
73	        with BytesIO() as buffer:
74	            soundfile.write(buffer, audio, sr, format="WAV")
75	            data = buffer.getvalue()

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/audio.py:77
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
76	
77	        return base64.b64encode(data).decode('utf-8')

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/audio.py:77
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
76	
77	        return base64.b64encode(data).decode('utf-8')

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/image.py:116
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
115	    def load_base64(self, media_type: str, data: str) -> Image.Image:
116	        return self.load_bytes(base64.b64decode(data))
117	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/image.py:116
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
115	    def load_base64(self, media_type: str, data: str) -> Image.Image:
116	        return self.load_bytes(base64.b64decode(data))
117	

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/image.py:136
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
135	
136	        return base64.b64encode(data).decode('utf-8')
137	

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/image.py:136
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
135	
136	        return base64.b64encode(data).decode('utf-8')
137	

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/image.py:149
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
148	    def load_base64(self, media_type: str, data: str) -> torch.Tensor:
149	        return self.load_bytes(base64.b64decode(data))
150	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/image.py:149
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
148	    def load_base64(self, media_type: str, data: str) -> torch.Tensor:
149	        return self.load_bytes(base64.b64decode(data))
150	

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/image.py:155
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
154	    def encode_base64(self, media: torch.Tensor) -> str:
155	        return base64.b64encode(media.numpy()).decode('utf-8')

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/image.py:155
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
154	    def encode_base64(self, media: torch.Tensor) -> str:
155	        return base64.b64encode(media.numpy()).decode('utf-8')

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/video.py:207
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
206	
207	        return self.load_bytes(base64.b64decode(data))
208	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/multimodal/video.py:207
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
206	
207	        return self.load_bytes(base64.b64decode(data))
208	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/platforms/cuda.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	            msg = (
45	                "CUDA_VISIBLE_DEVICES is set to empty string, which means"
46	                " GPU support is disabled. If you are using ray, please unset"
47	                " the environment variable `CUDA_VISIBLE_DEVICES` inside the"
48	                " worker/actor. "
49	                "Check https://github.com/vllm-project/vllm/issues/8402 for"
50	                " more information.")
51	            raise RuntimeError(msg)
52	        physical_device_id = device_ids[device_id]

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/spec_decode/spec_decode_worker.py:488
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
487	            assert num_lookahead_slots == 0, (
488	                "Prompt only runs should have num_lookahead_slots equal to 0. "
489	                "This should never happen, please file a bug at "
490	                "https://github.com/vllm-project/vllm/issues")

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/third_party/pynvml.py:2412
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
2411	                            # Check for nvml.dll in System32 first for DCH drivers
2412	                            nvmlLib = CDLL(os.path.join(os.getenv("WINDIR", "C:/Windows"), "System32/nvml.dll"))
2413	                        except OSError as ose:

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/third_party/pynvml.py:2416
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
2415	                            # load nvml.dll from %ProgramFiles%/NVIDIA Corporation/NVSMI/nvml.dll
2416	                            nvmlLib = CDLL(os.path.join(os.getenv("ProgramFiles", "C:/Program Files"), "NVIDIA Corporation/NVSMI/nvml.dll"))
2417	                    else:

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/third_party/pynvml.py:2419
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
2418	                        # assume linux
2419	                        nvmlLib = CDLL("libnvidia-ml.so.1")
2420	                except OSError as ose:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/transformers_utils/configs/arctic.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
18	ARCTIC_PRETRAINED_CONFIG_ARCHIVE_MAP = {
19	    "arctic": "https://huggingface.co/Snowflake/snowflake-arctic-instruct/tree/main/config.json",
20	}
21	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/transformers_utils/configs/mpt.py:169
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
168	                raise ImportError(
169	                    'TransformerEngine import fail. `fc_type: te` requires '
170	                    'TransformerEngine be installed. '
171	                    'The required version of transformer_engine also requires '

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/transformers_utils/s3_utils.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
111	        for sig in (signal.SIGINT, signal.SIGTERM):
112	            existing_handler = signal.getsignal(sig)
113	            signal.signal(sig, self._close_by_signal(existing_handler))

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/transformers_utils/s3_utils.py:113
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
112	            existing_handler = signal.getsignal(sig)
113	            signal.signal(sig, self._close_by_signal(existing_handler))
114	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/transformers_utils/s3_utils.py:113
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
112	            existing_handler = signal.getsignal(sig)
113	            signal.signal(sig, self._close_by_signal(existing_handler))
114	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/transformers_utils/s3_utils.py:113
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
112	            existing_handler = signal.getsignal(sig)
113	            signal.signal(sig, self._close_by_signal(existing_handler))
114	

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/transformers_utils/s3_utils.py:122
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
121	        if os.path.exists(self.dir):
122	            shutil.rmtree(self.dir)
123	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/transformers_utils/tokenizers/mistral.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
110	            with open(revision_file) as file:
111	                revision = file.read()
112	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/transformers_utils/utils.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
27	        with model.open("rb") as f:
28	            header = f.read(4)
29	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/usage/usage_lib.py:103
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
102	    for env_var, provider in env_to_cloud_provider.items():
103	        if os.environ.get(env_var):
104	            return provider

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/usage/usage_lib.py:154
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
153	                     extra_kvs: Optional[dict[str, Any]] = None) -> None:
154	        t = Thread(target=self._report_usage_worker,
155	                   args=(model_architecture, usage_context, extra_kvs or {}),
156	                   daemon=True)
157	        t.start()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/usage/usage_lib.py:183
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
182	        info = cpuinfo.get_cpu_info()
183	        self.num_cpu = info.get("count", None)
184	        self.cpu_type = info.get("brand_raw", "")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/usage/usage_lib.py:184
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
183	        self.num_cpu = info.get("count", None)
184	        self.cpu_type = info.get("brand_raw", "")
185	        self.cpu_family_model_stepping = ",".join([

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/usage/usage_lib.py:186
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
185	        self.cpu_family_model_stepping = ",".join([
186	            str(info.get("family", "")),
187	            str(info.get("model", "")),

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/usage/usage_lib.py:187
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
186	            str(info.get("family", "")),
187	            str(info.get("model", "")),
188	            str(info.get("stepping", ""))

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/usage/usage_lib.py:188
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
187	            str(info.get("model", "")),
188	            str(info.get("stepping", ""))
189	        ])

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/usage/usage_lib.py:233
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
232	            global_http_client = global_http_connection.get_sync_client()
233	            global_http_client.post(_USAGE_STATS_SERVER, json=data)
234	        except requests.exceptions.RequestException:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/usage/usage_lib.py:243
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
242	            json.dump(data, f)
243	            f.write("\n")
244	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:493
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
492	                f.cancel()
493	                await it.aclose()
494	

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:520
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
519	    # try ipv4
520	    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
521	    try:

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:522
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
521	    try:
522	        s.connect(("8.8.8.8", 80))  # Doesn't need to be reachable
523	        return s.getsockname()[0]

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:522
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
521	    try:
522	        s.connect(("8.8.8.8", 80))  # Doesn't need to be reachable
523	        return s.getsockname()[0]

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:529
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
528	    try:
529	        s = socket.socket(socket.AF_INET6, socket.SOCK_DGRAM)
530	        # Google's public DNS server, see

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:532
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
531	        # https://developers.google.com/speed/public-dns/docs/using#addresses
532	        s.connect(("2001:4860:4860::8888", 80))  # Doesn't need to be reachable
533	        return s.getsockname()[0]

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:542
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
541	        stacklevel=2)
542	    return "0.0.0.0"
543	

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:592
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
591	            try:
592	                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
593	                    s.bind(("", port))

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:601
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
600	    try:
601	        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
602	            s.bind(("", 0))

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:606
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
605	        # try ipv6
606	        with socket.socket(socket.AF_INET6, socket.SOCK_STREAM) as s:
607	            s.bind(("", 0))

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:622
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
621	            try:
622	                return psutil.Process(conn.pid)
623	            except psutil.NoSuchProcess:

--------------------------------------------------
>> Issue: [B829:getuser] getpass.getuser
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:1040
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b829_getuser.html
1039	        # add username to tmp_dir to avoid permission issues
1040	        tmp_dir = os.path.join(tmp_dir, getpass.getuser())
1041	        filename = (f"VLLM_TRACE_FUNCTION_for_process_{os.getpid()}"

--------------------------------------------------
>> Issue: [B329:blacklist] getpass_getuser
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:1040
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b329-getpass-getuser
1039	        # add username to tmp_dir to avoid permission issues
1040	        tmp_dir = os.path.join(tmp_dir, getpass.getuser())
1041	        filename = (f"VLLM_TRACE_FUNCTION_for_process_{os.getpid()}"

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:2005
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
2004	    try:
2005	        parent = psutil.Process(pid)
2006	    except psutil.NoSuchProcess:

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:2217
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
2216	        socket.setsockopt(zmq.constants.SNDBUF, buf_size)
2217	        socket.connect(path)
2218	    else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/utils.py:2274
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2273	        logger.warning(
2274	            "We must use the `spawn` multiprocessing start method. "
2275	            "Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. "
2276	            "See https://docs.vllm.ai/en/latest/getting_started/"
2277	            "troubleshooting.html#python-multiprocessing "
2278	            "for more information. Reason: %s", reason)
2279	        os.environ["VLLM_WORKER_MULTIPROC_METHOD"] = "spawn"
2280	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core.py:329
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
328	        self.output_queue: queue.Queue[EngineCoreOutputs] = queue.Queue()
329	        threading.Thread(target=self.process_input_socket,
330	                         args=(input_path, ),
331	                         daemon=True).start()
332	        threading.Thread(target=self.process_output_socket,

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core.py:332
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
331	                         daemon=True).start()
332	        threading.Thread(target=self.process_output_socket,
333	                         args=(output_path, engine_index),
334	                         daemon=True).start()
335	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core.py:364
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
363	        # Either SIGTERM or SIGINT will terminate the engine_core
364	        signal.signal(signal.SIGTERM, signal_handler)
365	        signal.signal(signal.SIGINT, signal_handler)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core.py:364
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
363	        # Either SIGTERM or SIGINT will terminate the engine_core
364	        signal.signal(signal.SIGTERM, signal_handler)
365	        signal.signal(signal.SIGINT, signal_handler)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core.py:365
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
364	        signal.signal(signal.SIGTERM, signal_handler)
365	        signal.signal(signal.SIGINT, signal_handler)
366	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core.py:365
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
364	        signal.signal(signal.SIGTERM, signal_handler)
365	        signal.signal(signal.SIGINT, signal_handler)
366	

--------------------------------------------------
>> Issue: [B805:send] socket.socket.send
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core.py:381
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b805_send.html
380	            # Send Readiness signal to EngineClient.
381	            ready_pipe.send({"status": "READY"})
382	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core.py:391
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
390	            logger.error("EngineCore hit an exception: %s", traceback)
391	            parent_process.send_signal(signal.SIGUSR1)
392	

--------------------------------------------------
>> Issue: [B805:send] socket.socket.send
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core.py:514
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b805_send.html
513	                encoder.encode_into(outputs, buffer)
514	                socket.send(buffer, copy=False)
515	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:292
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
291	                # Ensure socket is closed if process fails to start.
292	                self.close()
293	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:301
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
300	        if socket := getattr(self, "input_socket", None):
301	            socket.close(linger=0)
302	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:318
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
317	        for core_engine in self.core_engines:
318	            core_engine.close()
319	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:323
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
322	        if self.output_socket is not None:
323	            self.output_socket.close(linger=0)
324	        if self.shutdown_path is not None:

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:328
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
327	            with self.ctx.socket(zmq.PAIR) as shutdown_sender:
328	                shutdown_sender.connect(self.shutdown_path)
329	                # Send shutdown signal.

--------------------------------------------------
>> Issue: [B805:send] socket.socket.send
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:330
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b805_send.html
329	                # Send shutdown signal.
330	                shutdown_sender.send(b'')
331	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:365
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
364	
365	        if threading.current_thread() == threading.main_thread():
366	            signal.signal(signal.SIGUSR1, sigusr1_handler)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:365
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
364	
365	        if threading.current_thread() == threading.main_thread():
366	            signal.signal(signal.SIGUSR1, sigusr1_handler)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:366
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
365	        if threading.current_thread() == threading.main_thread():
366	            signal.signal(signal.SIGUSR1, sigusr1_handler)
367	        else:

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:366
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
365	        if threading.current_thread() == threading.main_thread():
366	            signal.signal(signal.SIGUSR1, sigusr1_handler)
367	        else:

--------------------------------------------------
>> Issue: [B809:recv] socket.socket.recv
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:475
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b809_recv.html
474	
475	                    frame = out_socket.recv(copy=False)
476	                    outputs = decoder.decode(frame.buffer)

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:484
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
483	                # Close sockets.
484	                shutdown_socket.close(linger=0)
485	                out_socket.close(linger=0)

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:485
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
484	                shutdown_socket.close(linger=0)
485	                out_socket.close(linger=0)
486	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/engine/core_client.py:488
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
487	        # Process outputs from engine in separate thread.
488	        self.output_queue_thread = Thread(target=process_outputs_socket,
489	                                          name="EngineCoreOutputQueueThread",
490	                                          daemon=True)
491	        self.output_queue_thread.start()

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
52	            # Propagate error up to parent process.
53	            parent_process = psutil.Process().parent()
54	            parent_process.send_signal(signal.SIGUSR1)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:54
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
53	            parent_process = psutil.Process().parent()
54	            parent_process.send_signal(signal.SIGUSR1)
55	            self.shutdown()

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
56	
57	        signal.signal(signal.SIGUSR1, sigusr1_handler)
58	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:57
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
56	
57	        signal.signal(signal.SIGUSR1, sigusr1_handler)
58	

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
72	        distributed_init_method = get_distributed_init_method(
73	            "127.0.0.1", get_open_port())
74	
75	        # Initialize worker and set up message queues for SchedulerOutputs

--------------------------------------------------
>> Issue: [B805:send] socket.socket.send
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:245
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b805_send.html
244	            ready_socket.send_string(WorkerProc.READY_STR)
245	            ready_socket.send(payload)
246	

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:273
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
272	        # Run EngineCore busy loop in background process.
273	        proc = context.Process(target=WorkerProc.worker_main,
274	                               kwargs=process_kwargs,
275	                               daemon=True)
276	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:312
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
311	        # Either SIGTERM or SIGINT will terminate the worker
312	        signal.signal(signal.SIGTERM, signal_handler)
313	        signal.signal(signal.SIGINT, signal_handler)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:312
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
311	        # Either SIGTERM or SIGINT will terminate the worker
312	        signal.signal(signal.SIGTERM, signal_handler)
313	        signal.signal(signal.SIGINT, signal_handler)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:313
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
312	        signal.signal(signal.SIGTERM, signal_handler)
313	        signal.signal(signal.SIGINT, signal_handler)
314	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:313
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
312	        signal.signal(signal.SIGTERM, signal_handler)
313	        signal.signal(signal.SIGINT, signal_handler)
314	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:333
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
332	            # error with IPC itself, we need to alert the parent.
333	            psutil.Process().parent().send_signal(signal.SIGUSR1)
334	            raise

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:333
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
332	            # error with IPC itself, we need to alert the parent.
333	            psutil.Process().parent().send_signal(signal.SIGUSR1)
334	            raise

--------------------------------------------------
>> Issue: [B809:recv] socket.socket.recv
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/executor/multiproc_executor.py:358
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b809_recv.html
357	        assert message == WorkerProc.READY_STR
358	        handle_frame = ready_socket.recv(copy=False)
359	        handle = pickle.loads(handle_frame.buffer)

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/structured_output/__init__.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
36	        max_workers = max(1, (multiprocessing.cpu_count() + 1) // 2)
37	        self.executor = ThreadPoolExecutor(max_workers=max_workers)
38	

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/v1/utils.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
117	        # Run busy loop in background process.
118	        self.proc = context.Process(target=target_fn,
119	                                    kwargs=process_kwargs,
120	                                    name=process_name)
121	        self._finalizer = weakref.finalize(self, shutdown, self.proc,

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/vllm/worker/worker_base.py:552
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
551	            "vllm_config is required to initialize the worker")
552	        enable_trace_function_call_for_thread(self.vllm_config)
553	

--------------------------------------------------

Code scanned:
	Total lines of code: 275397
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 185.0
		High: 310.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 451.0
		High: 44.0
Files skipped (1):
	/home2/blue/Documents/PyPIAgent/Dataset/evaluation/unzip_benign/vllm-0.8.3/vllm-0.8.3/.buildkite/nightly-benchmarks/scripts/convert-results-json-to-markdown.py (syntax error while parsing AST from file)
