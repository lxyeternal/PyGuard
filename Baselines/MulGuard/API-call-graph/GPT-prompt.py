import json
import openai
import re
import pandas as pd
from tqdm import tqdm

openai.api_key = ""
openai.base_url = ''

def read_json(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

def write_json(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

feature_set = read_json(r"output_top_500_katz_centrality.json")

prompt = f"""
feature_set = {feature_set}
You are a security API auditor. 
Your task is to determine whether a given Python API can potentially be used for malicious purposes.
Consider common attack techniques such as command execution, code obfuscation, data exfiltration, privilege escalation, etc.
If the API is not typically used in a malicious context, return a neutral evaluation.
Output must follow the required JSON format.
{{
    "api_name1": "xxx",
    "api_usage": "xxx"
}}.
"""

def get_response(prompt):
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You're playing an expert in the field of software engineering security."},
            {"role": "user", "content": prompt},
        ],
    )
    text = response.choices[0].message.content
    return text

result_json = get_response(prompt)

write_json(result_json, r"gpt_prompt_result_katz.json")
print(json.dumps(result_json, indent=2, ensure_ascii=False))
