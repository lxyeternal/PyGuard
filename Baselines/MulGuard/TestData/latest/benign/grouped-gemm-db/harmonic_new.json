{
    "torch.tensor": 8.125,
    "out.append": 7.625,
    "randn": 7.458333333333333,
    "to": 6.875,
    "torch.rand": 6.208333333333333,
    "torch.manual_seed": 6.0,
    "view": 6.0,
    "a.requires_grad_": 5.958333333333333,
    "b.requires_grad_": 5.958333333333333,
    "requires_grad_": 5.958333333333333,
    "ops.gmm": 5.958333333333333,
    "gmm": 5.958333333333333,
    "self.assertTrue": 5.958333333333333,
    "backward": 5.958333333333333,
    "mask.numel": 5.4375,
    "clone": 4.791666666666667,
    "out.sum": 4.791666666666667,
    "expected_out.sum": 4.791666666666667,
    "batch_sizes.cuda": 4.4375,
    "allclose": 4.4375,
    "get": 1.75,
    "nvcc_flags.extend": 1.125,
    "backend.gmm": 0.75,
    "a.detach": 0.5,
    "b.detach": 0.5,
    "Path": 0.25,
    "set": 0.25,
    "setup": 0.25,
    "get_device_capability": 0.25,
    "dirname": 0.25,
    "CUDAExtension": 0.25,
    "ModuleNotFoundError": 0.25,
    "abspath": 0.25,
    "read": 0.25,
    "find_packages": 0.25,
    "extra_deps.values": 0.25,
    "open": 0.25,
    "GroupedGemm.apply": 0.25,
    "ctx.save_for_backward": 0.25,
    "grad.contiguous": 0.25,
    "torch.empty": 0.25,
    "_allocate_output": 0.25,
    "add_flags": 0.25,
    "parameterized.parameters": 0.25,
    "torch.isclose": 0.25,
    "numpy": 0.25,
    "enumerate": 0.25,
    "torch.cat": 0.25,
    "unittest.main": 0.25,
    "print": 0.25,
    "dist.sum": 0.25,
    "format": 0.25,
    "out.cuda": 0.25,
    "batch_sizes.cpu": 0.25,
    "t": 0.25,
    "batch_sizes.sum": 0.25,
    "all": 0.25,
    "mask.sum": 0.25,
    "torch.logical_not": 0.25,
    "cuda": 0.25,
    "torch.ones": 0.25
}