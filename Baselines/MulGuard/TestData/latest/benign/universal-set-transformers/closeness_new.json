{
    "super": 0.897279914660379,
    "isinstance": 0.7172732077209689,
    "__init__": 0.6259738520613886,
    "torch.randn": 0.5465230595756329,
    "unsqueeze": 0.47380176930613965,
    "range": 0.4435738586050293,
    "nn.Linear": 0.44112272377784484,
    "transpose": 0.43339590376173587,
    "self.linear2": 0.4194015148842078,
    "self.attention": 0.41649832494357786,
    "reshape": 0.39560220732936546,
    "self.activation": 0.3892227175809266,
    "compute_aggregated_attention": 0.3646972745564295,
    "nn.Dropout": 0.36363636363636365,
    "getattr": 0.36363636363636365,
    "self.linear1": 0.36363636363636365,
    "math.sqrt": 0.33634071518180386,
    "key_multiplicities.float": 0.3043339452470269,
    "torch.sigmoid": 0.29554367201426024,
    "initial_state": 0.29212279021723925,
    "nn.Parameter": 0.2785111853842414,
    "iter": 0.27784564000844986,
    "torch.dropout": 0.2734456061936308,
    "MultiheadSetAttention": 0.2727272727272727,
    "expand": 0.27140668132690776,
    "next": 0.27128624992130046,
    "get": 0.2709021807613357,
    "self.assertFalse": 0.2697892971966882,
    "self.assertTrue": 0.2696137866157987,
    "torch.log": 0.2694886008789505,
    "torch.exp": 0.26712909605271323,
    "self.norm_x": 0.26699447234677426,
    "torch.cat": 0.26175567678684747,
    "self.dropout1": 0.26000516896039283,
    "self.dropout2": 0.26000516896039283,
    "Slots": 0.25964888350917764,
    "item": 0.2580185659411012,
    "self.mab2": 0.2552286210822796,
    "key.transpose": 0.2525461148714218,
    "self.wo": 0.25168415355215673,
    "self.slots": 0.2505455649725313,
    "torch.allclose": 0.24961246394823752,
    "any": 0.24859864560420838,
    "long": 0.24352163204304392,
    "torch.repeat_interleave": 0.23985888603357483,
    "self.norm_y": 0.23920116979093942,
    "view": 0.23782225237449117,
    "self.forward_immediate": 0.23776223776223776,
    "max": 0.23482714468629962,
    "hasattr": 0.23219860107300452,
    "torch.manual_seed": 0.23219860107300452,
    "float": 0.23219860107300452,
    "CrossSetAttentionBlock": 0.22884674447174447,
    "self.initial_state": 0.2287264973832138,
    "self.mab1": 0.2274216365125456,
    "self.forward_minibatch": 0.22727272727272727,
    "self.wk": 0.22652384928504332,
    "self.wv": 0.22652384928504332,
    "torch.isnan": 0.22545228078427273,
    "torch.isinf": 0.22545228078427273,
    "tuple": 0.21946434590222025,
    "minibatch.get": 0.21830808080808078,
    "torch.randint": 0.2178893695686762,
    "outputs_with_dup.append": 0.21726022094512104,
    "self.dropout_ffn": 0.21721008457982272,
    "abs": 0.21549790960731743,
    "warnings.catch_warnings": 0.21483601144618092,
    "self.wq": 0.21379748982360922,
    "self.scaled_dot_product_attention": 0.21201671891327062,
    "self.mab": 0.21075883575883578,
    "warnings.warn": 0.20979020979020976,
    "nn.LayerNorm": 0.2097678916827853,
    "nn.Identity": 0.2097678916827853,
    "query.size": 0.18822553897180763,
    "warnings.filterwarnings": 0.18181818181818182,
    "unittest.main": 0.18181818181818182,
    "warnings.simplefilter": 0.18181818181818182,
    "run": 0.18181818181818182,
    "SuppressWarningTextTestRunner": 0.18181818181818182,
    "k.transpose": 0.18181818181818182,
    "F.scaled_dot_product_attention": 0.18181818181818182,
    "F.softmax": 0.18181818181818182,
    "self.get": 0.18181818181818182,
    "attention.amax": 0.18181818181818182,
    "self.compute_aggregated_attention": 0.18181818181818182,
    "torch.where": 0.18181818181818182,
    "key_multiplicities.unsqueeze": 0.18181818181818182,
    "torch.normal": 0.18181818181818182,
    "k.repeat_interleave": 0.18181818181818182,
    "v.repeat_interleave": 0.18181818181818182,
    "k.size": 0.18181818181818182,
    "v.size": 0.18181818181818182,
    "self.norm_ffn": 0.18181818181818182,
    "TypeVar": 0.18181818181818182,
    "map": 0.18181818181818182,
    "nn.ModuleList": 0.18181818181818182,
    "self.norm": 0.18181818181818182,
    "self.dropout": 0.18181818181818182,
    "copy.deepcopy": 0.18181818181818182,
    "checkpoint": 0.18181818181818182,
    "self.softmax_block": 0.14533793671117615,
    "self.softmax_attention": 0.1448562655093878,
    "wq": 0.1439180537772087,
    "wk": 0.1439180537772087,
    "wv": 0.1439180537772087,
    "wo": 0.1439180537772087,
    "self.assertEqual": 0.1412895101639136,
    "self.compute_immediate_attention": 0.13939393939393938,
    "self._feedforward": 0.13868413868413867,
    "self.sigmoid_block": 0.13640185754963977,
    "self.assertLess": 0.13640185754963977,
    "attention.transpose": 0.1350169100224792,
    "zip": 0.1331265749176197,
    "itertools.chain": 0.13271225771225773,
    "self.reference_fn": 0.13235700469743025,
    "self.compute_attention": 0.13084454875499651,
    "norm_x": 0.12830805244181206,
    "norm_y": 0.12830805244181206,
    "norm_ffn": 0.12830805244181206,
    "linear1": 0.12830805244181206,
    "activation": 0.12830805244181206,
    "dropout_ffn": 0.12830805244181206,
    "linear2": 0.12830805244181206,
    "ScaledDotProductSoftmaxFlashSetAttention": 0.1273989898989899,
    "ScaledDotProductSoftmaxSetAttention": 0.12698027865958528,
    "ScaledDotProductSigmoidSetAttention": 0.12698027865958528,
    "q_proj.view": 0.12698027865958528,
    "k1_proj.view": 0.12698027865958528,
    "v1_proj.view": 0.12698027865958528,
    "m1.unsqueeze": 0.12698027865958528,
    "k2_proj.view": 0.12698027865958528,
    "v2_proj.view": 0.12698027865958528,
    "m2.unsqueeze": 0.12698027865958528,
    "attn_output.transpose": 0.12698027865958528,
    "k_proj.view": 0.12698027865958528,
    "v_proj.view": 0.12698027865958528,
    "self.sigmoid_attention": 0.12477592829705507,
    "MultiheadSetAttentionBlock": 0.12171122994652407,
    "dropout1": 0.1166307395581776,
    "dropout2": 0.1166307395581776,
    "output.isnan": 0.10576351752822342,
    "output.masked_fill": 0.0962566844919786,
    "output.transpose": 0.09318181818181817,
    "SelfSetAttentionBlock": 0.09090909090909091,
    "k1.size": 0.09090909090909091,
    "v1.size": 0.09090909090909091,
    "k2.size": 0.09090909090909091,
    "v2.size": 0.09090909090909091,
    "y1.size": 0.09090909090909091,
    "y2.size": 0.09090909090909091,
    "setUp": 0.09090909090909091,
    "self.attention_cls": 0.09090909090909091,
    "torch.zeros_like": 0.09090909090909091,
    "test_minibatch_consistency": 0.09090909090909091,
    "self.assertWarns": 0.09090909090909091,
    "self.skipTest": 0.09090909090909091,
    "k_dup_list.append": 0.09090909090909091,
    "v_dup_list.append": 0.09090909090909091,
    "reference_outputs.append": 0.09090909090909091,
    "F.sigmoid": 0.09090909090909091,
    "scores.sum": 0.09090909090909091,
    "MultiheadSlotSetAttention": 0.09090909090909091,
    "SoftmaxFlashSetAttention": 0.09090909090909091,
    "SoftmaxSlotSetAttention": 0.09090909090909091,
    "scaled_dot_product_attention.get": 0.09090909090909091,
    "scaled_dot_product_attention": 0.09090909090909091,
    "x.float": 0.09090909090909091,
    "multiplicities.float": 0.09090909090909091,
    "version": 0.09090909090909091,
    "immediate_call": 0.09090909090909091,
    "NotImplementedError": 0.09090909090909091,
    "MultiheadSetAttentionBlock.forward": 0.09090909090909091,
    "self.mhsa": 0.09090909090909091,
    "ValueError": 0.09090909090909091,
    "mod": 0.09090909090909091,
    "state.copy": 0.09090909090909091,
    "object": 0.09090909090909091,
    "self.generic_step": 0.09090909090909091,
    "SelfSetAttentionBlock.forward": 0.09090909090909091,
    "src.pop": 0.09090909090909091,
    "persisted_src.append": 0.09090909090909091,
    "self.preprocessor": 0.09090909090909091,
    "self.prepooler": 0.09090909090909091,
    "self.encoder": 0.09090909090909091,
    "self.pooler": 0.09090909090909091,
    "self.decoder": 0.09090909090909091,
    "layer": 0.09090909090909091,
    "self._minibatch_map_and_persist": 0.09090909090909091,
    "mb.get": 0.09090909090909091,
    "pipe": 0.09090909090909091,
    "unflatten": 0.09090909090909091,
    "attention.sum": 0.09090909090909091
}