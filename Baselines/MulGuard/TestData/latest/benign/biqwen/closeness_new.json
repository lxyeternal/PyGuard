{
    "to": 1.25877773860357,
    "isinstance": 1.2060980626295585,
    "getattr": 1.2005648048820152,
    "expand": 1.1882317213309253,
    "float": 1.1882317213309253,
    "torch.cat": 1.114182918112728,
    "torch.arange": 1.0747126951458896,
    "transpose": 1.0706195461787644,
    "logger.warning_once": 1.0664127406152153,
    "ValueError": 1.0623951589384661,
    "contiguous": 1.0604619614216348,
    "hidden_states.to": 1.0546095767879762,
    "__init__": 1.0471411514737128,
    "nn.Linear": 1.044477928038614,
    "normal_": 1.04167680155728,
    "get": 1.039899324667441,
    "super": 1.029569576101662,
    "torch.finfo": 1.0262639905378927,
    "cache_position.reshape": 1.0254386688732695,
    "past_key_values.get_seq_length": 1.024629312112083,
    "zero_": 1.022199079599355,
    "range": 1.011307146939902,
    "config.get_text_config": 1.0017788542445125,
    "self.post_init": 0.9989684254211814,
    "self.loss_function": 0.9661114512507799,
    "torch.matmul": 0.9198821033847197,
    "self.model": 0.9127770062497461,
    "self.score": 0.9120101496655311,
    "view": 0.8463438676500279,
    "add_start_docstrings_to_model_forward": 0.677249343832021,
    "is_torch_flex_attn_available": 0.6666666666666666,
    "logging.get_logger": 0.6666666666666666,
    "use_kernel_forward_from_hub": 0.6666666666666666,
    "add_start_docstrings": 0.6666666666666666,
    "cos.unsqueeze": 0.6666666666666666,
    "sin.unsqueeze": 0.6666666666666666,
    "hidden_states.reshape": 0.6666666666666666,
    "repeat_kv": 0.6666666666666666,
    "dropout": 0.6666666666666666,
    "torch.no_grad": 0.6666666666666666,
    "replace_return_docstrings": 0.6666666666666666,
    "add_code_sample_docstrings": 0.6666666666666666,
    "self.down_proj": 0.6666666666666666,
    "apply_rotary_pos_emb": 0.6666666666666666,
    "attention_interface": 0.6666666666666666,
    "self.o_proj": 0.6666666666666666,
    "nn.Parameter": 0.6666666666666666,
    "mean": 0.6666666666666666,
    "self.input_layernorm": 0.6666666666666666,
    "self.self_attn": 0.6666666666666666,
    "self.post_attention_layernorm": 0.6666666666666666,
    "self.mlp": 0.6666666666666666,
    "self.rope_init_fn": 0.6666666666666666,
    "self.register_buffer": 0.6666666666666666,
    "nn.Embedding": 0.6666666666666666,
    "nn.ModuleList": 0.6666666666666666,
    "self._update_causal_mask": 0.6666666666666666,
    "self.rotary_emb": 0.6666666666666666,
    "zip": 0.6666666666666666,
    "self.norm": 0.6666666666666666,
    "BaseModelOutputWithPast": 0.6666666666666666,
    "self._prepare_4d_causal_attention_mask_with_cache_position": 0.6666666666666666,
    "self.lm_head": 0.6666666666666666,
    "CausalLMOutputWithPast": 0.6666666666666666,
    "SequenceClassifierOutputWithPast": 0.6666666666666666,
    "nn.Dropout": 0.6666666666666666,
    "self.dropout": 0.6666666666666666,
    "TokenClassifierOutput": 0.6666666666666666,
    "self.transformer": 0.6666666666666666,
    "self.qa_outputs": 0.6666666666666666,
    "logits.split": 0.6666666666666666,
    "QuestionAnsweringModelOutput": 0.6666666666666666,
    "rotate_half": 0.6666666666666666,
    "key_states.transpose": 0.6666666666666666,
    "softmax": 0.6666666666666666,
    "attn_output.transpose": 0.6666666666666666,
    "past_key_value.update": 0.6666666666666666,
    "torch.ones": 0.6666666666666666,
    "torch.rsqrt": 0.6666666666666666,
    "hasattr": 0.6666666666666666,
    "torch.autocast": 0.6666666666666666,
    "cos.to": 0.6666666666666666,
    "sin.to": 0.6666666666666666,
    "self.embed_tokens": 0.6666666666666666,
    "DynamicCache": 0.6666666666666666,
    "cache_position.unsqueeze": 0.6666666666666666,
    "torch.zeros_like": 0.6666666666666666,
    "decoder_layer": 0.6666666666666666,
    "AttentionMaskConverter._ignore_causal_mask_sdpa": 0.6666666666666666,
    "past_key_values.get_max_cache_shape": 0.6666666666666666,
    "AttentionMaskConverter._unmask_unattended": 0.6666666666666666,
    "torch.full": 0.6666666666666666,
    "slice": 0.6666666666666666,
    "self.act_fn": 0.6666666666666666,
    "self.up_proj": 0.6666666666666666,
    "kwargs.get": 0.6666666666666666,
    "attn_output.reshape": 0.6666666666666666,
    "hidden_states.pow": 0.6666666666666666,
    "tuple": 0.6666666666666666,
    "emb.cos": 0.6666666666666666,
    "emb.sin": 0.6666666666666666,
    "make_flex_block_causal_mask": 0.6666666666666666,
    "attention_mask.dim": 0.6666666666666666,
    "causal_mask.clone": 0.6666666666666666,
    "masked_fill": 0.6666666666666666,
    "argmax": 0.6666666666666666,
    "start_logits.squeeze": 0.6666666666666666,
    "end_logits.squeeze": 0.6666666666666666,
    "self.gate_proj": 0.6666666666666666,
    "fill_": 0.6666666666666666,
    "type": 0.6666666666666666,
    "item": 0.6666666666666666,
    "diagonal_attend_mask.bitwise_or_": 0.6666666666666666,
    "self.q_proj": 0.6666666666666666,
    "self.k_proj": 0.6666666666666666,
    "self.v_proj": 0.6666666666666666,
    "inv_freq_expanded.float": 0.6666666666666666,
    "position_ids_expanded.float": 0.6666666666666666,
    "input_tensor.size": 0.6666666666666666,
    "sum": 0.6666666666666666,
    "Qwen3RMSNorm": 0.5030284675953968,
    "Qwen2RMSNorm": 0.4994723404255319,
    "Qwen2Model": 0.45767303609341825,
    "Qwen3Model": 0.4566521576107334,
    "Qwen2Attention": 0.3333333333333333,
    "Qwen2MLP": 0.3333333333333333,
    "Qwen2RotaryEmbedding": 0.3333333333333333,
    "Qwen2DecoderLayer": 0.3333333333333333,
    "int": 0.3333333333333333,
    "logging.basicConfig": 0.3333333333333333,
    "logging.getLogger": 0.3333333333333333,
    "os.getenv": 0.3333333333333333,
    "Qwen3Attention": 0.3333333333333333,
    "Qwen3MLP": 0.3333333333333333,
    "Qwen3RotaryEmbedding": 0.3333333333333333,
    "self.q_norm": 0.3333333333333333,
    "self.k_norm": 0.3333333333333333,
    "Qwen3DecoderLayer": 0.3333333333333333
}