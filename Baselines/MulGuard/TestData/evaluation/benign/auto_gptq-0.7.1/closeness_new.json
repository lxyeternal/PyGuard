{
    "range": 0.5440797191032496,
    "to": 0.5281378874567813,
    "isinstance": 0.5139978047555817,
    "len": 0.5107032308048568,
    "getLogger": 0.41509433962264153,
    "torch.zeros": 0.3577768782275541,
    "__init__": 0.34234748574220036,
    "contiguous": 0.3230750359652574,
    "super": 0.3187692099173889,
    "ValueError": 0.29264494894567966,
    "NotImplementedError": 0.2718554170120243,
    "torch.tensor": 0.2658881400870627,
    "self.register_buffer": 0.2624923744666904,
    "torch.cat": 0.23138024484464847,
    "clone": 0.21214903846962935,
    "list": 0.20722409285009297,
    "AutoGPTQForCausalLM.from_quantized": 0.20473152100065592,
    "float": 0.20137126809949332,
    "tokenizer": 0.19485886231169247,
    "model.named_modules": 0.19441606287550656,
    "AutoTokenizer.from_pretrained": 0.19057976203262803,
    "torch.device": 0.18795371062702199,
    "join": 0.18597300478836631,
    "int": 0.18311119287485841,
    "self.assertTrue": 0.1818058288549732,
    "reshape": 0.17701544609905598,
    "logger.info": 0.17217604091060726,
    "torch.no_grad": 0.169302974417175,
    "torch.round": 0.16455606549946172,
    "setattr": 0.15991520033919865,
    "math.ceil": 0.15919472262306464,
    "tokenizer.decode": 0.15098047604786147,
    "max": 0.1477519041795287,
    "dynamically_import_QuantLinear": 0.1453228285989928,
    "hasattr": 0.1406306155072236,
    "min": 0.13917755200774068,
    "torch.from_numpy": 0.13855948035383675,
    "logger.warning": 0.13437825378123322,
    "print": 0.13416071024105108,
    "compare_transformers_version": 0.1320754716981132,
    "unsqueeze": 0.1314089881488779,
    "getattr": 0.12471073869736064,
    "astype": 0.12469733172079864,
    "np.zeros": 0.12469733172079864,
    "generate": 0.12049917737249273,
    "torch.empty": 0.11631169032858388,
    "half": 0.11509473789134127,
    "x.reshape": 0.11320754716981132,
    "empty_cache": 0.11216939597146076,
    "isfile": 0.10459165465546287,
    "cls": 0.10385928826655065,
    "W.flatten": 0.10319221603242308,
    "W.t": 0.10319221603242308,
    "enumerate": 0.10038703434929849,
    "model.get_submodule": 0.09433962264150944,
    "tqdm": 0.09433962264150944,
    "qweight.astype": 0.09433962264150944,
    "qzeros.astype": 0.09433962264150944,
    "intweight.append": 0.09433962264150944,
    "intweight.t": 0.09433962264150944,
    "intweight.numpy": 0.09433962264150944,
    "scales.t": 0.09433962264150944,
    "torch.matmul": 0.09234765053820271,
    "torch.rand": 0.09210574899383377,
    "str": 0.0920878417496431,
    "isdir": 0.08953151195942226,
    "set": 0.08759487110254535,
    "run": 0.08433390508862207,
    "time.time": 0.08316249169945428,
    "keys": 0.0830763701707098,
    "torch.bitwise_and": 0.08228555292782688,
    "any": 0.08097818275393565,
    "s.reshape": 0.07781869799286345,
    "zeros.reshape": 0.07669937185583756,
    "torch.sum": 0.07654626788080798,
    "model.generate": 0.07547169811320754,
    "name.rsplit": 0.07547169811320754,
    "sum": 0.07547169811320754,
    "numpy": 0.07547169811320754,
    "cpu": 0.07547169811320754,
    "item": 0.07547169811320754,
    "zeros.t": 0.07547169811320754,
    "scales.clone": 0.07547169811320754,
    "zeros.numpy": 0.07547169811320754,
    "get_device_capability": 0.07303000099247163,
    "torch.zeros_like": 0.06910806174957118,
    "autogptq_post_init": 0.06878387386604062,
    "weight.reshape": 0.06854654779183081,
    "get": 0.06834271450038007,
    "items": 0.06723037707332376,
    "huggingface_hub.cached_assets_path": 0.06657345976676698,
    "w.reshape": 0.06498946446441639,
    "open": 0.06476348697779812,
    "math.log2": 0.06468402112131302,
    "torch.arange": 0.06419245102550915,
    "find_layers": 0.0615869933700223,
    "self.skipTest": 0.061262650092999235,
    "zip": 0.060793331178893115,
    "w.permute": 0.060008267735771906,
    "device": 0.05878084179970972,
    "scales.contiguous": 0.05833672012748597,
    "expand": 0.058075814384776644,
    "torch.randn": 0.05740666399036532,
    "torch.unsqueeze": 0.05675351901766996,
    "kwargs.pop": 0.05667170512918123,
    "torch.clamp": 0.05660377358490566,
    "_get_perms": 0.05660377358490566,
    "torch.all": 0.05660377358490566,
    "copy.deepcopy": 0.05660377358490566,
    "t": 0.05660377358490566,
    "json.load": 0.05660377358490566,
    "prepare_buffers": 0.05660377358490566,
    "all": 0.05660377358490566,
    "autocast": 0.05660377358490566,
    "QuantLinear": 0.05660377358490566,
    "triton.Config": 0.05660377358490566,
    "sorted": 0.05660377358490566,
    "recurse_setattr": 0.05660377358490566,
    "torch.bitwise_right_shift": 0.05660377358490566,
    "ImportError": 0.05660377358490566,
    "logger.warning_once": 0.05660377358490566,
    "g_idx.clone": 0.05660377358490566,
    "logger.debug": 0.05641519406046318,
    "TypeError": 0.052165658004034644,
    "tl.arange": 0.05200944104900788,
    "safe_save": 0.05151305357927646,
    "zeros.contiguous": 0.05126054493488238,
    "device_map.items": 0.051105976981987766,
    "synchronize": 0.050571171864972404,
    "get_device": 0.050428736556658714,
    "extensions.append": 0.05033462344783099,
    "self.model": 0.050254861385425086,
    "next": 0.04998596626572523,
    "torch.allclose": 0.04992917542569976,
    "linear_class": 0.04991594933773874,
    "torch.randint": 0.04991594933773874,
    "get_module_by_name_suffix": 0.04985902204594159,
    "QuantLinear.warmup": 0.048746546647012876,
    "torch.inference_mode": 0.04865881200485822,
    "warmup": 0.04844547288477513,
    "split": 0.048283660174840516,
    "cached_file": 0.04813483744301355,
    "make_quant": 0.048120938829375993,
    "scales.reshape": 0.04805676503789711,
    "x.flatten": 0.04780922431865828,
    "model_name_or_path.split": 0.0477055352384651,
    "EnvironmentError": 0.04763355194473325,
    "self.assertFalse": 0.047547169811320754,
    "abs": 0.04754320252972544,
    "name.startswith": 0.04722257466218117,
    "long": 0.04705589496067777,
    "AutoConfig.from_pretrained": 0.0464672621139664,
    "quantize": 0.046272607753260135,
    "is_available": 0.045525606469002694,
    "apply_rotary_pos_emb": 0.04387668672235528,
    "tl.zeros": 0.04291934480613726,
    "tl.store": 0.04291934480613726,
    "tl.load": 0.04291934480613726,
    "tl.program_id": 0.042573778422835024,
    "tl.cdiv": 0.042573778422835024,
    "tl.dot": 0.04200461026210194,
    "strip": 0.041837571780147666,
    "quant_matmul_248": 0.03991291727140784,
    "lower": 0.03930817610062892,
    "nn.Linear": 0.03773584905660377,
    "torch.max": 0.03773584905660377,
    "torch.full": 0.03773584905660377,
    "MarlinQuantLinear": 0.03773584905660377,
    "autogptq_marlin_cuda.gptq_repack": 0.03773584905660377,
    "torch.abs": 0.03773584905660377,
    "torch.mean": 0.03773584905660377,
    "_get_cached_marlin_save_name": 0.03773584905660377,
    "tempfile.TemporaryDirectory": 0.03773584905660377,
    "model.save_pretrained": 0.03773584905660377,
    "set_tuning_params": 0.03773584905660377,
    "mean": 0.03773584905660377,
    "numel": 0.03773584905660377,
    "BaseQuantizeConfig": 0.03773584905660377,
    "AutoGPTQForCausalLM.from_pretrained": 0.03773584905660377,
    "model.quantize": 0.03773584905660377,
    "GPTQLoraConfig": 0.03773584905660377,
    "GPTQAdaLoraConfig": 0.03773584905660377,
    "autogptq_marlin_cuda.mul": 0.03773584905660377,
    "tensor.view": 0.03773584905660377,
    "softmax": 0.03773584905660377,
    "compare_pytorch_version": 0.03773584905660377,
    "torch.finfo": 0.03773584905660377,
    "self.qkv_proj": 0.03773584905660377,
    "F.scaled_dot_product_attention": 0.03773584905660377,
    "torch.ones": 0.03773584905660377,
    "math.sqrt": 0.03773584905660377,
    "custom_autotune.autotune": 0.03773584905660377,
    "kn_values.items": 0.03773584905660377,
    "triton.cdiv": 0.03773584905660377,
    "load_checkpoint_in_model": 0.03773584905660377,
    "preprocess_checkpoint_qigen": 0.03773584905660377,
    "tolist": 0.03773584905660377,
    "accelerate.cpu_offload_with_hook": 0.03773584905660377,
    "values": 0.03773584905660377,
    "name.endswith": 0.03773584905660377,
    "find_tied_parameters": 0.03773584905660377,
    "device_to_buffers_size.items": 0.03773584905660377,
    "qinfer.unpack_zeros4": 0.03773584905660377,
    "qinfer.unpack_zeros2": 0.03773584905660377,
    "scales.transpose": 0.03773584905660377,
    "zeros.transpose": 0.03773584905660377,
    "name.split": 0.03773584905660377,
    "gc.collect": 0.03773584905660377,
    "new_module.to": 0.03773584905660377,
    "unpack_qzeros": 0.03773584905660377,
    "load_dataset": 0.03773584905660377,
    "type_as": 0.03773584905660377,
    "labels.append": 0.03773584905660377,
    "GenerationConfig": 0.03773584905660377,
    "postprocess_generation_ids": 0.03773584905660377,
    "decode": 0.03773584905660377,
    "np.array": 0.03773584905660377,
    "out.to": 0.03773584905660377,
    "x.view": 0.03773584905660377,
    "output.view": 0.03773584905660377,
    "x.half": 0.03773584905660377,
    "out.reshape": 0.03773584905660377,
    "transpose_quant_matmul_248": 0.03773584905660377,
    "model_autogptq.named_modules": 0.03522012578616352,
    "AutoAWQForCausalLM.from_quantized": 0.03522012578616352,
    "model_awq.generate": 0.03522012578616352,
    "partial": 0.03518612952575217,
    "move_to_device": 0.0347156915803936,
    "torch.Tensor": 0.03367510526223068,
    "cpp_extension.CUDAExtension": 0.03304154571843251,
    "model_q.generate": 0.03285248411034575,
    "_convert_tensor_to_list": 0.032714710891998185,
    "self.prune_configs": 0.031355579811840534,
    "get_balanced_memory": 0.031330032255628554,
    "find_params": 0.031217838765008575,
    "fields": 0.031217761014841826,
    "torch.manual_seed": 0.03104802480943686,
    "linear.eval": 0.03104802480943686,
    "linear.to": 0.03104802480943686,
    "make_q_matrix": 0.030956828341763387,
    "remove_hook_from_module": 0.030945738184741826,
    "attn_output.size": 0.030637390121004818,
    "CUDA_OLD_REFERENCE.to": 0.03048586633492294,
    "self.assertEqual": 0.03048586633492294,
    "transpose": 0.03043446830044097,
    "np.exp": 0.03034756703078451,
    "arg_names.index": 0.030314941871545643,
    "self.hook": 0.030314941871545643,
    "warnings.warn": 0.030274932614555255,
    "m.solve": 0.030064275347294216,
    "copy.copy": 0.029845626072041165,
    "model.to": 0.029801440355134587,
    "model.tie_weights": 0.029747542385491835,
    "accelerate.init_empty_weights": 0.029747542385491835,
    "state_dict": 0.029704539943368555,
    "accelerate.infer_auto_device_map": 0.029704539943368555,
    "platform.machine": 0.029666874006496646,
    "sample_blocks.append": 0.029649595687331536,
    "torch.diag": 0.029624301444143197,
    "scale.append": 0.029624301444143197,
    "zero.append": 0.029624301444143197,
    "_validate_marlin_compatibility": 0.0296195468812896,
    "torch.any": 0.029584281190062,
    "cuda": 0.029503253559857334,
    "sys.exit": 0.02941573564653863,
    "self.save_quantized": 0.029412784912962914,
    "device_map.values": 0.029313336970008128,
    "AutoModelForCausalLM.from_config": 0.029292501334430655,
    "get_module_by_name_prefix": 0.02925301430107411,
    "nested_move_to_device": 0.02925301430107411,
    "os.listdir": 0.029213825283063648,
    "gen_quant4": 0.029165645675079635,
    "x.float": 0.029143872576383463,
    "layers.keys": 0.029098012961181988,
    "platform.system": 0.028946944041283663,
    "layer": 0.02891064870416953,
    "self.linear_module": 0.028849056603773585,
    "get_diff": 0.02880432212606989,
    "searched_files.append": 0.028782214303480696,
    "simple_dispatch_model": 0.02865958059977284,
    "add_batch": 0.028624734848628815,
    "parse_version": 0.02830188679245283,
    "to_dict": 0.028257183774917868,
    "tuple": 0.02818075219738156,
    "model.eval": 0.028099115437432747,
    "linear": 0.02807726864330638,
    "self.unmerge": 0.028045977011494253,
    "config.pre_hook": 0.028025538402896896,
    "_get_linear_feature_count": 0.027941680960548887,
    "delattr": 0.027941680960548887,
    "_get_weight": 0.027941680960548887,
    "self.update_layer": 0.027941680960548887,
    "module.named_children": 0.027936809749008085,
    "new_module.named_modules": 0.027839728641085436,
    "convert_to_marlin": 0.027797594155125335,
    "attn_weights.size": 0.027695023722829084,
    "inject_to_model": 0.027655308182186075,
    "Event": 0.02756282062429354,
    "start_event.record": 0.02756282062429354,
    "torch.maximum": 0.027551868719728183,
    "attention_mask.size": 0.027359817424302737,
    "end_event.record": 0.0272911051212938,
    "start_event.elapsed_time": 0.0272911051212938,
    "latencies.append": 0.0272911051212938,
    "exllama_set_max_input_length": 0.026901607692454744,
    "self.assertRaises": 0.026901607692454744,
    "np.mean": 0.02635519616651692,
    "np.percentile": 0.02635519616651692,
    "module.to": 0.026193526051583867,
    "linear_gptq": 0.025961129238189815,
    "linear_awq": 0.025961129238189815,
    "tensor.permute": 0.0257312136841418,
    "submodule.post_init": 0.02566958844383153,
    "LoraModel._create_new_module": 0.02563479373201151,
    "recurse_getattr": 0.025453555878084178,
    "fixed_pos_embedding": 0.02500876219405339,
    "dict": 0.02484028140303776,
    "outputs.append": 0.024764150943396228,
    "input.stride": 0.023222060957910014,
    "qweight.stride": 0.023222060957910014,
    "output.stride": 0.023222060957910014,
    "scales.stride": 0.023222060957910014,
    "qzeros.stride": 0.023222060957910014,
    "scales.to": 0.022600041467965997,
    "get_gptq_peft_model": 0.022461814914645103,
    "self.check_model_trainable": 0.022461814914645103,
    "check_and_get_model_type": 0.022012578616352203,
    "inp.t": 0.020926243567753,
    "self.temp_dq_size": 0.020693852708460133,
    "get_closest_label": 0.02050861361771944,
    "m.Var": 0.019766397124887692,
    "m.Equation": 0.019766397124887692,
    "input_ids.append": 0.01945754716981132,
    "label_ids.append": 0.01945754716981132,
    "stride": 0.019328117809479982,
    "unpacked_qzeros.repeat_interleave": 0.019252984212552945,
    "normal_": 0.019245283018867926,
    "torch.clamp_": 0.019245283018867926,
    "old_module.parameters": 0.019245283018867926,
    "old_module.buffers": 0.019245283018867926,
    "g_idx_i.long": 0.01923076923076923,
    "cholesky": 0.019210977701543737,
    "m.view": 0.019145394006659266,
    "wf.unsqueeze": 0.019017669961066186,
    "f.get_tensor": 0.018986590720303786,
    "common_setup_kwargs.update": 0.018867924528301886,
    "setup": 0.018867924528301886,
    "read_text": 0.018867924528301886,
    "find_packages": 0.018867924528301886,
    "os.cpu_count": 0.018867924528301886,
    "subprocess.check_output": 0.018867924528301886,
    "get_python_lib": 0.018867924528301886,
    "include_dirs.append": 0.018867924528301886,
    "startswith": 0.018867924528301886,
    "Exception": 0.018867924528301886,
    "cpp_extension.CppExtension": 0.018867924528301886,
    "Path": 0.018867924528301886,
    "subprocess.run": 0.018867924528301886,
    "w.clone": 0.018867924528301886,
    "ref.t": 0.018867924528301886,
    "CudaOldQuantLinear": 0.018867924528301886,
    "cuda_old_linear.pack": 0.018867924528301886,
    "dequantize_weight": 0.018867924528301886,
    "dequantized_weight.to": 0.018867924528301886,
    "Linear": 0.018867924528301886,
    "copy_": 0.018867924528301886,
    "marlin_linear.pack": 0.018867924528301886,
    "cuda_old_linear.to": 0.018867924528301886,
    "marlin_linear.to": 0.018867924528301886,
    "linear_module.to": 0.018867924528301886,
    "cuda_old_linear": 0.018867924528301886,
    "marlin_linear": 0.018867924528301886,
    "res_cuda_old.abs": 0.018867924528301886,
    "os.remove": 0.018867924528301886,
    "parameterized.expand": 0.018867924528301886,
    "model_q.named_modules": 0.018867924528301886,
    "model_q.named_parameters": 0.018867924528301886,
    "model_q.named_buffers": 0.018867924528301886,
    "predicted_text.startswith": 0.018867924528301886,
    "torch.count_nonzero": 0.018867924528301886,
    "ref.abs": 0.018867924528301886,
    "linear_gptq.eval": 0.018867924528301886,
    "linear_gptq.to": 0.018867924528301886,
    "format": 0.018867924528301886,
    "lines.append": 0.018867924528301886,
    "ModuleNotFoundError": 0.018867924528301886,
    "WQLinear_GEMV": 0.018867924528301886,
    "WQLinear_GEMM": 0.018867924528301886,
    "logging.basicConfig": 0.018867924528301886,
    "model.save_quantized": 0.018867924528301886,
    "model_lora.gradient_checkpointing_enable": 0.018867924528301886,
    "Adam": 0.018867924528301886,
    "model_lora.train": 0.018867924528301886,
    "value.to": 0.018867924528301886,
    "model_lora.parameters": 0.018867924528301886,
    "optimizer.zero_grad": 0.018867924528301886,
    "losses.append": 0.018867924528301886,
    "loss.backward": 0.018867924528301886,
    "optimizer.step": 0.018867924528301886,
    "batch.items": 0.018867924528301886,
    "loss.item": 0.018867924528301886,
    "model_lora": 0.018867924528301886,
    "math.isfinite": 0.018867924528301886,
    "math.isnan": 0.018867924528301886,
    "torch.stack": 0.018867924528301886,
    "m.repeat": 0.018867924528301886,
    "torch.sin": 0.018867924528301886,
    "torch.cos": 0.018867924528301886,
    "nn.Dropout": 0.018867924528301886,
    "qkv.view": 0.018867924528301886,
    "query.to": 0.018867924528301886,
    "key.to": 0.018867924528301886,
    "torch.where": 0.018867924528301886,
    "attn_weights.to": 0.018867924528301886,
    "self.attn_dropout": 0.018867924528301886,
    "self._split_heads": 0.018867924528301886,
    "key.permute": 0.018867924528301886,
    "query.permute": 0.018867924528301886,
    "value.permute": 0.018867924528301886,
    "self._merge_heads": 0.018867924528301886,
    "self.out_proj": 0.018867924528301886,
    "self.resid_dropout": 0.018867924528301886,
    "duplicate_interleave": 0.018867924528301886,
    "rotate_every_two": 0.018867924528301886,
    "view": 0.018867924528301886,
    "torch.get_default_dtype": 0.018867924528301886,
    "query.size": 0.018867924528301886,
    "key.size": 0.018867924528301886,
    "key.transpose": 0.018867924528301886,
    "query.contiguous": 0.018867924528301886,
    "key.contiguous": 0.018867924528301886,
    "value.contiguous": 0.018867924528301886,
    "self._attn": 0.018867924528301886,
    "torch.sqrt": 0.018867924528301886,
    "qkv.size": 0.018867924528301886,
    "tensor.size": 0.018867924528301886,
    "torch.einsum": 0.018867924528301886,
    "torch.tril": 0.018867924528301886,
    "m.buffers": 0.018867924528301886,
    "hidden_states.size": 0.018867924528301886,
    "torch.split": 0.018867924528301886,
    "self.rotary_emb": 0.018867924528301886,
    "attn_output.transpose": 0.018867924528301886,
    "attn_output.reshape": 0.018867924528301886,
    "self.o_proj": 0.018867924528301886,
    "past_key_value.get_usable_length": 0.018867924528301886,
    "past_key_value.update": 0.018867924528301886,
    "query_states.contiguous": 0.018867924528301886,
    "key_states.contiguous": 0.018867924528301886,
    "value_states.contiguous": 0.018867924528301886,
    "query_states.view": 0.018867924528301886,
    "key_states.view": 0.018867924528301886,
    "value_states.view": 0.018867924528301886,
    "key_states.transpose": 0.018867924528301886,
    "silu": 0.018867924528301886,
    "c.to": 0.018867924528301886,
    "self.down_proj": 0.018867924528301886,
    "self.triton_llama_mlp": 0.018867924528301886,
    "c.reshape": 0.018867924528301886,
    "x.stride": 0.018867924528301886,
    "c.stride": 0.018867924528301886,
    "modules.triton_llama_mlp": 0.018867924528301886,
    "logging.getLogger": 0.018867924528301886,
    "logging.StreamHandler": 0.018867924528301886,
    "logging.Formatter": 0.018867924528301886,
    "handler.setFormatter": 0.018867924528301886,
    "logger.addHandler": 0.018867924528301886,
    "logger.setLevel": 0.018867924528301886,
    "field": 0.018867924528301886,
    "self._prepare_examples_for_quantization": 0.018867924528301886,
    "LayerHijacker": 0.018867924528301886,
    "pack_model": 0.018867924528301886,
    "prepare_inputs_for_generation": 0.018867924528301886,
    "create_repo": 0.018867924528301886,
    "os.makedirs": 0.018867924528301886,
    "save_pretrained": 0.018867924528301886,
    "model_init_kwargs.pop": 0.018867924528301886,
    "AutoModelForCausalLM.from_pretrained": 0.018867924528301886,
    "get_checkpoints": 0.018867924528301886,
    "named_modules": 0.018867924528301886,
    "self.enable_trainable_mode": 0.018867924528301886,
    "GeneralQuantLinear.inject_to_model": 0.018867924528301886,
    "json.dump": 0.018867924528301886,
    "args_from_json.items": 0.018867924528301886,
    "new_examples.append": 0.018867924528301886,
    "collate_data": 0.018867924528301886,
    "example.items": 0.018867924528301886,
    "create_commit": 0.018867924528301886,
    "torch.save": 0.018867924528301886,
    "BaseQuantizeConfig.from_pretrained": 0.018867924528301886,
    "model_save_name.endswith": 0.018867924528301886,
    "model.load_state_dict": 0.018867924528301886,
    "__getattr__": 0.018867924528301886,
    "self.to_dict": 0.018867924528301886,
    "tensor.long": 0.018867924528301886,
    "layer_inputs.append": 0.018867924528301886,
    "kwargs.get": 0.018867924528301886,
    "kwargs.items": 0.018867924528301886,
    "layer_input_kwargs.append": 0.018867924528301886,
    "layer_outputs.append": 0.018867924528301886,
    "CommitOperationAdd": 0.018867924528301886,
    "_validate_marlin_device_support": 0.018867924528301886,
    "no_init_weights": 0.018867924528301886,
    "init_contexts.append": 0.018867924528301886,
    "ContextManagers": 0.018867924528301886,
    "make_sure_no_tensor_in_meta_device": 0.018867924528301886,
    "prepare_model_for_marlin_load": 0.018867924528301886,
    "safe_load": 0.018867924528301886,
    "torch.load": 0.018867924528301886,
    "tensor.unsqueeze": 0.018867924528301886,
    "attention_masks.append": 0.018867924528301886,
    "position_ids.append": 0.018867924528301886,
    "v.unsqueeze": 0.018867924528301886,
    "GPTQ": 0.018867924528301886,
    "configure": 0.018867924528301886,
    "handles.append": 0.018867924528301886,
    "h.remove": 0.018867924528301886,
    "fasterquant": 0.018867924528301886,
    "free": 0.018867924528301886,
    "state_dict.items": 0.018867924528301886,
    "safetensors_metadata.items": 0.018867924528301886,
    "type": 0.018867924528301886,
    "register_forward_hook": 0.018867924528301886,
    "v.clone": 0.018867924528301886,
    "safe_open": 0.018867924528301886,
    "f.keys": 0.018867924528301886,
    "state_dict_key.rsplit": 0.018867924528301886,
    "gptq_layers.add": 0.018867924528301886,
    "unpack_awq": 0.018867924528301886,
    "pbar.set_description": 0.018867924528301886,
    "pack_from_tensors": 0.018867924528301886,
    "tensor.cpu": 0.018867924528301886,
    "non_gptq_params.add": 0.018867924528301886,
    "SUPPORTED_MODELS.append": 0.018867924528301886,
    "from_pretrained": 0.018867924528301886,
    "quant_func": 0.018867924528301886,
    "signature": 0.018867924528301886,
    "module.named_modules": 0.018867924528301886,
    "retie_parameters": 0.018867924528301886,
    "order_tensor.repeat": 0.018867924528301886,
    "order_tensor.reshape": 0.018867924528301886,
    "awq_qzeros.cuda": 0.018867924528301886,
    "awq_qweight.cuda": 0.018867924528301886,
    "weight.view": 0.018867924528301886,
    "zeros.view": 0.018867924528301886,
    "awq_reverse_reorder_int_tensor": 0.018867924528301886,
    "awq_scales.cuda": 0.018867924528301886,
    "unpacked_qzeros.contiguous": 0.018867924528301886,
    "unpacked_qzeros.cpu": 0.018867924528301886,
    "awq_scales.cpu": 0.018867924528301886,
    "awq_scales.clone": 0.018867924528301886,
    "res.update": 0.018867924528301886,
    "pack": 0.018867924528301886,
    "fixed_bytes.items": 0.018867924528301886,
    "scale_zeros_mat.half": 0.018867924528301886,
    "unpacked_qzeros.t": 0.018867924528301886,
    "FileNotFoundError": 0.018867924528301886,
    "obj.parameters": 0.018867924528301886,
    "obj.to": 0.018867924528301886,
    "logger.error": 0.018867924528301886,
    "qinfer.pack4": 0.018867924528301886,
    "scale.to": 0.018867924528301886,
    "zero.to": 0.018867924528301886,
    "g_idx.to": 0.018867924528301886,
    "AlignDevicesHook": 0.018867924528301886,
    "add_hook_to_module": 0.018867924528301886,
    "submodule.scratch_space_fixed": 0.018867924528301886,
    "ExLlamaV2DeviceTensors": 0.018867924528301886,
    "m.register_buffer": 0.018867924528301886,
    "unpacked_qweight.clone": 0.018867924528301886,
    "awq_scales.t": 0.018867924528301886,
    "unpacked_qzeros.numpy": 0.018867924528301886,
    "new_layer.to": 0.018867924528301886,
    "qinfer.pack3": 0.018867924528301886,
    "fixed_bytes.get": 0.018867924528301886,
    "submodule.parameters": 0.018867924528301886,
    "qinfer.pack2": 0.018867924528301886,
    "possible_index_file.replace": 0.018867924528301886,
    "functools.reduce": 0.018867924528301886,
    "attr.split": 0.018867924528301886,
    "model.state_dict": 0.018867924528301886,
    "Parameter": 0.018867924528301886,
    "ds.select": 0.018867924528301886,
    "ds.map": 0.018867924528301886,
    "DataLoader": 0.018867924528301886,
    "preprocess_fn": 0.018867924528301886,
    "sample_block.append": 0.018867924528301886,
    "append": 0.018867924528301886,
    "LongTensor": 0.018867924528301886,
    "load_fn": 0.018867924528301886,
    "dropped_indices.append": 0.018867924528301886,
    "attention_mask.append": 0.018867924528301886,
    "block.size": 0.018867924528301886,
    "pad_block": 0.018867924528301886,
    "random.sample": 0.018867924528301886,
    "pads.to": 0.018867924528301886,
    "self._prepare_data": 0.018867924528301886,
    "detach": 0.018867924528301886,
    "e_x.sum": 0.018867924528301886,
    "self._compute_batch_logits": 0.018867924528301886,
    "logits.append": 0.018867924528301886,
    "self._model": 0.018867924528301886,
    "np.max": 0.018867924528301886,
    "self._process_batch": 0.018867924528301886,
    "all_perplexity.append": 0.018867924528301886,
    "progress.set_description": 0.018867924528301886,
    "self.softmax": 0.018867924528301886,
    "np.log": 0.018867924528301886,
    "self._tokenizer": 0.018867924528301886,
    "cleanup_buffers_cuda": 0.018867924528301886,
    "LoraLayer.__init__": 0.018867924528301886,
    "result.to": 0.018867924528301886,
    "AdaLoraLayer.__init__": 0.018867924528301886,
    "ignore.append": 0.018867924528301886,
    "model.enable_trainable_mode": 0.018867924528301886,
    "hijack_peft_mappings": 0.018867924528301886,
    "xavier_uniform_": 0.018867924528301886,
    "zeros_": 0.018867924528301886,
    "GPTQLoraLinear": 0.018867924528301886,
    "GPTQSVDLinear": 0.018867924528301886,
    "x.type_as": 0.018867924528301886,
    "n.split": 0.018867924528301886,
    "results.add": 0.018867924528301886,
    "find_all_linear_names": 0.018867924528301886,
    "get_peft_model": 0.018867924528301886,
    "PeftModel.from_pretrained": 0.018867924528301886,
    "peft_config.to_dict": 0.018867924528301886,
    "lora_B": 0.018867924528301886,
    "lora_A": 0.018867924528301886,
    "lora_dropout": 0.018867924528301886,
    "Quantizer": 0.018867924528301886,
    "inp.matmul": 0.018867924528301886,
    "W.float": 0.018867924528301886,
    "torch.cholesky_inverse": 0.018867924528301886,
    "inp.unsqueeze": 0.018867924528301886,
    "nn.Unfold": 0.018867924528301886,
    "unfold": 0.018867924528301886,
    "inp.permute": 0.018867924528301886,
    "inp.flatten": 0.018867924528301886,
    "inp.float": 0.018867924528301886,
    "ready": 0.018867924528301886,
    "torch.argsort": 0.018867924528301886,
    "Err1.matmul": 0.018867924528301886,
    "Q.t": 0.018867924528301886,
    "inp.reshape": 0.018867924528301886,
    "quantizer.find_params": 0.018867924528301886,
    "groups.append": 0.018867924528301886,
    "flatten": 0.018867924528301886,
    "matmul": 0.018867924528301886,
    "Q.reshape": 0.018867924528301886,
    "err1.unsqueeze": 0.018867924528301886,
    "w.unsqueeze": 0.018867924528301886,
    "self.layer": 0.018867924528301886,
    "torch.minimum": 0.018867924528301886,
    "self.ready": 0.018867924528301886,
    "repeat": 0.018867924528301886,
    "x.min": 0.018867924528301886,
    "x.max": 0.018867924528301886,
    "torch.full_like": 0.018867924528301886,
    "q.abs_": 0.018867924528301886,
    "q.pow_": 0.018867924528301886,
    "x.permute": 0.018867924528301886,
    "x.t": 0.018867924528301886,
    "scale1.unsqueeze": 0.018867924528301886,
    "zero1.unsqueeze": 0.018867924528301886,
    "math.exp": 0.018867924528301886,
    "get_dataloader": 0.018867924528301886,
    "self._metric": 0.018867924528301886,
    "batch_data.items": 0.018867924528301886,
    "self._parse_labels": 0.018867924528301886,
    "self._predict": 0.018867924528301886,
    "v.to": 0.018867924528301886,
    "rouge.Rouge": 0.018867924528301886,
    "metric.get_scores": 0.018867924528301886,
    "predictions.append": 0.018867924528301886,
    "self.tokenizer": 0.018867924528301886,
    "get_predictions": 0.018867924528301886,
    "sub_predictions.append": 0.018867924528301886,
    "most_common": 0.018867924528301886,
    "each.lower": 0.018867924528301886,
    "gen_text.lower": 0.018867924528301886,
    "Counter": 0.018867924528301886,
    "ravel": 0.018867924528301886,
    "unpack_4bit_to_32bit_signed": 0.018867924528301886,
    "scales.repeat_interleave": 0.018867924528301886,
    "scale_perm.extend": 0.018867924528301886,
    "scale_perm_single.extend": 0.018867924528301886,
    "q.to": 0.018867924528301886,
    "s.to": 0.018867924528301886,
    "A.half": 0.018867924528301886,
    "mul": 0.018867924528301886,
    "perm.extend": 0.018867924528301886,
    "A.view": 0.018867924528301886,
    "C.view": 0.018867924528301886,
    "perm1.append": 0.018867924528301886,
    "perm.reshape": 0.018867924528301886,
    "res.reshape": 0.018867924528301886,
    "q.astype": 0.018867924528301886,
    "res.cpu": 0.018867924528301886,
    "_perm.numel": 0.018867924528301886,
    "x.to": 0.018867924528301886,
    "vecquant2matmul_faster_old": 0.018867924528301886,
    "vecquant2matmul_old": 0.018867924528301886,
    "vecquant3matmul_faster_old": 0.018867924528301886,
    "vecquant3matmul_old": 0.018867924528301886,
    "vecquant4matmul_faster_old": 0.018867924528301886,
    "vecquant4matmul_old": 0.018867924528301886,
    "vecquant8matmul_old": 0.018867924528301886,
    "gemm_half_q_half": 0.018867924528301886,
    "short": 0.018867924528301886,
    "temp_dq.get_scratch_slice": 0.018867924528301886,
    "ext_make_q_matrix": 0.018867924528301886,
    "ext_gemm_half_q_half": 0.018867924528301886,
    "narrow": 0.018867924528301886,
    "output.add_": 0.018867924528301886,
    "self.temp_fwd_size": 0.018867924528301886,
    "self.prepare": 0.018867924528301886,
    "torch.empty_like": 0.018867924528301886,
    "_torch_device": 0.018867924528301886,
    "GEKKO": 0.018867924528301886,
    "m.Const": 0.018867924528301886,
    "m.Maximize": 0.018867924528301886,
    "qinfer.compute_reduction_cpp": 0.018867924528301886,
    "np.ones": 0.018867924528301886,
    "split.astype": 0.018867924528301886,
    "mem_model": 0.018867924528301886,
    "np.sum": 0.018867924528301886,
    "compute_reductions": 0.018867924528301886,
    "qinfer.forward4": 0.018867924528301886,
    "qinfer.forward_gs4": 0.018867924528301886,
    "qinfer.forward2": 0.018867924528301886,
    "qinfer.forward_gs2": 0.018867924528301886,
    "qinfer.forward3": 0.018867924528301886,
    "qinfer.forward_gs3": 0.018867924528301886,
    "vecquant2matmul": 0.018867924528301886,
    "vecquant3matmul": 0.018867924528301886,
    "weights.append": 0.018867924528301886,
    "vecquant4matmul": 0.018867924528301886,
    "vecquant8matmul": 0.018867924528301886,
    "quant_linear_fn.apply": 0.018867924528301886,
    "out.half": 0.018867924528301886,
    "quant_matmul_inference_only_248": 0.018867924528301886,
    "make_q4": 0.018867924528301886,
    "q4_matmul": 0.018867924528301886,
    "ext_make_q4": 0.018867924528301886,
    "ext_q4_matmul": 0.018867924528301886,
    "out.add_": 0.018867924528301886,
    "custom_fwd": 0.018867924528301886,
    "tl.trans": 0.018867924528301886,
    "tl.sigmoid": 0.018867924528301886,
    "ctx.save_for_backward": 0.018867924528301886,
    "CustomizedTritonAutoTuner": 0.018867924528301886,
    "used.add": 0.018867924528301886,
    "meta.keys": 0.018867924528301886,
    "do_bench": 0.018867924528301886,
    "self.early_config_prune": 0.018867924528301886,
    "builtins.min": 0.018867924528301886,
    "zero_": 0.018867924528301886,
    "self._bench": 0.018867924528301886,
    "self.perf_model": 0.018867924528301886,
    "est_timing.keys": 0.018867924528301886,
    "np.empty": 0.018867924528301886,
    "levenshtein_distance": 0.018867924528301886,
    "size": 0.018867924528301886,
    "tokenizer.batch_decode": 0.018867924528301886,
    "sub_output_ids.cpu": 0.018867924528301886,
    "one_sub_generated_ids.index": 0.018867924528301886
}