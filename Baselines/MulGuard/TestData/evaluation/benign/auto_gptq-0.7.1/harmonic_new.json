{
    "range": 11.474842767295598,
    "to": 9.540880503144653,
    "isinstance": 8.572327044025156,
    "len": 7.635220125786164,
    "contiguous": 6.6415094339622645,
    "NotImplementedError": 6.221383647798742,
    "torch.zeros": 6.000000000000001,
    "logger.info": 5.248427672955975,
    "torch.device": 4.915094339622642,
    "torch.tensor": 4.691823899371069,
    "ValueError": 4.632075471698113,
    "join": 4.488993710691824,
    "clone": 4.30188679245283,
    "list": 4.257861635220126,
    "float": 3.946540880503145,
    "self.register_buffer": 3.9088050314465415,
    "find_layers": 3.8962264150943398,
    "dynamically_import_QuantLinear": 3.7893081761006298,
    "reshape": 3.578616352201258,
    "hasattr": 3.5628930817610063,
    "torch.cat": 3.5031446540880506,
    "getattr": 3.3773584905660377,
    "any": 3.188679245283019,
    "int": 3.1540880503144653,
    "__init__": 3.0754716981132075,
    "logger.warning": 3.0660377358490565,
    "str": 2.8207547169811322,
    "isfile": 2.811320754716981,
    "move_to_device": 2.688679245283019,
    "TypeError": 2.547169811320755,
    "isdir": 2.5377358490566038,
    "max": 2.5345911949685536,
    "super": 2.5283018867924527,
    "model.named_modules": 2.465408805031447,
    "safe_save": 2.4622641509433962,
    "_convert_tensor_to_list": 2.452830188679245,
    "get_device": 2.30188679245283,
    "torch.bitwise_and": 2.2830188679245285,
    "self.model": 2.2735849056603774,
    "logger.debug": 2.2704402515723268,
    "get_balanced_memory": 2.2452830188679247,
    "kwargs.pop": 2.2358490566037736,
    "fields": 2.2264150943396226,
    "remove_hook_from_module": 2.1792452830188678,
    "empty_cache": 2.1666666666666665,
    "unsqueeze": 2.040880503144654,
    "QuantLinear.warmup": 1.990566037735849,
    "torch.from_numpy": 1.9874213836477987,
    "scales.contiguous": 1.9811320754716981,
    "torch.inference_mode": 1.971698113207547,
    "model.tie_weights": 1.949685534591195,
    "accelerate.init_empty_weights": 1.9433962264150944,
    "zeros.contiguous": 1.9433962264150944,
    "state_dict": 1.940251572327044,
    "accelerate.infer_auto_device_map": 1.940251572327044,
    "warmup": 1.9371069182389937,
    "get_device_capability": 1.9371069182389935,
    "_validate_marlin_compatibility": 1.927672955974843,
    "device_map.items": 1.9245283018867925,
    "items": 1.9245283018867925,
    "self.save_quantized": 1.8679245283018868,
    "make_quant": 1.8616352201257862,
    "self.assertTrue": 1.8584905660377358,
    "AutoModelForCausalLM.from_config": 1.8522012578616354,
    "get_module_by_name_prefix": 1.8427672955974843,
    "nested_move_to_device": 1.8364779874213835,
    "os.listdir": 1.8270440251572326,
    "layers.keys": 1.7924528301886793,
    "set": 1.7924528301886793,
    "next": 1.7735849056603774,
    "huggingface_hub.cached_assets_path": 1.770440251572327,
    "get_module_by_name_suffix": 1.7547169811320755,
    "layer": 1.751572327044025,
    "model_name_or_path.split": 1.751572327044025,
    "EnvironmentError": 1.7264150943396226,
    "cls": 1.6918238993710693,
    "simple_dispatch_model": 1.6855345911949684,
    "add_batch": 1.6761006289308176,
    "name.startswith": 1.619496855345912,
    "to_dict": 1.578616352201258,
    "model.to": 1.5377358490566038,
    "model.eval": 1.5314465408805031,
    "cuda": 1.5314465408805031,
    "AutoConfig.from_pretrained": 1.4842767295597485,
    "cached_file": 1.4528301886792452,
    "device_map.values": 1.4433962264150944,
    "inject_to_model": 1.4339622641509433,
    "open": 1.408805031446541,
    "w.reshape": 1.4056603773584906,
    "AutoGPTQForCausalLM.from_quantized": 1.330188679245283,
    "searched_files.append": 1.330188679245283,
    "get": 1.3238993710691822,
    "astype": 1.2484276729559747,
    "np.zeros": 1.2484276729559747,
    "expand": 1.2201257861635217,
    "zeros.reshape": 1.2075471698113207,
    "w.permute": 1.2012578616352203,
    "module.named_children": 1.1981132075471699,
    "time.time": 1.1415094339622642,
    "torch.sum": 1.1289308176100628,
    "half": 1.1226415094339623,
    "torch.matmul": 1.10062893081761,
    "AutoTokenizer.from_pretrained": 1.0943396226415094,
    "s.reshape": 1.0786163522012577,
    "tokenizer.decode": 0.9622641509433962,
    "torch.empty": 0.9289308176100629,
    "submodule.post_init": 0.9150943396226415,
    "torch.no_grad": 0.871069182389937,
    "zip": 0.8632075471698113,
    "torch.zeros_like": 0.8427672955974842,
    "tokenizer": 0.7924528301886793,
    "find_params": 0.7830188679245284,
    "generate": 0.761006289308176,
    "weight.reshape": 0.7547169811320755,
    "print": 0.7515723270440251,
    "enumerate": 0.7075471698113207,
    "torch.Tensor": 0.6981132075471698,
    "scale.append": 0.6949685534591196,
    "zero.append": 0.6949685534591196,
    "torch.arange": 0.6823899371069182,
    "torch.diag": 0.6823899371069182,
    "torch.round": 0.6792452830188679,
    "warnings.warn": 0.6729559748427673,
    "model_q.generate": 0.6698113207547169,
    "setattr": 0.660377358490566,
    "W.flatten": 0.660377358490566,
    "W.t": 0.660377358490566,
    "self.skipTest": 0.6352201257861636,
    "autogptq_post_init": 0.6320754716981132,
    "scales.reshape": 0.6320754716981132,
    "x.float": 0.6194968553459118,
    "transpose": 0.6163522012578617,
    "linear_class": 0.6132075471698113,
    "torch.randint": 0.6132075471698113,
    "attn_output.size": 0.6132075471698113,
    "torch.manual_seed": 0.5943396226415094,
    "linear.eval": 0.5943396226415094,
    "linear.to": 0.5943396226415094,
    "torch.allclose": 0.5911949685534591,
    "self.linear_module": 0.5786163522012578,
    "torch.rand": 0.5754716981132075,
    "partial": 0.5754716981132075,
    "CUDA_OLD_REFERENCE.to": 0.5660377358490566,
    "self.assertEqual": 0.5660377358490566,
    "tl.arange": 0.5660377358490566,
    "long": 0.5628930817610063,
    "math.ceil": 0.5566037735849056,
    "m.solve": 0.5471698113207547,
    "_get_linear_feature_count": 0.5377358490566038,
    "delattr": 0.5377358490566038,
    "_get_weight": 0.5377358490566038,
    "self.update_layer": 0.5377358490566038,
    "tensor.permute": 0.5345911949685535,
    "new_module.named_modules": 0.5283018867924528,
    "gen_quant4": 0.5188679245283019,
    "keys": 0.5157232704402516,
    "self.unmerge": 0.5125786163522013,
    "attn_weights.size": 0.48427672955974843,
    "apply_rotary_pos_emb": 0.4842767295597484,
    "self.prune_configs": 0.4811320754716981,
    "torch.any": 0.4779874213836478,
    "abs": 0.4716981132075472,
    "get_diff": 0.4685534591194968,
    "x.flatten": 0.4685534591194968,
    "fixed_pos_embedding": 0.4654088050314465,
    "attention_mask.size": 0.4559748427672956,
    "arg_names.index": 0.44339622641509435,
    "self.hook": 0.44339622641509435,
    "run": 0.43081761006289304,
    "convert_to_marlin": 0.4276729559748428,
    "cpp_extension.CUDAExtension": 0.42452830188679247,
    "make_q_matrix": 0.42452830188679247,
    "module.to": 0.4213836477987421,
    "getLogger": 0.41509433962264153,
    "extensions.append": 0.41194968553459116,
    "linear": 0.41194968553459116,
    "copy.copy": 0.41194968553459116,
    "LoraModel._create_new_module": 0.41194968553459116,
    "synchronize": 0.4056603773584906,
    "sample_blocks.append": 0.4025157232704402,
    "quantize": 0.39622641509433965,
    "exllama_set_max_input_length": 0.3742138364779874,
    "self.assertRaises": 0.3742138364779874,
    "tuple": 0.36477987421383645,
    "torch.maximum": 0.3616352201257862,
    "math.log2": 0.35691823899371067,
    "config.pre_hook": 0.3553459119496855,
    "platform.machine": 0.3490566037735849,
    "split": 0.34591194968553457,
    "min": 0.33647798742138363,
    "sys.exit": 0.3270440251572327,
    "np.exp": 0.32075471698113206,
    "recurse_getattr": 0.3176100628930818,
    "platform.system": 0.30817610062893086,
    "Event": 0.29874213836477986,
    "start_event.record": 0.29874213836477986,
    "end_event.record": 0.2893081761006289,
    "start_event.elapsed_time": 0.2893081761006289,
    "latencies.append": 0.2893081761006289,
    "is_available": 0.25471698113207547,
    "np.mean": 0.25157232704402516,
    "np.percentile": 0.25157232704402516,
    "model_autogptq.named_modules": 0.24528301886792453,
    "AutoAWQForCausalLM.from_quantized": 0.24528301886792453,
    "model_awq.generate": 0.24528301886792453,
    "dict": 0.2389937106918239,
    "linear_gptq": 0.23270440251572327,
    "linear_awq": 0.23270440251572327,
    "tl.zeros": 0.1949685534591195,
    "tl.store": 0.1949685534591195,
    "tl.load": 0.18867924528301888,
    "tl.program_id": 0.18553459119496854,
    "tl.cdiv": 0.18553459119496854,
    "self.assertFalse": 0.16981132075471697,
    "tl.dot": 0.16037735849056603,
    "compare_transformers_version": 0.1320754716981132,
    "inp.t": 0.1320754716981132,
    "strip": 0.1320754716981132,
    "input.stride": 0.1320754716981132,
    "qweight.stride": 0.1320754716981132,
    "output.stride": 0.1320754716981132,
    "scales.stride": 0.1320754716981132,
    "qzeros.stride": 0.1320754716981132,
    "get_gptq_peft_model": 0.12264150943396226,
    "self.check_model_trainable": 0.12264150943396226,
    "scales.to": 0.12264150943396226,
    "device": 0.11320754716981132,
    "x.reshape": 0.11320754716981132,
    "torch.randn": 0.09433962264150944,
    "model.get_submodule": 0.09433962264150944,
    "tqdm": 0.09433962264150944,
    "qweight.astype": 0.09433962264150944,
    "qzeros.astype": 0.09433962264150944,
    "intweight.append": 0.09433962264150944,
    "intweight.t": 0.09433962264150944,
    "intweight.numpy": 0.09433962264150944,
    "scales.t": 0.09433962264150944,
    "quant_matmul_248": 0.09433962264150944,
    "outputs.append": 0.08490566037735849,
    "model.generate": 0.07547169811320754,
    "name.rsplit": 0.07547169811320754,
    "sum": 0.07547169811320754,
    "numpy": 0.07547169811320754,
    "cpu": 0.07547169811320754,
    "torch.unsqueeze": 0.07547169811320754,
    "item": 0.07547169811320754,
    "zeros.t": 0.07547169811320754,
    "scales.clone": 0.07547169811320754,
    "zeros.numpy": 0.07547169811320754,
    "self.temp_dq_size": 0.07547169811320754,
    "torch.clamp": 0.05660377358490566,
    "_get_perms": 0.05660377358490566,
    "torch.all": 0.05660377358490566,
    "copy.deepcopy": 0.05660377358490566,
    "t": 0.05660377358490566,
    "json.load": 0.05660377358490566,
    "prepare_buffers": 0.05660377358490566,
    "all": 0.05660377358490566,
    "autocast": 0.05660377358490566,
    "QuantLinear": 0.05660377358490566,
    "triton.Config": 0.05660377358490566,
    "sorted": 0.05660377358490566,
    "recurse_setattr": 0.05660377358490566,
    "torch.bitwise_right_shift": 0.05660377358490566,
    "ImportError": 0.05660377358490566,
    "parse_version": 0.05660377358490566,
    "lower": 0.05660377358490566,
    "get_closest_label": 0.05660377358490566,
    "logger.warning_once": 0.05660377358490566,
    "m.Var": 0.05660377358490566,
    "m.Equation": 0.05660377358490566,
    "g_idx.clone": 0.05660377358490566,
    "nn.Linear": 0.03773584905660377,
    "torch.max": 0.03773584905660377,
    "torch.full": 0.03773584905660377,
    "MarlinQuantLinear": 0.03773584905660377,
    "autogptq_marlin_cuda.gptq_repack": 0.03773584905660377,
    "torch.abs": 0.03773584905660377,
    "torch.mean": 0.03773584905660377,
    "_get_cached_marlin_save_name": 0.03773584905660377,
    "tempfile.TemporaryDirectory": 0.03773584905660377,
    "model.save_pretrained": 0.03773584905660377,
    "set_tuning_params": 0.03773584905660377,
    "mean": 0.03773584905660377,
    "numel": 0.03773584905660377,
    "BaseQuantizeConfig": 0.03773584905660377,
    "AutoGPTQForCausalLM.from_pretrained": 0.03773584905660377,
    "model.quantize": 0.03773584905660377,
    "GPTQLoraConfig": 0.03773584905660377,
    "GPTQAdaLoraConfig": 0.03773584905660377,
    "autogptq_marlin_cuda.mul": 0.03773584905660377,
    "m.view": 0.03773584905660377,
    "tensor.view": 0.03773584905660377,
    "softmax": 0.03773584905660377,
    "compare_pytorch_version": 0.03773584905660377,
    "torch.finfo": 0.03773584905660377,
    "self.qkv_proj": 0.03773584905660377,
    "F.scaled_dot_product_attention": 0.03773584905660377,
    "torch.ones": 0.03773584905660377,
    "math.sqrt": 0.03773584905660377,
    "custom_autotune.autotune": 0.03773584905660377,
    "stride": 0.03773584905660377,
    "kn_values.items": 0.03773584905660377,
    "triton.cdiv": 0.03773584905660377,
    "load_checkpoint_in_model": 0.03773584905660377,
    "preprocess_checkpoint_qigen": 0.03773584905660377,
    "tolist": 0.03773584905660377,
    "accelerate.cpu_offload_with_hook": 0.03773584905660377,
    "values": 0.03773584905660377,
    "f.get_tensor": 0.03773584905660377,
    "name.endswith": 0.03773584905660377,
    "check_and_get_model_type": 0.03773584905660377,
    "find_tied_parameters": 0.03773584905660377,
    "device_to_buffers_size.items": 0.03773584905660377,
    "qinfer.unpack_zeros4": 0.03773584905660377,
    "wf.unsqueeze": 0.03773584905660377,
    "qinfer.unpack_zeros2": 0.03773584905660377,
    "scales.transpose": 0.03773584905660377,
    "zeros.transpose": 0.03773584905660377,
    "name.split": 0.03773584905660377,
    "gc.collect": 0.03773584905660377,
    "new_module.to": 0.03773584905660377,
    "unpack_qzeros": 0.03773584905660377,
    "load_dataset": 0.03773584905660377,
    "input_ids.append": 0.03773584905660377,
    "label_ids.append": 0.03773584905660377,
    "normal_": 0.03773584905660377,
    "torch.clamp_": 0.03773584905660377,
    "type_as": 0.03773584905660377,
    "old_module.parameters": 0.03773584905660377,
    "old_module.buffers": 0.03773584905660377,
    "cholesky": 0.03773584905660377,
    "labels.append": 0.03773584905660377,
    "GenerationConfig": 0.03773584905660377,
    "postprocess_generation_ids": 0.03773584905660377,
    "decode": 0.03773584905660377,
    "np.array": 0.03773584905660377,
    "unpacked_qzeros.repeat_interleave": 0.03773584905660377,
    "out.to": 0.03773584905660377,
    "x.view": 0.03773584905660377,
    "output.view": 0.03773584905660377,
    "x.half": 0.03773584905660377,
    "out.reshape": 0.03773584905660377,
    "g_idx_i.long": 0.03773584905660377,
    "transpose_quant_matmul_248": 0.03773584905660377,
    "common_setup_kwargs.update": 0.018867924528301886,
    "setup": 0.018867924528301886,
    "read_text": 0.018867924528301886,
    "find_packages": 0.018867924528301886,
    "os.cpu_count": 0.018867924528301886,
    "subprocess.check_output": 0.018867924528301886,
    "get_python_lib": 0.018867924528301886,
    "include_dirs.append": 0.018867924528301886,
    "startswith": 0.018867924528301886,
    "Exception": 0.018867924528301886,
    "cpp_extension.CppExtension": 0.018867924528301886,
    "Path": 0.018867924528301886,
    "subprocess.run": 0.018867924528301886,
    "w.clone": 0.018867924528301886,
    "ref.t": 0.018867924528301886,
    "CudaOldQuantLinear": 0.018867924528301886,
    "cuda_old_linear.pack": 0.018867924528301886,
    "dequantize_weight": 0.018867924528301886,
    "dequantized_weight.to": 0.018867924528301886,
    "Linear": 0.018867924528301886,
    "copy_": 0.018867924528301886,
    "marlin_linear.pack": 0.018867924528301886,
    "cuda_old_linear.to": 0.018867924528301886,
    "marlin_linear.to": 0.018867924528301886,
    "linear_module.to": 0.018867924528301886,
    "cuda_old_linear": 0.018867924528301886,
    "marlin_linear": 0.018867924528301886,
    "res_cuda_old.abs": 0.018867924528301886,
    "os.remove": 0.018867924528301886,
    "parameterized.expand": 0.018867924528301886,
    "model_q.named_modules": 0.018867924528301886,
    "model_q.named_parameters": 0.018867924528301886,
    "model_q.named_buffers": 0.018867924528301886,
    "predicted_text.startswith": 0.018867924528301886,
    "torch.count_nonzero": 0.018867924528301886,
    "ref.abs": 0.018867924528301886,
    "linear_gptq.eval": 0.018867924528301886,
    "linear_gptq.to": 0.018867924528301886,
    "format": 0.018867924528301886,
    "lines.append": 0.018867924528301886,
    "ModuleNotFoundError": 0.018867924528301886,
    "WQLinear_GEMV": 0.018867924528301886,
    "WQLinear_GEMM": 0.018867924528301886,
    "logging.basicConfig": 0.018867924528301886,
    "model.save_quantized": 0.018867924528301886,
    "model_lora.gradient_checkpointing_enable": 0.018867924528301886,
    "Adam": 0.018867924528301886,
    "model_lora.train": 0.018867924528301886,
    "value.to": 0.018867924528301886,
    "model_lora.parameters": 0.018867924528301886,
    "optimizer.zero_grad": 0.018867924528301886,
    "losses.append": 0.018867924528301886,
    "loss.backward": 0.018867924528301886,
    "optimizer.step": 0.018867924528301886,
    "batch.items": 0.018867924528301886,
    "loss.item": 0.018867924528301886,
    "model_lora": 0.018867924528301886,
    "math.isfinite": 0.018867924528301886,
    "math.isnan": 0.018867924528301886,
    "torch.stack": 0.018867924528301886,
    "m.repeat": 0.018867924528301886,
    "torch.sin": 0.018867924528301886,
    "torch.cos": 0.018867924528301886,
    "nn.Dropout": 0.018867924528301886,
    "qkv.view": 0.018867924528301886,
    "query.to": 0.018867924528301886,
    "key.to": 0.018867924528301886,
    "torch.where": 0.018867924528301886,
    "attn_weights.to": 0.018867924528301886,
    "self.attn_dropout": 0.018867924528301886,
    "self._split_heads": 0.018867924528301886,
    "key.permute": 0.018867924528301886,
    "query.permute": 0.018867924528301886,
    "value.permute": 0.018867924528301886,
    "self._merge_heads": 0.018867924528301886,
    "self.out_proj": 0.018867924528301886,
    "self.resid_dropout": 0.018867924528301886,
    "duplicate_interleave": 0.018867924528301886,
    "rotate_every_two": 0.018867924528301886,
    "view": 0.018867924528301886,
    "torch.get_default_dtype": 0.018867924528301886,
    "query.size": 0.018867924528301886,
    "key.size": 0.018867924528301886,
    "key.transpose": 0.018867924528301886,
    "query.contiguous": 0.018867924528301886,
    "key.contiguous": 0.018867924528301886,
    "value.contiguous": 0.018867924528301886,
    "self._attn": 0.018867924528301886,
    "torch.sqrt": 0.018867924528301886,
    "qkv.size": 0.018867924528301886,
    "tensor.size": 0.018867924528301886,
    "torch.einsum": 0.018867924528301886,
    "torch.tril": 0.018867924528301886,
    "m.buffers": 0.018867924528301886,
    "hidden_states.size": 0.018867924528301886,
    "torch.split": 0.018867924528301886,
    "self.rotary_emb": 0.018867924528301886,
    "attn_output.transpose": 0.018867924528301886,
    "attn_output.reshape": 0.018867924528301886,
    "self.o_proj": 0.018867924528301886,
    "past_key_value.get_usable_length": 0.018867924528301886,
    "past_key_value.update": 0.018867924528301886,
    "query_states.contiguous": 0.018867924528301886,
    "key_states.contiguous": 0.018867924528301886,
    "value_states.contiguous": 0.018867924528301886,
    "query_states.view": 0.018867924528301886,
    "key_states.view": 0.018867924528301886,
    "value_states.view": 0.018867924528301886,
    "key_states.transpose": 0.018867924528301886,
    "silu": 0.018867924528301886,
    "c.to": 0.018867924528301886,
    "self.down_proj": 0.018867924528301886,
    "self.triton_llama_mlp": 0.018867924528301886,
    "c.reshape": 0.018867924528301886,
    "x.stride": 0.018867924528301886,
    "c.stride": 0.018867924528301886,
    "modules.triton_llama_mlp": 0.018867924528301886,
    "logging.getLogger": 0.018867924528301886,
    "logging.StreamHandler": 0.018867924528301886,
    "logging.Formatter": 0.018867924528301886,
    "handler.setFormatter": 0.018867924528301886,
    "logger.addHandler": 0.018867924528301886,
    "logger.setLevel": 0.018867924528301886,
    "field": 0.018867924528301886,
    "self._prepare_examples_for_quantization": 0.018867924528301886,
    "LayerHijacker": 0.018867924528301886,
    "pack_model": 0.018867924528301886,
    "prepare_inputs_for_generation": 0.018867924528301886,
    "create_repo": 0.018867924528301886,
    "os.makedirs": 0.018867924528301886,
    "save_pretrained": 0.018867924528301886,
    "model_init_kwargs.pop": 0.018867924528301886,
    "AutoModelForCausalLM.from_pretrained": 0.018867924528301886,
    "get_checkpoints": 0.018867924528301886,
    "named_modules": 0.018867924528301886,
    "self.enable_trainable_mode": 0.018867924528301886,
    "GeneralQuantLinear.inject_to_model": 0.018867924528301886,
    "json.dump": 0.018867924528301886,
    "args_from_json.items": 0.018867924528301886,
    "new_examples.append": 0.018867924528301886,
    "collate_data": 0.018867924528301886,
    "example.items": 0.018867924528301886,
    "create_commit": 0.018867924528301886,
    "torch.save": 0.018867924528301886,
    "BaseQuantizeConfig.from_pretrained": 0.018867924528301886,
    "model_save_name.endswith": 0.018867924528301886,
    "model.load_state_dict": 0.018867924528301886,
    "__getattr__": 0.018867924528301886,
    "self.to_dict": 0.018867924528301886,
    "tensor.long": 0.018867924528301886,
    "layer_inputs.append": 0.018867924528301886,
    "kwargs.get": 0.018867924528301886,
    "kwargs.items": 0.018867924528301886,
    "layer_input_kwargs.append": 0.018867924528301886,
    "layer_outputs.append": 0.018867924528301886,
    "CommitOperationAdd": 0.018867924528301886,
    "_validate_marlin_device_support": 0.018867924528301886,
    "no_init_weights": 0.018867924528301886,
    "init_contexts.append": 0.018867924528301886,
    "ContextManagers": 0.018867924528301886,
    "make_sure_no_tensor_in_meta_device": 0.018867924528301886,
    "prepare_model_for_marlin_load": 0.018867924528301886,
    "safe_load": 0.018867924528301886,
    "torch.load": 0.018867924528301886,
    "tensor.unsqueeze": 0.018867924528301886,
    "attention_masks.append": 0.018867924528301886,
    "position_ids.append": 0.018867924528301886,
    "v.unsqueeze": 0.018867924528301886,
    "GPTQ": 0.018867924528301886,
    "configure": 0.018867924528301886,
    "handles.append": 0.018867924528301886,
    "h.remove": 0.018867924528301886,
    "fasterquant": 0.018867924528301886,
    "free": 0.018867924528301886,
    "state_dict.items": 0.018867924528301886,
    "safetensors_metadata.items": 0.018867924528301886,
    "type": 0.018867924528301886,
    "register_forward_hook": 0.018867924528301886,
    "v.clone": 0.018867924528301886,
    "safe_open": 0.018867924528301886,
    "f.keys": 0.018867924528301886,
    "state_dict_key.rsplit": 0.018867924528301886,
    "gptq_layers.add": 0.018867924528301886,
    "unpack_awq": 0.018867924528301886,
    "pbar.set_description": 0.018867924528301886,
    "pack_from_tensors": 0.018867924528301886,
    "tensor.cpu": 0.018867924528301886,
    "non_gptq_params.add": 0.018867924528301886,
    "SUPPORTED_MODELS.append": 0.018867924528301886,
    "from_pretrained": 0.018867924528301886,
    "quant_func": 0.018867924528301886,
    "signature": 0.018867924528301886,
    "module.named_modules": 0.018867924528301886,
    "retie_parameters": 0.018867924528301886,
    "order_tensor.repeat": 0.018867924528301886,
    "order_tensor.reshape": 0.018867924528301886,
    "awq_qzeros.cuda": 0.018867924528301886,
    "awq_qweight.cuda": 0.018867924528301886,
    "weight.view": 0.018867924528301886,
    "zeros.view": 0.018867924528301886,
    "awq_reverse_reorder_int_tensor": 0.018867924528301886,
    "awq_scales.cuda": 0.018867924528301886,
    "unpacked_qzeros.contiguous": 0.018867924528301886,
    "unpacked_qzeros.cpu": 0.018867924528301886,
    "awq_scales.cpu": 0.018867924528301886,
    "awq_scales.clone": 0.018867924528301886,
    "res.update": 0.018867924528301886,
    "pack": 0.018867924528301886,
    "fixed_bytes.items": 0.018867924528301886,
    "scale_zeros_mat.half": 0.018867924528301886,
    "unpacked_qzeros.t": 0.018867924528301886,
    "FileNotFoundError": 0.018867924528301886,
    "obj.parameters": 0.018867924528301886,
    "obj.to": 0.018867924528301886,
    "logger.error": 0.018867924528301886,
    "qinfer.pack4": 0.018867924528301886,
    "scale.to": 0.018867924528301886,
    "zero.to": 0.018867924528301886,
    "g_idx.to": 0.018867924528301886,
    "AlignDevicesHook": 0.018867924528301886,
    "add_hook_to_module": 0.018867924528301886,
    "submodule.scratch_space_fixed": 0.018867924528301886,
    "ExLlamaV2DeviceTensors": 0.018867924528301886,
    "m.register_buffer": 0.018867924528301886,
    "unpacked_qweight.clone": 0.018867924528301886,
    "awq_scales.t": 0.018867924528301886,
    "unpacked_qzeros.numpy": 0.018867924528301886,
    "new_layer.to": 0.018867924528301886,
    "qinfer.pack3": 0.018867924528301886,
    "fixed_bytes.get": 0.018867924528301886,
    "submodule.parameters": 0.018867924528301886,
    "qinfer.pack2": 0.018867924528301886,
    "possible_index_file.replace": 0.018867924528301886,
    "functools.reduce": 0.018867924528301886,
    "attr.split": 0.018867924528301886,
    "model.state_dict": 0.018867924528301886,
    "Parameter": 0.018867924528301886,
    "ds.select": 0.018867924528301886,
    "ds.map": 0.018867924528301886,
    "DataLoader": 0.018867924528301886,
    "preprocess_fn": 0.018867924528301886,
    "sample_block.append": 0.018867924528301886,
    "append": 0.018867924528301886,
    "LongTensor": 0.018867924528301886,
    "load_fn": 0.018867924528301886,
    "dropped_indices.append": 0.018867924528301886,
    "attention_mask.append": 0.018867924528301886,
    "block.size": 0.018867924528301886,
    "pad_block": 0.018867924528301886,
    "random.sample": 0.018867924528301886,
    "pads.to": 0.018867924528301886,
    "self._prepare_data": 0.018867924528301886,
    "detach": 0.018867924528301886,
    "e_x.sum": 0.018867924528301886,
    "self._compute_batch_logits": 0.018867924528301886,
    "logits.append": 0.018867924528301886,
    "self._model": 0.018867924528301886,
    "np.max": 0.018867924528301886,
    "self._process_batch": 0.018867924528301886,
    "all_perplexity.append": 0.018867924528301886,
    "progress.set_description": 0.018867924528301886,
    "self.softmax": 0.018867924528301886,
    "np.log": 0.018867924528301886,
    "self._tokenizer": 0.018867924528301886,
    "cleanup_buffers_cuda": 0.018867924528301886,
    "LoraLayer.__init__": 0.018867924528301886,
    "result.to": 0.018867924528301886,
    "AdaLoraLayer.__init__": 0.018867924528301886,
    "ignore.append": 0.018867924528301886,
    "model.enable_trainable_mode": 0.018867924528301886,
    "hijack_peft_mappings": 0.018867924528301886,
    "xavier_uniform_": 0.018867924528301886,
    "zeros_": 0.018867924528301886,
    "GPTQLoraLinear": 0.018867924528301886,
    "GPTQSVDLinear": 0.018867924528301886,
    "x.type_as": 0.018867924528301886,
    "n.split": 0.018867924528301886,
    "results.add": 0.018867924528301886,
    "find_all_linear_names": 0.018867924528301886,
    "get_peft_model": 0.018867924528301886,
    "PeftModel.from_pretrained": 0.018867924528301886,
    "peft_config.to_dict": 0.018867924528301886,
    "lora_B": 0.018867924528301886,
    "lora_A": 0.018867924528301886,
    "lora_dropout": 0.018867924528301886,
    "Quantizer": 0.018867924528301886,
    "inp.matmul": 0.018867924528301886,
    "W.float": 0.018867924528301886,
    "torch.cholesky_inverse": 0.018867924528301886,
    "inp.unsqueeze": 0.018867924528301886,
    "nn.Unfold": 0.018867924528301886,
    "unfold": 0.018867924528301886,
    "inp.permute": 0.018867924528301886,
    "inp.flatten": 0.018867924528301886,
    "inp.float": 0.018867924528301886,
    "ready": 0.018867924528301886,
    "torch.argsort": 0.018867924528301886,
    "Err1.matmul": 0.018867924528301886,
    "Q.t": 0.018867924528301886,
    "inp.reshape": 0.018867924528301886,
    "quantizer.find_params": 0.018867924528301886,
    "groups.append": 0.018867924528301886,
    "flatten": 0.018867924528301886,
    "matmul": 0.018867924528301886,
    "Q.reshape": 0.018867924528301886,
    "err1.unsqueeze": 0.018867924528301886,
    "w.unsqueeze": 0.018867924528301886,
    "self.layer": 0.018867924528301886,
    "torch.minimum": 0.018867924528301886,
    "self.ready": 0.018867924528301886,
    "repeat": 0.018867924528301886,
    "x.min": 0.018867924528301886,
    "x.max": 0.018867924528301886,
    "torch.full_like": 0.018867924528301886,
    "q.abs_": 0.018867924528301886,
    "q.pow_": 0.018867924528301886,
    "x.permute": 0.018867924528301886,
    "x.t": 0.018867924528301886,
    "scale1.unsqueeze": 0.018867924528301886,
    "zero1.unsqueeze": 0.018867924528301886,
    "math.exp": 0.018867924528301886,
    "get_dataloader": 0.018867924528301886,
    "self._metric": 0.018867924528301886,
    "batch_data.items": 0.018867924528301886,
    "self._parse_labels": 0.018867924528301886,
    "self._predict": 0.018867924528301886,
    "v.to": 0.018867924528301886,
    "rouge.Rouge": 0.018867924528301886,
    "metric.get_scores": 0.018867924528301886,
    "predictions.append": 0.018867924528301886,
    "self.tokenizer": 0.018867924528301886,
    "get_predictions": 0.018867924528301886,
    "sub_predictions.append": 0.018867924528301886,
    "most_common": 0.018867924528301886,
    "each.lower": 0.018867924528301886,
    "gen_text.lower": 0.018867924528301886,
    "Counter": 0.018867924528301886,
    "ravel": 0.018867924528301886,
    "unpack_4bit_to_32bit_signed": 0.018867924528301886,
    "scales.repeat_interleave": 0.018867924528301886,
    "scale_perm.extend": 0.018867924528301886,
    "scale_perm_single.extend": 0.018867924528301886,
    "q.to": 0.018867924528301886,
    "s.to": 0.018867924528301886,
    "A.half": 0.018867924528301886,
    "mul": 0.018867924528301886,
    "perm.extend": 0.018867924528301886,
    "A.view": 0.018867924528301886,
    "C.view": 0.018867924528301886,
    "perm1.append": 0.018867924528301886,
    "perm.reshape": 0.018867924528301886,
    "res.reshape": 0.018867924528301886,
    "q.astype": 0.018867924528301886,
    "res.cpu": 0.018867924528301886,
    "_perm.numel": 0.018867924528301886,
    "x.to": 0.018867924528301886,
    "vecquant2matmul_faster_old": 0.018867924528301886,
    "vecquant2matmul_old": 0.018867924528301886,
    "vecquant3matmul_faster_old": 0.018867924528301886,
    "vecquant3matmul_old": 0.018867924528301886,
    "vecquant4matmul_faster_old": 0.018867924528301886,
    "vecquant4matmul_old": 0.018867924528301886,
    "vecquant8matmul_old": 0.018867924528301886,
    "gemm_half_q_half": 0.018867924528301886,
    "short": 0.018867924528301886,
    "temp_dq.get_scratch_slice": 0.018867924528301886,
    "ext_make_q_matrix": 0.018867924528301886,
    "ext_gemm_half_q_half": 0.018867924528301886,
    "narrow": 0.018867924528301886,
    "output.add_": 0.018867924528301886,
    "self.temp_fwd_size": 0.018867924528301886,
    "self.prepare": 0.018867924528301886,
    "torch.empty_like": 0.018867924528301886,
    "_torch_device": 0.018867924528301886,
    "GEKKO": 0.018867924528301886,
    "m.Const": 0.018867924528301886,
    "m.Maximize": 0.018867924528301886,
    "qinfer.compute_reduction_cpp": 0.018867924528301886,
    "np.ones": 0.018867924528301886,
    "split.astype": 0.018867924528301886,
    "mem_model": 0.018867924528301886,
    "np.sum": 0.018867924528301886,
    "compute_reductions": 0.018867924528301886,
    "qinfer.forward4": 0.018867924528301886,
    "qinfer.forward_gs4": 0.018867924528301886,
    "qinfer.forward2": 0.018867924528301886,
    "qinfer.forward_gs2": 0.018867924528301886,
    "qinfer.forward3": 0.018867924528301886,
    "qinfer.forward_gs3": 0.018867924528301886,
    "vecquant2matmul": 0.018867924528301886,
    "vecquant3matmul": 0.018867924528301886,
    "weights.append": 0.018867924528301886,
    "vecquant4matmul": 0.018867924528301886,
    "vecquant8matmul": 0.018867924528301886,
    "quant_linear_fn.apply": 0.018867924528301886,
    "out.half": 0.018867924528301886,
    "quant_matmul_inference_only_248": 0.018867924528301886,
    "make_q4": 0.018867924528301886,
    "q4_matmul": 0.018867924528301886,
    "ext_make_q4": 0.018867924528301886,
    "ext_q4_matmul": 0.018867924528301886,
    "out.add_": 0.018867924528301886,
    "custom_fwd": 0.018867924528301886,
    "tl.trans": 0.018867924528301886,
    "tl.sigmoid": 0.018867924528301886,
    "ctx.save_for_backward": 0.018867924528301886,
    "CustomizedTritonAutoTuner": 0.018867924528301886,
    "used.add": 0.018867924528301886,
    "meta.keys": 0.018867924528301886,
    "do_bench": 0.018867924528301886,
    "self.early_config_prune": 0.018867924528301886,
    "builtins.min": 0.018867924528301886,
    "zero_": 0.018867924528301886,
    "self._bench": 0.018867924528301886,
    "self.perf_model": 0.018867924528301886,
    "est_timing.keys": 0.018867924528301886,
    "np.empty": 0.018867924528301886,
    "levenshtein_distance": 0.018867924528301886,
    "size": 0.018867924528301886,
    "tokenizer.batch_decode": 0.018867924528301886,
    "sub_output_ids.cpu": 0.018867924528301886,
    "one_sub_generated_ids.index": 0.018867924528301886
}