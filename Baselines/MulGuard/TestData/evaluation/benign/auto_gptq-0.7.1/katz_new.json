{
    "getLogger": 0.5700872936959251,
    "to": 0.4825980954048302,
    "len": 0.4747403563476767,
    "isinstance": 0.46902309454622887,
    "range": 0.43039974463841674,
    "__init__": 0.376174629742169,
    "super": 0.35469200188293115,
    "torch.zeros": 0.30834445185093795,
    "ValueError": 0.29155213634802374,
    "contiguous": 0.25961945660132735,
    "torch.tensor": 0.24467747257372244,
    "NotImplementedError": 0.2298921868842727,
    "compare_transformers_version": 0.2230186972888474,
    "self.register_buffer": 0.22205000663106195,
    "tokenizer": 0.21775947690982406,
    "list": 0.20276447607635237,
    "model.named_modules": 0.19986377305411618,
    "AutoTokenizer.from_pretrained": 0.1968875146230513,
    "AutoGPTQForCausalLM.from_quantized": 0.19538573399107267,
    "torch.cat": 0.19517436475607725,
    "setattr": 0.17862204722432695,
    "torch.no_grad": 0.17461661551274366,
    "float": 0.17426207838158408,
    "math.ceil": 0.1732591616327519,
    "torch.round": 0.17142155677219473,
    "min": 0.1586139752932788,
    "torch.device": 0.15737847774818808,
    "clone": 0.1554106409794315,
    "join": 0.15495056874187135,
    "int": 0.1538289784523476,
    "reshape": 0.1518124979999305,
    "logger.info": 0.15180920832086786,
    "tokenizer.decode": 0.14835077316040213,
    "print": 0.14306799450368862,
    "self.assertTrue": 0.14140389338957618,
    "logger.warning": 0.13378736846606773,
    "hasattr": 0.13039188528000545,
    "max": 0.1296927370411843,
    "x.reshape": 0.1290484769325985,
    "torch.from_numpy": 0.1286813758069789,
    "dynamically_import_QuantLinear": 0.12791872463711587,
    "astype": 0.12765868711461567,
    "np.zeros": 0.12765868711461567,
    "generate": 0.11219066868414489,
    "model.get_submodule": 0.1106498808170635,
    "torch.empty": 0.11034506724968429,
    "cls": 0.10901571647785176,
    "empty_cache": 0.10872397421342858,
    "half": 0.10818063331391443,
    "unsqueeze": 0.10796648010309984,
    "tqdm": 0.10729384262394456,
    "W.flatten": 0.10702603475016473,
    "W.t": 0.10702603475016473,
    "scales.t": 0.10692070051012553,
    "qweight.astype": 0.10578297693952468,
    "qzeros.astype": 0.10578297693952468,
    "intweight.append": 0.10578297693952468,
    "intweight.t": 0.10578297693952468,
    "intweight.numpy": 0.10578297693952468,
    "model.generate": 0.1021680796284843,
    "getattr": 0.09803053341889605,
    "enumerate": 0.09440750342774706,
    "run": 0.09424987066660469,
    "keys": 0.09377223211582165,
    "torch.rand": 0.092832924336378,
    "sum": 0.09176668266677104,
    "item": 0.0909612696860331,
    "cpu": 0.0900177588988929,
    "name.rsplit": 0.08889181626176162,
    "numpy": 0.08824523313835334,
    "isfile": 0.08641125381290751,
    "isdir": 0.0858098313877962,
    "str": 0.08574933730344673,
    "torch.matmul": 0.08556752604747361,
    "zeros.t": 0.08553541692981281,
    "scales.clone": 0.08553541692981281,
    "zeros.numpy": 0.08553541692981281,
    "set": 0.08441622391403981,
    "device": 0.0739636231267218,
    "time.time": 0.06854771617812452,
    "recurse_setattr": 0.06853991300296051,
    "autocast": 0.0670187530930966,
    "triton.Config": 0.06611983334753181,
    "prepare_buffers": 0.06589553219467333,
    "huggingface_hub.cached_assets_path": 0.06588486727481391,
    "any": 0.06571437667059209,
    "s.reshape": 0.06556757463795947,
    "torch.sum": 0.06541285825290494,
    "math.log2": 0.06532005493671819,
    "torch.all": 0.06519424287382072,
    "items": 0.06516141967844988,
    "logger.warning_once": 0.06497869644656815,
    "torch.randn": 0.06485409264654678,
    "torch.clamp": 0.06482146189883156,
    "t": 0.06482146189883156,
    "_get_perms": 0.06473448167534487,
    "all": 0.0643533485595535,
    "g_idx.clone": 0.06432794229655028,
    "autogptq_post_init": 0.06405633194834061,
    "open": 0.06390789869450204,
    "json.load": 0.06383470429672164,
    "torch.zeros_like": 0.0638197971959978,
    "sorted": 0.06373943198013611,
    "zeros.reshape": 0.06351883560190238,
    "weight.reshape": 0.06340411749477182,
    "ImportError": 0.06329283562549377,
    "torch.bitwise_and": 0.06329242566397246,
    "get_device_capability": 0.06325854034071242,
    "torch.arange": 0.06291701991786332,
    "QuantLinear": 0.06287747617911797,
    "torch.unsqueeze": 0.0627517848873872,
    "torch.bitwise_right_shift": 0.06273756477316941,
    "copy.deepcopy": 0.06262578657033312,
    "BaseQuantizeConfig": 0.050295341167958356,
    "AutoGPTQForCausalLM.from_pretrained": 0.050295341167958356,
    "model.quantize": 0.050295341167958356,
    "tempfile.TemporaryDirectory": 0.04974289173267838,
    "model.save_pretrained": 0.04974289173267838,
    "torch.randint": 0.04922009025920116,
    "autogptq_marlin_cuda.mul": 0.04860528821247693,
    "name.split": 0.04826315965964258,
    "self.assertFalse": 0.047225481077709214,
    "strip": 0.047066905390810744,
    "lower": 0.046885384991958066,
    "labels.append": 0.04678007942734578,
    "GenerationConfig": 0.04678007942734578,
    "postprocess_generation_ids": 0.04678007942734578,
    "decode": 0.04678007942734578,
    "split": 0.04638852049836469,
    "EnvironmentError": 0.046379624335745946,
    "self.model": 0.04636308465789397,
    "gc.collect": 0.04605887242139701,
    "torch.inference_mode": 0.04554704873067332,
    "_get_cached_marlin_save_name": 0.045501626608560886,
    "self.skipTest": 0.045304681771790895,
    "get": 0.04529964488501996,
    "zip": 0.044897050625743534,
    "w.reshape": 0.04476438263515229,
    "tl.arange": 0.04472858734787207,
    "device_to_buffers_size.items": 0.04454836787580701,
    "load_dataset": 0.0444383417500274,
    "tl.zeros": 0.04438859678095467,
    "tl.store": 0.04435969208238748,
    "tolist": 0.04435231445078692,
    "tl.cdiv": 0.04435138447416919,
    "tl.load": 0.04434754959186983,
    "tl.program_id": 0.04432247977560201,
    "tl.dot": 0.04423468125584087,
    "linear_class": 0.04421274971458985,
    "w.permute": 0.04419282283334263,
    "np.array": 0.04414894398028487,
    "triton.cdiv": 0.04412340520780592,
    "synchronize": 0.04411731738181391,
    "custom_autotune.autotune": 0.04409450050923873,
    "mean": 0.044046693769601644,
    "quant_matmul_248": 0.043927878647687234,
    "transpose_quant_matmul_248": 0.04378511100102584,
    "x.view": 0.04377122181330563,
    "output.view": 0.04377122181330563,
    "x.half": 0.04377122181330563,
    "GPTQLoraConfig": 0.043704500273939205,
    "GPTQAdaLoraConfig": 0.043704500273939205,
    "long": 0.04347496551083262,
    "x.flatten": 0.04343797130155078,
    "torch.full": 0.043436178318518835,
    "torch.abs": 0.043436178318518835,
    "quantize": 0.04335309731003086,
    "expand": 0.04335183007585245,
    "MarlinQuantLinear": 0.04334919809503215,
    "autogptq_marlin_cuda.gptq_repack": 0.04334919809503215,
    "torch.allclose": 0.043235297400469996,
    "safe_save": 0.04318933079044175,
    "kn_values.items": 0.043184560727638224,
    "zeros.contiguous": 0.04316955043598249,
    "torch.max": 0.04315278922832867,
    "unpack_qzeros": 0.0431433481356146,
    "abs": 0.04312497032766891,
    "new_module.to": 0.04307234127969114,
    "torch.ones": 0.04301596860472344,
    "scales.contiguous": 0.042874756319311653,
    "out.reshape": 0.04281139679290917,
    "torch.mean": 0.04278220433658236,
    "math.sqrt": 0.0427527264854505,
    "extensions.append": 0.04274394678746514,
    "apply_rotary_pos_emb": 0.042688086828847734,
    "nn.Linear": 0.0426675431595194,
    "warmup": 0.04265176246195896,
    "is_available": 0.042619474029741165,
    "tensor.view": 0.042615980457472655,
    "softmax": 0.042615980457472655,
    "compare_pytorch_version": 0.042615980457472655,
    "torch.finfo": 0.042615980457472655,
    "self.qkv_proj": 0.042615980457472655,
    "F.scaled_dot_product_attention": 0.042615980457472655,
    "type_as": 0.042505347521241355,
    "numel": 0.042460224097264763,
    "out.to": 0.04242866685157489,
    "find_layers": 0.04238253155312156,
    "next": 0.04236543292134916,
    "model_name_or_path.split": 0.042141305221554896,
    "find_tied_parameters": 0.04200562456501376,
    "kwargs.pop": 0.041959766675502067,
    "scales.reshape": 0.04191205821132628,
    "qinfer.unpack_zeros4": 0.041837764584308684,
    "qinfer.unpack_zeros2": 0.041837764584308684,
    "scales.transpose": 0.041837764584308684,
    "zeros.transpose": 0.041837764584308684,
    "logger.debug": 0.04179185285241191,
    "TypeError": 0.041785400224850555,
    "load_checkpoint_in_model": 0.041601646789052635,
    "set_tuning_params": 0.04159472432857819,
    "get_device": 0.04149689339309479,
    "device_map.items": 0.041387776206602375,
    "get_module_by_name_suffix": 0.04113425439412405,
    "QuantLinear.warmup": 0.04104841521360109,
    "make_quant": 0.04079772917564856,
    "cached_file": 0.040586400555068756,
    "name.startswith": 0.04036063731761254,
    "AutoConfig.from_pretrained": 0.040208027322903225,
    "preprocess_checkpoint_qigen": 0.040091142243462635,
    "accelerate.cpu_offload_with_hook": 0.040091142243462635,
    "values": 0.040091142243462635,
    "name.endswith": 0.040091142243462635,
    "SUPPORTED_MODELS.append": 0.029761325833766523,
    "parse_version": 0.027474828300639183,
    "np.empty": 0.026518595817780446,
    "levenshtein_distance": 0.026518595817780446,
    "functools.reduce": 0.026505095104340688,
    "attr.split": 0.026505095104340688,
    "check_and_get_model_type": 0.026122281633782753,
    "from_pretrained": 0.025978630998030654,
    "quant_func": 0.025978630998030654,
    "signature": 0.025978630998030654,
    "math.exp": 0.025143021005674514,
    "get_dataloader": 0.024784947309795892,
    "self._metric": 0.024784947309795892,
    "batch_data.items": 0.024784947309795892,
    "self._parse_labels": 0.024784947309795892,
    "self._predict": 0.024784947309795892,
    "v.to": 0.024784947309795892,
    "outputs.append": 0.02468313678128988,
    "size": 0.024508732217036155,
    "tokenizer.batch_decode": 0.024508732217036155,
    "sub_output_ids.cpu": 0.024508732217036155,
    "one_sub_generated_ids.index": 0.024508732217036155,
    "cleanup_buffers_cuda": 0.024300807866095127,
    "logging.basicConfig": 0.02429601148853897,
    "model.save_quantized": 0.02429601148853897,
    "rouge.Rouge": 0.02408054997661045,
    "metric.get_scores": 0.02408054997661045,
    "model_autogptq.named_modules": 0.02399633985676105,
    "AutoAWQForCausalLM.from_quantized": 0.02399633985676105,
    "model_awq.generate": 0.02399633985676105,
    "os.remove": 0.023743562053259,
    "np.exp": 0.023104936338228986,
    "cpp_extension.CUDAExtension": 0.023005280186009624,
    "partial": 0.02285535011820853,
    "get_closest_label": 0.022815638690809065,
    "make_q_matrix": 0.0227941867086085,
    "platform.machine": 0.022739138179076333,
    "predictions.append": 0.022699529450735327,
    "self.tokenizer": 0.022699529450735327,
    "get_predictions": 0.022699529450735327,
    "sub_predictions.append": 0.022699529450735327,
    "most_common": 0.022699529450735327,
    "each.lower": 0.022699529450735327,
    "gen_text.lower": 0.022699529450735327,
    "Counter": 0.022699529450735327,
    "sys.exit": 0.022644958445105695,
    "Event": 0.022613374709096953,
    "start_event.record": 0.022613374709096953,
    "get_gptq_peft_model": 0.022613055308683634,
    "self.check_model_trainable": 0.022613055308683634,
    "self.prune_configs": 0.022594662825232474,
    "input.stride": 0.02258748875629242,
    "qweight.stride": 0.02258748875629242,
    "output.stride": 0.02258748875629242,
    "scales.stride": 0.02258748875629242,
    "qzeros.stride": 0.02258748875629242,
    "end_event.record": 0.022578422872900655,
    "start_event.elapsed_time": 0.022578422872900655,
    "latencies.append": 0.022578422872900655,
    "platform.system": 0.022575116981304023,
    "scales.to": 0.02255286760197703,
    "self._prepare_data": 0.022507635107253694,
    "detach": 0.022507635107253694,
    "e_x.sum": 0.022507635107253694,
    "self._compute_batch_logits": 0.022507635107253694,
    "logits.append": 0.022507635107253694,
    "self._model": 0.022507635107253694,
    "np.max": 0.022507635107253694,
    "self._process_batch": 0.022507635107253694,
    "all_perplexity.append": 0.022507635107253694,
    "progress.set_description": 0.022507635107253694,
    "self.softmax": 0.022507635107253694,
    "np.log": 0.022507635107253694,
    "self._tokenizer": 0.022507635107253694,
    "torch.any": 0.022476504034076375,
    "self.hook": 0.022470774082220084,
    "arg_names.index": 0.022464166034642734,
    "np.mean": 0.022428795050649996,
    "np.percentile": 0.022428795050649996,
    "model_lora.gradient_checkpointing_enable": 0.02239022354954994,
    "Adam": 0.02239022354954994,
    "model_lora.train": 0.02239022354954994,
    "value.to": 0.02239022354954994,
    "model_lora.parameters": 0.02239022354954994,
    "optimizer.zero_grad": 0.02239022354954994,
    "losses.append": 0.02239022354954994,
    "loss.backward": 0.02239022354954994,
    "optimizer.step": 0.02239022354954994,
    "batch.items": 0.02239022354954994,
    "loss.item": 0.02239022354954994,
    "model_lora": 0.02239022354954994,
    "math.isfinite": 0.02239022354954994,
    "math.isnan": 0.02239022354954994,
    "linear_gptq": 0.022363108147931687,
    "linear_awq": 0.02236310814793168,
    "custom_fwd": 0.02233003995984075,
    "tl.trans": 0.02233003995984075,
    "tl.sigmoid": 0.02233003995984075,
    "ctx.save_for_backward": 0.02233003995984075,
    "copy.copy": 0.0223164838895257,
    "common_setup_kwargs.update": 0.022303408659430434,
    "setup": 0.022303408659430434,
    "read_text": 0.022303408659430434,
    "find_packages": 0.022303408659430434,
    "os.cpu_count": 0.022303408659430434,
    "subprocess.check_output": 0.022303408659430434,
    "get_python_lib": 0.022303408659430434,
    "include_dirs.append": 0.022303408659430434,
    "startswith": 0.022303408659430434,
    "Exception": 0.022303408659430434,
    "cpp_extension.CppExtension": 0.022303408659430434,
    "Path": 0.022303408659430434,
    "subprocess.run": 0.022303408659430434,
    "torch.Tensor": 0.022293246121747868,
    "transpose": 0.02226553659873605,
    "sample_blocks.append": 0.022262000602407475,
    "self.temp_dq_size": 0.02225092129132153,
    "attn_output.size": 0.022245274597233838,
    "tuple": 0.02223147666109166,
    "m.solve": 0.022217251978889078,
    "linear_gptq.eval": 0.022212664087552885,
    "linear_gptq.to": 0.022212664087552885,
    "format": 0.022212664087552885,
    "lines.append": 0.022212664087552885,
    "ModuleNotFoundError": 0.022212664087552885,
    "WQLinear_GEMV": 0.022212664087552885,
    "WQLinear_GEMM": 0.022212664087552885,
    "model_q.generate": 0.022209408110002115,
    "config.pre_hook": 0.022197841139763766,
    "short": 0.022152387405019985,
    "convert_to_marlin": 0.022150135284452584,
    "gemm_half_q_half": 0.022119542776252804,
    "temp_dq.get_scratch_slice": 0.022119542776252804,
    "ext_make_q_matrix": 0.022119542776252804,
    "ext_gemm_half_q_half": 0.022119542776252804,
    "narrow": 0.022119542776252804,
    "output.add_": 0.022119542776252804,
    "self.temp_fwd_size": 0.022119542776252804,
    "self.prepare": 0.022119542776252804,
    "torch.empty_like": 0.022119542776252804,
    "_torch_device": 0.022119542776252804,
    "torch.maximum": 0.02207121780764427,
    "dict": 0.022031365975132777,
    "torch.manual_seed": 0.022000085627036963,
    "linear.eval": 0.022000085627036963,
    "linear.to": 0.022000085627036963,
    "label_ids.append": 0.02199321240021191,
    "input_ids.append": 0.021993212400211907,
    "warnings.warn": 0.02197498443088549,
    "gen_quant4": 0.021974230876898832,
    "CustomizedTritonAutoTuner": 0.021965143103611643,
    "used.add": 0.021965143103611643,
    "meta.keys": 0.021965143103611643,
    "do_bench": 0.021965143103611643,
    "self.early_config_prune": 0.021965143103611643,
    "builtins.min": 0.021965143103611643,
    "zero_": 0.021965143103611643,
    "self._bench": 0.021965143103611643,
    "self.perf_model": 0.021965143103611643,
    "est_timing.keys": 0.021965143103611643,
    "append": 0.02196164383584918,
    "LongTensor": 0.02196164383584918,
    "block.size": 0.02196164383584918,
    "pad_block": 0.02196164383584918,
    "attn_weights.size": 0.021938119028790823,
    "ds.select": 0.021930706642773707,
    "ds.map": 0.021930706642773707,
    "DataLoader": 0.021930706642773707,
    "preprocess_fn": 0.021930706642773707,
    "sample_block.append": 0.021930706642773707,
    "load_fn": 0.021930706642773707,
    "dropped_indices.append": 0.021930706642773707,
    "attention_mask.append": 0.021930706642773707,
    "random.sample": 0.021930706642773707,
    "pads.to": 0.021930706642773707,
    "find_params": 0.021926377857244238,
    "CUDA_OLD_REFERENCE.to": 0.021918435448301153,
    "self.assertEqual": 0.02191784749644537,
    "recurse_getattr": 0.021915363791264814,
    "repeat": 0.02187511670051066,
    "attention_mask.size": 0.021852723358481665,
    "torch.minimum": 0.02184504477878857,
    "self.ready": 0.02184504477878857,
    "x.min": 0.02184504477878857,
    "x.max": 0.02184504477878857,
    "torch.full_like": 0.02184504477878857,
    "q.abs_": 0.02184504477878857,
    "q.pow_": 0.02184504477878857,
    "x.permute": 0.02184504477878857,
    "x.t": 0.02184504477878857,
    "scale1.unsqueeze": 0.02184504477878857,
    "zero1.unsqueeze": 0.02184504477878857,
    "stride": 0.021787591050239703,
    "x.stride": 0.021758394385020325,
    "c.stride": 0.021758394385020325,
    "model.state_dict": 0.02175806455530188,
    "Parameter": 0.02175806455530188,
    "move_to_device": 0.021749644039709366,
    "silu": 0.02172948968645314,
    "c.to": 0.02172948968645314,
    "self.down_proj": 0.02172948968645314,
    "self.triton_llama_mlp": 0.02172948968645314,
    "c.reshape": 0.02172948968645314,
    "modules.triton_llama_mlp": 0.02172948968645314,
    "x.float": 0.021725004916319957,
    "scale.append": 0.02171422890028352,
    "zero.append": 0.021714228900283513,
    "self.linear_module": 0.02171292545334678,
    "m.Var": 0.02167353967805481,
    "m.Equation": 0.02167353967805481,
    "torch.diag": 0.02167133647724137,
    "make_q4": 0.021651679037052823,
    "q4_matmul": 0.021651679037052823,
    "ext_make_q4": 0.021651679037052823,
    "ext_q4_matmul": 0.021651679037052823,
    "out.add_": 0.021651679037052823,
    "_get_linear_feature_count": 0.021647952591132853,
    "delattr": 0.021647952591132853,
    "_get_weight": 0.021647952591132853,
    "self.update_layer": 0.021647952591132853,
    "new_module.named_modules": 0.021623489069171976,
    "m.Const": 0.021617702352842206,
    "np.sum": 0.021617702352842206,
    "w.clone": 0.021591133539730266,
    "ref.t": 0.021591133539730266,
    "CudaOldQuantLinear": 0.021591133539730266,
    "cuda_old_linear.pack": 0.021591133539730266,
    "dequantize_weight": 0.021591133539730266,
    "dequantized_weight.to": 0.021591133539730266,
    "Linear": 0.021591133539730266,
    "copy_": 0.021591133539730266,
    "marlin_linear.pack": 0.021591133539730266,
    "cuda_old_linear.to": 0.021591133539730266,
    "marlin_linear.to": 0.021591133539730266,
    "linear_module.to": 0.021591133539730266,
    "cuda_old_linear": 0.021591133539730266,
    "marlin_linear": 0.021591133539730266,
    "res_cuda_old.abs": 0.021591133539730266,
    "GEKKO": 0.021590204574596802,
    "m.Maximize": 0.021590204574596802,
    "qinfer.compute_reduction_cpp": 0.021590204574596802,
    "np.ones": 0.021590204574596802,
    "split.astype": 0.021590204574596802,
    "mem_model": 0.021590204574596802,
    "compute_reductions": 0.021590204574596802,
    "qinfer.forward4": 0.021590204574596802,
    "qinfer.forward_gs4": 0.021590204574596802,
    "qinfer.forward2": 0.021590204574596802,
    "qinfer.forward_gs2": 0.021590204574596802,
    "qinfer.forward3": 0.021590204574596802,
    "qinfer.forward_gs3": 0.021590204574596802,
    "get_diff": 0.02158608726039396,
    "hidden_states.size": 0.021561655688598403,
    "torch.split": 0.021561655688598403,
    "self.rotary_emb": 0.021561655688598403,
    "attn_output.transpose": 0.021561655688598403,
    "attn_output.reshape": 0.021561655688598403,
    "self.o_proj": 0.021561655688598403,
    "past_key_value.get_usable_length": 0.021561655688598403,
    "past_key_value.update": 0.021561655688598403,
    "query_states.contiguous": 0.021561655688598403,
    "key_states.contiguous": 0.021561655688598403,
    "value_states.contiguous": 0.021561655688598403,
    "query_states.view": 0.021561655688598403,
    "key_states.view": 0.021561655688598403,
    "value_states.view": 0.021561655688598403,
    "key_states.transpose": 0.021561655688598403,
    "self.unmerge": 0.021534591616808037,
    "LoraModel._create_new_module": 0.02149659704821758,
    "_convert_tensor_to_list": 0.02148741943059483,
    "quant_linear_fn.apply": 0.021455071041185086,
    "out.half": 0.021455071041185086,
    "quant_matmul_inference_only_248": 0.021455071041185086,
    "unpacked_qzeros.repeat_interleave": 0.021436139318737186,
    "module.to": 0.021427036131524087,
    "linear": 0.021409136467043368,
    "exllama_set_max_input_length": 0.02140595950444474,
    "self.assertRaises": 0.02140595950444474,
    "ravel": 0.021385283580312726,
    "unpack_4bit_to_32bit_signed": 0.021385283580312726,
    "scales.repeat_interleave": 0.021385283580312726,
    "scale_perm.extend": 0.021385283580312726,
    "scale_perm_single.extend": 0.021385283580312726,
    "q.to": 0.021385283580312726,
    "s.to": 0.021385283580312726,
    "A.half": 0.021385283580312726,
    "mul": 0.021385283580312726,
    "perm.extend": 0.021385283580312726,
    "A.view": 0.021385283580312726,
    "C.view": 0.021385283580312726,
    "perm1.append": 0.021385283580312726,
    "perm.reshape": 0.021385283580312726,
    "res.reshape": 0.021385283580312726,
    "q.astype": 0.021385283580312726,
    "res.cpu": 0.021385283580312726,
    "_perm.numel": 0.021385283580312726,
    "parameterized.expand": 0.021372207145033625,
    "torch.count_nonzero": 0.021372207145033625,
    "normal_": 0.021364202279411455,
    "torch.clamp_": 0.021364202279411455,
    "old_module.parameters": 0.021364202279411455,
    "old_module.buffers": 0.021364202279411455,
    "inp.t": 0.021355333664325342,
    "model_q.named_modules": 0.02134716431886631,
    "model_q.named_parameters": 0.02134716431886631,
    "model_q.named_buffers": 0.02134716431886631,
    "predicted_text.startswith": 0.02134716431886631,
    "ref.abs": 0.02134716431886631,
    "peft_config.to_dict": 0.021338987352632566,
    "LoraLayer.__init__": 0.02131427672438926,
    "result.to": 0.02131427672438926,
    "AdaLoraLayer.__init__": 0.02131427672438926,
    "ignore.append": 0.02131427672438926,
    "model.enable_trainable_mode": 0.02131427672438926,
    "hijack_peft_mappings": 0.02131427672438926,
    "xavier_uniform_": 0.02131427672438926,
    "zeros_": 0.02131427672438926,
    "GPTQLoraLinear": 0.02131427672438926,
    "GPTQSVDLinear": 0.02131427672438926,
    "x.type_as": 0.02131427672438926,
    "n.split": 0.02131427672438926,
    "results.add": 0.02131427672438926,
    "find_all_linear_names": 0.02131427672438926,
    "get_peft_model": 0.02131427672438926,
    "PeftModel.from_pretrained": 0.02131427672438926,
    "lora_B": 0.02131427672438926,
    "lora_A": 0.02131427672438926,
    "lora_dropout": 0.02131427672438926,
    "g_idx_i.long": 0.021268973084582348,
    "cholesky": 0.02123800304470159,
    "vecquant2matmul": 0.021221192218312368,
    "vecquant3matmul": 0.021221192218312368,
    "weights.append": 0.021221192218312368,
    "vecquant4matmul": 0.021221192218312368,
    "vecquant8matmul": 0.021221192218312368,
    "torch.argsort": 0.021214536920776843,
    "self.layer": 0.021214536920776843,
    "x.to": 0.021207474633262523,
    "vecquant2matmul_faster_old": 0.021207474633262523,
    "vecquant2matmul_old": 0.021207474633262523,
    "vecquant3matmul_faster_old": 0.021207474633262523,
    "vecquant3matmul_old": 0.021207474633262523,
    "vecquant4matmul_faster_old": 0.021207474633262523,
    "vecquant4matmul_old": 0.021207474633262523,
    "vecquant8matmul_old": 0.021207474633262523,
    "tensor.permute": 0.021198543960443402,
    "fields": 0.02119451279568541,
    "Quantizer": 0.021191070796852094,
    "inp.matmul": 0.021191070796852094,
    "W.float": 0.021191070796852094,
    "torch.cholesky_inverse": 0.021191070796852094,
    "inp.unsqueeze": 0.021191070796852094,
    "nn.Unfold": 0.021191070796852094,
    "unfold": 0.021191070796852094,
    "inp.permute": 0.021191070796852094,
    "inp.flatten": 0.021191070796852094,
    "inp.float": 0.021191070796852094,
    "ready": 0.021191070796852094,
    "Err1.matmul": 0.021191070796852094,
    "Q.t": 0.021191070796852094,
    "inp.reshape": 0.021191070796852094,
    "quantizer.find_params": 0.021191070796852094,
    "groups.append": 0.021191070796852094,
    "flatten": 0.021191070796852094,
    "matmul": 0.021191070796852094,
    "Q.reshape": 0.021191070796852094,
    "err1.unsqueeze": 0.021191070796852094,
    "w.unsqueeze": 0.021191070796852094,
    "get_balanced_memory": 0.021169848361626272,
    "fixed_pos_embedding": 0.021126431140249338,
    "remove_hook_from_module": 0.021117558960994487,
    "m.view": 0.021098494470704002,
    "nn.Dropout": 0.02107640961978913,
    "torch.stack": 0.02105432476887426,
    "m.repeat": 0.02105432476887426,
    "torch.sin": 0.02105432476887426,
    "torch.cos": 0.02105432476887426,
    "qkv.view": 0.02105432476887426,
    "query.to": 0.02105432476887426,
    "key.to": 0.02105432476887426,
    "torch.where": 0.02105432476887426,
    "attn_weights.to": 0.02105432476887426,
    "self.attn_dropout": 0.02105432476887426,
    "self._split_heads": 0.02105432476887426,
    "key.permute": 0.02105432476887426,
    "query.permute": 0.02105432476887426,
    "value.permute": 0.02105432476887426,
    "self._merge_heads": 0.02105432476887426,
    "self.out_proj": 0.02105432476887426,
    "self.resid_dropout": 0.02105432476887426,
    "duplicate_interleave": 0.02105432476887426,
    "rotate_every_two": 0.02105432476887426,
    "view": 0.02105432476887426,
    "torch.get_default_dtype": 0.02105432476887426,
    "query.size": 0.02105432476887426,
    "key.size": 0.02105432476887426,
    "key.transpose": 0.02105432476887426,
    "query.contiguous": 0.02105432476887426,
    "key.contiguous": 0.02105432476887426,
    "value.contiguous": 0.02105432476887426,
    "self._attn": 0.02105432476887426,
    "torch.sqrt": 0.02105432476887426,
    "qkv.size": 0.02105432476887426,
    "tensor.size": 0.02105432476887426,
    "torch.einsum": 0.02105432476887426,
    "torch.tril": 0.02105432476887426,
    "m.buffers": 0.02105432476887426,
    "cuda": 0.02094676995506832,
    "model.to": 0.020931219336898416,
    "device_map.values": 0.020790247762813022,
    "state_dict": 0.020741575647619075,
    "model.tie_weights": 0.020735303809704838,
    "accelerate.infer_auto_device_map": 0.020712284571371597,
    "accelerate.init_empty_weights": 0.020707262261228924,
    "_validate_marlin_compatibility": 0.020685585414503226,
    "self.save_quantized": 0.020616788536201115,
    "nested_move_to_device": 0.02059714968838481,
    "os.listdir": 0.020570820952034306,
    "AutoModelForCausalLM.from_config": 0.020559925742991172,
    "searched_files.append": 0.020545771490744217,
    "get_module_by_name_prefix": 0.020520888467128087,
    "layers.keys": 0.02045451464696875,
    "layer": 0.020437963970215425,
    "module.named_children": 0.02035003406428455,
    "simple_dispatch_model": 0.020315462018174604,
    "add_batch": 0.020301137024139226,
    "submodule.post_init": 0.020294982918229624,
    "wf.unsqueeze": 0.020275715835863108,
    "awq_reverse_reorder_int_tensor": 0.020261495721645317,
    "module.named_modules": 0.020247560009711882,
    "retie_parameters": 0.020247560009711882,
    "order_tensor.repeat": 0.020247560009711882,
    "order_tensor.reshape": 0.020247560009711882,
    "awq_qzeros.cuda": 0.020247560009711882,
    "awq_qweight.cuda": 0.020247560009711882,
    "weight.view": 0.020247560009711882,
    "zeros.view": 0.020247560009711882,
    "awq_scales.cuda": 0.020247560009711882,
    "unpacked_qzeros.contiguous": 0.020247560009711882,
    "unpacked_qzeros.cpu": 0.020247560009711882,
    "awq_scales.cpu": 0.020247560009711882,
    "awq_scales.clone": 0.020247560009711882,
    "res.update": 0.020247560009711882,
    "pack": 0.020247560009711882,
    "fixed_bytes.items": 0.020247560009711882,
    "scale_zeros_mat.half": 0.020247560009711882,
    "unpacked_qzeros.t": 0.020247560009711882,
    "FileNotFoundError": 0.020247560009711882,
    "obj.parameters": 0.020247560009711882,
    "obj.to": 0.020247560009711882,
    "logger.error": 0.020247560009711882,
    "qinfer.pack4": 0.020247560009711882,
    "scale.to": 0.020247560009711882,
    "zero.to": 0.020247560009711882,
    "g_idx.to": 0.020247560009711882,
    "AlignDevicesHook": 0.020247560009711882,
    "add_hook_to_module": 0.020247560009711882,
    "submodule.scratch_space_fixed": 0.020247560009711882,
    "ExLlamaV2DeviceTensors": 0.020247560009711882,
    "m.register_buffer": 0.020247560009711882,
    "unpacked_qweight.clone": 0.020247560009711882,
    "awq_scales.t": 0.020247560009711882,
    "unpacked_qzeros.numpy": 0.020247560009711882,
    "new_layer.to": 0.020247560009711882,
    "qinfer.pack3": 0.020247560009711882,
    "fixed_bytes.get": 0.020247560009711882,
    "submodule.parameters": 0.020247560009711882,
    "qinfer.pack2": 0.020247560009711882,
    "possible_index_file.replace": 0.020247560009711882,
    "to_dict": 0.020093366022858456,
    "model.eval": 0.02000892236263192,
    "inject_to_model": 0.01988377284683378,
    "f.get_tensor": 0.01986329249042649,
    "field": 0.01985343736208862,
    "save_pretrained": 0.01985343736208862,
    "model_init_kwargs.pop": 0.01985343736208862,
    "attention_masks.append": 0.01985343736208862,
    "logging.getLogger": 0.019843582233750757,
    "logging.StreamHandler": 0.019843582233750757,
    "logging.Formatter": 0.019843582233750757,
    "handler.setFormatter": 0.019843582233750757,
    "logger.addHandler": 0.019843582233750757,
    "logger.setLevel": 0.019843582233750757,
    "self._prepare_examples_for_quantization": 0.019843582233750757,
    "LayerHijacker": 0.019843582233750757,
    "pack_model": 0.019843582233750757,
    "prepare_inputs_for_generation": 0.019843582233750757,
    "create_repo": 0.019843582233750757,
    "os.makedirs": 0.019843582233750757,
    "AutoModelForCausalLM.from_pretrained": 0.019843582233750757,
    "get_checkpoints": 0.019843582233750757,
    "named_modules": 0.019843582233750757,
    "self.enable_trainable_mode": 0.019843582233750757,
    "GeneralQuantLinear.inject_to_model": 0.019843582233750757,
    "json.dump": 0.019843582233750757,
    "args_from_json.items": 0.019843582233750757,
    "new_examples.append": 0.019843582233750757,
    "collate_data": 0.019843582233750757,
    "example.items": 0.019843582233750757,
    "create_commit": 0.019843582233750757,
    "torch.save": 0.019843582233750757,
    "BaseQuantizeConfig.from_pretrained": 0.019843582233750757,
    "model_save_name.endswith": 0.019843582233750757,
    "model.load_state_dict": 0.019843582233750757,
    "__getattr__": 0.019843582233750757,
    "self.to_dict": 0.019843582233750757,
    "tensor.long": 0.019843582233750757,
    "layer_inputs.append": 0.019843582233750757,
    "kwargs.get": 0.019843582233750757,
    "kwargs.items": 0.019843582233750757,
    "layer_input_kwargs.append": 0.019843582233750757,
    "layer_outputs.append": 0.019843582233750757,
    "CommitOperationAdd": 0.019843582233750757,
    "_validate_marlin_device_support": 0.019843582233750757,
    "no_init_weights": 0.019843582233750757,
    "init_contexts.append": 0.019843582233750757,
    "ContextManagers": 0.019843582233750757,
    "make_sure_no_tensor_in_meta_device": 0.019843582233750757,
    "prepare_model_for_marlin_load": 0.019843582233750757,
    "safe_load": 0.019843582233750757,
    "torch.load": 0.019843582233750757,
    "tensor.unsqueeze": 0.019843582233750757,
    "position_ids.append": 0.019843582233750757,
    "v.unsqueeze": 0.019843582233750757,
    "GPTQ": 0.019843582233750757,
    "configure": 0.019843582233750757,
    "handles.append": 0.019843582233750757,
    "h.remove": 0.019843582233750757,
    "fasterquant": 0.019843582233750757,
    "free": 0.019843582233750757,
    "state_dict.items": 0.019843582233750757,
    "safetensors_metadata.items": 0.019843582233750757,
    "type": 0.019843582233750757,
    "register_forward_hook": 0.019843582233750757,
    "v.clone": 0.019843582233750757,
    "safe_open": 0.019843582233750757,
    "f.keys": 0.019843582233750757,
    "state_dict_key.rsplit": 0.019843582233750757,
    "gptq_layers.add": 0.019843582233750757,
    "unpack_awq": 0.019843582233750757,
    "pbar.set_description": 0.019843582233750757,
    "pack_from_tensors": 0.019843582233750757,
    "tensor.cpu": 0.019843582233750757,
    "non_gptq_params.add": 0.019843582233750757
}