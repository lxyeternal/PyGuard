{
    "to": 0.6035304963249107,
    "range": 0.598746158824051,
    "isinstance": 0.5656427436990531,
    "len": 0.5491156531601293,
    "getLogger": 0.4339622641509434,
    "torch.zeros": 0.3733618141598859,
    "super": 0.3535434112968687,
    "__init__": 0.34949705863267033,
    "NotImplementedError": 0.33546663154829215,
    "ValueError": 0.32213218159037454,
    "contiguous": 0.3197391329030713,
    "torch.tensor": 0.28300143965570645,
    "self.register_buffer": 0.2714379260494248,
    "AutoGPTQForCausalLM.from_quantized": 0.25995039202586373,
    "torch.cat": 0.2509150492411106,
    "self.assertTrue": 0.24052153297436316,
    "AutoTokenizer.from_pretrained": 0.2307845892751553,
    "clone": 0.2277458786819314,
    "torch.device": 0.21481840812563488,
    "list": 0.21183883479362292,
    "model.named_modules": 0.20264367996511895,
    "tokenizer": 0.20200495259457524,
    "float": 0.19954783162330328,
    "int": 0.1941882615737063,
    "tokenizer.decode": 0.19243335281071128,
    "logger.info": 0.18835691098569168,
    "reshape": 0.18652082562158837,
    "join": 0.1851405024705131,
    "torch.round": 0.17721676347013277,
    "torch.no_grad": 0.17654997404203257,
    "setattr": 0.1719810976538507,
    "math.ceil": 0.17182411479268048,
    "min": 0.1549080793420416,
    "compare_transformers_version": 0.1509433962264151,
    "torch.from_numpy": 0.1507273896970883,
    "max": 0.15048420686548133,
    "getattr": 0.14910881689806577,
    "logger.warning": 0.1444719540517889,
    "dynamically_import_QuantLinear": 0.14406246894153413,
    "generate": 0.14370084644203548,
    "unsqueeze": 0.14054404714782073,
    "print": 0.13988527196074366,
    "hasattr": 0.139000830663344,
    "astype": 0.13763536043255228,
    "np.zeros": 0.13763536043255228,
    "torch.empty": 0.12392966376713282,
    "half": 0.1226747593569016,
    "x.reshape": 0.1215495949807765,
    "enumerate": 0.11395627433363283,
    "empty_cache": 0.11325277902351595,
    "W.flatten": 0.11242173684380263,
    "W.t": 0.11242173684380263,
    "qweight.astype": 0.10723690607369413,
    "intweight.append": 0.1063026723477517,
    "intweight.t": 0.10620071801055048,
    "intweight.numpy": 0.10620071801055048,
    "scales.t": 0.10549477525609022,
    "qzeros.astype": 0.10535008731932292,
    "cls": 0.10356896943207701,
    "torch.rand": 0.10279343298211222,
    "tqdm": 0.1002006634838017,
    "str": 0.09986325134064544,
    "isfile": 0.09983238943723102,
    "model.get_submodule": 0.09907912756238466,
    "isdir": 0.09906670996026638,
    "time.time": 0.09754145225843337,
    "torch.matmul": 0.09176982839579954,
    "set": 0.08980928647713979,
    "any": 0.0854562715082473,
    "zeros.t": 0.08508661199078407,
    "scales.clone": 0.08508661199078407,
    "zeros.numpy": 0.08508661199078407,
    "run": 0.08461978273299027,
    "keys": 0.08360205831903944,
    "model.generate": 0.08347627215551744,
    "device": 0.08101171722892846,
    "sum": 0.08084134330129346,
    "numpy": 0.08050963496826286,
    "cpu": 0.07962713387241689,
    "item": 0.07910806174957119,
    "zeros.reshape": 0.0779079411154883,
    "name.rsplit": 0.07756196818349982,
    "get": 0.07750362844702467,
    "autogptq_post_init": 0.0763786468663649,
    "s.reshape": 0.07563012010451364,
    "weight.reshape": 0.07536802819821686,
    "torch.sum": 0.07520760162269596,
    "torch.bitwise_and": 0.07311608726703066,
    "torch.zeros_like": 0.07227259114051567,
    "self.skipTest": 0.06990807934204162,
    "w.reshape": 0.06952077572023664,
    "items": 0.06849299586928637,
    "torch.arange": 0.06677525212486367,
    "torch.bitwise_right_shift": 0.06531780588384362,
    "triton.Config": 0.0650417231181152,
    "recurse_setattr": 0.06459326836685327,
    "huggingface_hub.cached_assets_path": 0.06446312676287756,
    "prepare_buffers": 0.0643905360886493,
    "g_idx.clone": 0.06421616882691385,
    "logger.warning_once": 0.0641447199387018,
    "find_layers": 0.06351749196177818,
    "zip": 0.0634648370497427,
    "ImportError": 0.06310336258148383,
    "synchronize": 0.06270521930899291,
    "QuantLinear": 0.06248348395962159,
    "open": 0.06177053435864401,
    "autocast": 0.06154819825165144,
    "copy.deepcopy": 0.0612598034456347,
    "math.log2": 0.061177815894797025,
    "json.load": 0.06117720339863451,
    "get_device_capability": 0.06069412457044049,
    "torch.unsqueeze": 0.060664178588706895,
    "w.permute": 0.06056813806139952,
    "torch.all": 0.06048511237190482,
    "_get_perms": 0.059770418260984295,
    "sorted": 0.05976090110791072,
    "t": 0.059716339365935046,
    "torch.randn": 0.05909856414355537,
    "torch.clamp": 0.058572828788462206,
    "all": 0.05826510027293224,
    "TypeError": 0.05790062554035498,
    "expand": 0.05769230769230769,
    "tl.arange": 0.05704626712449999,
    "extensions.append": 0.05653531232028918,
    "linear_class": 0.05525606469002695,
    "torch.randint": 0.05525606469002695,
    "get_device": 0.05522781083478841,
    "zeros.contiguous": 0.05480682839173405,
    "scales.contiguous": 0.05480682839173405,
    "safe_save": 0.054595576489488915,
    "device_map.items": 0.05442257596048981,
    "model_autogptq.named_modules": 0.05370101596516691,
    "AutoAWQForCausalLM.from_quantized": 0.05370101596516691,
    "model_awq.generate": 0.05370101596516691,
    "self.model": 0.052569123056841104,
    "get_module_by_name_suffix": 0.0524758853345539,
    "kwargs.pop": 0.05236976385427791,
    "warmup": 0.05172767187719129,
    "QuantLinear.warmup": 0.05101798640424486,
    "split": 0.05079825834542816,
    "self.assertFalse": 0.05079825834542816,
    "tl.zeros": 0.050727459379093065,
    "logger.debug": 0.0505431675242996,
    "tl.store": 0.05026726609791497,
    "next": 0.05014269858886951,
    "x.flatten": 0.04979035639412998,
    "long": 0.04957365747460087,
    "scales.reshape": 0.049306563457506856,
    "torch.inference_mode": 0.04920691428345398,
    "tl.cdiv": 0.04881588728804559,
    "tl.load": 0.048550391164289004,
    "is_available": 0.048249673667972,
    "make_quant": 0.04821520396458097,
    "torch.allclose": 0.047966184758637585,
    "tl.program_id": 0.047895500725689405,
    "cached_file": 0.04776031689524036,
    "quantize": 0.04731275014293882,
    "strip": 0.04662291495761553,
    "_get_cached_marlin_save_name": 0.045960328979196906,
    "model_name_or_path.split": 0.04559520223457568,
    "tolist": 0.0455440844903287,
    "set_tuning_params": 0.045522611560347405,
    "tempfile.TemporaryDirectory": 0.04499274310595065,
    "model.save_pretrained": 0.04499274310595065,
    "EnvironmentError": 0.044499822000712,
    "tl.dot": 0.044196254734680876,
    "preprocess_checkpoint_qigen": 0.04362960325936474,
    "out.to": 0.043541364296081284,
    "abs": 0.04353508127093032,
    "name.split": 0.04344460570875665,
    "quant_matmul_248": 0.04321712009387641,
    "model_q.generate": 0.043126684636118594,
    "qinfer.unpack_zeros4": 0.0429769392033543,
    "name.startswith": 0.042886526866590946,
    "accelerate.cpu_offload_with_hook": 0.04262376601287246,
    "load_dataset": 0.04261792452830189,
    "numel": 0.042602575621443546,
    "autogptq_marlin_cuda.mul": 0.04245283018867924,
    "parse_version": 0.04245283018867924,
    "lower": 0.04245283018867924,
    "type_as": 0.04243567753001715,
    "load_checkpoint_in_model": 0.04226342068990699,
    "out.reshape": 0.04224549035869791,
    "torch.abs": 0.042166952544311034,
    "math.sqrt": 0.04208118925100057,
    "GPTQAdaLoraConfig": 0.04204053109713487,
    "x.half": 0.042011193088193816,
    "new_module.to": 0.04193517174649251,
    "AutoConfig.from_pretrained": 0.04180722959647844,
    "qinfer.unpack_zeros2": 0.04177897574123989,
    "transpose_quant_matmul_248": 0.04176574128400704,
    "torch.mean": 0.041337907375643225,
    "unpack_qzeros": 0.04121125954010051,
    "apply_rotary_pos_emb": 0.04120730053027501,
    "torch.max": 0.041128263769773195,
    "MarlinQuantLinear": 0.040902493732682406,
    "autogptq_marlin_cuda.gptq_repack": 0.040902493732682406,
    "move_to_device": 0.04070250385665124,
    "GPTQLoraConfig": 0.040642907058001394,
    "torch.full": 0.04059462550028588,
    "triton.cdiv": 0.04056780771000743,
    "np.array": 0.0405317171987745,
    "mean": 0.04043126684636118,
    "scales.transpose": 0.040281521413596894,
    "zeros.transpose": 0.040281521413596894,
    "F.scaled_dot_product_attention": 0.04023924035022814,
    "device_to_buffers_size.items": 0.04013177598083258,
    "torch.ones": 0.040059655937846834,
    "softmax": 0.0399679368602787,
    "values": 0.03993399899416275,
    "name.endswith": 0.039801205874541584,
    "torch.finfo": 0.03954248366013071,
    "partial": 0.039504716981132074,
    "nn.Linear": 0.03942589042478055,
    "labels.append": 0.03937653814602133,
    "GenerationConfig": 0.03937653814602133,
    "postprocess_generation_ids": 0.03930817610062892,
    "tensor.view": 0.039271180170181275,
    "cpp_extension.CUDAExtension": 0.039187227866473155,
    "custom_autotune.autotune": 0.03918722786647314,
    "gc.collect": 0.03918722786647314,
    "self.qkv_proj": 0.03912319644839067,
    "find_tied_parameters": 0.0389683691570484,
    "x.view": 0.038804685064501285,
    "kn_values.items": 0.03853873946206343,
    "compare_pytorch_version": 0.038432605746701196,
    "output.view": 0.038344491783323185,
    "BaseQuantizeConfig": 0.03773584905660377,
    "AutoGPTQForCausalLM.from_pretrained": 0.03773584905660377,
    "model.quantize": 0.03773584905660377,
    "SUPPORTED_MODELS.append": 0.03773584905660377,
    "decode": 0.03773584905660377,
    "_convert_tensor_to_list": 0.037379850480598074,
    "torch.Tensor": 0.037286612758310876,
    "torch.manual_seed": 0.03638814016172506,
    "linear.eval": 0.03638814016172506,
    "linear.to": 0.03638814016172506,
    "self.assertEqual": 0.035489667565139264,
    "CUDA_OLD_REFERENCE.to": 0.03504043126684636,
    "get_balanced_memory": 0.032989201376527826,
    "fields": 0.03287053518452593,
    "make_q_matrix": 0.032866707242848445,
    "platform.machine": 0.03265602322206096,
    "self.prune_configs": 0.032590051457975985,
    "np.exp": 0.03245283018867925,
    "Event": 0.032345013477088944,
    "start_event.record": 0.032345013477088944,
    "remove_hook_from_module": 0.032039871840512636,
    "arg_names.index": 0.03201829616923957,
    "torch.any": 0.0319706498951782,
    "find_params": 0.031903945111492284,
    "transpose": 0.031446540880503145,
    "attn_output.size": 0.031446540880503145,
    "sys.exit": 0.03120464441219158,
    "m.solve": 0.03099730458221024,
    "self.hook": 0.03087478559176672,
    "end_event.record": 0.03032345013477089,
    "start_event.elapsed_time": 0.03032345013477089,
    "latencies.append": 0.03032345013477089,
    "warnings.warn": 0.03018867924528302,
    "state_dict": 0.02978521419247656,
    "platform.system": 0.02975326560232221,
    "model.tie_weights": 0.029547881808472762,
    "sample_blocks.append": 0.0294811320754717,
    "accelerate.infer_auto_device_map": 0.02942921561647087,
    "accelerate.init_empty_weights": 0.02942921561647087,
    "x.float": 0.02939042089985486,
    "_validate_marlin_compatibility": 0.029310549424468965,
    "copy.copy": 0.028891509433962265,
    "torch.diag": 0.02881646655231561,
    "scale.append": 0.02881646655231561,
    "zero.append": 0.02881646655231561,
    "AutoModelForCausalLM.from_config": 0.028717218464459477,
    "self.linear_module": 0.028679245283018868,
    "check_and_get_model_type": 0.02830188679245283,
    "input.stride": 0.02830188679245283,
    "qweight.stride": 0.02830188679245283,
    "output.stride": 0.02830188679245283,
    "scales.stride": 0.02830188679245283,
    "qzeros.stride": 0.02830188679245283,
    "outputs.append": 0.02830188679245283,
    "_get_linear_feature_count": 0.02792452830188679,
    "delattr": 0.02792452830188679,
    "_get_weight": 0.02792452830188679,
    "self.update_layer": 0.02792452830188679,
    "self.save_quantized": 0.027649222736442387,
    "scales.to": 0.027576197387518146,
    "new_module.named_modules": 0.027547169811320753,
    "tuple": 0.0274442538593482,
    "config.pre_hook": 0.0274442538593482,
    "exllama_set_max_input_length": 0.027403414195867025,
    "cuda": 0.027253668763102725,
    "nested_move_to_device": 0.027174557968434793,
    "model.to": 0.027103923330338425,
    "get_diff": 0.026954177897574125,
    "np.mean": 0.026954177897574125,
    "np.percentile": 0.026954177897574125,
    "get_module_by_name_prefix": 0.026699893200427198,
    "convert_to_marlin": 0.02660861151427189,
    "layers.keys": 0.0265812270084253,
    "get_gptq_peft_model": 0.026554856743535988,
    "self.check_model_trainable": 0.026554856743535988,
    "os.listdir": 0.0264625608164234,
    "attn_weights.size": 0.02641509433962264,
    "linear_awq": 0.02628032345013477,
    "gen_quant4": 0.02615780445969125,
    "os.remove": 0.026124818577648767,
    "layer": 0.025987896048415806,
    "simple_dispatch_model": 0.02586922985641391,
    "device_map.values": 0.02575621443545972,
    "torch.maximum": 0.025157232704402514,
    "linear_gptq": 0.024932614555256066,
    "LoraModel._create_new_module": 0.02490566037735849,
    "self.unmerge": 0.02490566037735849,
    "input_ids.append": 0.024764150943396228,
    "label_ids.append": 0.024764150943396228,
    "attention_mask.size": 0.024737945492662474,
    "self.assertRaises": 0.024707996406109614,
    "find_packages": 0.02467343976777939,
    "inp.t": 0.024356775300171527,
    "add_batch": 0.024207903168387324,
    "LongTensor": 0.024174528301886794,
    "self.temp_dq_size": 0.023737066342057214,
    "WQLinear_GEMV": 0.02358490566037736,
    "WQLinear_GEMM": 0.02358490566037736,
    "append": 0.02358490566037736,
    "block.size": 0.02358490566037736,
    "pad_block": 0.02358490566037736,
    "model_q.named_modules": 0.02336028751123091,
    "to_dict": 0.023258573632372135,
    "searched_files.append": 0.02321054207846661,
    "normal_": 0.023018867924528303,
    "torch.clamp_": 0.023018867924528303,
    "module.to": 0.023018867924528303,
    "load_fn": 0.022995283018867923,
    "dropped_indices.append": 0.022995283018867923,
    "get_closest_label": 0.022969647251845776,
    "model_q.named_parameters": 0.022911051212938002,
    "model_q.named_buffers": 0.022911051212938002,
    "self.to_dict": 0.02290257505636644,
    "tensor.long": 0.02290257505636644,
    "self.early_config_prune": 0.022870211549456832,
    "__getattr__": 0.02278390886436454,
    "layer_inputs.append": 0.02278390886436454,
    "kwargs.get": 0.02278390886436454,
    "kwargs.items": 0.02278390886436454,
    "layer_input_kwargs.append": 0.02278390886436454,
    "recurse_getattr": 0.022738268021286888,
    "perm.extend": 0.022718521370812476,
    "model.eval": 0.022665242672362643,
    "model.load_state_dict": 0.022665242672362643,
    "attr.split": 0.022641509433962263,
    "model_save_name.endswith": 0.022546576480360743,
    "layer_outputs.append": 0.022546576480360743,
    "CommitOperationAdd": 0.022546576480360743,
    "_validate_marlin_device_support": 0.022546576480360743,
    "no_init_weights": 0.022546576480360743,
    "init_contexts.append": 0.022546576480360743,
    "ContextManagers": 0.022546576480360743,
    "os.cpu_count": 0.022496371552975326,
    "subprocess.check_output": 0.022496371552975326,
    "get_python_lib": 0.022496371552975326,
    "include_dirs.append": 0.022496371552975326,
    "linear": 0.022461814914645103,
    "np.sum": 0.022461814914645103,
    "sample_block.append": 0.02240566037735849,
    "attention_mask.append": 0.02240566037735849,
    "random.sample": 0.02240566037735849,
    "pads.to": 0.02240566037735849,
    "mul": 0.022333461686561418,
    "torch.argsort": 0.022298456260720412,
    "result.to": 0.022264150943396226,
    "AdaLoraLayer.__init__": 0.022264150943396226,
    "BaseQuantizeConfig.from_pretrained": 0.02219057790435505,
    "x.to": 0.022133526850507984,
    "vecquant2matmul_faster_old": 0.022133526850507984,
    "vecquant2matmul_old": 0.022133526850507984,
    "vecquant3matmul": 0.022133526850507984,
    "inject_to_model": 0.02207191171235315,
    "torch.count_nonzero": 0.022012578616352203,
    "from_pretrained": 0.022012578616352203,
    "x.min": 0.022012578616352203,
    "x.max": 0.022012578616352203,
    "torch.full_like": 0.022012578616352203,
    "inp.unsqueeze": 0.021955403087478557,
    "nn.Unfold": 0.021955403087478557,
    "unfold": 0.021955403087478557,
    "inp.permute": 0.021955403087478557,
    "inp.flatten": 0.021955403087478557,
    "inp.float": 0.021955403087478557,
    "q.to": 0.02194840200231036,
    "s.to": 0.02194840200231036,
    "A.half": 0.02194840200231036,
    "fixed_pos_embedding": 0.021920088790233078,
    "GPTQLoraLinear": 0.02188679245283019,
    "torch.save": 0.02183457932834935,
    "make_sure_no_tensor_in_meta_device": 0.02183457932834935,
    "DataLoader": 0.021816037735849055,
    "preprocess_fn": 0.021816037735849055,
    "Exception": 0.02177068214804064,
    "vecquant2matmul": 0.02177068214804064,
    "weights.append": 0.02177068214804064,
    "safe_load": 0.021715913136347454,
    "torch.load": 0.021715913136347454,
    "tensor.permute": 0.021642619311875694,
    "cholesky": 0.021612349914236707,
    "create_commit": 0.021597246944345554,
    "prepare_model_for_marlin_load": 0.021597246944345554,
    "attention_masks.append": 0.021597246944345554,
    "safetensors_metadata.items": 0.021597246944345554,
    "mem_model": 0.021563342318059297,
    "xavier_uniform_": 0.02150943396226415,
    "zeros_": 0.02150943396226415,
    "GPTQSVDLinear": 0.02150943396226415,
    "x.type_as": 0.02150943396226415,
    "repeat": 0.02148846960167715,
    "example.items": 0.021478580752343657,
    "tensor.unsqueeze": 0.021478580752343657,
    "state_dict.items": 0.021478580752343657,
    "vecquant4matmul": 0.021407837445573293,
    "vecquant8matmul": 0.021407837445573293,
    "json.dump": 0.02135991456034176,
    "new_examples.append": 0.02135991456034176,
    "collate_data": 0.02135991456034176,
    "position_ids.append": 0.02135991456034176,
    "v.unsqueeze": 0.02135991456034176,
    "GPTQ": 0.02135991456034176,
    "configure": 0.02135991456034176,
    "handles.append": 0.02135991456034176,
    "h.remove": 0.02135991456034176,
    "fasterquant": 0.02135991456034176,
    "free": 0.02135991456034176,
    "output.add_": 0.021302495435179546,
    "inp.reshape": 0.021269296740994852,
    "quantizer.find_params": 0.021269296740994852,
    "groups.append": 0.021269296740994852,
    "fixed_bytes.items": 0.021263851452530697,
    "submodule.scratch_space_fixed": 0.021263851452530697,
    "ExLlamaV2DeviceTensors": 0.021263851452530697,
    "m.register_buffer": 0.021263851452530697,
    "submodule.post_init": 0.021263851452530697,
    "get_checkpoints": 0.02124124836833986,
    "args_from_json.items": 0.02124124836833986,
    "ds.select": 0.02122641509433962,
    "ds.map": 0.02122641509433962,
    "unpacked_qzeros.repeat_interleave": 0.021178282633808238,
    "stride": 0.02116889093419236,
    "c.stride": 0.02116889093419236,
    "dict": 0.021154945683247568,
    "detach": 0.021132075471698115,
    "self._compute_batch_logits": 0.021132075471698115,
    "logits.append": 0.021132075471698115,
    "named_modules": 0.021122582176337962,
    "self.enable_trainable_mode": 0.021122582176337962,
    "GeneralQuantLinear.inject_to_model": 0.021122582176337962,
    "type": 0.021122582176337962,
    "register_forward_hook": 0.021122582176337962,
    "pack": 0.021114106019766397,
    "unpacked_qweight.clone": 0.021114106019766397,
    "awq_scales.t": 0.021114106019766397,
    "unpacked_qzeros.numpy": 0.021114106019766397,
    "wf.unsqueeze": 0.021114106019766397,
    "m.Var": 0.021114106019766397,
    "m.Equation": 0.021114106019766397,
    "compute_reductions": 0.021114106019766397,
    "qinfer.forward4": 0.021114106019766397,
    "qinfer.forward_gs4": 0.021114106019766397,
    "startswith": 0.02104499274310595,
    "cpp_extension.CppExtension": 0.02104499274310595,
    "vecquant3matmul_faster_old": 0.02104499274310595,
    "vecquant3matmul_old": 0.02104499274310595,
    "ctx.save_for_backward": 0.02104499274310595,
    "model_init_kwargs.pop": 0.021003915984336062,
    "qinfer.pack4": 0.020964360587002098,
    "scale.to": 0.020964360587002098,
    "zero.to": 0.020964360587002098,
    "g_idx.to": 0.020964360587002098,
    "AlignDevicesHook": 0.020964360587002098,
    "add_hook_to_module": 0.020964360587002098,
    "new_layer.to": 0.020964360587002098,
    "submodule.parameters": 0.020964360587002098,
    "q.abs_": 0.020964360587002098,
    "q.pow_": 0.020964360587002098,
    "self._metric": 0.020964360587002098,
    "batch_data.items": 0.020964360587002098,
    "self._parse_labels": 0.020964360587002098,
    "self._predict": 0.020964360587002098,
    "torch.cholesky_inverse": 0.020926243567753,
    "ready": 0.020926243567753,
    "Err1.matmul": 0.020926243567753,
    "flatten": 0.020926243567753,
    "matmul": 0.020926243567753,
    "AutoModelForCausalLM.from_pretrained": 0.020885249792334165,
    "quant_linear_fn.apply": 0.020875150541951024,
    "res.update": 0.020814615154237798,
    "scale_zeros_mat.half": 0.020814615154237798,
    "unpacked_qzeros.t": 0.020814615154237798,
    "FileNotFoundError": 0.020814615154237798,
    "obj.parameters": 0.020814615154237798,
    "obj.to": 0.020814615154237798,
    "qinfer.pack3": 0.020814615154237798,
    "fixed_bytes.get": 0.020814615154237798,
    "model.state_dict": 0.02080309627479439,
    "A.view": 0.02079322294955718,
    "C.view": 0.02079322294955718,
    "perm1.append": 0.02079322294955718,
    "perm.reshape": 0.02079322294955718,
    "save_pretrained": 0.020766583600332265,
    "v.clone": 0.020766583600332265,
    "LoraLayer.__init__": 0.020754716981132078,
    "hijack_peft_mappings": 0.020754716981132078,
    "x.stride": 0.02070869765301427,
    "ext_q4_matmul": 0.02070869765301427,
    "out.add_": 0.02070869765301427,
    "short": 0.020693852708460133,
    "temp_dq.get_scratch_slice": 0.020693852708460133,
    "ext_make_q_matrix": 0.020693852708460133,
    "ext_gemm_half_q_half": 0.020693852708460133,
    "narrow": 0.020693852708460133,
    "self.temp_fwd_size": 0.020693852708460133,
    "self.prepare": 0.020693852708460133,
    "vecquant4matmul_faster_old": 0.020682148040638608,
    "vecquant4matmul_old": 0.020682148040638608,
    "unpacked_qzeros.contiguous": 0.020664869721473498,
    "unpacked_qzeros.cpu": 0.020664869721473498,
    "awq_scales.cpu": 0.020664869721473498,
    "awq_scales.clone": 0.020664869721473498,
    "logger.error": 0.020664869721473498,
    "np.ones": 0.020664869721473498,
    "split.astype": 0.020664869721473498,
    "Linear": 0.020583190394511147,
    "copy_": 0.020583190394511147,
    "marlin_linear.pack": 0.020583190394511147,
    "cuda_old_linear.to": 0.020583190394511147,
    "marlin_linear.to": 0.020583190394511147,
    "Q.t": 0.020583190394511147,
    "Q.reshape": 0.020583190394511147,
    "err1.unsqueeze": 0.020583190394511147,
    "meta.keys": 0.020583190394511147,
    "do_bench": 0.020583190394511147,
    "builtins.min": 0.020583190394511147,
    "query_states.view": 0.02054507337526205,
    "key_states.view": 0.02054507337526205,
    "value_states.view": 0.02054507337526205,
    "query.contiguous": 0.02053274139844617,
    "key.contiguous": 0.02053274139844617,
    "value.contiguous": 0.02053274139844617,
    "self._attn": 0.02053274139844617,
    "torch.sqrt": 0.02053274139844617,
    "qkv.size": 0.02053274139844617,
    "awq_reverse_reorder_int_tensor": 0.02051512428870919,
    "qinfer.pack2": 0.02051512428870919,
    "self.ready": 0.020440251572327043,
    "x.permute": 0.020440251572327043,
    "x.t": 0.020440251572327043,
    "prepare_inputs_for_generation": 0.02041058502432657,
    "create_repo": 0.02041058502432657,
    "os.makedirs": 0.02041058502432657,
    "e_x.sum": 0.020377358490566037,
    "self._model": 0.020377358490566037,
    "np.max": 0.020377358490566037,
    "model.enable_trainable_mode": 0.020377358490566037,
    "n.split": 0.020377358490566037,
    "results.add": 0.020377358490566037,
    "find_all_linear_names": 0.020377358490566037,
    "old_module.parameters": 0.020377358490566037,
    "old_module.buffers": 0.020377358490566037,
    "Path": 0.020319303338171262,
    "Parameter": 0.020319303338171262,
    "custom_fwd": 0.020319303338171262,
    "safe_open": 0.02029191883232467,
    "f.keys": 0.02029191883232467,
    "query.size": 0.020255271920088788,
    "key.size": 0.020255271920088788,
    "key.transpose": 0.020255271920088788,
    "tensor.size": 0.020255271920088788,
    "parameterized.expand": 0.02021563342318059,
    "predicted_text.startswith": 0.02021563342318059,
    "format": 0.02021563342318059,
    "lines.append": 0.02021563342318059,
    "module.named_children": 0.02021563342318059,
    "weight.view": 0.02021563342318059,
    "zeros.view": 0.02021563342318059,
    "awq_scales.cuda": 0.02021563342318059,
    "possible_index_file.replace": 0.02021563342318059,
    "qinfer.forward2": 0.02021563342318059,
    "qinfer.forward_gs2": 0.02021563342318059,
    "pack_model": 0.020173252640322773,
    "CudaOldQuantLinear": 0.02015437392795883,
    "cuda_old_linear.pack": 0.02015437392795883,
    "dequantize_weight": 0.02015437392795883,
    "dequantized_weight.to": 0.02015437392795883,
    "key_states.transpose": 0.02012578616352201,
    "torch.empty_like": 0.020085209981740716,
    "out.half": 0.02007226013649137,
    "unpack_4bit_to_32bit_signed": 0.020023103581055066,
    "scales.repeat_interleave": 0.020023103581055066,
    "scale_perm.extend": 0.020023103581055066,
    "scale_perm_single.extend": 0.020023103581055066,
    "CustomizedTritonAutoTuner": 0.020011435105774727,
    "used.add": 0.020011435105774727,
    "zero_": 0.020011435105774727,
    "self._bench": 0.020011435105774727,
    "self.perf_model": 0.020011435105774727,
    "est_timing.keys": 0.020011435105774727,
    "ignore.append": 0.02,
    "get_peft_model": 0.02,
    "PeftModel.from_pretrained": 0.02,
    "peft_config.to_dict": 0.02,
    "torch.einsum": 0.01997780244173141,
    "torch.tril": 0.01997780244173141,
    "g_idx_i.long": 0.01995645863570392,
    "f.get_tensor": 0.019935920256318976,
    "order_tensor.repeat": 0.019916142557651992,
    "order_tensor.reshape": 0.019916142557651992,
    "awq_qzeros.cuda": 0.019916142557651992,
    "awq_qweight.cuda": 0.019916142557651992,
    "torch.minimum": 0.019916142557651992,
    "inp.matmul": 0.019897084048027442,
    "W.float": 0.019897084048027442,
    "self.layer": 0.019897084048027442,
    "LayerHijacker": 0.019817254064317075,
    "silu": 0.019788311090658078,
    "c.to": 0.019788311090658078,
    "self.down_proj": 0.019788311090658078,
    "retie_parameters": 0.019766397124887692,
    "m.Const": 0.019766397124887692,
    "m.Maximize": 0.019766397124887692,
    "qinfer.compute_reduction_cpp": 0.019766397124887692,
    "qinfer.forward3": 0.019766397124887692,
    "qinfer.forward_gs3": 0.019766397124887692,
    "ref.t": 0.01972555746140652,
    "linear_module.to": 0.01972555746140652,
    "cuda_old_linear": 0.01972555746140652,
    "marlin_linear": 0.01972555746140652,
    "res_cuda_old.abs": 0.01972555746140652,
    "past_key_value.get_usable_length": 0.019706498951781972,
    "past_key_value.update": 0.019706498951781972,
    "query_states.contiguous": 0.019706498951781972,
    "key_states.contiguous": 0.019706498951781972,
    "value_states.contiguous": 0.019706498951781972,
    "m.view": 0.01970033296337403,
    "torch.get_default_dtype": 0.01970033296337403,
    "tensor.cpu": 0.01969858787231518,
    "self._process_batch": 0.019622641509433963,
    "common_setup_kwargs.update": 0.019593613933236578,
    "setup": 0.019593613933236578,
    "read_text": 0.019593613933236578,
    "subprocess.run": 0.019593613933236578,
    "vecquant8matmul_old": 0.019593613933236578,
    "tl.trans": 0.019593613933236578,
    "state_dict_key.rsplit": 0.019579921680313278,
    "gptq_layers.add": 0.019579921680313278,
    "unpack_awq": 0.019579921680313278,
    "pbar.set_description": 0.019579921680313278,
    "pack_from_tensors": 0.019579921680313278,
    "Quantizer": 0.01955403087478559,
    "ModuleNotFoundError": 0.01954177897574124,
    "gemm_half_q_half": 0.019476567255021303,
    "module.named_modules": 0.01946690625935909,
    "self._prepare_examples_for_quantization": 0.01946125548831138,
    "nn.Dropout": 0.019422863485016647,
    "torch.where": 0.019422863485016647,
    "attn_weights.to": 0.019422863485016647,
    "self.attn_dropout": 0.019422863485016647,
    "scale1.unsqueeze": 0.019392033542976937,
    "zero1.unsqueeze": 0.019392033542976937,
    "self.triton_llama_mlp": 0.019328117809479982,
    "c.reshape": 0.019328117809479982,
    "modules.triton_llama_mlp": 0.019328117809479982,
    "make_q4": 0.019328117809479982,
    "ext_make_q4": 0.019328117809479982,
    "w.clone": 0.019296740994854202,
    "self.rotary_emb": 0.019287211740041926,
    "attn_output.transpose": 0.019287211740041926,
    "attn_output.reshape": 0.019287211740041926,
    "self.o_proj": 0.019287211740041926,
    "ravel": 0.019252984212552945,
    "res.reshape": 0.019252984212552945,
    "q.astype": 0.019252984212552945,
    "lora_B": 0.019245283018867926,
    "non_gptq_params.add": 0.019223923104307584,
    "w.unsqueeze": 0.019210977701543737,
    "m.repeat": 0.019145394006659266,
    "qkv.view": 0.019145394006659266,
    "query.to": 0.019145394006659266,
    "key.to": 0.019145394006659266,
    "self._split_heads": 0.019145394006659266,
    "key.permute": 0.019145394006659266,
    "query.permute": 0.019145394006659266,
    "value.permute": 0.019145394006659266,
    "self._merge_heads": 0.019145394006659266,
    "self.out_proj": 0.019145394006659266,
    "self.resid_dropout": 0.019145394006659266,
    "duplicate_interleave": 0.019145394006659266,
    "rotate_every_two": 0.019145394006659266,
    "view": 0.019145394006659266,
    "m.buffers": 0.019145394006659266,
    "field": 0.019105256912305683,
    "ref.abs": 0.018867924528301886,
    "linear_gptq.eval": 0.018867924528301886,
    "linear_gptq.to": 0.018867924528301886,
    "logging.basicConfig": 0.018867924528301886,
    "model.save_quantized": 0.018867924528301886,
    "model_lora.gradient_checkpointing_enable": 0.018867924528301886,
    "Adam": 0.018867924528301886,
    "model_lora.train": 0.018867924528301886,
    "value.to": 0.018867924528301886,
    "model_lora.parameters": 0.018867924528301886,
    "optimizer.zero_grad": 0.018867924528301886,
    "losses.append": 0.018867924528301886,
    "loss.backward": 0.018867924528301886,
    "optimizer.step": 0.018867924528301886,
    "batch.items": 0.018867924528301886,
    "loss.item": 0.018867924528301886,
    "model_lora": 0.018867924528301886,
    "math.isfinite": 0.018867924528301886,
    "math.isnan": 0.018867924528301886,
    "torch.stack": 0.018867924528301886,
    "torch.sin": 0.018867924528301886,
    "torch.cos": 0.018867924528301886,
    "hidden_states.size": 0.018867924528301886,
    "torch.split": 0.018867924528301886,
    "logging.getLogger": 0.018867924528301886,
    "logging.StreamHandler": 0.018867924528301886,
    "logging.Formatter": 0.018867924528301886,
    "handler.setFormatter": 0.018867924528301886,
    "logger.addHandler": 0.018867924528301886,
    "logger.setLevel": 0.018867924528301886,
    "quant_func": 0.018867924528301886,
    "signature": 0.018867924528301886,
    "functools.reduce": 0.018867924528301886,
    "self._prepare_data": 0.018867924528301886,
    "all_perplexity.append": 0.018867924528301886,
    "progress.set_description": 0.018867924528301886,
    "self.softmax": 0.018867924528301886,
    "np.log": 0.018867924528301886,
    "self._tokenizer": 0.018867924528301886,
    "cleanup_buffers_cuda": 0.018867924528301886,
    "lora_A": 0.018867924528301886,
    "lora_dropout": 0.018867924528301886,
    "math.exp": 0.018867924528301886,
    "get_dataloader": 0.018867924528301886,
    "v.to": 0.018867924528301886,
    "rouge.Rouge": 0.018867924528301886,
    "metric.get_scores": 0.018867924528301886,
    "predictions.append": 0.018867924528301886,
    "self.tokenizer": 0.018867924528301886,
    "get_predictions": 0.018867924528301886,
    "sub_predictions.append": 0.018867924528301886,
    "most_common": 0.018867924528301886,
    "each.lower": 0.018867924528301886,
    "gen_text.lower": 0.018867924528301886,
    "Counter": 0.018867924528301886,
    "res.cpu": 0.018867924528301886,
    "_perm.numel": 0.018867924528301886,
    "_torch_device": 0.018867924528301886,
    "GEKKO": 0.018867924528301886,
    "quant_matmul_inference_only_248": 0.018867924528301886,
    "q4_matmul": 0.018867924528301886,
    "tl.sigmoid": 0.018867924528301886,
    "np.empty": 0.018867924528301886,
    "levenshtein_distance": 0.018867924528301886,
    "size": 0.018867924528301886,
    "tokenizer.batch_decode": 0.018867924528301886,
    "sub_output_ids.cpu": 0.018867924528301886,
    "one_sub_generated_ids.index": 0.018867924528301886
}