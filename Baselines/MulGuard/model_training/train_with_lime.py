import os
import json
import matplotlib.pyplot as plt
from data_loader import load_data
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import numpy as np
from lime import lime_tabular
import joblib
import re
import xgboost as xgb



def get_malicious_purposes(api_id, sensitive_apis):
    
    for api in sensitive_apis:
        if api["api_id"] == api_id:
            return api["malicious_purposes"]
    return ["unknown"]


def get_malicious_api_name(api_id, sensitive_apis):
    
    for api in sensitive_apis:
        if api["api_id"] == api_id:
            return api["api_name"]
    return ["unknown"]


def load_sensitive_apis(file_path):
    with open(file_path, 'r') as f:
        return json.load(f)["apis"]



def train_with_progress_bar(model, X_train, y_train, X_test, y_test, model_name, model_save_path, sensitive_apis,
                            n_iter=100):
    
    model_dir = os.path.join(model_save_path, model_name.replace(" ", "_").lower())
    os.makedirs(model_dir, exist_ok=True)


    with tqdm(total=n_iter, desc=f"Training {model_name}", unit="iter") as pbar:
        for i in range(n_iter):
            if hasattr(model, 'partial_fit'):
                model.partial_fit(X_train, y_train, classes=np.unique(y_train))
            else:
                
                model.fit(X_train, y_train)
            pbar.update(1)


    y_pred = model.predict(X_test)
    tqdm.write(f"\n{model_name} Results")


    report = classification_report(y_test, y_pred, digits=5)
    tqdm.write(report)

    with open(os.path.join(model_dir, f"{model_name.replace(' ', '_').lower()}_report.txt"), "w") as f:
        f.write(report)



    model_filename = os.path.join(model_dir, f"{model_name.replace(' ', '_').lower()}_model.pkl")
    joblib.dump(model, model_filename)
    tqdm.write(f"{model_name} saved to {model_filename}")


    # comment out the explainable analysis part, only retain the training and evaluation results
    # if you need the explainable analysis, you can uncomment the following code
    # malicious_indices = np.where(y_pred == 1)[0]  
    # for i in malicious_indices:  
    #     test_sample = X_test[i]
    #     explanation = explainer.explain_instance(test_sample, model.predict_proba, num_features=5)
    #     tqdm.write(f"\nSample {i + 1} (Predicted as Malicious) Explanation:")
    #     for feature, weight in explanation.as_list():
    #         if weight != 0:  
    #             print(feature)
    #             match = re.search(r"feature_(\d+)", feature)
    #             print(match)
    #             feature_idx = int(match.group(1))
    #             print(feature_idx)
    #             api_id = feature_idx + 1  
    #             malicious_purposes = get_malicious_purposes(api_id, sensitive_apis)
    #             API_NAME = get_malicious_api_name(api_id,sensitive_apis)
    #             tqdm.write(f"{feature}: {weight}, API NAME :{API_NAME}, API ID: {api_id}, Malicious Purposes: {malicious_purposes}")


def main():
    # using absolute path
    base_path = "/home2/wenbo/Documents/PyPIAgent/Tools/MulGuard"
    mal_data_path = os.path.join(base_path, 'fea_ex/dataset/mal_katz_feature_vectors.txt')
    ben_data_path = os.path.join(base_path, 'fea_ex/dataset/ben_katz_feature_vectors.txt')
    sensitive_api_file = os.path.join(base_path, "API-call-graph/katz_sensitive_api.json")
    model_save_path = os.path.join(base_path, "model_training/models")

    # ensure the model save directory exists
    os.makedirs(model_save_path, exist_ok=True)

    X_train, X_test, y_train, y_test = load_data(
        mal_data_path,
        ben_data_path)

    # fix the sensitive API loading
    sensitive_apis = load_sensitive_apis(sensitive_api_file)  

    # comment out the LIME explainer, because the explainer has been disabled
    # global explainer
    # explainer = lime_tabular.LimeTabularExplainer(
    #     X_train,
    #     training_labels=y_train,
    #     feature_names=[f"feature_{i}" for i in range(X_train.shape[1])],
    #     class_names=["benign", "malicious"],  
    #     verbose=False,
    #     mode="classification"
    # )

    # NB
    nb_model = GaussianNB()
    train_with_progress_bar(nb_model, X_train, y_train, X_test, y_test, "Naive Bayes (NB)", model_save_path,
                            sensitive_apis, n_iter=100)

    # MLP
    mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1, warm_start=True, random_state=42)
    train_with_progress_bar(mlp_model, X_train, y_train, X_test, y_test, "Multi-Layer Perceptron (MLP)",
                            model_save_path, sensitive_apis, n_iter=500)

    # RF
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    train_with_progress_bar(rf_model, X_train, y_train, X_test, y_test, "Random Forest (RF)", model_save_path,
                            sensitive_apis, n_iter=100)

    # DT
    dt_model = DecisionTreeClassifier(random_state=42)
    train_with_progress_bar(dt_model, X_train, y_train, X_test, y_test, "Decision Tree (DT)", model_save_path,
                            sensitive_apis, n_iter=100)

    # SVM
    sgd_model = SGDClassifier(loss="log_loss", random_state=42)
    train_with_progress_bar(sgd_model, X_train, y_train, X_test, y_test, "SGD Classifier (SVM)", model_save_path,
                            sensitive_apis, n_iter=100)

    xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42,
                                  use_label_encoder=False, eval_metric='logloss')
    train_with_progress_bar(xgb_model, X_train, y_train, X_test, y_test, "XGBoost (XGB)", model_save_path,
                            sensitive_apis, n_iter=100)



if __name__ == "__main__":
    main()
