#!/usr/bin/env python3
"""
Batch prediction script for MulGuard models.

This script loads all trained models and performs batch predictions on packages in TestData.
It supports multiprocessing for efficient processing of large datasets.

Usage:
    python batch_predict.py                                    # Predict all TestData
    python batch_predict.py evaluation benign                  # Predict specific directory
    python batch_predict.py latest malware                     # Predict specific directory
"""

import os
import sys
import json
import time
import csv
from pathlib import Path
from multiprocessing import Pool, cpu_count
from typing import Dict, List, Tuple, Optional
import numpy as np
import joblib
from tqdm import tqdm
import pandas as pd


class ModelPredictor:
    """Class to handle model loading and predictions"""
    
    def __init__(self, models_dir: str):
        self.models_dir = Path(models_dir)
        self.models = {}
        self.feature_names = None
        self._load_all_models()
    
    def _load_all_models(self):
        """Load all available trained models using folder names as model identifiers"""
        # Scan the models directory for model folders
        for model_folder in self.models_dir.iterdir():
            if model_folder.is_dir():
                model_pkl_path = model_folder / f"{model_folder.name}_model.pkl"
                if model_pkl_path.exists():
                    try:
                        self.models[model_folder.name] = joblib.load(model_pkl_path)
                        print(f"Loaded model: {model_folder.name}")
                    except Exception as e:
                        print(f"Failed to load {model_folder.name}: {e}")
                else:
                    print(f"Model file not found: {model_pkl_path}")
        
        if not self.models:
            raise ValueError("No models could be loaded!")
        
        print(f"Successfully loaded {len(self.models)} models: {list(self.models.keys())}")
    
    def load_feature_vector(self, package_dir: Path) -> Optional[np.ndarray]:
        """Load feature vector from package directory"""
        # Try different feature vector files (katz first since models were trained with katz)
        feature_files = [
            "katz_feature_vector.json",
            "harmonic_feature_vector.json",
            "degree_feature_vector.json", 
            "closeness_feature_vector.json"
        ]
        
        for feature_file in feature_files:
            feature_path = package_dir / feature_file
            if feature_path.exists():
                try:
                    with open(feature_path, 'r') as f:
                        feature_vector = json.load(f)
                    
                    # Store feature names for first successful load
                    if self.feature_names is None:
                        self.feature_names = list(feature_vector.keys())
                    
                    # Convert to numpy array
                    features = np.array([list(feature_vector.values())])
                    return features
                except Exception as e:
                    print(f"Error loading {feature_path}: {e}")
                    continue
        
        return None
    
    def predict_package(self, package_dir: Path) -> Dict[str, int]:
        """Predict maliciousness for a single package"""
        features = self.load_feature_vector(package_dir)
        if features is None:
            return {}
        
        # Check if features are all zeros (no API calls)
        if np.sum(features) == 0:
            return {model_name: 0 for model_name in self.models.keys()}
        
        predictions = {}
        for model_name, model in self.models.items():
            try:
                prediction = model.predict(features)[0]
                predictions[model_name] = int(prediction)
            except Exception as e:
                print(f"Error predicting with {model_name}: {e}")
                predictions[model_name] = -1  # Error indicator
        
        return predictions


def predict_single_package(args: Tuple[Path, Path, str]) -> Tuple[str, Dict[str, int]]:
    """Process a single package (for multiprocessing)"""
    package_dir, models_dir, package_name = args
    
    try:
        predictor = ModelPredictor(str(models_dir))
        predictions = predictor.predict_package(package_dir)
        return package_name, predictions
    except Exception as e:
        return package_name, {"error": str(e)}


def predict_directory(source_dir: Path, models_dir: Path, num_processes: int = 20) -> Dict[str, Dict[str, int]]:
    """Predict all packages in a directory using multiprocessing"""
    if not source_dir.exists():
        print(f"Source directory does not exist: {source_dir}")
        return {}
    
    # Get all package directories
    package_dirs = [d for d in source_dir.iterdir() if d.is_dir()]
    
    if not package_dirs:
        print(f"No package directories found in {source_dir}")
        return {}
    
    print(f"Found {len(package_dirs)} packages to predict")
    print(f"Using {num_processes} processes")
    
    # Prepare arguments for multiprocessing
    args_list = [(pkg_dir, models_dir, pkg_dir.name) for pkg_dir in package_dirs]
    
    results = {}
    
    with Pool(processes=num_processes) as pool:
        # Use imap for progress tracking
        with tqdm(total=len(args_list), desc="Predicting packages", unit="pkg") as pbar:
            for package_name, predictions in pool.imap(predict_single_package, args_list):
                results[package_name] = predictions
                pbar.update(1)
                
                # Show prediction results for malicious packages
                if predictions and not predictions.get("error"):
                    malicious_models = [model for model, pred in predictions.items() if pred == 1]
                    if malicious_models:
                        tqdm.write(f"üö® {package_name}: MALICIOUS by {', '.join(malicious_models)}")
    
    return results


def save_predictions_to_csv(results: Dict[str, Dict[str, int]], output_file: Path, 
                           dataset: str, package_type: str):
    """Save prediction results to CSV file with specified format"""
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    # Prepare data for CSV
    csv_data = []
    
    # Get all model names from the first result (assuming all packages have same models)
    model_names = []
    for predictions in results.values():
        if not predictions.get("error"):
            model_names = [name for name in predictions.keys() if name != "error"]
            break
    
    # Sort model names for consistent column order
    model_names = sorted(model_names)
    
    for package_name, predictions in results.items():
        if predictions.get("error"):
            # Handle error cases - set all predictions to -1
            row = {
                "dataset": dataset,
                "package_type": package_type,
                "package_name": package_name
            }
            for model_name in model_names:
                row[model_name] = -1  # Error indicator
            csv_data.append(row)
        else:
            row = {
                "dataset": dataset,
                "package_type": package_type, 
                "package_name": package_name
            }
            for model_name in model_names:
                row[model_name] = predictions.get(model_name, -1)
            csv_data.append(row)
    
    # Create DataFrame and save to CSV
    if csv_data:
        df = pd.DataFrame(csv_data)
        
        # Ensure column order: dataset, package_type, package_name, then model columns
        column_order = ["dataset", "package_type", "package_name"] + model_names
        df = df[column_order]
        
        df.to_csv(output_file, index=False)
        
        print(f"\nPrediction results saved to: {output_file}")
        print(f"Total packages processed: {len(csv_data)}")
        
        # Print summary statistics
        print(f"\n=== Prediction Summary for {dataset}/{package_type} ===")
        for model_name in model_names:
            benign_count = (df[model_name] == 0).sum()
            malicious_count = (df[model_name] == 1).sum()
            error_count = (df[model_name] == -1).sum()
            total_valid = benign_count + malicious_count
            
            if total_valid > 0:
                malicious_rate = malicious_count / total_valid * 100
                print(f"{model_name}:")
                print(f"  Benign: {benign_count}, Malicious: {malicious_count}")
                print(f"  Malicious rate: {malicious_rate:.2f}%")
                if error_count > 0:
                    print(f"  Errors: {error_count}")
    else:
        print("No data to save!")


def predict_all_testdata(num_processes: int = 20):
    """Predict all packages in TestData directory"""
    base_testdata = Path("/home2/wenbo/Documents/PyPIAgent/Tools/MulGuard/TestData")
    models_dir = Path("/home2/wenbo/Documents/PyPIAgent/Tools/MulGuard/model_training/models")
    
    # Define all possible combinations
    datasets = ["evaluation", "latest", "obfuscation"]
    package_types = ["benign", "malware"]
    
    for dataset in datasets:
        for package_type in package_types:
            source_dir = base_testdata / dataset / package_type
            if source_dir.exists():
                print(f"\n{'='*60}")
                print(f"Processing: {dataset}/{package_type}")
                print(f"{'='*60}")
                
                results = predict_directory(source_dir, models_dir, num_processes)
                
                # Save results to CSV
                output_file = base_testdata / dataset / f"predictions_{package_type}.csv"
                save_predictions_to_csv(results, output_file, dataset, package_type)
            else:
                print(f"Directory not found: {source_dir}")


def predict_specific_directory(dataset_type: str, package_type: str, num_processes: int = 20):
    """Predict packages in a specific directory"""
    base_testdata = Path("/home2/wenbo/Documents/PyPIAgent/Tools/MulGuard/TestData")
    models_dir = Path("/home2/wenbo/Documents/PyPIAgent/Tools/MulGuard/model_training/models")
    
    source_dir = base_testdata / dataset_type / package_type
    
    if not source_dir.exists():
        print(f"Directory does not exist: {source_dir}")
        return
    
    print(f"Processing: {dataset_type}/{package_type}")
    print(f"Using {num_processes} processes")
    
    results = predict_directory(source_dir, models_dir, num_processes)
    
    # Save results to CSV
    output_file = base_testdata / dataset_type / f"predictions_{package_type}.csv"
    save_predictions_to_csv(results, output_file, dataset_type, package_type)


def predict_single_package_demo(package_path: str):
    """Demo function to predict a single package"""
    models_dir = Path("/home2/wenbo/Documents/PyPIAgent/Tools/MulGuard/model_training/models")
    package_dir = Path(package_path)
    
    if not package_dir.exists():
        print(f"Package directory does not exist: {package_dir}")
        return
    
    print(f"Predicting single package: {package_dir.name}")
    
    predictor = ModelPredictor(str(models_dir))
    predictions = predictor.predict_package(package_dir)
    
    print(f"\nPrediction results for {package_dir.name}:")
    print("-" * 50)
    
    for model_name, prediction in predictions.items():
        if model_name == "error":
            print(f"Error: {prediction}")
            continue
            
        status = "üö® MALICIOUS" if prediction == 1 else "‚úÖ BENIGN"
        if prediction == -1:
            status = "‚ùå ERROR"
        print(f"{model_name:30} : {status}")
    
    # Check if any model predicted malicious
    malicious_models = [model for model, pred in predictions.items() if pred == 1]
    if malicious_models:
        print(f"\nüö® Package flagged as MALICIOUS by: {', '.join(malicious_models)}")
    else:
        print(f"\n‚úÖ Package appears BENIGN according to all models")


if __name__ == "__main__":
    if len(sys.argv) == 1:
        # Predict all TestData with 20 processes
        print("Starting batch prediction for all TestData...")
        start_time = time.time()
        predict_all_testdata()
        end_time = time.time()
        print(f"\nTotal processing time: {end_time - start_time:.2f} seconds")
        
    elif len(sys.argv) == 2:
        # Single package demo
        package_path = sys.argv[1]
        predict_single_package_demo(package_path)
        
    elif len(sys.argv) == 3:
        # Predict specific directory with 20 processes
        dataset_type = sys.argv[1]  # evaluation, latest, or obfuscation
        package_type = sys.argv[2]  # benign or malware
        
        valid_datasets = ['evaluation', 'latest', 'obfuscation']
        valid_types = ['benign', 'malware']
        
        if dataset_type not in valid_datasets:
            print(f"Invalid dataset type: {dataset_type}. Must be one of: {', '.join(valid_datasets)}")
            sys.exit(1)
        
        if package_type not in valid_types:
            print(f"Invalid package type: {package_type}. Must be one of: {', '.join(valid_types)}")
            sys.exit(1)
        
        start_time = time.time()
        predict_specific_directory(dataset_type, package_type)
        end_time = time.time()
        print(f"\nProcessing time: {end_time - start_time:.2f} seconds")
        
    else:
        print("Usage:")
        print("  python batch_predict.py                                    # Predict all TestData (20 processes)")
        print("  python batch_predict.py <package_path>                     # Predict single package (demo)")
        print("  python batch_predict.py <dataset> <type>                   # Predict specific directory (20 processes)")
        print("")
        print("Examples:")
        print("  python batch_predict.py                                    # Predict all")
        print("  python batch_predict.py /path/to/package                   # Single package demo")
        print("  python batch_predict.py evaluation benign                  # Predict evaluation/benign")
        print("  python batch_predict.py latest malware                     # Predict latest/malware")
        print("")
        print("Note: Uses 20 processes by default for optimal performance")
        sys.exit(1)
