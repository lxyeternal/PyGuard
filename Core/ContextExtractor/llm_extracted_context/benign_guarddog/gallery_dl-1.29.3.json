[
  {
    "metadata": {
      "package_name": "gallery_dl-1.29.3",
      "report_path": "/home2/blue/Documents/PyPIAgent/Codes/tool_detect/detect_output/study/guarddog/benign/gallery_dl-1.29.3.txt",
      "total_matches": 25
    }
  },
  {
    "pyfile": "everia.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/gallery_dl-1.29.3/gallery_dl-1.29.3/gallery_dl/extractor/everia.py",
    "line_number": "50",
    "type_description": "shady-links",
    "original_snippet": "example = \"https://everia.club/0000/00/00/TITLE\"",
    "context_snippet": "class EveriaPostExtractor(EveriaExtractor):\n    subcategory = \"post\"\n    directory_fmt = (\"{category}\", \"{title}\")\n    archive_fmt = \"{post_url}_{num}\"\n    pattern = BASE_PATTERN + r\"(/\\d{4}/\\d{2}/\\d{2}/[^/?#]+)\"\n    example = \"https://everia.club/0000/00/00/TITLE\"\n\n    def items(self):\n        url = self.root + self.groups[0]\n        page = self.request(url).text\n        content = text.extr(page, 'itemprop=\"text\">', \"</div>\")\n        urls = re.findall(r'img.*?src=\"([^\"]+)', content)\n\n        data = {\n            \"title\": text.unescape(\n                text.extr(page, 'itemprop=\"headline\">', \"</h1>\")),\n            \"tags\": list(text.extract_iter(page, 'rel=\"tag\">', \"</a>\")),\n            \"post_url\": url,\n            \"post_category\": text.extr(\n                page, \"post-in-category-\", \" \").capitalize(),\n            \"count\": len(urls),\n        }\n\n        yield Message.Directory, data\n        for data[\"num\"], url in enumerate(urls, 1):\n            yield Message.Url, url, text.nameext_from_url(url, data)",
    "hash_value": "1c9485dbf73b3ec540e38faaba6e5431",
    "detection_index": 1
  },
  {
    "pyfile": "lexica.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/gallery_dl-1.29.3/gallery_dl-1.29.3/gallery_dl/extractor/lexica.py",
    "line_number": "31",
    "type_description": "shady-links",
    "original_snippet": "base = (\"https://lexica-serve-encoded-images2.sharif.workers.dev\"",
    "context_snippet": "    def items(self):\n        base = (\"https://lexica-serve-encoded-images2.sharif.workers.dev\"\n                \"/full_jpg/\")\n        tags = self.text\n\n        for image in self.posts():\n            image[\"filename\"] = image[\"id\"]\n            image[\"extension\"] = \"jpg\"\n            image[\"search_tags\"] = tags\n            yield Message.Directory, image\n            yield Message.Url, base + image[\"id\"], image",
    "hash_value": "e28863815c085ee52c0e9ad5609c2189",
    "detection_index": 1
  },
  {
    "pyfile": "recursive.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/gallery_dl-1.29.3/gallery_dl-1.29.3/gallery_dl/extractor/recursive.py",
    "line_number": "20",
    "type_description": "shady-links",
    "original_snippet": "example = \"recursive:https://pastebin.com/raw/FLwrCYsT\"",
    "context_snippet": "class RecursiveExtractor(Extractor):\n    \"\"\"Extractor that fetches URLs from a remote or local source\"\"\"\n    category = \"recursive\"\n    pattern = r\"r(?:ecursive)?:\"\n    example = \"recursive:https://pastebin.com/raw/FLwrCYsT\"\n\n    def items(self):\n        url = self.url.partition(\":\")[2]\n\n        if url.startswith(\"file://\"):\n            with open(url[7:]) as fp:\n                page = fp.read()\n        else:\n            page = self.request(text.ensure_http_scheme(url)).text\n\n        for match in re.finditer(r\"https?://[^\\s\\\"']+\", page):\n            yield Message.Queue, match.group(0), {}",
    "hash_value": "36c64e28c79db236f93d60ea0def2937",
    "detection_index": 1
  },
  {
    "pyfile": "rule34xyz.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/gallery_dl-1.29.3/gallery_dl-1.29.3/gallery_dl/extractor/rule34xyz.py",
    "line_number": "111",
    "type_description": "shady-links",
    "original_snippet": "example = \"https://rule34.xyz/post/12345\"",
    "context_snippet": "class Rule34xyzPostExtractor(Rule34xyzExtractor):\n    subcategory = \"post\"\n    archive_fmt = \"{id}\"\n    pattern = BASE_PATTERN + r\"/post/(\\d+)\"\n    example = \"https://rule34.xyz/post/12345\"\n\n    def posts(self):\n        return (self._fetch_post(self.groups[0]),);",
    "hash_value": "5bce633fd09f7b148655da96f4b54dfe",
    "detection_index": 1
  },
  {
    "pyfile": "urlshortener.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/gallery_dl-1.29.3/gallery_dl-1.29.3/gallery_dl/extractor/urlshortener.py",
    "line_number": "20",
    "type_description": "shady-links",
    "original_snippet": "\"root\": \"https://bit.ly\",",
    "context_snippet": "BASE_PATTERN = UrlshortenerExtractor.update({\n    \"bitly\": {\n        \"root\": \"https://bit.ly\",\n        \"pattern\": r\"bit\\.ly\",\n    },\n    \"tco\": {\n        # t.co sends 'http-equiv=\"refresh\"' (200) when using browser UA\n        \"headers\": {\"User-Agent\": None},\n        \"root\": \"https://t.co\",\n        \"pattern\": r\"t\\.co\",\n    },\n})",
    "hash_value": "590d9162c31057b4f1251161eec06689",
    "detection_index": 1
  },
  {
    "pyfile": "vichan.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/gallery_dl-1.29.3/gallery_dl-1.29.3/gallery_dl/extractor/vichan.py",
    "line_number": "39",
    "type_description": "shady-links",
    "original_snippet": "example = \"https://8kun.top/a/res/12345.html\"",
    "context_snippet": "class VichanThreadExtractor(VichanExtractor):\n    \"\"\"Extractor for vichan threads\"\"\"\n    subcategory = \"thread\"\n    directory_fmt = (\"{category}\", \"{board}\", \"{thread} {title}\")\n    filename_fmt = \"{time}{num:?-//} {filename}.{extension}\"\n    archive_fmt = \"{board}_{thread}_{tim}\"\n    pattern = BASE_PATTERN + r\"/([^/?#]+)/res/(\\d+)\"\n    example = \"https://8kun.top/a/res/12345.html\"\n\n    def __init__(self, match):\n        VichanExtractor.__init__(self, match)\n        index = match.lastindex\n        self.board = match.group(index-1)\n        self.thread = match.group(index)\n\n    def items(self):\n        url = \"{}/{}/res/{}.json\".format(self.root, self.board, self.thread)\n        posts = self.request(url).json()[\"posts\"]\n        title = posts[0].get(\"sub\") or text.remove_html(posts[0][\"com\"])\n        process = (self._process_8kun if self.category == \"8kun\" else\n                   self._process)\n        data = {\n            \"board\" : self.board,\n            \"thread\": self.thread,\n            \"title\" : text.unescape(title)[:50],\n            \"num\"   : 0,\n        }\n\n        yield Message.Directory, data\n        for post in posts:\n            if \"filename\" in post:\n                yield process(post, data)\n                if \"extra_files\" in post:\n                    for post[\"num\"], filedata in enumerate(\n                            post[\"extra_files\"], 1):\n                        yield process(post, filedata)\n\n    def _process(self, post, data):\n        post.update(data)\n        post[\"extension\"] = post[\"ext\"][1:]\n        post[\"url\"] = \"{}/{}/src/{}{}\".format(\n            self.root, post[\"board\"], post[\"tim\"], post[\"ext\"])\n        return Message.Url, post[\"url\"], post\n\n    @staticmethod\n    def _process_8kun(post, data):\n        post.update(data)\n        post[\"extension\"] = post[\"ext\"][1:]\n\n        tim = post[\"tim\"]\n        if len(tim) > 16:\n            post[\"url\"] = \"https://media.128ducks.com/file_store/{}{}\".format(\n                tim, post[\"ext\"])\n        else:\n            post[\"url\"] = \"https://media.128ducks.com/{}/src/{}{}\".format(\n                post[\"board\"], tim, post[\"ext\"])\n\n        return Message.Url, post[\"url\"], post",
    "hash_value": "0a21ae6098da3798d0762906920bfd91",
    "detection_index": 1
  }
]