[
  {
    "metadata": {
      "package_name": "sagemaker_pyspark-1.4.5",
      "report_path": "/home2/blue/Documents/PyPIAgent/Codes/tool_detect/detect_output/study/guarddog/benign/sagemaker_pyspark-1.4.5.txt",
      "total_matches": 1
    }
  },
  {
    "pyfile": "setup.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/sagemaker_pyspark-1.4.5/sagemaker_pyspark-1.4.5/setup.py",
    "line_number": "39",
    "type_description": "code-execution",
    "original_snippet": "p = subprocess.Popen(\n\"sbt printClasspath\".split(),\nstdout=subprocess.PIPE,\nstderr=subprocess.PIPE,\ncwd=\"../sagemaker-spark-sdk/\",\n)",
    "context_snippet": "try:  # noqa\n    if in_sagemaker_sdk:\n        try:\n            shutil.copyfile(os.path.join(\"..\", VERSION_PATH), VERSION_PATH)\n        except OSError:\n            print(\"Could not copy VERSION file\")\n            exit(1)\n\n        try:\n            os.mkdir(TEMP_PATH)\n        except OSError:\n            print(\"Could not create dir {0}\".format(TEMP_PATH), file=sys.stderr)\n            exit(1)\n\n        p = subprocess.Popen(\n            \"sbt printClasspath\".split(),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            cwd=\"../sagemaker-spark-sdk/\",\n        )\n\n        output, errors = p.communicate()\n\n        classpath = []\n        # Java Libraries to include.\n        java_libraries = [\"aws\", \"sagemaker\", \"hadoop\", \"htrace\"]\n        for line in output.decode(\"utf-8\").splitlines():\n            path = str(line.strip())\n            if path.endswith(\".jar\") and os.path.exists(path):\n                jar = os.path.basename(path).lower()\n                if any(lib in jar for lib in java_libraries):\n                    classpath.append(path)\n\n        os.mkdir(JARS_TARGET)\n        for jar in classpath:\n            target_path = os.path.join(JARS_TARGET, os.path.basename(jar))\n            if not os.path.exists(target_path):\n                shutil.copy(jar, target_path)\n\n        if len(classpath) == 0:\n            print(\"Failed to retrieve the jar classpath. Can't package\")\n            exit(-1)\n\n    else:\n        if not os.path.exists(JARS_TARGET):\n            print(\n                \"You need to be in the sagemaker-pyspark-sdk root folder to package\",\n                file=sys.stderr,\n            )\n            exit(-1)\n\n    setup(\n        name=\"sagemaker_pyspark\",\n        version=read_version(),\n        description=\"Amazon SageMaker PySpark Bindings\",\n        author=\"Amazon Web Services\",\n        url=\"https://github.com/aws/sagemaker-spark\",\n        license=\"Apache License 2.0\",\n        python_requires=\">= 3.7\",\n        zip_safe=False,\n        packages=[\n            \"sagemaker_pyspark\",\n            \"sagemaker_pyspark.algorithms\",\n            \"sagemaker_pyspark.transformation\",\n            \"sagemaker_pyspark.transformation.deserializers\",\n            \"sagemaker_pyspark.transformation.serializers\",\n            \"sagemaker_pyspark.jars\",\n            \"sagemaker_pyspark.licenses\",\n        ],\n        package_dir={\n            \"sagemaker_pyspark\": \"src/sagemaker_pyspark\",\n            \"sagemaker_pyspark.jars\": \"deps/jars\",\n            \"sagemaker_pyspark.licenses\": \"licenses\",\n        },\n        include_package_data=True,\n        package_data={\n            \"sagemaker_pyspark.jars\": [\"*.jar\"],\n            \"sagemaker_pyspark.licenses\": [\"*.txt\"],\n        },\n        scripts=[\"bin/sagemakerpyspark-jars\", \"bin/sagemakerpyspark-emr-jars\"],\n        install_requires=[\n            \"pyspark==3.3.0\",\n            \"numpy\",\n        ],\n    )\n\nfinally:\n    if in_sagemaker_sdk:\n        if os.path.exists(JARS_TARGET):\n            shutil.rmtree(JARS_TARGET)\n\n        if os.path.exists(TEMP_PATH):\n            os.rmdir(TEMP_PATH)\n\n        if os.path.exists(VERSION_PATH):\n            os.remove(VERSION_PATH)\n",
    "hash_value": "c6357473374e034d47a40c938589d8cb",
    "detection_index": 1
  }
]