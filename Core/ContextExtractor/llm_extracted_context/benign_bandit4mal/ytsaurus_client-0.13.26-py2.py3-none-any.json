[
  {
    "metadata": {
      "package_name": "ytsaurus_client-0.13.26-py2.py3-none-any",
      "total_matches": 3,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "_dill.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/ytsaurus_client-0.13.26-py2.py3-none-any/yt/packages/dill/_dill.py",
    "line_number": "1867",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1866\t        if PY3:\n1867\t            pickler.write(bytes('c__builtin__\\nNoneType\\n', 'UTF-8'))\n1868\t        else:",
    "context_snippet": "@register(TypeType)\ndef save_type(pickler, obj, postproc_list=None):\n    if obj in _typemap:\n        log.info(\"T1: %s\" % obj)\n        pickler.save_reduce(_load_type, (_typemap[obj],), obj=obj)\n        log.info(\"# T1\")\n    elif obj.__bases__ == (tuple,) and all([hasattr(obj, attr) for attr in ('_fields','_asdict','_make','_replace')]):\n        # special case: namedtuples\n        log.info(\"T6: %s\" % obj)\n        if OLD37 or (not obj._field_defaults):\n            pickler.save_reduce(_create_namedtuple, (obj.__name__, obj._fields, obj.__module__), obj=obj)\n        else:\n            defaults = [obj._field_defaults[field] for field in obj._fields if field in obj._field_defaults]\n            pickler.save_reduce(_create_namedtuple, (obj.__name__, obj._fields, obj.__module__, defaults), obj=obj)\n        log.info(\"# T6\")\n        return\n\n    # special cases: NoneType, NotImplementedType, EllipsisType\n    elif obj is type(None):\n        log.info(\"T7: %s\" % obj)\n        #XXX: pickler.save_reduce(type, (None,), obj=obj)\n        if PY3:\n            pickler.write(bytes('c__builtin__\\nNoneType\\n', 'UTF-8'))\n        else:\n            pickler.write('c__builtin__\\nNoneType\\n')\n        log.info(\"# T7\")\n    elif obj is NotImplementedType:\n        log.info(\"T7: %s\" % obj)\n        pickler.save_reduce(type, (NotImplemented,), obj=obj)\n        log.info(\"# T7\")\n    elif obj is EllipsisType:\n        log.info(\"T7: %s\" % obj)\n        pickler.save_reduce(type, (Ellipsis,), obj=obj)\n        log.info(\"# T7\")\n\n    else:\n        obj_name = getattr(obj, '__qualname__', getattr(obj, '__name__', None))\n        _byref = getattr(pickler, '_byref', None)\n        obj_recursive = id(obj) in getattr(pickler, '_postproc', ())\n        incorrectly_named = not _locate_function(obj, pickler)\n        if not _byref and not obj_recursive and incorrectly_named: # not a function, but the name was held over\n            if issubclass(type(obj), type):\n                # thanks to Tom Stepleton pointing out pickler._session unneeded\n                _t = 'T2'\n                log.info(\"%s: %s\" % (_t, obj))\n                _dict = _dict_from_dictproxy(obj.__dict__)\n            else:\n                _t = 'T3'\n                log.info(\"%s: %s\" % (_t, obj))\n                _dict = obj.__dict__\n           #print (_dict)\n           #print (\"%s\\n%s\" % (type(obj), obj.__name__))\n           #print (\"%s\\n%s\" % (obj.__bases__, obj.__dict__))\n            for name in _dict.get(\"__slots__\", []):\n                del _dict[name]\n            if PY3 and obj_name != obj.__name__:\n                if postproc_list is None:\n                    postproc_list = []\n                postproc_list.append((setattr, (obj, '__qualname__', obj_name)))\n            _save_with_postproc(pickler, (_create_type, (\n                type(obj), obj.__name__, obj.__bases__, _dict\n            )), obj=obj, postproc_list=postproc_list)\n            log.info(\"# %s\" % _t)\n        else:\n            log.info(\"T4: %s\" % obj)\n            if incorrectly_named:\n                warnings.warn('Cannot locate reference to %r.' % (obj,), PicklingWarning)\n            if obj_recursive:\n                warnings.warn('Cannot pickle %r: %s.%s has recursive self-references that trigger a RecursionError.' % (obj, obj.__module__, obj_name), PicklingWarning)\n           #print (obj.__dict__)\n           #print (\"%s\\n%s\" % (type(obj), obj.__name__))\n           #print (\"%s\\n%s\" % (obj.__bases__, obj.__dict__))\n            StockPickler.save_global(pickler, obj, name=obj_name)\n            log.info(\"# T4\")\n    return",
    "hash_value": "82561f65c7b608ffe2ba9852d27a28b5"
  },
  {
    "pyfile": "connectionpool.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/ytsaurus_client-0.13.26-py2.py3-none-any/yt/packages/urllib3/connectionpool.py",
    "line_number": "274",
    "type_description": "B807:close",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "273\t            log.debug(\"Resetting dropped connection: %s\", self.host)\n274\t            conn.close()\n275\t            if getattr(conn, \"auto_open\", 1) == 0:",
    "context_snippet": "def _get_conn(self, timeout=None):\n    \"\"\"\n    Get a connection. Will return a pooled connection if one is available.\n\n    If no connections are available and :prop:`.block` is ``False``, then a\n    fresh connection is returned.\n\n    :param timeout:\n        Seconds to wait before giving up and raising\n        :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and\n        :prop:`.block` is ``True``.\n    \"\"\"\n    conn = None\n    try:\n        conn = self.pool.get(block=self.block, timeout=timeout)\n\n    except AttributeError:  # self.pool is None\n        raise ClosedPoolError(self, \"Pool is closed.\")\n\n    except queue.Empty:\n        if self.block:\n            raise EmptyPoolError(\n                self,\n                \"Pool reached maximum size and no more connections are allowed.\",\n            )\n        pass  # Oh well, we'll create a new connection then\n\n    # If this is a persistent connection, check if it got disconnected\n    if conn and is_connection_dropped(conn):\n        log.debug(\"Resetting dropped connection: %s\", self.host)\n        conn.close()\n        if getattr(conn, \"auto_open\", 1) == 0:\n            # This is a proxied connection that has been mutated by\n            # http.client._tunnel() and cannot be reused (since it would\n            # attempt to bypass the proxy)\n            conn = None\n\n    return conn or self._new_conn()",
    "hash_value": "6356ba84ddf07ea112d824359266f55d"
  },
  {
    "pyfile": "connectionpool.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/ytsaurus_client-0.13.26-py2.py3-none-any/yt/packages/urllib3/connectionpool.py",
    "line_number": "440",
    "type_description": "B826:getresponse",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "439\t                # Python 2.7, use buffering of HTTP responses\n440\t                httplib_response = conn.getresponse(buffering=True)\n441\t            except TypeError:",
    "context_snippet": "    def _make_request(\n        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw\n    ):\n        \"\"\"\n        Perform a request on a given urllib connection object taken from our\n        pool.\n\n        :param conn:\n            a connection from one of our connection pools\n\n        :param timeout:\n            Socket timeout in seconds for the request. This can be a\n            float or integer, which will set the same timeout value for\n            the socket connect and the socket read, or an instance of\n            :class:`urllib3.util.Timeout`, which gives you more fine-grained\n            control over your timeouts.\n        \"\"\"\n        self.num_requests += 1\n\n        timeout_obj = self._get_timeout(timeout)\n        timeout_obj.start_connect()\n        conn.timeout = timeout_obj.connect_timeout\n\n        # Trigger any extra validation we need to do.\n        try:\n            self._validate_conn(conn)\n        except (SocketTimeout, BaseSSLError) as e:\n            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\n            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n            raise\n\n        # conn.request() calls http.client.*.request, not the method in\n        # urllib3.request. It also calls makefile (recv) on the socket.\n        try:\n            if chunked:\n                conn.request_chunked(method, url, **httplib_request_kw)\n            else:\n                conn.request(method, url, **httplib_request_kw)\n\n        # We are swallowing BrokenPipeError (errno.EPIPE) since the server is\n        # legitimately able to close the connection after sending a valid response.\n        # With this behaviour, the received response is still readable.\n        except BrokenPipeError:\n            # Python 3\n            pass\n        except IOError as e:\n            # Python 2 and macOS/Linux\n            # EPIPE and ESHUTDOWN are BrokenPipeError on Python 2, and EPROTOTYPE is needed on macOS\n            # https://erickt.github.io/blog/2014/11/19/adventures-in-debugging-a-potential-osx-kernel-bug/\n            if e.errno not in {\n                errno.EPIPE,\n                errno.ESHUTDOWN,\n                errno.EPROTOTYPE,\n            }:\n                raise\n\n        # Reset the timeout for the recv() on the socket\n        read_timeout = timeout_obj.read_timeout\n\n        # App Engine doesn't have a sock attr\n        if getattr(conn, \"sock\", None):\n            # In Python 3 socket.py will catch EAGAIN and return None when you\n            # try and read into the file pointer created by http.client, which\n            # instead raises a BadStatusLine exception. Instead of catching\n            # the exception and assuming all BadStatusLine exceptions are read\n            # timeouts, check for a zero timeout before making the request.\n            if read_timeout == 0:\n                raise ReadTimeoutError(\n                    self, url, \"Read timed out. (read timeout=%s)\" % read_timeout\n                )\n            if read_timeout is Timeout.DEFAULT_TIMEOUT:\n                conn.sock.settimeout(socket.getdefaulttimeout())\n            else:  # None or a value\n                conn.sock.settimeout(read_timeout)\n\n        # Receive the response from the server\n        try:\n            try:\n                # Python 2.7, use buffering of HTTP responses\n                httplib_response = conn.getresponse(buffering=True)\n            except TypeError:\n                # Python 3\n                try:\n                    httplib_response = conn.getresponse()\n                except BaseException as e:\n                    # Remove the TypeError from the exception chain in\n                    # Python 3 (including for exceptions like SystemExit).\n                    # Otherwise it looks like a bug in the code.\n                    six.raise_from(e, None)\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n            raise\n\n        # AppEngine doesn't have a version attr.\n        http_version = getattr(conn, \"_http_vsn_str\", \"HTTP/?\")\n        log.debug(\n            '%s://%s:%s \"%s %s %s\" %s %s',\n            self.scheme,\n            self.host,\n            self.port,\n            method,\n            url,\n            http_version,\n            httplib_response.status,\n            httplib_response.length,\n        )\n\n        try:\n            assert_header_parsing(httplib_response.msg)\n        except (HeaderParsingError, TypeError) as hpe:  # Platform-specific: Python 3\n            log.warning(\n                \"Failed to parse headers (url=%s): %s\",\n                self._absolute_url(url),\n                hpe,\n                exc_info=True,\n            )\n\n        return httplib_response",
    "hash_value": "be548cbad65043190844344220ecf8b6"
  }
]