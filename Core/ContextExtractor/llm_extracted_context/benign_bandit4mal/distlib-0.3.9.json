[
  {
    "metadata": {
      "package_name": "distlib-0.3.9",
      "total_matches": 2,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "wheel.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/distlib-0.3.9/distlib-0.3.9/distlib/wheel.py",
    "line_number": "336",
    "type_description": "B802:b64encode",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "335\t        result = hasher(data).digest()\n336\t        result = base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')\n337\t        return hash_kind, result",
    "context_snippet": "def get_hash(self, data, hash_kind=None):\n    if hash_kind is None:\n        hash_kind = self.hash_kind\n    try:\n        hasher = getattr(hashlib, hash_kind)\n    except AttributeError:\n        raise DistlibException('Unsupported hash algorithm: %r' % hash_kind)\n    result = hasher(data).digest()\n    result = base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')\n    return hash_kind, result",
    "hash_value": "01e4749a991791f33f2e82644415c442"
  },
  {
    "pyfile": "wheel.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/distlib-0.3.9/distlib-0.3.9/distlib/wheel.py",
    "line_number": "732",
    "type_description": "B836:rmtree",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "731\t            finally:\n732\t                shutil.rmtree(workdir)\n733",
    "context_snippet": "def install(self, paths, maker, **kwargs):\n    \"\"\"\n    Install a wheel to the specified paths. If kwarg ``warner`` is\n    specified, it should be a callable, which will be called with two\n    tuples indicating the wheel version of this software and the wheel\n    version in the file, if there is a discrepancy in the versions.\n    This can be used to issue any warnings to raise any exceptions.\n    If kwarg ``lib_only`` is True, only the purelib/platlib files are\n    installed, and the headers, scripts, data and dist-info metadata are\n    not written. If kwarg ``bytecode_hashed_invalidation`` is True, written\n    bytecode will try to use file-hash based invalidation (PEP-552) on\n    supported interpreter versions (CPython 3.7+).\n\n    The return value is a :class:`InstalledDistribution` instance unless\n    ``options.lib_only`` is True, in which case the return value is ``None``.\n    \"\"\"\n\n    dry_run = maker.dry_run\n    warner = kwargs.get('warner')\n    lib_only = kwargs.get('lib_only', False)\n    bc_hashed_invalidation = kwargs.get('bytecode_hashed_invalidation', False)\n\n    pathname = os.path.join(self.dirname, self.filename)\n    name_ver = '%s-%s' % (self.name, self.version)\n    data_dir = '%s.data' % name_ver\n    info_dir = '%s.dist-info' % name_ver\n\n    metadata_name = posixpath.join(info_dir, LEGACY_METADATA_FILENAME)\n    wheel_metadata_name = posixpath.join(info_dir, 'WHEEL')\n    record_name = posixpath.join(info_dir, 'RECORD')\n\n    wrapper = codecs.getreader('utf-8')\n\n    with ZipFile(pathname, 'r') as zf:\n        with zf.open(wheel_metadata_name) as bwf:\n            wf = wrapper(bwf)\n            message = message_from_file(wf)\n        wv = message['Wheel-Version'].split('.', 1)\n        file_version = tuple([int(i) for i in wv])\n        if (file_version != self.wheel_version) and warner:\n            warner(self.wheel_version, file_version)\n\n        if message['Root-Is-Purelib'] == 'true':\n            libdir = paths['purelib']\n        else:\n            libdir = paths['platlib']\n\n        records = {}\n        with zf.open(record_name) as bf:\n            with CSVReader(stream=bf) as reader:\n                for row in reader:\n                    p = row[0]\n                    records[p] = row\n\n        data_pfx = posixpath.join(data_dir, '')\n        info_pfx = posixpath.join(info_dir, '')\n        script_pfx = posixpath.join(data_dir, 'scripts', '')\n\n        # make a new instance rather than a copy of maker's,\n        # as we mutate it\n        fileop = FileOperator(dry_run=dry_run)\n        fileop.record = True  # so we can rollback if needed\n\n        bc = not sys.dont_write_bytecode  # Double negatives. Lovely!\n\n        outfiles = []  # for RECORD writing\n\n        # for script copying/shebang processing\n        workdir = tempfile.mkdtemp()\n        # set target dir later\n        # we default add_launchers to False, as the\n        # Python Launcher should be used instead\n        maker.source_dir = workdir\n        maker.target_dir = None\n        try:\n            for zinfo in zf.infolist():\n                arcname = zinfo.filename\n                if isinstance(arcname, text_type):\n                    u_arcname = arcname\n                else:\n                    u_arcname = arcname.decode('utf-8')\n                if self.skip_entry(u_arcname):\n                    continue\n                row = records[u_arcname]\n                if row[2] and str(zinfo.file_size) != row[2]:\n                    raise DistlibException('size mismatch for '\n                                           '%s' % u_arcname)\n                if row[1]:\n                    kind, value = row[1].split('=', 1)\n                    with zf.open(arcname) as bf:\n                        data = bf.read()\n                    _, digest = self.get_hash(data, kind)\n                    if digest != value:\n                        raise DistlibException('digest mismatch for '\n                                               '%s' % arcname)\n\n                if lib_only and u_arcname.startswith((info_pfx, data_pfx)):\n                    logger.debug('lib_only: skipping %s', u_arcname)\n                    continue\n                is_script = (u_arcname.startswith(script_pfx) and not u_arcname.endswith('.exe'))\n\n                if u_arcname.startswith(data_pfx):\n                    _, where, rp = u_arcname.split('/', 2)\n                    outfile = os.path.join(paths[where], convert_path(rp))\n                else:\n                    # meant for site-packages.\n                    if u_arcname in (wheel_metadata_name, record_name):\n                        continue\n                    outfile = os.path.join(libdir, convert_path(u_arcname))\n                if not is_script:\n                    with zf.open(arcname) as bf:\n                        fileop.copy_stream(bf, outfile)\n                    # Issue #147: permission bits aren't preserved. Using\n                    # zf.extract(zinfo, libdir) should have worked, but didn't,\n                    # see https://www.thetopsites.net/article/53834422.shtml\n                    # So ... manually preserve permission bits as given in zinfo\n                    if os.name == 'posix':\n                        # just set the normal permission bits\n                        os.chmod(outfile, (zinfo.external_attr >> 16) & 0x1FF)\n                    outfiles.append(outfile)\n                    # Double check the digest of the written file\n                    if not dry_run and row[1]:\n                        with open(outfile, 'rb') as bf:\n                            data = bf.read()\n                            _, newdigest = self.get_hash(data, kind)\n                            if newdigest != digest:\n                                raise DistlibException('digest mismatch '\n                                                       'on write for '\n                                                       '%s' % outfile)\n                    if bc and outfile.endswith('.py'):\n                        try:\n                            pyc = fileop.byte_compile(outfile, hashed_invalidation=bc_hashed_invalidation)\n                            outfiles.append(pyc)\n                        except Exception:\n                            # Don't give up if byte-compilation fails,\n                            # but log it and perhaps warn the user\n                            logger.warning('Byte-compilation failed', exc_info=True)\n                else:\n                    fn = os.path.basename(convert_path(arcname))\n                    workname = os.path.join(workdir, fn)\n                    with zf.open(arcname) as bf:\n                        fileop.copy_stream(bf, workname)\n\n                    dn, fn = os.path.split(outfile)\n                    maker.target_dir = dn\n                    filenames = maker.make(fn)\n                    fileop.set_executable_mode(filenames)\n                    outfiles.extend(filenames)\n\n            if lib_only:\n                logger.debug('lib_only: returning None')\n                dist = None\n            else:\n                # Generate scripts\n\n                # Try to get pydist.json so we can see if there are\n                # any commands to generate. If this fails (e.g. because\n                # of a legacy wheel), log a warning but don't give up.\n                commands = None\n                file_version = self.info['Wheel-Version']\n                if file_version == '1.0':\n                    # Use legacy info\n                    ep = posixpath.join(info_dir, 'entry_points.txt')\n                    try:\n                        with zf.open(ep) as bwf:\n                            epdata = read_exports(bwf)\n                        commands = {}\n                        for key in ('console', 'gui'):\n                            k = '%s_scripts' % key\n                            if k in epdata:\n                                commands['wrap_%s' % key] = d = {}\n                                for v in epdata[k].values():\n                                    s = '%s:%s' % (v.prefix, v.suffix)\n                                    if v.flags:\n                                        s += ' [%s]' % ','.join(v.flags)\n                                    d[v.name] = s\n                    except Exception:\n                        logger.warning('Unable to read legacy script '\n                                       'metadata, so cannot generate '\n                                       'scripts')\n                else:\n                    try:\n                        with zf.open(metadata_name) as bwf:\n                            wf = wrapper(bwf)\n                            commands = json.load(wf).get('extensions')\n                            if commands:\n                                commands = commands.get('python.commands')\n                    except Exception:\n                        logger.warning('Unable to read JSON metadata, so '\n                                       'cannot generate scripts')\n                if commands:\n                    console_scripts = commands.get('wrap_console', {})\n                    gui_scripts = commands.get('wrap_gui', {})\n                    if console_scripts or gui_scripts:\n                        script_dir = paths.get('scripts', '')\n                        if not os.path.isdir(script_dir):\n                            raise ValueError('Valid script path not '\n                                             'specified')\n                        maker.target_dir = script_dir\n                        for k, v in console_scripts.items():\n                            script = '%s = %s' % (k, v)\n                            filenames = maker.make(script)\n                            fileop.set_executable_mode(filenames)\n\n                        if gui_scripts:\n                            options = {'gui': True}\n                            for k, v in gui_scripts.items():\n                                script = '%s = %s' % (k, v)\n                                filenames = maker.make(script, options)\n                                fileop.set_executable_mode(filenames)\n\n                p = os.path.join(libdir, info_dir)\n                dist = InstalledDistribution(p)\n\n                # Write SHARED\n                paths = dict(paths)  # don't change passed in dict\n                del paths['purelib']\n                del paths['platlib']\n                paths['lib'] = libdir\n                p = dist.write_shared_locations(paths, dry_run)\n                if p:\n                    outfiles.append(p)\n\n                # Write RECORD\n                dist.write_installed_files(outfiles, paths['prefix'], dry_run)\n            return dist\n        except Exception:  # pragma: no cover\n            logger.exception('installation failed.')\n            fileop.rollback()\n            raise\n        finally:\n            shutil.rmtree(workdir)",
    "hash_value": "8fd6b87398b2e6e95086a3685f76299c"
  }
]