[
  {
    "metadata": {
      "package_name": "srt-3.5.3",
      "total_matches": 1,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "utils.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/srt-3.5.3/srt-3.5.3/srt_tools/utils.py",
    "line_number": "172",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "171\t                args.input = srt.parse(\n172\t                    r_enc(args.input).read(), ignore_errors=args.ignore_parsing_errors\n173\t                )",
    "context_snippet": "def set_basic_args(args):\n    # TODO: dedupe some of this\n    if getattr(args, \"inplace\", None):\n        if args.input == DASH_STREAM_MAP[\"input\"]:\n            raise ValueError(\"Cannot use --inplace on stdin\")\n\n        if args.output != DASH_STREAM_MAP[\"output\"]:\n            raise ValueError(\"Cannot use -o and -p together\")\n\n        args.output = args.input\n\n    for stream_name in (\"input\", \"output\"):\n        log.debug('Processing stream \"%s\"', stream_name)\n\n        try:\n            stream = getattr(args, stream_name)\n        except AttributeError:\n            # For example, in the case of no_output\n            continue\n\n        # We don't use system default encoding, because usually one runs this\n        # on files they got from elsewhere. As such, be opinionated that these\n        # files are probably UTF-8. Looking for the BOM on reading allows us to\n        # be more liberal with what we accept, without adding BOMs on write.\n        read_encoding = args.encoding or \"utf-8-sig\"\n        write_encoding = args.encoding or \"utf-8\"\n\n        r_enc = codecs.getreader(read_encoding)\n        w_enc = codecs.getwriter(write_encoding)\n\n        log.debug(\"Got %r as stream\", stream)\n        # We don't use encoding= option to open because we want to have the\n        # same universal newlines behaviour as STD{IN,OUT}_BYTESTREAM\n        if stream in DASH_STREAM_MAP.values():\n            log.debug(\"%s in DASH_STREAM_MAP\", stream_name)\n            if stream is args.input:\n                args.input = srt.parse(\n                    r_enc(args.input).read(), ignore_errors=args.ignore_parsing_errors\n                )\n            elif stream is args.output:\n                # Since args.output is not in text mode (since we didn't\n                # earlier know the encoding), we have no universal newline\n                # support and need to do it ourselves\n                args.output = w_enc(args.output)\n        else:\n            log.debug(\"%s not in DASH_STREAM_MAP\", stream_name)\n            if stream is args.input:\n                if isinstance(args.input, MutableSequence):\n                    for i, input_fn in enumerate(args.input):\n                        if input_fn in DASH_STREAM_MAP.values():\n                            if stream is args.input:\n                                args.input[i] = srt.parse(\n                                    r_enc(input_fn).read(),\n                                    ignore_errors=args.ignore_parsing_errors,\n                                )\n                        else:\n                            f = r_enc(open(input_fn, \"rb\"))\n                            with f:\n                                args.input[i] = srt.parse(\n                                    f.read(), ignore_errors=args.ignore_parsing_errors\n                                )\n                else:\n                    f = r_enc(open(stream, \"rb\"))\n                    with f:\n                        args.input = srt.parse(\n                            f.read(), ignore_errors=args.ignore_parsing_errors\n                        )\n            else:\n                args.output = w_enc(open(args.output, \"wb\"))",
    "hash_value": "5691bf38b097bcae5c052eb919eccf19"
  }
]