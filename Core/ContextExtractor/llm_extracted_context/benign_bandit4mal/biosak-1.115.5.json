[
  {
    "metadata": {
      "package_name": "biosak-1.115.5",
      "total_matches": 5,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "link_16s.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/biosak-1.115.5/BioSAK-1.115.5/BioSAK/link_16s.py",
    "line_number": "1511",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1510\t                file_out_ffn_handle.write('>%s\\n' % each_16s.id)\n1511\t                file_out_ffn_handle.write('%s\\n' % str(each_16s.seq))\n1512\t        file_out_ffn_handle.close()",
    "context_snippet": "def qc_16s(file_in, file_out_ffn, uclust_op_fasta, uclust_op_uc, uclust_op_txt, no_polish, min_16s_len, no_cluster, uclust_iden_cutoff):\n\n    file_out_path, file_out_base, file_out_ext = sep_path_basename_ext(file_out_ffn)\n    barrnap_stdout      = '%s/%s.log'       % (file_out_path, file_out_base)\n    file_out_ffn_tmp    = '%s/%s_tmp%s'     % (file_out_path, file_out_base, file_out_ext)\n    file_out_gff        = '%s/%s.gff'       % (file_out_path, file_out_base)\n\n    # remove non-16S sequences, then filter by length\n    if no_polish is False:\n\n        barrnap_cmd = 'barrnap --quiet -o %s %s 2> %s > %s' % (file_out_ffn_tmp, file_in, barrnap_stdout, file_out_gff)\n        os.system(barrnap_cmd)\n\n        wrote_id = []\n        file_out_ffn_handle = open(file_out_ffn, 'w')\n        for each_16s in SeqIO.parse(file_out_ffn_tmp, 'fasta'):\n            seq_id = each_16s.id\n            if seq_id.startswith('16S_rRNA::'):\n                seq_id_polished = seq_id[10:].split(':')[0]\n                if len(each_16s.seq) >= min_16s_len:\n                    if seq_id_polished not in wrote_id:\n                        file_out_ffn_handle.write('>%s\\n' % seq_id_polished)\n                        file_out_ffn_handle.write('%s\\n' % str(each_16s.seq))\n                        wrote_id.append(seq_id_polished)\n                    else:\n                        file_out_ffn_handle.write('>%s_%s\\n' % (seq_id_polished, (wrote_id.count(seq_id_polished) + 1)))\n                        file_out_ffn_handle.write('%s\\n' % str(each_16s.seq))\n                        wrote_id.append(seq_id_polished)\n        file_out_ffn_handle.close()\n\n        # remove tmp files\n        os.system('rm %s' % file_out_ffn_tmp)\n        os.system('rm %s.fai' % file_in)\n\n    # only filter input 16S by length\n    else:\n        file_out_ffn_handle = open(file_out_ffn, 'w')\n        for each_16s in SeqIO.parse(file_in, 'fasta'):\n            if len(each_16s.seq) >= min_16s_len:\n                file_out_ffn_handle.write('>%s\\n' % each_16s.id)\n                file_out_ffn_handle.write('%s\\n' % str(each_16s.seq))\n        file_out_ffn_handle.close()\n\n    # check if there are no qualified sequences\n    if os.stat(file_out_ffn).st_size == 0:\n        print('No input 16S rRNA gene sequences passed quality control, program exited!')\n        exit()\n\n    # cluster 16S\n    if no_cluster is False:\n        uclust_cmd = 'usearch -cluster_fast %s -id %s -centroids %s -uc %s -sort length -quiet' % (file_out_ffn, (uclust_iden_cutoff/100), uclust_op_fasta, uclust_op_uc)\n        os.system(uclust_cmd)\n\n        # get readable cluster results\n        parse_uclust_output(uclust_op_uc, uclust_op_txt)\n",
    "hash_value": "8a4050759a224f772d1a455d9afdd538"
  },
  {
    "pyfile": "blca_subset_db_gg.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/biosak-1.115.5/BioSAK-1.115.5/BioSAK/blca_subset_db_gg.py",
    "line_number": "111",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "110\t        if len(ln) == 2:\n111\t            taxout.write(ln[0] + \"\\t\")\n112\t            tmp = dict(x.split(\"__\") for x in ln[1].split(\";\"))",
    "context_snippet": "def format_gg_taxfile(taxfile):\n    ''' Read in Greengenes taxonomy file, and format it and write out into BLCA compatiable format '''\n    leveldic={'c':'class','g':'genus','k':'superkingdom','f':'family','o':'order','p':'phylum','s':'species'}\n    taxin=open(taxfile)\n    outtaxfile = os.path.splitext(taxfile)[0] + \".taxonomy\"\n    if os.path.isfile(outtaxfile):\n        os.remove(outtaxfile)\n    taxout=open(outtaxfile,'w')\n    for l in taxin:\n        ln=l.rstrip().replace(\" \",\"\").split(\"\\t\")\n        if len(ln) == 2:\n            taxout.write(ln[0] + \"\\t\")\n            tmp = dict(x.split(\"__\") for x in ln[1].split(\";\"))\n            oldnames = list(tmp.keys())\n            for k in oldnames:\n                tmp[leveldic[k]]=tmp.pop(k)\n            for key, val in tmp.items():\n                taxout.write(key+':'+val+\";\")\n            taxout.write(\"\\n\")\n    taxin.close()\n    taxout.close()\n    print(os.path.basename(taxfile), \"has been formatted and outputted!\")",
    "hash_value": "9f058db57ae0094898f5084fac69ec92"
  },
  {
    "pyfile": "arCOG.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/biosak-1.115.5/BioSAK-1.115.5/BioSAK/arCOG.py",
    "line_number": "52",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "51\t    file_out_handle = open(file_out, 'w')\n52\t    file_out_handle.write(file_out_header)\n53\t    line_num = 0",
    "context_snippet": "def AnnotateNorm(file_in, skip_header, value_column, Divisor_value, file_out, file_out_header):\n\n    file_out_handle = open(file_out, 'w')\n    file_out_handle.write(file_out_header)\n    line_num = 0\n    for each_line in open(file_in):\n        each_line_split = each_line.strip().split('\\t')\n        value_str = each_line_split[value_column - 1]\n        if (skip_header is True and line_num > 0) or (skip_header is False):\n            value_pct = 0\n            if Divisor_value != 0:\n                value_pct = float(value_str) * 100 / Divisor_value\n            each_line_split[value_column - 1] = str(float(\"{0:.2f}\".format(value_pct)))\n            file_out_handle.write('%s\\n' % '\\t'.join(each_line_split))\n        line_num += 1\n    file_out_handle.close()",
    "hash_value": "849dafbbf1cb1eaa8c5acacfa10b2577"
  },
  {
    "pyfile": "abd_mask.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/biosak-1.115.5/BioSAK-1.115.5/BioSAK/abd_mask.py",
    "line_number": "132",
    "type_description": "B812:system",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "131\t    print(shell_cmd_11)\n132\t    os.system(shell_cmd_11)\n133",
    "context_snippet": "import os\nimport glob\nimport argparse\nfrom Bio import SeqIO\nimport multiprocessing as mp\n\n\ndef sep_path_basename_ext(file_in):\n\n    f_path, f_name = os.path.split(file_in)\n    if f_path == '':\n        f_path = '.'\n    f_base, f_ext = os.path.splitext(f_name)\n\n    return f_name, f_path, f_base, f_ext[1:]\n\n\ndef rename_and_cat_gnm(gnm_dir, gnm_ext, combined_renamed_fna, rename_txt):\n\n    gnm_file_re = '%s/*.%s' % (gnm_dir, gnm_ext)\n    gnm_file_list = glob.glob(gnm_file_re)\n\n    gnm_rename_txt_handle = open(rename_txt, 'w')\n    combined_renamed_fa_handle = open(combined_renamed_fna, 'w')\n    for each_gnm in sorted(gnm_file_list):\n        _, _, gnm_base, _ = sep_path_basename_ext(each_gnm)\n        gnm_id_no_underscore = gnm_base.replace('_', '')\n        gnm_rename_txt_handle.write('%s\\t%s\\n' % (gnm_base, gnm_id_no_underscore))\n\n        seq_index = 1\n        for each_seq in SeqIO.parse(each_gnm, 'fasta'):\n            combined_renamed_fa_handle.write('>%s_%s\\n%s\\n' % (gnm_id_no_underscore, seq_index, str(each_seq.seq)))\n            seq_index += 1\n\n    gnm_rename_txt_handle.close()\n    combined_renamed_fa_handle.close()\n\n\ndef abd_mask(args):\n\n    seq_dir         = args['i']\n    seq_ext         = args['x']\n    op_dir          = args['o']\n    op_prefix       = args['p']\n    num_threads     = args['t']\n    force_overwrite = args['f']\n\n    ########################################## define file and directory name ##########################################\n\n    renamed_combined_fna    = '%s/%s.fna'       % (op_dir, op_prefix)\n    renamed_combined_txt    = '%s/%s.txt'       % (op_dir, op_prefix)\n    tRNAscan_wd             = '%s/tRNAscan_wd'  % op_dir\n\n    ####################################################################################################################\n\n    seq_file_re     = '%s/*.%s' % (seq_dir, seq_ext)\n    seq_file_list   = glob.glob(seq_file_re)\n    if len(seq_file_list) == 0:\n        print('No sequence files found in %s, program exited!' % seq_dir)\n        exit()\n\n    # create op dir\n    if os.path.isdir(op_dir) is True:\n        if force_overwrite is True:\n            os.system('rm -r %s' % op_dir)\n        else:\n            print('Output directory detected, program exited!')\n            exit()\n    os.system('mkdir %s' % op_dir)\n\n    # rename and combine sequences\n    print('rename and combine input genomes')\n    rename_and_cat_gnm(seq_dir, seq_ext, renamed_combined_fna, renamed_combined_txt)\n\n    ####################################################################################################################\n\n    # get rRNA regions\n    shell_cmd_1_metaxa2_ssu_cmd     = 'metaxa2 --plus --mode m --cpu %s --multi_thread T --table T -g ssu --not_found T -i %s -o %s/%s.metaxa2_ssu'             % (num_threads, renamed_combined_fna, op_dir, op_prefix)\n    shell_cmd_2_metaxa2_lsu_cmd     = 'metaxa2 --plus --mode m --cpu %s --multi_thread T --table T -g lsu --not_found T -i %s -o %s/%s.metaxa2_lsu'             % (num_threads, renamed_combined_fna, op_dir, op_prefix)\n    shell_cmd_3                     = 'cut -f 1,9,10 %s/%s.metaxa2_ssu.extraction.results > %s/%s.masked_metaxa_ssu.bed'                                        % (op_dir, op_prefix, op_dir, op_prefix)\n    shell_cmd_4                     = 'cut -f 1,9,10 %s/%s.metaxa2_lsu.extraction.results > %s/%s.masked_metaxa_lsu.bed'                                        % (op_dir, op_prefix, op_dir, op_prefix)\n    shell_cmd_5                     = 'cat %s/%s.masked_metaxa_ssu.bed %s/%s.masked_metaxa_lsu.bed > %s/%s.masked_metaxa.bed'                                   % (op_dir, op_prefix, op_dir, op_prefix, op_dir, op_prefix)\n    shell_cmd_6_barrnap_bac_cmd     = 'barrnap --kingdom bac --threads %s --reject 0.3 %s > %s/%s.barrnap_bac.gff'                                              % (num_threads, renamed_combined_fna, op_dir, op_prefix)\n    shell_cmd_7_barrnap_arc_cmd     = 'barrnap --kingdom arc --threads %s --reject 0.3 %s > %s/%s.barrnap_arc.gff'                                              % (num_threads, renamed_combined_fna, op_dir, op_prefix)\n    shell_cmd_8_barrnap_euk_cmd     = 'barrnap --kingdom euk --threads %s --reject 0.3 %s > %s/%s.barrnap_euk.gff'                                              % (num_threads, renamed_combined_fna, op_dir, op_prefix)\n    shell_cmd_9                     = 'cut -f 1,4,5 %s/%s.barrnap_bac.gff > %s/%s.masked_barrnap_bac.bed'                                                       % (op_dir, op_prefix, op_dir, op_prefix)\n    shell_cmd_10                    = 'cut -f 1,4,5 %s/%s.barrnap_arc.gff > %s/%s.masked_barrnap_arc.bed'                                                       % (op_dir, op_prefix, op_dir, op_prefix)\n    shell_cmd_11                    = 'cut -f 1,4,5 %s/%s.barrnap_euk.gff > %s/%s.masked_barrnap_euk.bed'                                                       % (op_dir, op_prefix, op_dir, op_prefix)\n    shell_cmd_12                    = 'cat %s/%s.masked_barrnap_bac.bed %s/%s.masked_barrnap_arc.bed %s/%s.masked_barrnap_euk.bed > %s/%s.masked_barrnap.bed'   % (op_dir, op_prefix, op_dir, op_prefix, op_dir, op_prefix, op_dir, op_prefix)\n    shell_cmd_13                    = 'cat %s/%s.masked_barrnap.bed %s/%s.masked_metaxa.bed > %s/%s.masked_rrna.bed'                                            % (op_dir, op_prefix, op_dir, op_prefix, op_dir, op_prefix)\n\n    print(shell_cmd_1_metaxa2_ssu_cmd)\n    os.system(shell_cmd_1_metaxa2_ssu_cmd)\n\n    print(shell_cmd_2_metaxa2_lsu_cmd)\n    os.system(shell_cmd_2_metaxa2_lsu_cmd)\n\n    print(shell_cmd_3)\n    os.system(shell_cmd_3)\n\n    print(shell_cmd_4)\n    os.system(shell_cmd_4)\n\n    print(shell_cmd_5)\n    os.system(shell_cmd_5)\n\n    print(shell_cmd_6_barrnap_bac_cmd)\n    os.system(shell_cmd_6_barrnap_bac_cmd)\n\n    print(shell_cmd_7_barrnap_arc_cmd)\n    os.system(shell_cmd_7_barrnap_arc_cmd)\n\n    print(shell_cmd_8_barrnap_euk_cmd)\n    os.system(shell_cmd_8_barrnap_euk_cmd)\n\n    print(shell_cmd_9)\n    os.system(shell_cmd_9)\n\n    print(shell_cmd_10)\n    os.system(shell_cmd_10)\n\n    print(shell_cmd_11)\n    os.system(shell_cmd_11)\n\n    print(shell_cmd_12)\n    os.system(shell_cmd_12)\n\n    print(shell_cmd_13)\n    os.system(shell_cmd_13)\n\n    ################################################# get tRNA regions #################################################\n\n    os.system('mkdir %s' % tRNAscan_wd)\n\n    threads_per_job = num_threads/(len(seq_file_list)*2)\n    if threads_per_job == 0:\n        threads_per_job = 1\n\n    tRNAscan_cmd_list = []\n    for each_gnm in seq_file_list:\n        _, _, gnm_base, _ = sep_path_basename_ext(each_gnm)\n        trnascan_arc_cmd = 'tRNAscan-SE -A -b %s/%s.ar.bedformat --thread %s %s'  % (tRNAscan_wd, gnm_base, threads_per_job, each_gnm)\n        trnascan_bac_cmd = 'tRNAscan-SE -B -b %s/%s.bac.bedformat --thread %s %s' % (tRNAscan_wd, gnm_base, threads_per_job, each_gnm)\n        tRNAscan_cmd_list.append(trnascan_arc_cmd)\n        tRNAscan_cmd_list.append(trnascan_bac_cmd)\n\n    # run tRNAscan-SE with multiprocessing\n    pool = mp.Pool(processes=num_threads)\n    pool.map(os.system, tRNAscan_cmd_list)\n    pool.close()\n    pool.join()\n\n    # combine the results\n    shell_cmd_16 = 'cat %s/%s.ar.bedformat %s/%s.bac.bedformat > %s/%s.bedformat'   % (tRNAscan_wd, op_prefix, tRNAscan_wd, op_prefix, op_dir, op_prefix)\n    shell_cmd_17 = 'cut -f 1,2,3 %s/%s.bedformat > %s/%s.masked_trnascan.bed'       % (op_dir, op_prefix, op_dir, op_prefix)\n    print(shell_cmd_16)\n    os.system(shell_cmd_16)\n    print(shell_cmd_17)\n    os.system(shell_cmd_17)\n\n    ####################################################################################################################\n\n    # find duplicated areas\n    shell_cmd_18    = 'dustmasker -in %s -out %s/%s.lowcom.out -outfmt acclist'         % (renamed_combined_fna, op_dir, op_prefix)\n    shell_cmd_19    = \"cut -d '>' -f 2 %s/%s.lowcom.out > %s/%s.masked_dustmasker.bed\"  % (op_dir, op_prefix, op_dir, op_prefix)\n    print(shell_cmd_18)\n    os.system(shell_cmd_18)\n    print(shell_cmd_19)\n    os.system(shell_cmd_19)\n\n    # cover the above area with NNNN\n    shell_cmd_20    = \"cat %s/%s.masked_rrna.bed %s/%s.masked_trnascan.bed %s/%s.masked_dustmasker.bed > %s/%s.mask.bed\"    % (op_dir, op_prefix, op_dir, op_prefix, op_dir, op_prefix, op_dir, op_prefix)\n    shell_cmd_21    = \"awk -F'\\t' '$2>=0' %s/%s.mask.bed > %s/%s.mask_0.bed\"                                                % (op_dir, op_prefix, op_dir, op_prefix)\n    shell_cmd_22    = \"bedtools maskfasta -fi %s -bed %s/%s.mask_0.bed -fo %s/%s.masked.fna\"                                % (renamed_combined_fna, op_dir, op_prefix, op_dir, op_prefix)\n    print(shell_cmd_20)\n    os.system(shell_cmd_20)\n    print(shell_cmd_21)\n    os.system(shell_cmd_21)\n    print(shell_cmd_22)\n    os.system(shell_cmd_22)\n\n    ####################################################################################################################\n\n    print('Masked sequences exported to %s/%s.masked.fna' % (op_dir, op_prefix))\n    print('Done!')\n",
    "hash_value": "ffdffe0681bced1836a91bc2e0d8eb09"
  },
  {
    "pyfile": "link_16s.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/biosak-1.115.5/BioSAK-1.115.5/BioSAK/link_16s.py",
    "line_number": "2837",
    "type_description": "B812:system",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "2836\t    report_and_log(('Rd1: removing splitted subsets from disk'), pwd_log_file, keep_quiet)\n2837\t    os.system('rm -r %s' % input_reads_to_16s_sam_sorted_split_folder)\n2838",
    "context_snippet": "    report_and_log(('Rd1: removing splitted subsets from disk'), pwd_log_file, keep_quiet)\n    os.system('rm -r %s' % input_reads_to_16s_sam_sorted_split_folder)\n",
    "hash_value": "827ca35f3f58f24ff445b3ff5d648a3c"
  }
]