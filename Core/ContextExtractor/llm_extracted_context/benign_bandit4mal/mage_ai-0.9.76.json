[
  {
    "metadata": {
      "package_name": "mage_ai-0.9.76",
      "total_matches": 3,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "azure_devops.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/mage_ai-0.9.76/mage_ai-0.9.76/mage_ai/data_preparation/git/clients/azure_devops.py",
    "line_number": "105",
    "type_description": "B820:get",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "104\t            url=pr.get('url'),\n105\t            user=pr.get('createdBy', {}).get('displayName'),\n106\t        )",
    "context_snippet": "def create_pull_request(\n    self,\n    repository_name: str,\n    base_branch: str,\n    body: str,\n    compare_branch: str,\n    title: str,\n):\n    project_name, repository_name = repository_name.split('/')\n    data = {\n        'title': title,\n        'description': body,\n        'sourceRefName': compare_branch,\n        'targetRefName': base_branch,\n    }\n\n    resp = requests.post(\n        f'https://dev.azure.com/{self.organization}/{project_name}/_apis/git/repositories/{repository_name}/pullrequests?api-version=7.1-preview.1',  # noqa: E501\n        headers={\n            'Accept': 'application/json',\n            'Authorization': f'Bearer {self.access_token}',\n            'Content-Type': 'application/json',\n        },\n        data=json.dumps(data),\n        timeout=10,\n    )\n\n    resp.raise_for_status()\n    pr = resp.json()\n    return dict(\n        body=pr.get('description'),\n        created_at=pr.get('creationDate'),\n        id=pr.get('pullRequestId'),\n        is_merged=pr.get('status') == 'completed',\n        merged=pr.get('status') == 'completed',\n        state=pr.get('status'),\n        title=pr.get('title'),\n        url=pr.get('url'),\n        user=pr.get('createdBy', {}).get('displayName'),\n    )",
    "hash_value": "2c5c101227535f3e993fde71bde8bb93"
  },
  {
    "pyfile": "integration_pipeline.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/mage_ai-0.9.76/mage_ai-0.9.76/mage_ai/data_preparation/models/pipelines/integration_pipeline.py",
    "line_number": "172",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "171\t            with open(file_path, 'w') as f:\n172\t                f.write(json.dumps(dict(bookmarks={})))\n173",
    "context_snippet": "def destination_state_file_path(self, stream: str, destination_table: str) -> str:\n    stream_dir = f'{self.destination_dir}/{clean_name(stream)}'\n    file_path = f'{stream_dir}/{clean_name(destination_table)}_state'\n\n    os.makedirs(stream_dir, exist_ok=True)\n\n    if not os.path.exists(file_path):\n        with open(file_path, 'w') as f:\n            f.write(json.dumps(dict(bookmarks={})))\n\n    return file_path",
    "hash_value": "1db2d368f31a29e8179904e84bcdedbe"
  },
  {
    "pyfile": "models.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/mage_ai-0.9.76/mage_ai-0.9.76/mage_ai/kernels/magic/kernels/models.py",
    "line_number": "43",
    "type_description": "B840:executor",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "42\t    def __initialize_kernel(self, num_processes: Optional[int] = None) -> None:\n43\t        self.executor = ThreadPoolExecutor()\n44\t        self.num_processes = num_processes or DEFAULT_NUM_PROCESSES",
    "context_snippet": "from concurrent.futures import ThreadPoolExecutor\nfrom typing import Optional\n\nDEFAULT_NUM_PROCESSES = 1\n\nclass Kernel:\n    def __initialize_kernel(self, num_processes: Optional[int] = None) -> None:\n        self.executor = ThreadPoolExecutor()\n        self.num_processes = num_processes or DEFAULT_NUM_PROCESSES\n\n        # These need to go before starting the thread.\n        self.pool = Pool(processes=self.num_processes)\n        self.context_manager = SyncManager()\n        self.context_manager.start()\n\n        self.read_queue = cast(Queue, self.context_manager.Queue())\n\n        # Track active processes\n        self.processes: List[Process] = []\n\n        self.shared_dict = self.context_manager.dict()\n        self.shared_list = self.context_manager.list()\n        self.lock = self.context_manager.Lock()\n\n        self.stop_event = Event()\n        self.stop_event_pool = AsyncEvent()\n\n        # Initialize a queue using the SyncManager so that it can be serialized and deserialized\n        # or else it will throw an error when trying to pass it to a process.\n        # Thread to read and forward results from read queue to write queue.\n        self.reader_thread = ReaderThread(\n            args=(self.read_queue, self.write_queue, self.stop_event), start=True\n        )",
    "hash_value": "69a700d724f9f2436c0be30613028744"
  }
]