[
  {
    "metadata": {
      "package_name": "chromadb-1.0.4",
      "total_matches": 1,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "test_cross_version_persist.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/chromadb-1.0.4/chromadb-1.0.4/chromadb/test/property/test_cross_version_persist.py",
    "line_number": "301",
    "type_description": "B812:system",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "300\t    system.start()\n301\t    client = ClientCreator.from_system(system)\n302\t    coll = client.get_collection(",
    "context_snippet": "def test_cycle_versions(\n    version_settings: Tuple[str, Settings],\n    collection_strategy: strategies.Collection,\n    embeddings_strategy: strategies.RecordSet,\n) -> None:\n    # Test backwards compatibility\n    # For the current version, ensure that we can load a collection from\n    # the previous versions\n    version, settings = version_settings\n    # The strategies can generate metadatas of malformed inputs. Other tests\n    # will error check and cover these cases to make sure they error. Here we\n    # just convert them to valid values since the error cases are already tested\n    if embeddings_strategy[\"metadatas\"] == {}:\n        embeddings_strategy[\"metadatas\"] = None\n    if embeddings_strategy[\"metadatas\"] is not None and isinstance(\n        embeddings_strategy[\"metadatas\"], list\n    ):\n        embeddings_strategy[\"metadatas\"] = [\n            m if m is None or len(m) > 0 else None\n            for m in embeddings_strategy[\"metadatas\"]\n        ]\n\n    patch_for_version(version, collection_strategy, embeddings_strategy, settings)\n\n    # Can't pickle a function, and we won't need them\n    collection_strategy.embedding_function = None\n    collection_strategy.known_metadata_keys = {}\n\n    # Run the task in a separate process to avoid polluting the current process\n    # with the old version. Using spawn instead of fork to avoid sharing the\n    # current process memory which would cause the old version to be loaded\n    ctx = multiprocessing.get_context(\"spawn\")\n    conn1, conn2 = multiprocessing.Pipe()\n    p = ctx.Process(\n        target=persist_generated_data_with_old_version,\n        args=(version, settings, collection_strategy, embeddings_strategy, conn2),\n    )\n    p.start()\n    p.join()\n\n    if conn1.poll():\n        e = conn1.recv()\n        raise e\n\n    p.close()\n\n    # Switch to the current version (local working directory) and check the invariants\n    # are preserved for the collection\n    system = config.System(settings)\n    system.start()\n    client = ClientCreator.from_system(system)\n    coll = client.get_collection(\n        name=collection_strategy.name,\n        embedding_function=not_implemented_ef(),  # type: ignore\n    )\n\n    embeddings_queue = system.instance(SqliteDB)\n\n    # Automatic pruning should be disabled since embeddings_queue is non-empty\n    if packaging_version.Version(version) < packaging_version.Version(\n        \"0.5.7\"\n    ):  # (automatic pruning is enabled by default in 0.5.7 and later)\n        assert (\n            embeddings_queue.config.get_parameter(\"automatically_purge\").value is False\n        )\n\n    # Update to True so log_size_below_max() invariant will pass\n    embeddings_queue.set_config(\n        EmbeddingsQueueConfigurationInternal(\n            [ConfigurationParameter(\"automatically_purge\", True)]\n        )\n    )\n\n    # Should be able to clean log immediately after updating\n\n    # 07/29/24: the max_seq_id for vector segments was moved from the pickled metadata file to SQLite.\n    # Cleaning the log is dependent on vector segments migrating their max_seq_id from the pickled metadata file to SQLite.\n    # Vector segments migrate this field automatically on init, but at this point the segment has not been loaded yet.\n    if \"CHROMA_RUST_BINDINGS_TEST_ONLY\" in os.environ:\n        # Trigger log purge in Rust impl\n        invariants.count(coll, embeddings_strategy)\n    else:\n        trigger_vector_segments_max_seq_id_migration(\n            embeddings_queue, system.instance(SegmentManager)\n        )\n        embeddings_queue.purge_log(coll.id)\n    invariants.log_size_below_max(system, [coll], True)\n\n    # Should be able to add embeddings\n    coll.add(**embeddings_strategy)  # type: ignore\n\n    invariants.count(coll, embeddings_strategy)\n    invariants.metadatas_match(coll, embeddings_strategy)\n    invariants.documents_match(coll, embeddings_strategy)\n    invariants.ids_match(coll, embeddings_strategy)\n    invariants.ann_accuracy(coll, embeddings_strategy)\n    invariants.log_size_below_max(system, [coll], True)\n\n    # Shutdown system\n    system.stop()",
    "hash_value": "19177d73d9af017da588b6c87e41e470"
  }
]