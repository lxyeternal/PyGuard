[
  {
    "metadata": {
      "package_name": "yolov5-7.0.14",
      "total_matches": 1,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "val.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/yolov5-7.0.14/yolov5-7.0.14/yolov5/val.py",
    "line_number": "316",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "315\t    text_file = open(save_dir / \"results.html\", \"w\")\n316\t    text_file.write(results_html)\n317\t    text_file.close()",
    "context_snippet": "def run(\n        data,\n        weights=None,  # model.pt path(s)\n        batch_size=None,  # batch size\n        batch=None,  # batch size\n        imgsz=None,  # inference size (pixels)\n        img=None,  # inference size (pixels)\n        conf_thres=0.001,  # confidence threshold\n        iou_thres=0.6,  # NMS IoU threshold\n        max_det=300,  # maximum detections per image\n        task='val',  # train, val, test, speed or study\n        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n        workers=8,  # max dataloader workers (per RANK in DDP mode)\n        single_cls=False,  # treat as single-class dataset\n        augment=False,  # augmented inference\n        verbose=False,  # verbose output\n        save_txt=False,  # save results to *.txt\n        save_hybrid=False,  # save label+prediction hybrid results to *.txt\n        save_conf=False,  # save confidences in --save-txt labels\n        save_json=False,  # save a COCO-JSON results file\n        project='runs/val',  # save to project/name\n        name='exp',  # save to project/name\n        exist_ok=False,  # existing project/name ok, do not increment\n        half=True,  # use FP16 half-precision inference\n        dnn=False,  # use OpenCV DNN for ONNX inference\n        model=None,\n        dataloader=None,\n        save_dir=Path(''),\n        plots=True,\n        callbacks=Callbacks(),\n        compute_loss=None,\n):\n    ...\n    # Export results as html\n    header = \"Class Images Labels P R mAP@.5 mAP@.5:.95\"\n    headers = header.split()\n    data = []\n    data.append(['all', seen, nt.sum(), f\"{float(mp):0.3f}\", f\"{float(mr):0.3f}\", f\"{float(map50):0.3f}\", f\"{float(map):0.3f}\"])\n    for i, c in enumerate(ap_class):\n        data.append([names[c], seen, nt[c], f\"{float(p[i]):0.3f}\", f\"{float(r[i]):0.3f}\", f\"{float(ap50[i]):0.3f}\", f\"{float(ap[i]):0.3f}\"])\n    results_df = pd.DataFrame(data,columns=headers)\n    results_html = results_df.to_html()\n    text_file = open(save_dir / \"results.html\", \"w\")\n    text_file.write(results_html)\n    text_file.close()\n    ...",
    "hash_value": "6bf89baf19f5e9a2bc44b017463df18f"
  }
]