[
  {
    "metadata": {
      "package_name": "hdmf-4.0.0",
      "total_matches": 2,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "test_io_hdf5_h5tools.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/hdmf-4.0.0/hdmf-4.0.0/tests/unit/test_io_hdf5_h5tools.py",
    "line_number": "1757",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1756\t        with HDF5IO(self.path, manager=get_foo_buildmanager(), mode='r') as io:\n1757\t            read_foofile = io.read()\n1758\t            self.assertListEqual(self.foofile2.buckets['bucket2'].foos['foo2'].my_data,",
    "context_snippet": "def test_write_w(self):\n    # mode 'w' should overwrite contents of file\n    with HDF5IO(self.path, manager=get_foo_buildmanager(), mode='w') as io:\n        io.write(self.foofile2)\n\n    with HDF5IO(self.path, manager=get_foo_buildmanager(), mode='r') as io:\n        read_foofile = io.read()\n        self.assertListEqual(self.foofile2.buckets['bucket2'].foos['foo2'].my_data,\n                             read_foofile.buckets['bucket2'].foos['foo2'].my_data[:].tolist())",
    "hash_value": "466b3d98c00e7ee48ad4dfcbd2c56c80"
  },
  {
    "pyfile": "test_io_hdf5_h5tools.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/hdmf-4.0.0/hdmf-4.0.0/tests/unit/test_io_hdf5_h5tools.py",
    "line_number": "1451",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1450\t        with HDF5IO(self.path1, mode='a', manager=get_foo_buildmanager()) as new_io3:\n1451\t            new_io3.read()\n1452",
    "context_snippet": "    def test_close_linked_files_auto(self):\n        \"\"\"Test closing a file with close_links=True (default).\n        \"\"\"\n        # Create the first file\n        foo1 = Foo('foo1', [0, 1, 2, 3, 4], \"I am foo1\", 17, 3.14)\n        bucket1 = FooBucket('bucket1', [foo1])\n        foofile1 = FooFile(buckets=[bucket1])\n\n        # Write the first file\n        with HDF5IO(self.path1, mode='w', manager=get_foo_buildmanager()) as io:\n            io.write(foofile1)\n\n        # Create the second file\n        manager = get_foo_buildmanager()  # use the same manager for read and write so that links work\n        with HDF5IO(self.path1, mode='r', manager=manager) as read_io:\n            read_foofile1 = read_io.read()\n            foofile2 = FooFile(foo_link=read_foofile1.buckets['bucket1'].foos['foo1'])  # cross-file link\n\n            # Write the second file\n            with HDF5IO(self.path2, mode='w', manager=manager) as write_io:\n                write_io.write(foofile2)\n\n        with HDF5IO(self.path2, mode='a', manager=get_foo_buildmanager()) as new_io1:\n            read_foofile2 = new_io1.read()  # keep reference to container in memory\n\n        self.assertFalse(read_foofile2.foo_link.my_data)\n\n        # should be able to reopen both files\n        with HDF5IO(self.path1, mode='a', manager=get_foo_buildmanager()) as new_io3:\n            new_io3.read()\n",
    "hash_value": "0605855420695f8226e5cdaced907961"
  }
]