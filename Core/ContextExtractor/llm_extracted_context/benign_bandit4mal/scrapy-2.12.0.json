[
  {
    "metadata": {
      "package_name": "scrapy-2.12.0",
      "total_matches": 2,
      "processing_date": "2025-05-18 01:49:40"
    }
  },
  {
    "pyfile": "test_downloadermiddleware_httpcache.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/scrapy-2.12.0/scrapy-2.12.0/tests/test_downloadermiddleware_httpcache.py",
    "line_number": "38",
    "type_description": "B836:rmtree",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "37\t        self.crawler.stats.close_spider(self.spider, \"\")\n38\t        shutil.rmtree(self.tmpdir)\n39",
    "context_snippet": "import shutil\nimport tempfile\nimport email.utils\nimport time\nimport unittest\nfrom scrapy.http import Request, Response\nfrom scrapy.spiders import Spider\nfrom scrapy.utils.test import get_crawler\n\nclass _BaseTest(unittest.TestCase):\n    storage_class = \"scrapy.extensions.httpcache.DbmCacheStorage\"\n    policy_class = \"scrapy.extensions.httpcache.RFC2616Policy\"\n\n    def setUp(self):\n        self.yesterday = email.utils.formatdate(time.time() - 86400)\n        self.today = email.utils.formatdate()\n        self.tomorrow = email.utils.formatdate(time.time() + 86400)\n        self.crawler = get_crawler(Spider)\n        self.spider = self.crawler._create_spider(\"example.com\")\n        self.tmpdir = tempfile.mkdtemp()\n        self.request = Request(\"http://www.example.com\", headers={\"User-Agent\": \"test\"})\n        self.response = Response(\n            \"http://www.example.com\",\n            headers={\"Content-Type\": \"text/html\"},\n            body=b\"test body\",\n            status=202,\n        )\n        self.crawler.stats.open_spider(self.spider)\n\n    def tearDown(self):\n        self.crawler.stats.close_spider(self.spider, \"\")\n        shutil.rmtree(self.tmpdir)\n",
    "hash_value": "5c753886c4d742305ef1aab401704485"
  },
  {
    "pyfile": "test_scheduler_base.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/scrapy-2.12.0/scrapy-2.12.0/tests/test_scheduler_base.py",
    "line_number": "137",
    "type_description": "B825:request",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "136\t        while self.scheduler.has_pending_requests():\n137\t            request = self.scheduler.next_request()\n138\t            dequeued.append(request.url)",
    "context_snippet": "def test_enqueue_dequeue(self):\n    self.assertFalse(self.scheduler.has_pending_requests())\n    for url in URLS:\n        self.assertTrue(self.scheduler.enqueue_request(Request(url)))\n        self.assertFalse(self.scheduler.enqueue_request(Request(url)))\n    self.assertTrue(self.scheduler.has_pending_requests)\n\n    dequeued = []\n    while self.scheduler.has_pending_requests():\n        request = self.scheduler.next_request()\n        dequeued.append(request.url)\n    self.assertEqual(set(dequeued), set(URLS))\n    self.assertFalse(self.scheduler.has_pending_requests())",
    "hash_value": "09ba2bae5d5837971ff10fcb85c1c56a"
  }
]