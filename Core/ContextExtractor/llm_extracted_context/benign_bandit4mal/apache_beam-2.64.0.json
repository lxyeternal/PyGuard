[
  {
    "metadata": {
      "package_name": "apache_beam-2.64.0",
      "total_matches": 6,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "streaming_cache.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/apache_beam-2.64.0/apache_beam-2.64.0/apache_beam/runners/interactive/caching/streaming_cache.py",
    "line_number": "310",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "309\n310\t    reader = StreamingCacheSource(\n311\t        self._cache_dir,\n312\t        labels,\n313\t        self._is_cache_complete,\n314\t        self.load_pcoder(*labels)).read(tail=tail)\n315",
    "context_snippet": "def read(self, *labels, **args):\n    \"\"\"Returns a generator to read all records from file.\"\"\"\n    tail = args.pop('tail', False)\n\n    # Only immediately return when the file doesn't exist when the user wants a\n    # snapshot of the cache (when tail is false).\n    if not self.exists(*labels) and not tail:\n      return iter([]), -1\n\n    reader = StreamingCacheSource(\n        self._cache_dir,\n        labels,\n        self._is_cache_complete,\n        self.load_pcoder(*labels)).read(tail=tail)\n\n    # Return an empty iterator if there is nothing in the file yet. This can\n    # only happen when tail is False.\n    try:\n      header = next(reader)\n    except StopIteration:\n      return iter([]), -1\n    return StreamingCache.Reader([header], [reader]).read(), 1",
    "hash_value": "737d7d7903a2b7cc8928568764ab639d"
  },
  {
    "pyfile": "standard_coders_test.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/apache_beam-2.64.0/apache_beam-2.64.0/apache_beam/coders/standard_coders_test.py",
    "line_number": "310",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "309\t      doc_sep = '\\n---\\n'\n310\t      docs = open(STANDARD_CODERS_YAML).read().split(doc_sep)\n311",
    "context_snippet": "@classmethod\ndef tearDownClass(cls):\n    if cls.fix and cls.to_fix:\n      print(\"FIXING\", len(cls.to_fix), \"TESTS\")\n      doc_sep = '\\n---\\n'\n      docs = open(STANDARD_CODERS_YAML).read().split(doc_sep)\n\n      def quote(s):\n        return json.dumps(s.decode('latin1')).replace(r'\\u0000', r'\\0')\n\n      for (doc_ix, expected_encoded), actual_encoded in cls.to_fix.items():\n        print(quote(expected_encoded), \"->\", quote(actual_encoded))\n        docs[doc_ix] = docs[doc_ix].replace(\n            quote(expected_encoded) + ':', quote(actual_encoded) + ':')\n      open(STANDARD_CODERS_YAML, 'w').write(doc_sep.join(docs))",
    "hash_value": "b162c946f69e998a22db44087f9951b0"
  },
  {
    "pyfile": "flink_uber_jar_job_server.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/apache_beam-2.64.0/apache_beam-2.64.0/apache_beam/runners/portability/flink_uber_jar_job_server.py",
    "line_number": "187",
    "type_description": "B820:get",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "186\t    if flink_status == 'COMPLETED':\n187\t      flink_status = self.get('v1/jobs/%s' % self._flink_job_id)['state']\n188\t    beam_state = {",
    "context_snippet": "  def _get_state(self):\n    \"\"\"Query flink to get the current state.\n\n    :return: tuple of int and Timestamp or None\n      timestamp will be None if the state has not changed since the last query.\n    \"\"\"\n    # For just getting the status, execution-result seems cheaper.\n    flink_status = self.get('v1/jobs/%s/execution-result' %\n                            self._flink_job_id)['status']['id']\n    if flink_status == 'COMPLETED':\n      flink_status = self.get('v1/jobs/%s' % self._flink_job_id)['state']\n    beam_state = {\n        'CREATED': beam_job_api_pb2.JobState.STARTING,\n        'RUNNING': beam_job_api_pb2.JobState.RUNNING,\n        'FAILING': beam_job_api_pb2.JobState.RUNNING,\n        'FAILED': beam_job_api_pb2.JobState.FAILED,\n        'CANCELLING': beam_job_api_pb2.JobState.CANCELLING,\n        'CANCELED': beam_job_api_pb2.JobState.CANCELLED,\n        'FINISHED': beam_job_api_pb2.JobState.DONE,\n        'RESTARTING': beam_job_api_pb2.JobState.RUNNING,\n        'SUSPENDED': beam_job_api_pb2.JobState.RUNNING,\n        'RECONCILING': beam_job_api_pb2.JobState.RUNNING,\n        'IN_PROGRESS': beam_job_api_pb2.JobState.RUNNING,\n        'COMPLETED': beam_job_api_pb2.JobState.DONE,\n    }.get(flink_status, beam_job_api_pb2.JobState.UNSPECIFIED)\n    if self.is_terminal_state(beam_state):\n      self.delete_jar()\n    # update the state history if it has changed\n    return beam_state, self.set_state(beam_state)",
    "hash_value": "aaf4b116a40293cc947f4d4b337de680"
  },
  {
    "pyfile": "textio_test.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/apache_beam-2.64.0/apache_beam-2.64.0/apache_beam/io/textio_test.py",
    "line_number": "970",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "969\t      with gzip.GzipFile(file_name, 'wb') as f:\n970\t        f.write('\\n'.join(lines).encode('utf-8'))\n971",
    "context_snippet": "def test_read_auto_gzip(self):\n    _, lines = write_data(15)\n    with TempDir() as tempdir:\n      file_name = tempdir.create_temp_file(suffix='.gz')\n\n      with gzip.GzipFile(file_name, 'wb') as f:\n        f.write('\\n'.join(lines).encode('utf-8'))\n\n      with TestPipeline() as pipeline:\n        pcoll = pipeline | 'Read' >> ReadFromText(file_name)\n        assert_that(pcoll, equal_to(lines))",
    "hash_value": "ed3c3aaad6a9df4732410c41039cb526"
  },
  {
    "pyfile": "stager_test.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/apache_beam-2.64.0/apache_beam-2.64.0/apache_beam/runners/portability/stager_test.py",
    "line_number": "542",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "541\t      with open(to_path, 'w') as f:\n542\t        f.write('Package content.')\n543\t      return to_path",
    "context_snippet": "def file_download(_, to_path):\n  with open(to_path, 'w') as f:\n    f.write('Package content.')\n  return to_path",
    "hash_value": "6d337e4187d4fd544c7ce884b8609ba4"
  },
  {
    "pyfile": "tft_test.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/apache_beam-2.64.0/apache_beam-2.64.0/apache_beam/ml/transforms/tft_test.py",
    "line_number": "163",
    "type_description": "B836:rmtree",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "162\t  def tearDown(self):\n163\t    shutil.rmtree(self.artifact_location)\n164",
    "context_snippet": "class ScaleZScoreTest(unittest.TestCase):\n  def setUp(self) -> None:\n    self.artifact_location = tempfile.mkdtemp()\n\n  def tearDown(self):\n    shutil.rmtree(self.artifact_location)",
    "hash_value": "6f45bd7a25c2f275910f480794a9a2e5"
  }
]