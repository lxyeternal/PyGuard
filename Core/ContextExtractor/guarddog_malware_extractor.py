"""
Extract malicious code context from guarddog malware detection reports using LLM.
"""
import os
import json
import re
from pathlib import Path
import sys
import hashlib
from collections import defaultdict

PYGUARD_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PYGUARD_ROOT))
from Utils.llmquery import LLMAgent

SOURCE_DIR = str(PYGUARD_ROOT / "Core" / "ContextExtractor" / "tool_scan_output" / "guarddog" / "malware")
TARGET_DIR = str(PYGUARD_ROOT / "Core" / "ContextExtractor" / "llm_extracted_context" / "malware")
PROMPT_PATH = str(PYGUARD_ROOT / "Resources" / "Prompts" / "codeslice" / "malicious_code_extract.txt")

os.makedirs(TARGET_DIR, exist_ok=True)

def normalize_code(code_snippet):
    """Normalize code snippet, remove possible changes (e.g. variable names, spaces, etc.)"""
    normalized = re.sub(r'\s+', '', code_snippet)
    normalized = normalized.lower()
    return normalized

def hash_code(code_snippet):
    """Generate hash value for code snippet, for comparison similarity"""
    normalized = normalize_code(code_snippet)
    return hashlib.md5(normalized.encode()).hexdigest()

def extract_malicious_locations(txt_content):
    archive_pattern = r'Found \d+ potentially malicious indicators in (.*?)(\.tar\.gz|\.zip|\.whl)'
    archive_match = re.search(archive_pattern, txt_content)
    
    if not archive_match:
        print("Warning: Unable to extract compressed package path")
        return None, 0
    
    zip_path = archive_match.group(1) + archive_match.group(2)
    print(f"Extracted compressed package path: {zip_path}")
    
    lines = txt_content.split('\n')
    malicious_locations = {}
    current_type = ""
    match_count = 0
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        type_match = re.match(r'^([\w\-]+): found (\d+) .* matches', line)
        if type_match:
            current_type = line
            match_count_str = type_match.group(2)
            try:
                match_count += int(match_count_str)
            except ValueError:
                pass
            print(f"Found type description: {current_type}")
            i += 1
            continue
        
        location_match = re.search(r'\*.*?\s+at\s+([\w\-\.\/]+\.py):(\d+)', line)
        if location_match and current_type:
            relative_path = location_match.group(1)
            line_number = location_match.group(2)
            
            print(f"Found file location: {relative_path}:{line_number}")
            
            full_path = zip_path.replace('zip_malware', 'unzip_malware').replace('.tar.gz', '').replace('.zip', '').replace('.whl', '') + '/' + relative_path
            
            code_lines = []
            j = i + 1
            while j < len(lines):
                next_line = lines[j].strip()
                if not next_line or next_line.startswith('*') or re.match(r'^[\w\-]+: found \d+ .* matches', next_line):
                    break
                code_line = re.sub(r'^\s+', '', next_line)
                code_lines.append(code_line)
                j += 1
            
            code_snippet = '\n'.join(code_lines)
            
            location_info = {
                'line_number': line_number,
                'type_description': current_type,
                'code_snippet': code_snippet,
                'full_match': line,
                'full_path': full_path
            }
            
            if full_path not in malicious_locations:
                malicious_locations[full_path] = []
                print(f"Add new file path: {full_path}")
            
            malicious_locations[full_path].append(location_info)
            
            i = j
            continue
        
        i += 1
    
    if not malicious_locations:
        print("Warning: No malicious code location found")
    else:
        print(f"Found {len(malicious_locations)} files with malicious code locations")
    
    return malicious_locations, match_count

def read_source_code(file_path):
    """Read source code file content"""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            return f.read()
    except Exception as e:
        print(f"Error reading file {file_path}: {e}")
        return None

def process_with_llm(code_content, detection_info, prompt_template):
    try:
        with open(prompt_template, 'r', encoding='utf-8') as f:
            prompt = f.read()
        
        full_code = code_content
        
        detection_context = "Detection information:\n"
        for info in detection_info:
            detection_context += f"- Line {info['line_number']}: {info['type_description']}\n"
            detection_context += f"  {info['code_snippet']}\n"
        
        code_with_context = f"{detection_context}\nSource code:\n{full_code}"
        prompt = prompt.replace("{CODE}", code_with_context)
        
        llm_agent = LLMAgent()
        
        messages = [
            {"role": "system", "content": "You are an expert malware code analyst."},
            {"role": "user", "content": prompt}
        ]
        
        response = llm_agent.perform_query(messages)
        
        return response
    except Exception as e:
        print(f"LLM处理失败: {e}")
        return None

def is_benign(txt_content):
    """判断报告是否表明代码是良性的（没有恶意代码）"""
    if "Found 0 potentially malicious indicators" in txt_content or "benign" in txt_content.lower():
        return True
    return False

def main():
    """主函数，处理所有报告文件"""
    txt_files = [f for f in os.listdir(SOURCE_DIR) if f.endswith('.txt')]
    print(f"找到 {len(txt_files)} 个txt文件")
    
    processed = 0
    skipped_exists = 0
    skipped_duplicate = 0
    failed = 0
    
    processed_code_hashes = {}
    code_hash_map = {}
    analyzed_code_hashes = {}
    
    simple_malware_files = []
    for txt_file in txt_files:
        print(f"\n预处理文件: {txt_file}")
        txt_path = os.path.join(SOURCE_DIR, txt_file)
        
        try:
            with open(txt_path, 'r', encoding='utf-8', errors='ignore') as f:
                txt_content = f.read()
            
            if is_benign(txt_content):
                print(f"{txt_file} 没有恶意代码，跳过")
                continue
            
            malicious_locations, match_count = extract_malicious_locations(txt_content)
            
            if match_count == 1 and malicious_locations and len(malicious_locations) == 1:
                print(f"{txt_file} 只有一个匹配，加入简单恶意包列表")
                
                full_path = next(iter(malicious_locations.keys()))
                location_infos = malicious_locations[full_path]
                code_hash = hash_code(location_infos[0]['code_snippet'])
                
                simple_malware_files.append((txt_file, txt_path, malicious_locations, code_hash))
            else:
                print(f"{txt_file} 有多个匹配 ({match_count})，不作为简单恶意包处理")
                
        except Exception as e:
            print(f"预处理文件 {txt_file} 时出错: {e}")
    
    print(f"\n找到 {len(simple_malware_files)} 个简单恶意包（只有一个匹配）")
    
    print("\n进行代码去重...")
    unique_code_hashes = set()
    duplicate_packages = []
    
    for txt_file, txt_path, malicious_locations, code_hash in simple_malware_files:
        if code_hash in unique_code_hashes:
            print(f"{txt_file} 包含重复的恶意代码，将被跳过")
            duplicate_packages.append(txt_file)
        else:
            unique_code_hashes.add(code_hash)
    
    print(f"发现 {len(unique_code_hashes)} 个唯一的恶意代码模式")
    print(f"发现 {len(duplicate_packages)} 个包含重复恶意代码的包")
    
    for txt_file, txt_path, malicious_locations, code_hash in simple_malware_files:
        print(f"\n处理简单恶意包: {txt_file}")
        
        json_file = os.path.join(TARGET_DIR, os.path.splitext(txt_file)[0] + '.json')
        if os.path.exists(json_file):
            print(f"跳过已处理的文件: {txt_file}")
            skipped_exists += 1
            continue
        
        if code_hash in analyzed_code_hashes:
            first_package = analyzed_code_hashes[code_hash]
            print(f"跳过重复的恶意代码 (与 {first_package} 重复)，不生成JSON")
            
            if code_hash in code_hash_map:
                code_hash_map[code_hash]['packages'].append(txt_file)
            
            skipped_duplicate += 1
            continue
        
        try:
            full_path = next(iter(malicious_locations.keys()))
            location_infos = malicious_locations[full_path]
            
            code_content = read_source_code(full_path)
            if not code_content:
                print(f"无法读取源代码: {full_path}")
                failed += 1
                continue
            
            analyzed_code_hashes[code_hash] = txt_file
            
            llm_result = None
            if code_hash in processed_code_hashes:
                print(f"发现重复代码片段，复用之前的LLM分析结果")
                llm_result = processed_code_hashes[code_hash]
            else:
                print(f"使用LLM分析新的代码片段")
                llm_result = process_with_llm(code_content, location_infos, PROMPT_PATH)
                if not llm_result:
                    print(f"LLM处理失败: {full_path}")
                    failed += 1
                    continue
                
                processed_code_hashes[code_hash] = llm_result
            
            code_hash_map[code_hash] = {
                'code': location_infos[0]['code_snippet'],
                'type': location_infos[0]['type_description'],
                'packages': [txt_file],
                'first_analysis_package': txt_file,
                'first_analysis_path': full_path
            }
            
            try:
                json_match = re.search(r'```json\s*(.*?)\s*```', llm_result, re.DOTALL)
                if json_match:
                    file_result = json.loads(json_match.group(1))
                else:
                    file_result = json.loads(llm_result)
                
                if "malicious_code" in file_result:
                    if file_result["malicious_code"].strip() == "":
                        print(f"LLM判断文件 {full_path} 不包含恶意代码，跳过")
                        continue
                    
                    file_name = os.path.basename(full_path)
                    
                    final_result = []
                    
                    malicious_entry = {
                        "pyfile": file_name,
                        "malicious_code_snippets": file_result["malicious_code"],
                        "hash_value": code_hash
                    }
                    
                    final_result.append(malicious_entry)
                    
                    metadata_entry = {
                        "metadata": {
                            "package_name": os.path.splitext(txt_file)[0],
                            "report_path": txt_path,
                            "source_path": full_path,
                            "code_hash": code_hash
                        }
                    }
                    final_result.append(metadata_entry)
                    
                    with open(json_file, 'w', encoding='utf-8') as f:
                        json.dump(final_result, f, ensure_ascii=False, indent=2)
                    
                    print(f"已生成JSON文件: {json_file}")
                    processed += 1
                else:
                    print(f"警告: LLM返回的JSON没有'malicious_code'字段: {full_path}")
                    failed += 1
                
            except json.JSONDecodeError as e:
                print(f"无法解析LLM返回的JSON: {full_path}, 错误: {e}")
                file_name = os.path.basename(full_path).replace('.', '_')
                debug_file = os.path.join(TARGET_DIR, f"{os.path.splitext(txt_file)[0]}_{file_name}_debug.txt")
                with open(debug_file, 'w', encoding='utf-8') as f:
                    f.write(llm_result)
                
                print(f"已保存原始响应: {debug_file}")
                failed += 1
            
        except Exception as e:
            print(f"处理文件 {txt_file} 时出错: {e}")
            failed += 1
    
    print("\n生成恶意代码重复性报告...")
    duplicate_report = []
    
    for code_hash, info in code_hash_map.items():
        if len(info['packages']) > 1:
            duplicate_report.append({
                "hash": code_hash,
                "count": len(info['packages']),
                "packages": info['packages'],
                "code": info['code'],
                "type": info['type'],
                "first_analysis": info['first_analysis_package'],
                "first_path": info['first_analysis_path']
            })
    
    duplicate_report.sort(key=lambda x: x['count'], reverse=True)
    
    dup_report_path = os.path.join(TARGET_DIR, "duplicate_code_report.json")
    with open(dup_report_path, 'w', encoding='utf-8') as f:
        json.dump(duplicate_report, f, ensure_ascii=False, indent=2)
    
    duplicate_index = {}
    for dup_pattern in duplicate_report:
        for pkg in dup_pattern['packages'][1:]:
            duplicate_index[pkg] = {
                "hash": dup_pattern['hash'],
                "duplicate_of": dup_pattern['first_analysis'],
                "total_duplicates": dup_pattern['count']
            }
    
    dup_index_path = os.path.join(TARGET_DIR, "duplicate_package_index.json")
    with open(dup_index_path, 'w', encoding='utf-8') as f:
        json.dump(duplicate_index, f, ensure_ascii=False, indent=2)
    
    summary_path = os.path.join(TARGET_DIR, "processing_summary.txt")
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write(f"恶意代码处理摘要\n")
        f.write(f"==============\n\n")
        f.write(f"总计txt文件: {len(txt_files)}\n")
        f.write(f"简单恶意包文件(只有一个匹配): {len(simple_malware_files)}\n")
        f.write(f"成功处理: {processed}\n")
        f.write(f"跳过(已存在): {skipped_exists}\n")
        f.write(f"跳过(重复代码): {skipped_duplicate}\n")
        f.write(f"处理失败: {failed}\n\n")
        
        f.write(f"唯一恶意代码模式: {len(unique_code_hashes)}\n")
        f.write(f"重复的恶意代码模式: {len(duplicate_report)}\n\n")
        
        if duplicate_report:
            f.write(f"重复恶意代码模式前10个:\n")
            f.write(f"-------------------\n\n")
            for i, pattern in enumerate(duplicate_report[:10], 1):
                f.write(f"{i}. 出现次数: {pattern['count']} 个包\n")
                f.write(f"   类型: {pattern['type']}\n")
                f.write(f"   哈希值: {pattern['hash']}\n")
                f.write(f"   首次分析包: {pattern['first_analysis']}\n")
                f.write(f"   代码:\n")
                for line in pattern['code'].split('\n'):
                    f.write(f"     {line}\n")
                f.write(f"   包列表: {', '.join(pattern['packages'][:5])}{'...' if len(pattern['packages']) > 5 else ''}\n\n")
    
    print(f"\n处理完成: 成功 {processed} 个, 跳过(已存在) {skipped_exists} 个, 跳过(重复) {skipped_duplicate} 个, 失败 {failed} 个")
    print(f"唯一恶意代码模式: {len(unique_code_hashes)}")
    print(f"重复的恶意代码模式: {len(duplicate_report)}")
    print(f"重复代码报告已保存到: {dup_report_path}")
    print(f"重复包索引已保存到: {dup_index_path}")
    print(f"处理摘要已保存到: {summary_path}")

if __name__ == "__main__":
    main() 