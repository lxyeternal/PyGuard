[31m--[ [0m[34mMatch #[0m[33m1[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m140 | [0m[35m                metadata["parentClass"] = s.get("title")[0m
[30;1m141 | [0m[35m                struct_field = {[0m
[30;1m142 | [0m[35m                    "name": key,[0m
[30;1m143 | [0m[35m                    "nullable": "default" not in metadata and value.get("anyOf") is not None,[0m
[30;1m144 | [0m[35m                    "metadata": metadata,[0m
[30;1m145 | [0m[35m                    "type": spark_type,[0m
[30;1m146 | [0m[35m                }[0m

[31m--[ [0m[34mMatch #[0m[33m2[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m137 | [0m[35m[0m
[30;1m138 | [0m[35m            for key, value in s.get("properties", {}).items():[0m
[30;1m139 | [0m[35m                spark_type, metadata = get_type(value)[0m
[30;1m140 | [0m[35m                metadata["parentClass"] = s.get("title")[0m
[30;1m141 | [0m[35m                struct_field = {[0m
[30;1m142 | [0m[35m                    "name": key,[0m
[30;1m143 | [0m[35m                    "nullable": "default" not in metadata and value.get("anyOf") is not None,[0m

[31m--[ [0m[34mMatch #[0m[33m3[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m135 | [0m[35m            """Return a list of fields of a struct"""[0m
[30;1m136 | [0m[35m            fields = [][0m
[30;1m137 | [0m[35m[0m
[30;1m138 | [0m[35m            for key, value in s.get("properties", {}).items():[0m
[30;1m139 | [0m[35m                spark_type, metadata = get_type(value)[0m
[30;1m140 | [0m[35m                metadata["parentClass"] = s.get("title")[0m
[30;1m141 | [0m[35m                struct_field = {[0m

[31m--[ [0m[34mMatch #[0m[33m4[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m122 | [0m[35m                else:[0m
[30;1m123 | [0m[35m                    value_type, m = get_type(a)[0m
[30;1m124 | [0m[35m                # if isinstance(value_type, dict) and len(value_type) == 1:[0m
[30;1m125 | [0m[35m                # value_type = value_type.get("type")[0m
[30;1m126 | [0m[35m                spark_type = {"keyType": "string", "type": "map", "valueContainsNull": True, "valueT[0m
[30;1m127 | [0m[35m            else:[0m
[30;1m128 | [0m[35m                raise NotImplementedError([0m

[31m--[ [0m[34mMatch #[0m[33m5[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m86 | [0m[35m                    spark_type = get_type_of_definition(r, schema)[0m
[30;1m87 | [0m[35m                    classes_seen[class_name] = spark_type[0m
[30;1m88 | [0m[35m            elif t == "array":[0m
[30;1m89 | [0m[35m                items = value.get("items")[0m
[30;1m90 | [0m[35m                tn, metadata = get_type(items)[0m
[30;1m91 | [0m[35m                spark_type = {[0m
[30;1m92 | [0m[35m                    "type": "array",[0m

[31m--[ [0m[34mMatch #[0m[33m6[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m77 | [0m[35m                    NotImplementedError(f"Union type {ao} is not supported yet. Use coerce_type opti[0m
[30;1m78 | [0m[35m[0m
[30;1m79 | [0m[35m            if "default" in value:[0m
[30;1m80 | [0m[35m                metadata["default"] = value.get("default")[0m
[30;1m81 | [0m[35m            if r is not None:[0m
[30;1m82 | [0m[35m                class_name = r.replace("#/definitions/", "")[0m
[30;1m83 | [0m[35m                if class_name in classes_seen:[0m

[31m--[ [0m[34mMatch #[0m[33m7[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m72 | [0m[35m                if len(ao) == 2 and (ao[0].get("type") == "null" or ao[1].get("type") == "null"):[0m
[30;1m73 | [0m[35m                    # this is an optional column. We will remove the null type[0m
[30;1m74 | [0m[35m                    t = ao[0].get("type") if ao[0].get("type") != "null" else ao[1].get("type")[0m
[30;1m75 | [0m[35m                    f = ao[0].get("format") if ao[0].get("type") != "null" else ao[1].get("format")[0m
[30;1m76 | [0m[35m                else:[0m
[30;1m77 | [0m[35m                    NotImplementedError(f"Union type {ao} is not supported yet. Use coerce_type opti[0m
[30;1m78 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m8[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m72 | [0m[35m                if len(ao) == 2 and (ao[0].get("type") == "null" or ao[1].get("type") == "null"):[0m
[30;1m73 | [0m[35m                    # this is an optional column. We will remove the null type[0m
[30;1m74 | [0m[35m                    t = ao[0].get("type") if ao[0].get("type") != "null" else ao[1].get("type")[0m
[30;1m75 | [0m[35m                    f = ao[0].get("format") if ao[0].get("type") != "null" else ao[1].get("format")[0m
[30;1m76 | [0m[35m                else:[0m
[30;1m77 | [0m[35m                    NotImplementedError(f"Union type {ao} is not supported yet. Use coerce_type opti[0m
[30;1m78 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m9[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m72 | [0m[35m                if len(ao) == 2 and (ao[0].get("type") == "null" or ao[1].get("type") == "null"):[0m
[30;1m73 | [0m[35m                    # this is an optional column. We will remove the null type[0m
[30;1m74 | [0m[35m                    t = ao[0].get("type") if ao[0].get("type") != "null" else ao[1].get("type")[0m
[30;1m75 | [0m[35m                    f = ao[0].get("format") if ao[0].get("type") != "null" else ao[1].get("format")[0m
[30;1m76 | [0m[35m                else:[0m
[30;1m77 | [0m[35m                    NotImplementedError(f"Union type {ao} is not supported yet. Use coerce_type opti[0m
[30;1m78 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m10[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m71 | [0m[35m            if ao is not None:[0m
[30;1m72 | [0m[35m                if len(ao) == 2 and (ao[0].get("type") == "null" or ao[1].get("type") == "null"):[0m
[30;1m73 | [0m[35m                    # this is an optional column. We will remove the null type[0m
[30;1m74 | [0m[35m                    t = ao[0].get("type") if ao[0].get("type") != "null" else ao[1].get("type")[0m
[30;1m75 | [0m[35m                    f = ao[0].get("format") if ao[0].get("type") != "null" else ao[1].get("format")[0m
[30;1m76 | [0m[35m                else:[0m
[30;1m77 | [0m[35m                    NotImplementedError(f"Union type {ao} is not supported yet. Use coerce_type opti[0m

[31m--[ [0m[34mMatch #[0m[33m11[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m71 | [0m[35m            if ao is not None:[0m
[30;1m72 | [0m[35m                if len(ao) == 2 and (ao[0].get("type") == "null" or ao[1].get("type") == "null"):[0m
[30;1m73 | [0m[35m                    # this is an optional column. We will remove the null type[0m
[30;1m74 | [0m[35m                    t = ao[0].get("type") if ao[0].get("type") != "null" else ao[1].get("type")[0m
[30;1m75 | [0m[35m                    f = ao[0].get("format") if ao[0].get("type") != "null" else ao[1].get("format")[0m
[30;1m76 | [0m[35m                else:[0m
[30;1m77 | [0m[35m                    NotImplementedError(f"Union type {ao} is not supported yet. Use coerce_type opti[0m

[31m--[ [0m[34mMatch #[0m[33m12[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m71 | [0m[35m            if ao is not None:[0m
[30;1m72 | [0m[35m                if len(ao) == 2 and (ao[0].get("type") == "null" or ao[1].get("type") == "null"):[0m
[30;1m73 | [0m[35m                    # this is an optional column. We will remove the null type[0m
[30;1m74 | [0m[35m                    t = ao[0].get("type") if ao[0].get("type") != "null" else ao[1].get("type")[0m
[30;1m75 | [0m[35m                    f = ao[0].get("format") if ao[0].get("type") != "null" else ao[1].get("format")[0m
[30;1m76 | [0m[35m                else:[0m
[30;1m77 | [0m[35m                    NotImplementedError(f"Union type {ao} is not supported yet. Use coerce_type opti[0m

[31m--[ [0m[34mMatch #[0m[33m13[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m69 | [0m[35m                return ft, metadata[0m
[30;1m70 | [0m[35m[0m
[30;1m71 | [0m[35m            if ao is not None:[0m
[30;1m72 | [0m[35m                if len(ao) == 2 and (ao[0].get("type") == "null" or ao[1].get("type") == "null"):[0m
[30;1m73 | [0m[35m                    # this is an optional column. We will remove the null type[0m
[30;1m74 | [0m[35m                    t = ao[0].get("type") if ao[0].get("type") != "null" else ao[1].get("type")[0m
[30;1m75 | [0m[35m                    f = ao[0].get("format") if ao[0].get("type") != "null" else ao[1].get("format")[0m

[31m--[ [0m[34mMatch #[0m[33m14[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m69 | [0m[35m                return ft, metadata[0m
[30;1m70 | [0m[35m[0m
[30;1m71 | [0m[35m            if ao is not None:[0m
[30;1m72 | [0m[35m                if len(ao) == 2 and (ao[0].get("type") == "null" or ao[1].get("type") == "null"):[0m
[30;1m73 | [0m[35m                    # this is an optional column. We will remove the null type[0m
[30;1m74 | [0m[35m                    t = ao[0].get("type") if ao[0].get("type") != "null" else ao[1].get("type")[0m
[30;1m75 | [0m[35m                    f = ao[0].get("format") if ao[0].get("type") != "null" else ao[1].get("format")[0m

[31m--[ [0m[34mMatch #[0m[33m15[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m62 | [0m[35m            f = value.get("format")[0m
[30;1m63 | [0m[35m            r = value.get("$ref")[0m
[30;1m64 | [0m[35m            a = value.get("additionalProperties")[0m
[30;1m65 | [0m[35m            ft = value.get("coerce_type")[0m
[30;1m66 | [0m[35m            metadata = {}[0m
[30;1m67 | [0m[35m[0m
[30;1m68 | [0m[35m            if ft is not None:[0m

[31m--[ [0m[34mMatch #[0m[33m16[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m61 | [0m[35m            ao = value.get("anyOf")[0m
[30;1m62 | [0m[35m            f = value.get("format")[0m
[30;1m63 | [0m[35m            r = value.get("$ref")[0m
[30;1m64 | [0m[35m            a = value.get("additionalProperties")[0m
[30;1m65 | [0m[35m            ft = value.get("coerce_type")[0m
[30;1m66 | [0m[35m            metadata = {}[0m
[30;1m67 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m17[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m60 | [0m[35m            t = value.get("type")[0m
[30;1m61 | [0m[35m            ao = value.get("anyOf")[0m
[30;1m62 | [0m[35m            f = value.get("format")[0m
[30;1m63 | [0m[35m            r = value.get("$ref")[0m
[30;1m64 | [0m[35m            a = value.get("additionalProperties")[0m
[30;1m65 | [0m[35m            ft = value.get("coerce_type")[0m
[30;1m66 | [0m[35m            metadata = {}[0m

[31m--[ [0m[34mMatch #[0m[33m18[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m59 | [0m[35m            """Returns a type of single field"""[0m
[30;1m60 | [0m[35m            t = value.get("type")[0m
[30;1m61 | [0m[35m            ao = value.get("anyOf")[0m
[30;1m62 | [0m[35m            f = value.get("format")[0m
[30;1m63 | [0m[35m            r = value.get("$ref")[0m
[30;1m64 | [0m[35m            a = value.get("additionalProperties")[0m
[30;1m65 | [0m[35m            ft = value.get("coerce_type")[0m

[31m--[ [0m[34mMatch #[0m[33m19[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m58 | [0m[35m        def get_type(value: dict) -> Tuple[str, dict]:[0m
[30;1m59 | [0m[35m            """Returns a type of single field"""[0m
[30;1m60 | [0m[35m            t = value.get("type")[0m
[30;1m61 | [0m[35m            ao = value.get("anyOf")[0m
[30;1m62 | [0m[35m            f = value.get("format")[0m
[30;1m63 | [0m[35m            r = value.get("$ref")[0m
[30;1m64 | [0m[35m            a = value.get("additionalProperties")[0m

[31m--[ [0m[34mMatch #[0m[33m20[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m57 | [0m[35m[0m
[30;1m58 | [0m[35m        def get_type(value: dict) -> Tuple[str, dict]:[0m
[30;1m59 | [0m[35m            """Returns a type of single field"""[0m
[30;1m60 | [0m[35m            t = value.get("type")[0m
[30;1m61 | [0m[35m            ao = value.get("anyOf")[0m
[30;1m62 | [0m[35m            f = value.get("format")[0m
[30;1m63 | [0m[35m            r = value.get("$ref")[0m

[31m--[ [0m[34mMatch #[0m[33m21[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m40 | [0m[35m            d = get_definition(ref, schema)[0m
[30;1m41 | [0m[35m[0m
[30;1m42 | [0m[35m            if "enum" in d:[0m
[30;1m43 | [0m[35m                enum_type = d.get("type")[0m
[30;1m44 | [0m[35m                if enum_type == "string":[0m
[30;1m45 | [0m[35m                    return "string"[0m
[30;1m46 | [0m[35m                elif enum_type == "numeric":[0m

[31m--[ [0m[34mMatch #[0m[33m22[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m30 | [0m[35m[0m
[30;1m31 | [0m[35m        def get_definition(ref: str, schema: dict):[0m
[30;1m32 | [0m[35m            id = ref.replace("#/$defs/", "")[0m
[30;1m33 | [0m[35m            d = schema.get("$defs", {}).get(id)[0m
[30;1m34 | [0m[35m            if d is None:[0m
[30;1m35 | [0m[35m                raise RuntimeError(f"Definition {id} does not exist")[0m
[30;1m36 | [0m[35m            return d[0m

[31m--[ [0m[34mMatch #[0m[33m23[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m30 | [0m[35m[0m
[30;1m31 | [0m[35m        def get_definition(ref: str, schema: dict):[0m
[30;1m32 | [0m[35m            id = ref.replace("#/$defs/", "")[0m
[30;1m33 | [0m[35m            d = schema.get("$defs", {}).get(id)[0m
[30;1m34 | [0m[35m            if d is None:[0m
[30;1m35 | [0m[35m                raise RuntimeError(f"Definition {id} does not exist")[0m
[30;1m36 | [0m[35m            return d[0m

[31m--[ [0m[34mMatch #[0m[33m24[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m97 | [0m[35m                spark_type = "timestamp"[0m
[30;1m98 | [0m[35m            elif t == "string" and f == "date":[0m
[30;1m99 | [0m[35m                spark_type = "date"[0m
[30;1m100 | [0m[35m            # elif t == "string" and f == "time":  # FIXME: time type in spark does not exist[0m
[30;1m101 | [0m[35m            #     spark_type = {[0m
[30;1m102 | [0m[35m            #         "type": "long",[0m
[30;1m103 | [0m[35m            #         "logicalType": "time-micros",[0m

[31m--[ [0m[34mMatch #[0m[33m25[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/src/pydantic_spark/base.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m127 | [0m[35m            else:[0m
[30;1m128 | [0m[35m                raise NotImplementedError([0m
[30;1m129 | [0m[35m                    f"Type '{t}' not support yet, "[0m
[30;1m130 | [0m[35m                    f"please report this at https://github.com/godatadriven/pydantic-avro/issues"[0m
[30;1m131 | [0m[35m                )[0m
[30;1m132 | [0m[35m            return spark_type, metadata[0m
[30;1m133 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m26[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/PKG-INFO[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m32 | [0m[35m[0m
[30;1m33 | [0m[35m### Install[0m
[30;1m34 | [0m[35m[0m
[30;1m35 | [0m[35m```bash[0m
[30;1m36 | [0m[35mpip install pydantic-spark[0m
[30;1m37 | [0m[35m```[0m
[30;1m38 | [0m[35m[0m
[30;1m39 | [0m[35m### Pydantic class to spark schema[0m

[31m--[ [0m[34mMatch #[0m[33m27[0m[34m of [0m[33m27[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/pydantic_spark-1.0.1/README.md[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m9 | [0m[35m[0m
[30;1m10 | [0m[35m### Install[0m
[30;1m11 | [0m[35m[0m
[30;1m12 | [0m[35m```bash[0m
[30;1m13 | [0m[35mpip install pydantic-spark[0m
[30;1m14 | [0m[35m```[0m
[30;1m15 | [0m[35m[0m
[30;1m16 | [0m[35m### Pydantic class to spark schema[0m

27 matches found.
