[31m--[ [0m[34mMatch #[0m[33m1[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1011 | [0m[35m[0m
[30;1m1012 | [0m[35m* ``Databricks: add more methods to represent run state information (#19723)``[0m
[30;1m1013 | [0m[35m* ``Databricks - allow Azure SP authentication on other Azure clouds (#19722)``[0m
[30;1m1014 | [0m[35m* ``Databricks: allow to specify PAT in Password field (#19585)``[0m
[30;1m1015 | [0m[35m* ``Databricks jobs 2.1 (#19544)``[0m
[30;1m1016 | [0m[35m* ``Update Databricks API from 2.0 to 2.1 (#19412)``[0m
[30;1m1017 | [0m[35m* ``Authentication with AAD tokens in Databricks provider (#19335)``[0m

[31m--[ [0m[34mMatch #[0m[33m2[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m715 | [0m[35m            auth = BearerAuth(token)[0m
[30;1m716 | [0m[35m        else:[0m
[30;1m717 | [0m[35m            self.log.info("Using basic auth.")[0m
[30;1m718 | [0m[35m            auth = aiohttp.BasicAuth(self.databricks_conn.login, self.databricks_conn.password)[0m
[30;1m719 | [0m[35m[0m
[30;1m720 | [0m[35m        request_func: Any[0m
[30;1m721 | [0m[35m        if method == "GET":[0m

[31m--[ [0m[34mMatch #[0m[33m3[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m649 | [0m[35m            auth = _TokenAuth(token)[0m
[30;1m650 | [0m[35m        else:[0m
[30;1m651 | [0m[35m            self.log.info("Using basic auth.")[0m
[30;1m652 | [0m[35m            auth = HTTPBasicAuth(self.databricks_conn.login, self.databricks_conn.password)[0m
[30;1m653 | [0m[35m[0m
[30;1m654 | [0m[35m        request_func: Any[0m
[30;1m655 | [0m[35m        if method == "GET":[0m

[31m--[ [0m[34mMatch #[0m[33m4[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m603 | [0m[35m[0m
[30;1m604 | [0m[35m            return await self._a_get_aad_token_for_default_az_credential(DEFAULT_DATABRICKS_SCOPE)[0m
[30;1m605 | [0m[35m        elif self.databricks_conn.extra_dejson.get("service_principal_oauth", False):[0m
[30;1m606 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m607 | [0m[35m                raise AirflowException("Service Principal credentials aren't provided")[0m
[30;1m608 | [0m[35m            self.log.debug("Using Service Principal Token.")[0m
[30;1m609 | [0m[35m            return await self._a_get_sp_token(OIDC_TOKEN_SERVICE_URL.format(self.databricks_conn.hos[0m

[31m--[ [0m[34mMatch #[0m[33m5[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m590 | [0m[35m            self.log.debug("Using token auth.")[0m
[30;1m591 | [0m[35m            return self.databricks_conn.password[0m
[30;1m592 | [0m[35m        elif "azure_tenant_id" in self.databricks_conn.extra_dejson:[0m
[30;1m593 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m594 | [0m[35m                raise AirflowException("Azure SPN credentials aren't provided")[0m
[30;1m595 | [0m[35m            self.log.debug("Using AAD Token for SPN.")[0m
[30;1m596 | [0m[35m            return await self._a_get_aad_token(DEFAULT_DATABRICKS_SCOPE)[0m

[31m--[ [0m[34mMatch #[0m[33m6[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m588 | [0m[35m            return self.databricks_conn.extra_dejson["token"][0m
[30;1m589 | [0m[35m        elif not self.databricks_conn.login and self.databricks_conn.password:[0m
[30;1m590 | [0m[35m            self.log.debug("Using token auth.")[0m
[30;1m591 | [0m[35m            return self.databricks_conn.password[0m
[30;1m592 | [0m[35m        elif "azure_tenant_id" in self.databricks_conn.extra_dejson:[0m
[30;1m593 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m594 | [0m[35m                raise AirflowException("Azure SPN credentials aren't provided")[0m

[31m--[ [0m[34mMatch #[0m[33m7[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m586 | [0m[35m                "Using token auth. For security reasons, please set token in Password field instead [0m
[30;1m587 | [0m[35m            )[0m
[30;1m588 | [0m[35m            return self.databricks_conn.extra_dejson["token"][0m
[30;1m589 | [0m[35m        elif not self.databricks_conn.login and self.databricks_conn.password:[0m
[30;1m590 | [0m[35m            self.log.debug("Using token auth.")[0m
[30;1m591 | [0m[35m            return self.databricks_conn.password[0m
[30;1m592 | [0m[35m        elif "azure_tenant_id" in self.databricks_conn.extra_dejson:[0m

[31m--[ [0m[34mMatch #[0m[33m8[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m583 | [0m[35m    async def _a_get_token(self, raise_error: bool = False) -> str | None:[0m
[30;1m584 | [0m[35m        if "token" in self.databricks_conn.extra_dejson:[0m
[30;1m585 | [0m[35m            self.log.info([0m
[30;1m586 | [0m[35m                "Using token auth. For security reasons, please set token in Password field instead [0m
[30;1m587 | [0m[35m            )[0m
[30;1m588 | [0m[35m            return self.databricks_conn.extra_dejson["token"][0m
[30;1m589 | [0m[35m        elif not self.databricks_conn.login and self.databricks_conn.password:[0m

[31m--[ [0m[34mMatch #[0m[33m9[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m571 | [0m[35m            self.log.debug("Using default Azure Credential authentication.")[0m
[30;1m572 | [0m[35m            return self._get_aad_token_for_default_az_credential(DEFAULT_DATABRICKS_SCOPE)[0m
[30;1m573 | [0m[35m        elif self.databricks_conn.extra_dejson.get("service_principal_oauth", False):[0m
[30;1m574 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m575 | [0m[35m                raise AirflowException("Service Principal credentials aren't provided")[0m
[30;1m576 | [0m[35m            self.log.debug("Using Service Principal Token.")[0m
[30;1m577 | [0m[35m            return self._get_sp_token(OIDC_TOKEN_SERVICE_URL.format(self.databricks_conn.host))[0m

[31m--[ [0m[34mMatch #[0m[33m10[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m559 | [0m[35m            self.log.debug("Using token auth.")[0m
[30;1m560 | [0m[35m            return self.databricks_conn.password[0m
[30;1m561 | [0m[35m        elif "azure_tenant_id" in self.databricks_conn.extra_dejson:[0m
[30;1m562 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m563 | [0m[35m                raise AirflowException("Azure SPN credentials aren't provided")[0m
[30;1m564 | [0m[35m            self.log.debug("Using AAD Token for SPN.")[0m
[30;1m565 | [0m[35m            return self._get_aad_token(DEFAULT_DATABRICKS_SCOPE)[0m

[31m--[ [0m[34mMatch #[0m[33m11[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m557 | [0m[35m            return self.databricks_conn.extra_dejson["token"][0m
[30;1m558 | [0m[35m        elif not self.databricks_conn.login and self.databricks_conn.password:[0m
[30;1m559 | [0m[35m            self.log.debug("Using token auth.")[0m
[30;1m560 | [0m[35m            return self.databricks_conn.password[0m
[30;1m561 | [0m[35m        elif "azure_tenant_id" in self.databricks_conn.extra_dejson:[0m
[30;1m562 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m563 | [0m[35m                raise AirflowException("Azure SPN credentials aren't provided")[0m

[31m--[ [0m[34mMatch #[0m[33m12[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m555 | [0m[35m                "Using token auth. For security reasons, please set token in Password field instead [0m
[30;1m556 | [0m[35m            )[0m
[30;1m557 | [0m[35m            return self.databricks_conn.extra_dejson["token"][0m
[30;1m558 | [0m[35m        elif not self.databricks_conn.login and self.databricks_conn.password:[0m
[30;1m559 | [0m[35m            self.log.debug("Using token auth.")[0m
[30;1m560 | [0m[35m            return self.databricks_conn.password[0m
[30;1m561 | [0m[35m        elif "azure_tenant_id" in self.databricks_conn.extra_dejson:[0m

[31m--[ [0m[34mMatch #[0m[33m13[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m552 | [0m[35m    def _get_token(self, raise_error: bool = False) -> str | None:[0m
[30;1m553 | [0m[35m        if "token" in self.databricks_conn.extra_dejson:[0m
[30;1m554 | [0m[35m            self.log.info([0m
[30;1m555 | [0m[35m                "Using token auth. For security reasons, please set token in Password field instead [0m
[30;1m556 | [0m[35m            )[0m
[30;1m557 | [0m[35m            return self.databricks_conn.extra_dejson["token"][0m
[30;1m558 | [0m[35m        elif not self.databricks_conn.login and self.databricks_conn.password:[0m

[31m--[ [0m[34mMatch #[0m[33m14[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m498 | [0m[35m        return headers[0m
[30;1m499 | [0m[35m[0m
[30;1m500 | [0m[35m    @staticmethod[0m
[30;1m501 | [0m[35m    def _is_oauth_token_valid(token: dict, time_key="expires_on") -> bool:[0m
[30;1m502 | [0m[35m        """[0m
[30;1m503 | [0m[35m        Check if an OAuth token is valid and hasn't expired yet.[0m
[30;1m504 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m15[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m455 | [0m[35m                        "expires_on": token.expires_on,[0m
[30;1m456 | [0m[35m                    }[0m
[30;1m457 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m458 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m459 | [0m[35m                    break[0m
[30;1m460 | [0m[35m        except ImportError as e:[0m
[30;1m461 | [0m[35m            raise AirflowOptionalProviderFeatureException(e)[0m

[31m--[ [0m[34mMatch #[0m[33m16[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m454 | [0m[35m                        "token_type": "Bearer",[0m
[30;1m455 | [0m[35m                        "expires_on": token.expires_on,[0m
[30;1m456 | [0m[35m                    }[0m
[30;1m457 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m458 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m459 | [0m[35m                    break[0m
[30;1m460 | [0m[35m        except ImportError as e:[0m

[31m--[ [0m[34mMatch #[0m[33m17[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m431 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m432 | [0m[35m        """[0m
[30;1m433 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m434 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m435 | [0m[35m            return aad_token["access_token"][0m
[30;1m436 | [0m[35m[0m
[30;1m437 | [0m[35m        self.log.info("Existing AAD token is expired, or going to expire soon. Refreshing...")[0m

[31m--[ [0m[34mMatch #[0m[33m18[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m430 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m431 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m432 | [0m[35m        """[0m
[30;1m433 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m434 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m435 | [0m[35m            return aad_token["access_token"][0m
[30;1m436 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m19[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m410 | [0m[35m                        "expires_on": token.expires_on,[0m
[30;1m411 | [0m[35m                    }[0m
[30;1m412 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m413 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m414 | [0m[35m                    break[0m
[30;1m415 | [0m[35m        except ImportError as e:[0m
[30;1m416 | [0m[35m            raise AirflowOptionalProviderFeatureException(e)[0m

[31m--[ [0m[34mMatch #[0m[33m20[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m409 | [0m[35m                        "token_type": "Bearer",[0m
[30;1m410 | [0m[35m                        "expires_on": token.expires_on,[0m
[30;1m411 | [0m[35m                    }[0m
[30;1m412 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m413 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m414 | [0m[35m                    break[0m
[30;1m415 | [0m[35m        except ImportError as e:[0m

[31m--[ [0m[34mMatch #[0m[33m21[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m388 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m389 | [0m[35m        """[0m
[30;1m390 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m391 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m392 | [0m[35m            return aad_token["access_token"][0m
[30;1m393 | [0m[35m[0m
[30;1m394 | [0m[35m        self.log.info("Existing AAD token is expired, or going to expire soon. Refreshing...")[0m

[31m--[ [0m[34mMatch #[0m[33m22[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m387 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m388 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m389 | [0m[35m        """[0m
[30;1m390 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m391 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m392 | [0m[35m            return aad_token["access_token"][0m
[30;1m393 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m23[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m368 | [0m[35m                        "expires_on": token.expires_on,[0m
[30;1m369 | [0m[35m                    }[0m
[30;1m370 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m371 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m372 | [0m[35m                    break[0m
[30;1m373 | [0m[35m        except ImportError as e:[0m
[30;1m374 | [0m[35m            raise AirflowOptionalProviderFeatureException(e)[0m

[31m--[ [0m[34mMatch #[0m[33m24[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m367 | [0m[35m                        "token_type": "Bearer",[0m
[30;1m368 | [0m[35m                        "expires_on": token.expires_on,[0m
[30;1m369 | [0m[35m                    }[0m
[30;1m370 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m371 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m372 | [0m[35m                    break[0m
[30;1m373 | [0m[35m        except ImportError as e:[0m

[31m--[ [0m[34mMatch #[0m[33m25[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m358 | [0m[35m                    else:[0m
[30;1m359 | [0m[35m                        credential = AsyncClientSecretCredential([0m
[30;1m360 | [0m[35m                            client_id=self.databricks_conn.login,[0m
[30;1m361 | [0m[35m                            client_secret=self.databricks_conn.password,[0m
[30;1m362 | [0m[35m                            tenant_id=self.databricks_conn.extra_dejson["azure_tenant_id"],[0m
[30;1m363 | [0m[35m                        )[0m
[30;1m364 | [0m[35m                        token = await credential.get_token(f"{resource}/.default")[0m

[31m--[ [0m[34mMatch #[0m[33m26[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m341 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m342 | [0m[35m        """[0m
[30;1m343 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m344 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m345 | [0m[35m            return aad_token["access_token"][0m
[30;1m346 | [0m[35m[0m
[30;1m347 | [0m[35m        self.log.info("Existing AAD token is expired, or going to expire soon. Refreshing...")[0m

[31m--[ [0m[34mMatch #[0m[33m27[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m340 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m341 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m342 | [0m[35m        """[0m
[30;1m343 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m344 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m345 | [0m[35m            return aad_token["access_token"][0m
[30;1m346 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m28[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m321 | [0m[35m                        "expires_on": token.expires_on,[0m
[30;1m322 | [0m[35m                    }[0m
[30;1m323 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m324 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m325 | [0m[35m                    break[0m
[30;1m326 | [0m[35m        except ImportError as e:[0m
[30;1m327 | [0m[35m            raise AirflowOptionalProviderFeatureException(e)[0m

[31m--[ [0m[34mMatch #[0m[33m29[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m320 | [0m[35m                        "token_type": "Bearer",[0m
[30;1m321 | [0m[35m                        "expires_on": token.expires_on,[0m
[30;1m322 | [0m[35m                    }[0m
[30;1m323 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m324 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m325 | [0m[35m                    break[0m
[30;1m326 | [0m[35m        except ImportError as e:[0m

[31m--[ [0m[34mMatch #[0m[33m30[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m311 | [0m[35m                    else:[0m
[30;1m312 | [0m[35m                        credential = ClientSecretCredential([0m
[30;1m313 | [0m[35m                            client_id=self.databricks_conn.login,[0m
[30;1m314 | [0m[35m                            client_secret=self.databricks_conn.password,[0m
[30;1m315 | [0m[35m                            tenant_id=self.databricks_conn.extra_dejson["azure_tenant_id"],[0m
[30;1m316 | [0m[35m                        )[0m
[30;1m317 | [0m[35m                        token = credential.get_token(f"{resource}/.default")[0m

[31m--[ [0m[34mMatch #[0m[33m31[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m297 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m298 | [0m[35m        """[0m
[30;1m299 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m300 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m301 | [0m[35m            return aad_token["access_token"][0m
[30;1m302 | [0m[35m[0m
[30;1m303 | [0m[35m        self.log.info("Existing AAD token is expired, or going to expire soon. Refreshing...")[0m

[31m--[ [0m[34mMatch #[0m[33m32[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m296 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m297 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m298 | [0m[35m        """[0m
[30;1m299 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m300 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m301 | [0m[35m            return aad_token["access_token"][0m
[30;1m302 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m33[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m278 | [0m[35m                        jsn["expires_on"] = int(time.time() + jsn["expires_in"])[0m
[30;1m279 | [0m[35m[0m
[30;1m280 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m281 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m282 | [0m[35m                    break[0m
[30;1m283 | [0m[35m        except RetryError:[0m
[30;1m284 | [0m[35m            raise AirflowException(f"API requests to Databricks failed {self.retry_limit} times. Giv[0m

[31m--[ [0m[34mMatch #[0m[33m34[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m277 | [0m[35m                        jsn = await resp.json()[0m
[30;1m278 | [0m[35m                        jsn["expires_on"] = int(time.time() + jsn["expires_in"])[0m
[30;1m279 | [0m[35m[0m
[30;1m280 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m281 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m282 | [0m[35m                    break[0m
[30;1m283 | [0m[35m        except RetryError:[0m

[31m--[ [0m[34mMatch #[0m[33m35[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m265 | [0m[35m                with attempt:[0m
[30;1m266 | [0m[35m                    async with self._session.post([0m
[30;1m267 | [0m[35m                        resource,[0m
[30;1m268 | [0m[35m                        auth=aiohttp.BasicAuth(self.databricks_conn.login, self.databricks_conn.pass[0m
[30;1m269 | [0m[35m                        data="grant_type=client_credentials&scope=all-apis",[0m
[30;1m270 | [0m[35m                        headers={[0m
[30;1m271 | [0m[35m                            **self.user_agent_header,[0m

[31m--[ [0m[34mMatch #[0m[33m36[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m256 | [0m[35m    async def _a_get_sp_token(self, resource: str) -> str:[0m
[30;1m257 | [0m[35m        """Async version of `_get_sp_token()`."""[0m
[30;1m258 | [0m[35m        sp_token = self.oauth_tokens.get(resource)[0m
[30;1m259 | [0m[35m        if sp_token and self._is_oauth_token_valid(sp_token):[0m
[30;1m260 | [0m[35m            return sp_token["access_token"][0m
[30;1m261 | [0m[35m[0m
[30;1m262 | [0m[35m        self.log.info("Existing Service Principal token is expired, or going to expire soon. Refresh[0m

[31m--[ [0m[34mMatch #[0m[33m37[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m255 | [0m[35m[0m
[30;1m256 | [0m[35m    async def _a_get_sp_token(self, resource: str) -> str:[0m
[30;1m257 | [0m[35m        """Async version of `_get_sp_token()`."""[0m
[30;1m258 | [0m[35m        sp_token = self.oauth_tokens.get(resource)[0m
[30;1m259 | [0m[35m        if sp_token and self._is_oauth_token_valid(sp_token):[0m
[30;1m260 | [0m[35m            return sp_token["access_token"][0m
[30;1m261 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m38[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m243 | [0m[35m                    jsn["expires_on"] = int(time.time() + jsn["expires_in"])[0m
[30;1m244 | [0m[35m[0m
[30;1m245 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m246 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m247 | [0m[35m                    break[0m
[30;1m248 | [0m[35m        except RetryError:[0m
[30;1m249 | [0m[35m            raise AirflowException(f"API requests to Databricks failed {self.retry_limit} times. Giv[0m

[31m--[ [0m[34mMatch #[0m[33m39[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m242 | [0m[35m                    jsn = resp.json()[0m
[30;1m243 | [0m[35m                    jsn["expires_on"] = int(time.time() + jsn["expires_in"])[0m
[30;1m244 | [0m[35m[0m
[30;1m245 | [0m[35m                    self._is_oauth_token_valid(jsn)[0m
[30;1m246 | [0m[35m                    self.oauth_tokens[resource] = jsn[0m
[30;1m247 | [0m[35m                    break[0m
[30;1m248 | [0m[35m        except RetryError:[0m

[31m--[ [0m[34mMatch #[0m[33m40[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m229 | [0m[35m                with attempt:[0m
[30;1m230 | [0m[35m                    resp = requests.post([0m
[30;1m231 | [0m[35m                        resource,[0m
[30;1m232 | [0m[35m                        auth=HTTPBasicAuth(self.databricks_conn.login, self.databricks_conn.password[0m
[30;1m233 | [0m[35m                        data="grant_type=client_credentials&scope=all-apis",[0m
[30;1m234 | [0m[35m                        headers={[0m
[30;1m235 | [0m[35m                            **self.user_agent_header,[0m

[31m--[ [0m[34mMatch #[0m[33m41[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m220 | [0m[35m    def _get_sp_token(self, resource: str) -> str:[0m
[30;1m221 | [0m[35m        """Get Service Principal token."""[0m
[30;1m222 | [0m[35m        sp_token = self.oauth_tokens.get(resource)[0m
[30;1m223 | [0m[35m        if sp_token and self._is_oauth_token_valid(sp_token):[0m
[30;1m224 | [0m[35m            return sp_token["access_token"][0m
[30;1m225 | [0m[35m[0m
[30;1m226 | [0m[35m        self.log.info("Existing Service Principal token is expired, or going to expire soon. Refresh[0m

[31m--[ [0m[34mMatch #[0m[33m42[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m219 | [0m[35m[0m
[30;1m220 | [0m[35m    def _get_sp_token(self, resource: str) -> str:[0m
[30;1m221 | [0m[35m        """Get Service Principal token."""[0m
[30;1m222 | [0m[35m        sp_token = self.oauth_tokens.get(resource)[0m
[30;1m223 | [0m[35m        if sp_token and self._is_oauth_token_valid(sp_token):[0m
[30;1m224 | [0m[35m            return sp_token["access_token"][0m
[30;1m225 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m43[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m114 | [0m[35m            raise ValueError("Retry limit must be greater than or equal to 1")[0m
[30;1m115 | [0m[35m        self.retry_limit = retry_limit[0m
[30;1m116 | [0m[35m        self.retry_delay = retry_delay[0m
[30;1m117 | [0m[35m        self.oauth_tokens: dict[str, dict] = {}[0m
[30;1m118 | [0m[35m        self.token_timeout_seconds = 10[0m
[30;1m119 | [0m[35m        self.caller = caller[0m
[30;1m120 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m44[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m74 | [0m[35m[0m
[30;1m75 | [0m[35m    Following parameters are necessary if using authentication with OAuth token for AWS Databricks S[0m
[30;1m76 | [0m[35m[0m
[30;1m77 | [0m[35m    * ``service_principal_oauth``: required boolean flag.  If specified as ``true``, use the Client [0m
[30;1m78 | [0m[35m[0m
[30;1m79 | [0m[35m    Following parameters are necessary if using authentication with AAD token:[0m
[30;1m80 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m45[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m70 | [0m[35m[0m
[30;1m71 | [0m[35m    Following parameter could be used if using the *PAT* authentication method:[0m
[30;1m72 | [0m[35m[0m
[30;1m73 | [0m[35m    * ``token``: Specify PAT to use. Consider to switch to specification of PAT in the Password fiel[0m
[30;1m74 | [0m[35m[0m
[30;1m75 | [0m[35m    Following parameters are necessary if using authentication with OAuth token for AWS Databricks S[0m
[30;1m76 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m46[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m59 | [0m[35mlan to reuse this connection with e.g. HttpOperator)[0m
[30;1m60 | [0m[35m    * If authentication with *Databricks Service Principal OAuth* is used then specify the ID of the[0m
[30;1m61 | [0m[35m[0m
[30;1m62 | [0m[35mPassword (optional)[0m
[30;1m63 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``password`` us[0m
[30;1m64 | [0m[35m    * If authentication with *Azure Service Principal* is used then specify the secret of the Azure [0m
[30;1m65 | [0m[35m    * If authentication with *PAT* is used, then specify PAT (recommended)[0m

[31m--[ [0m[34mMatch #[0m[33m47[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m59 | [0m[35moken' then it will be sent using Basic Auth which is allowed by Databricks API, this may be useful i[0m
[30;1m60 | [0m[35m    * If authentication with *Databricks Service Principal OAuth* is used then specify the ID of the[0m
[30;1m61 | [0m[35m[0m
[30;1m62 | [0m[35mPassword (optional)[0m
[30;1m63 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``password`` us[0m
[30;1m64 | [0m[35m    * If authentication with *Azure Service Principal* is used then specify the secret of the Azure [0m

[31m--[ [0m[34mMatch #[0m[33m48[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m34 | [0m[35m   i.e. add a token to the Airflow connection. This is the recommended method.[0m
[30;1m35 | [0m[35m2. Use Databricks login credentials[0m
[30;1m36 | [0m[35m   i.e. add the username and password used to login to the Databricks account to the Airflow connect[0m
[30;1m37 | [0m[35m   Note that username/password authentication is discouraged and not supported for[0m
[30;1m38 | [0m[35m   :class:`~airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator`.[0m
[30;1m39 | [0m[35m3. Using Azure Active Directory (AAD) token generated from Azure Service Principal's ID and secret[0m
[30;1m40 | [0m[35m   (only on Azure Databricks).  Service principal could be defined as a[0m

[31m--[ [0m[34mMatch #[0m[33m49[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m33 | [0m[35m   <https://docs.databricks.com/dev-tools/api/latest/authentication.html>`_[0m
[30;1m34 | [0m[35m   i.e. add a token to the Airflow connection. This is the recommended method.[0m
[30;1m35 | [0m[35m2. Use Databricks login credentials[0m
[30;1m36 | [0m[35m   i.e. add the username and password used to login to the Databricks account to the Airflow connect[0m
[30;1m37 | [0m[35m   Note that username/password authentication is discouraged and not supported for[0m
[30;1m38 | [0m[35m   :class:`~airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator`.[0m
[30;1m39 | [0m[35m3. Using Azure Active Directory (AAD) token generated from Azure Service Principal's ID and secret[0m

[31m--[ [0m[34mMatch #[0m[33m50[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/triggers/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m264 | [0m[35m        conn = session.query(Connection).filter(Connection.conn_id == DEFAULT_CONN_ID).first()[0m
[30;1m265 | [0m[35m        conn.host = HOST[0m
[30;1m266 | [0m[35m        conn.login = LOGIN[0m
[30;1m267 | [0m[35m        conn.password = PASSWORD[0m
[30;1m268 | [0m[35m        conn.extra = None[0m
[30;1m269 | [0m[35m        session.commit()[0m
[30;1m270 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m51[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/triggers/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m264 | [0m[35m        conn = session.query(Connection).filter(Connection.conn_id == DEFAULT_CONN_ID).first()[0m
[30;1m265 | [0m[35m        conn.host = HOST[0m
[30;1m266 | [0m[35m        conn.login = LOGIN[0m
[30;1m267 | [0m[35m        conn.password = PASSWORD[0m
[30;1m268 | [0m[35m        conn.extra = None[0m
[30;1m269 | [0m[35m        session.commit()[0m
[30;1m270 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m52[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/triggers/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m126 | [0m[35m        conn = session.query(Connection).filter(Connection.conn_id == DEFAULT_CONN_ID).first()[0m
[30;1m127 | [0m[35m        conn.host = HOST[0m
[30;1m128 | [0m[35m        conn.login = LOGIN[0m
[30;1m129 | [0m[35m        conn.password = PASSWORD[0m
[30;1m130 | [0m[35m        conn.extra = None[0m
[30;1m131 | [0m[35m        session.commit()[0m
[30;1m132 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m53[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/triggers/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m126 | [0m[35m        conn = session.query(Connection).filter(Connection.conn_id == DEFAULT_CONN_ID).first()[0m
[30;1m127 | [0m[35m        conn.host = HOST[0m
[30;1m128 | [0m[35m        conn.login = LOGIN[0m
[30;1m129 | [0m[35m        conn.password = PASSWORD[0m
[30;1m130 | [0m[35m        conn.extra = None[0m
[30;1m131 | [0m[35m        session.commit()[0m
[30;1m132 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m54[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/triggers/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m37 | [0m[35mDEFAULT_CONN_ID = "databricks_default"[0m
[30;1m38 | [0m[35mHOST = "xx.cloud.databricks.com"[0m
[30;1m39 | [0m[35mLOGIN = "login"[0m
[30;1m40 | [0m[35mPASSWORD = "password"[0m
[30;1m41 | [0m[35mPOLLING_INTERVAL_SECONDS = 30[0m
[30;1m42 | [0m[35mRETRY_DELAY = 10[0m
[30;1m43 | [0m[35mRETRY_LIMIT = 3[0m

[31m--[ [0m[34mMatch #[0m[33m55[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/triggers/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m37 | [0m[35mDEFAULT_CONN_ID = "databricks_default"[0m
[30;1m38 | [0m[35mHOST = "xx.cloud.databricks.com"[0m
[30;1m39 | [0m[35mLOGIN = "login"[0m
[30;1m40 | [0m[35mPASSWORD = "password"[0m
[30;1m41 | [0m[35mPOLLING_INTERVAL_SECONDS = 30[0m
[30;1m42 | [0m[35mRETRY_DELAY = 10[0m
[30;1m43 | [0m[35mRETRY_LIMIT = 3[0m

[31m--[ [0m[34mMatch #[0m[33m56[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000702[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Environment[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks.py[0m
   Pattern: [32m(env|environment).{1,50}(get|post|curl|nc|invoke-restmethod)[0m
[30;1m50 | [0m[35mDAG_ID = "example_databricks_operator"[0m
[30;1m51 | [0m[35m[0m
[30;1m52 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "c9cf6468-babe-41a6-abc3-10ac358c71ee")[0m
[30;1m53 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "cf414a2206dfb397")[0m
[30;1m54 | [0m[35m[0m
[30;1m55 | [0m[35mwith DAG([0m
[30;1m56 | [0m[35m    dag_id=DAG_ID,[0m

[31m--[ [0m[34mMatch #[0m[33m57[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000702[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Environment[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks.py[0m
   Pattern: [32m(env|environment).{1,50}(get|post|curl|nc|invoke-restmethod)[0m
[30;1m49 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m50 | [0m[35mDAG_ID = "example_databricks_operator"[0m
[30;1m51 | [0m[35m[0m
[30;1m52 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "c9cf6468-babe-41a6-abc3-10ac358c71ee")[0m
[30;1m53 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "cf414a2206dfb397")[0m
[30;1m54 | [0m[35m[0m
[30;1m55 | [0m[35mwith DAG([0m

[31m--[ [0m[34mMatch #[0m[33m58[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000702[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Environment[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks.py[0m
   Pattern: [32m(env|environment).{1,50}(get|post|curl|nc|invoke-restmethod)[0m
[30;1m46 | [0m[35m    DatabricksTaskOperator,[0m
[30;1m47 | [0m[35m)[0m
[30;1m48 | [0m[35m[0m
[30;1m49 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m50 | [0m[35mDAG_ID = "example_databricks_operator"[0m
[30;1m51 | [0m[35m[0m
[30;1m52 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "c9cf6468-babe-41a6-abc3-10ac358c71ee")[0m

[31m--[ [0m[34mMatch #[0m[33m59[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000702[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Environment[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_sensors.py[0m
   Pattern: [32m(env|environment).{1,50}(get|post|curl|nc|invoke-restmethod)[0m
[30;1m26 | [0m[35mfrom airflow.providers.databricks.sensors.databricks_sql import DatabricksSqlSensor[0m
[30;1m27 | [0m[35m[0m
[30;1m28 | [0m[35m# [Env variable to be used from the OS][0m
[30;1m29 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m30 | [0m[35m# [DAG name to be shown on Airflow UI][0m
[30;1m31 | [0m[35mDAG_ID = "example_databricks_sensor"[0m
[30;1m32 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m60[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000702[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Environment[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_workflow.py[0m
   Pattern: [32m(env|environment).{1,50}(get|post|curl|nc|invoke-restmethod)[0m
[30;1m39 | [0m[35mUSER = os.environ.get("USER")[0m
[30;1m40 | [0m[35m[0m
[30;1m41 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "d3773b5a-56f9-422c-ae60-048eaa90aa33")[0m
[30;1m42 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "368fe30b92228713")[0m
[30;1m43 | [0m[35m[0m
[30;1m44 | [0m[35m# job_cluster_spec example for Databricks on Azure[0m
[30;1m45 | [0m[35mjob_cluster_spec = [[0m

[31m--[ [0m[34mMatch #[0m[33m61[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000702[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Environment[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_workflow.py[0m
   Pattern: [32m(env|environment).{1,50}(get|post|curl|nc|invoke-restmethod)[0m
[30;1m38 | [0m[35mGROUP_ID = os.getenv("DATABRICKS_GROUP_ID", "1234").replace(".", "_")[0m
[30;1m39 | [0m[35mUSER = os.environ.get("USER")[0m
[30;1m40 | [0m[35m[0m
[30;1m41 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "d3773b5a-56f9-422c-ae60-048eaa90aa33")[0m
[30;1m42 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "368fe30b92228713")[0m
[30;1m43 | [0m[35m[0m
[30;1m44 | [0m[35m# job_cluster_spec example for Databricks on Azure[0m

[31m--[ [0m[34mMatch #[0m[33m62[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000702[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Environment[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_workflow.py[0m
   Pattern: [32m(env|environment).{1,50}(get|post|curl|nc|invoke-restmethod)[0m
[30;1m36 | [0m[35mDATABRICKS_NOTIFICATION_EMAIL = os.getenv("DATABRICKS_NOTIFICATION_EMAIL", "your_email@serviceprovid[0m
[30;1m37 | [0m[35m[0m
[30;1m38 | [0m[35mGROUP_ID = os.getenv("DATABRICKS_GROUP_ID", "1234").replace(".", "_")[0m
[30;1m39 | [0m[35mUSER = os.environ.get("USER")[0m
[30;1m40 | [0m[35m[0m
[30;1m41 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "d3773b5a-56f9-422c-ae60-048eaa90aa33")[0m
[30;1m42 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "368fe30b92228713")[0m

[31m--[ [0m[34mMatch #[0m[33m63[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks_sql.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m48 | [0m[35m    conn = session.query(Connection).filter(Connection.conn_id == DEFAULT_CONN_ID).first()[0m
[30;1m49 | [0m[35m    conn.host = HOST[0m
[30;1m50 | [0m[35m    conn.login = None[0m
[30;1m51 | [0m[35m    conn.password = TOKEN[0m
[30;1m52 | [0m[35m    conn.extra = None[0m
[30;1m53 | [0m[35m    session.commit()[0m
[30;1m54 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m64[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m838 | [0m[35mflow/commit/56bdfe7a840c25360d596ca94fd11d2ccfadb4ba>`__  2021-11-22   ``Databricks - allow Azure SP[0m
[30;1m839 | [0m[35m`244627e3da <https://github.com/apache/airflow/commit/244627e3daa3e416696e5ddb20a2d4ea5e16b96e>`__  [0m
[30;1m840 | [0m[35m`0a4a8bdb94 <https://github.com/apache/airflow/commit/0a4a8bdb943979820fa7067797764e47f3e0b0c3>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m65[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m2109 | [0m[35m        conn.schema = None[0m
[30;1m2110 | [0m[35m        conn.port = None[0m
[30;1m2111 | [0m[35m        conn.login = "c64f6d12-f6e4-45a4-846e-032b42b27758"[0m
[30;1m2112 | [0m[35m        conn.password = "secret"[0m
[30;1m2113 | [0m[35m        conn.extra = json.dumps({"service_principal_oauth": True})[0m
[30;1m2114 | [0m[35m        session.commit()[0m
[30;1m2115 | [0m[35m        self.hook = DatabricksHook(retry_args=DEFAULT_RETRY_ARGS)[0m

[31m--[ [0m[34mMatch #[0m[33m66[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m2068 | [0m[35m        conn.schema = None[0m
[30;1m2069 | [0m[35m        conn.port = None[0m
[30;1m2070 | [0m[35m        conn.login = "c64f6d12-f6e4-45a4-846e-032b42b27758"[0m
[30;1m2071 | [0m[35m        conn.password = "secret"[0m
[30;1m2072 | [0m[35m        conn.extra = json.dumps({"service_principal_oauth": True})[0m
[30;1m2073 | [0m[35m        session.commit()[0m
[30;1m2074 | [0m[35m        self.hook = DatabricksHook(retry_args=DEFAULT_RETRY_ARGS)[0m

[31m--[ [0m[34mMatch #[0m[33m67[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1952 | [0m[35m        self.client_id = "9ff815a6-4404-4ab8-85cb-cd0e6f879c1d"[0m
[30;1m1953 | [0m[35m        conn = session.query(Connection).filter(Connection.conn_id == DEFAULT_CONN_ID).first()[0m
[30;1m1954 | [0m[35m        conn.login = self.client_id[0m
[30;1m1955 | [0m[35m        conn.password = "secret"[0m
[30;1m1956 | [0m[35m        conn.host = HOST[0m
[30;1m1957 | [0m[35m        conn.schema = None[0m
[30;1m1958 | [0m[35m        conn.port = None[0m

[31m--[ [0m[34mMatch #[0m[33m68[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1899 | [0m[35m        conn.schema = None[0m
[30;1m1900 | [0m[35m        conn.port = None[0m
[30;1m1901 | [0m[35m        conn.login = self.client_id[0m
[30;1m1902 | [0m[35m        conn.password = "secret"[0m
[30;1m1903 | [0m[35m        conn.extra = json.dumps([0m
[30;1m1904 | [0m[35m            {[0m
[30;1m1905 | [0m[35m                "host": HOST,[0m

[31m--[ [0m[34mMatch #[0m[33m69[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1853 | [0m[35m        conn.schema = None[0m
[30;1m1854 | [0m[35m        conn.port = None[0m
[30;1m1855 | [0m[35m        conn.login = "9ff815a6-4404-4ab8-85cb-cd0e6f879c1d"[0m
[30;1m1856 | [0m[35m        conn.password = "secret"[0m
[30;1m1857 | [0m[35m        conn.extra = json.dumps([0m
[30;1m1858 | [0m[35m            {[0m
[30;1m1859 | [0m[35m                "host": HOST,[0m

[31m--[ [0m[34mMatch #[0m[33m70[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1834 | [0m[35m        mock_get.assert_called_once_with([0m
[30;1m1835 | [0m[35m            get_run_output_endpoint(HOST),[0m
[30;1m1836 | [0m[35m            json={"run_id": RUN_ID},[0m
[30;1m1837 | [0m[35m            auth=aiohttp.BasicAuth(LOGIN, PASSWORD),[0m
[30;1m1838 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1839 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1840 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m71[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1817 | [0m[35m        mock_get.assert_called_once_with([0m
[30;1m1818 | [0m[35m            get_cluster_endpoint(HOST),[0m
[30;1m1819 | [0m[35m            json={"cluster_id": CLUSTER_ID},[0m
[30;1m1820 | [0m[35m            auth=aiohttp.BasicAuth(LOGIN, PASSWORD),[0m
[30;1m1821 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1822 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1823 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m72[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1800 | [0m[35m        mock_get.assert_called_once_with([0m
[30;1m1801 | [0m[35m            get_run_endpoint(HOST),[0m
[30;1m1802 | [0m[35m            json={"run_id": RUN_ID},[0m
[30;1m1803 | [0m[35m            auth=aiohttp.BasicAuth(LOGIN, PASSWORD),[0m
[30;1m1804 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1805 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1806 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m73[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1783 | [0m[35m        mock_get.assert_called_once_with([0m
[30;1m1784 | [0m[35m            get_run_endpoint(HOST),[0m
[30;1m1785 | [0m[35m            json={"run_id": RUN_ID},[0m
[30;1m1786 | [0m[35m            auth=aiohttp.BasicAuth(LOGIN, PASSWORD),[0m
[30;1m1787 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1788 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1789 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m74[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1767 | [0m[35m        mock_patch.assert_called_once_with([0m
[30;1m1768 | [0m[35m            submit_run_endpoint(HOST),[0m
[30;1m1769 | [0m[35m            json={"cluster_name": "new_name"},[0m
[30;1m1770 | [0m[35m            auth=aiohttp.BasicAuth(LOGIN, PASSWORD),[0m
[30;1m1771 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1772 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1773 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m75[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1671 | [0m[35m        conn.schema = None[0m
[30;1m1672 | [0m[35m        conn.port = None[0m
[30;1m1673 | [0m[35m        conn.login = LOGIN[0m
[30;1m1674 | [0m[35m        conn.password = PASSWORD[0m
[30;1m1675 | [0m[35m        conn.extra = None[0m
[30;1m1676 | [0m[35m        session.commit()[0m
[30;1m1677 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m76[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1671 | [0m[35m        conn.schema = None[0m
[30;1m1672 | [0m[35m        conn.port = None[0m
[30;1m1673 | [0m[35m        conn.login = LOGIN[0m
[30;1m1674 | [0m[35m        conn.password = PASSWORD[0m
[30;1m1675 | [0m[35m        conn.extra = None[0m
[30;1m1676 | [0m[35m        session.commit()[0m
[30;1m1677 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m77[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1567 | [0m[35m        self.tenant_id = "3ff810a6-5504-4ab8-85cb-cd0e6f879c1d"[0m
[30;1m1568 | [0m[35m        self.client_id = "9ff815a6-4404-4ab8-85cb-cd0e6f879c1d"[0m
[30;1m1569 | [0m[35m        conn.login = self.client_id[0m
[30;1m1570 | [0m[35m        conn.password = "secret"[0m
[30;1m1571 | [0m[35m        conn.host = HOST[0m
[30;1m1572 | [0m[35m        conn.schema = None[0m
[30;1m1573 | [0m[35m        conn.port = None[0m

[31m--[ [0m[34mMatch #[0m[33m78[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1519 | [0m[35m        conn.schema = None[0m
[30;1m1520 | [0m[35m        conn.port = None[0m
[30;1m1521 | [0m[35m        conn.login = self.client_id[0m
[30;1m1522 | [0m[35m        conn.password = "secret"[0m
[30;1m1523 | [0m[35m        conn.extra = json.dumps([0m
[30;1m1524 | [0m[35m            {[0m
[30;1m1525 | [0m[35m                "host": HOST,[0m

[31m--[ [0m[34mMatch #[0m[33m79[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1475 | [0m[35m        conn.schema = None[0m
[30;1m1476 | [0m[35m        conn.port = None[0m
[30;1m1477 | [0m[35m        conn.login = "9ff815a6-4404-4ab8-85cb-cd0e6f879c1d"[0m
[30;1m1478 | [0m[35m        conn.password = "secret"[0m
[30;1m1479 | [0m[35m        conn.extra = json.dumps([0m
[30;1m1480 | [0m[35m            {[0m
[30;1m1481 | [0m[35m                "host": HOST,[0m

[31m--[ [0m[34mMatch #[0m[33m80[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1349 | [0m[35m        conn.schema = "http"[0m
[30;1m1350 | [0m[35m        conn.port = 7908[0m
[30;1m1351 | [0m[35m        conn.login = None[0m
[30;1m1352 | [0m[35m        conn.password = None[0m
[30;1m1353 | [0m[35m        conn.extra = json.dumps({"token": TOKEN})[0m
[30;1m1354 | [0m[35m        session.commit()[0m
[30;1m1355 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m81[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1328 | [0m[35m        conn.schema = None[0m
[30;1m1329 | [0m[35m        conn.port = None[0m
[30;1m1330 | [0m[35m        conn.login = None[0m
[30;1m1331 | [0m[35m        conn.password = None[0m
[30;1m1332 | [0m[35m        conn.extra = json.dumps({"token": TOKEN})[0m
[30;1m1333 | [0m[35m[0m
[30;1m1334 | [0m[35m        session.commit()[0m

[31m--[ [0m[34mMatch #[0m[33m82[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1298 | [0m[35m        conn.schema = None[0m
[30;1m1299 | [0m[35m        conn.port = None[0m
[30;1m1300 | [0m[35m        conn.login = None[0m
[30;1m1301 | [0m[35m        conn.password = TOKEN[0m
[30;1m1302 | [0m[35m        conn.extra = None[0m
[30;1m1303 | [0m[35m        session.commit()[0m
[30;1m1304 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m83[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1286 | [0m[35m[0m
[30;1m1287 | [0m[35m[0m
[30;1m1288 | [0m[35m@pytest.mark.db_test[0m
[30;1m1289 | [0m[35mclass TestDatabricksHookTokenInPassword:[0m
[30;1m1290 | [0m[35m    """[0m
[30;1m1291 | [0m[35m    Tests for DatabricksHook.[0m
[30;1m1292 | [0m[35m    """[0m

[31m--[ [0m[34mMatch #[0m[33m84[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1263 | [0m[35m        conn.schema = None[0m
[30;1m1264 | [0m[35m        conn.port = None[0m
[30;1m1265 | [0m[35m        conn.login = None[0m
[30;1m1266 | [0m[35m        conn.password = None[0m
[30;1m1267 | [0m[35m        conn.extra = json.dumps({"token": TOKEN, "host": HOST})[0m
[30;1m1268 | [0m[35m[0m
[30;1m1269 | [0m[35m        session.commit()[0m

[31m--[ [0m[34mMatch #[0m[33m85[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1244 | [0m[35m            list_spark_versions_endpoint(HOST),[0m
[30;1m1245 | [0m[35m            json=None,[0m
[30;1m1246 | [0m[35m            params=None,[0m
[30;1m1247 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1248 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1249 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1250 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m86[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1227 | [0m[35m            list_spark_versions_endpoint(HOST),[0m
[30;1m1228 | [0m[35m            json=None,[0m
[30;1m1229 | [0m[35m            params=None,[0m
[30;1m1230 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1231 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1232 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1233 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m87[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1210 | [0m[35m            f"{sql_statements_endpoint(HOST)}/{STATEMENT_ID}/cancel",[0m
[30;1m1211 | [0m[35m            json=None,[0m
[30;1m1212 | [0m[35m            params=None,[0m
[30;1m1213 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1214 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1215 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1216 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m88[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1195 | [0m[35m            f"{sql_statements_endpoint(HOST)}/{STATEMENT_ID}",[0m
[30;1m1196 | [0m[35m            json=None,[0m
[30;1m1197 | [0m[35m            params=None,[0m
[30;1m1198 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1199 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1200 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1201 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m89[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1178 | [0m[35m            sql_statements_endpoint(HOST),[0m
[30;1m1179 | [0m[35m            json=json,[0m
[30;1m1180 | [0m[35m            params=None,[0m
[30;1m1181 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1182 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1183 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1184 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m90[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1154 | [0m[35m            list_pipelines_endpoint(HOST),[0m
[30;1m1155 | [0m[35m            json=None,[0m
[30;1m1156 | [0m[35m            params={"filter": f"name LIKE '{PIPELINE_NAME}'", "max_results": 25},[0m
[30;1m1157 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1158 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1159 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1160 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m91[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1131 | [0m[35m            list_pipelines_endpoint(HOST),[0m
[30;1m1132 | [0m[35m            json=None,[0m
[30;1m1133 | [0m[35m            params={"filter": f"name LIKE '{ne_pipeline_name}'", "max_results": 25},[0m
[30;1m1134 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1135 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1136 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1137 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m92[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1084 | [0m[35m            list_pipelines_endpoint(HOST),[0m
[30;1m1085 | [0m[35m            json=None,[0m
[30;1m1086 | [0m[35m            params={"filter": f"name LIKE '{PIPELINE_NAME}'", "max_results": 25},[0m
[30;1m1087 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1088 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1089 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1090 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m93[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1068 | [0m[35m                "include_user_names": False,[0m
[30;1m1069 | [0m[35m                "name": JOB_NAME,[0m
[30;1m1070 | [0m[35m            },[0m
[30;1m1071 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1072 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1073 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1074 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m94[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1039 | [0m[35m                "include_user_names": False,[0m
[30;1m1040 | [0m[35m                "name": job_name,[0m
[30;1m1041 | [0m[35m            },[0m
[30;1m1042 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1043 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1044 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1045 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m95[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m1014 | [0m[35m                "include_user_names": False,[0m
[30;1m1015 | [0m[35m                "name": JOB_NAME,[0m
[30;1m1016 | [0m[35m            },[0m
[30;1m1017 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m1018 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m1019 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m1020 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m96[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m955 | [0m[35m            list_jobs_endpoint(HOST),[0m
[30;1m956 | [0m[35m            json=None,[0m
[30;1m957 | [0m[35m            params={"limit": 25, "page_token": "", "expand_tasks": False, "include_user_names": Fals[0m
[30;1m958 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m959 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m960 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m961 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m97[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m942 | [0m[35m            "token_type": "Bearer",[0m
[30;1m943 | [0m[35m        }[0m
[30;1m944 | [0m[35m        with pytest.raises(AirflowException):[0m
[30;1m945 | [0m[35m            self.hook._is_oauth_token_valid(token, time_key="expiration")[0m
[30;1m946 | [0m[35m[0m
[30;1m947 | [0m[35m    @mock.patch("airflow.providers.databricks.hooks.databricks_base.requests")[0m
[30;1m948 | [0m[35m    def test_list_jobs_success_single_page(self, mock_requests):[0m

[31m--[ [0m[34mMatch #[0m[33m98[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m935 | [0m[35m        with pytest.raises(AirflowException):[0m
[30;1m936 | [0m[35m            self.hook._is_oauth_token_valid({"access_token": access_token, "token_type": token_type}[0m
[30;1m937 | [0m[35m[0m
[30;1m938 | [0m[35m    def test_is_oauth_token_valid_raises_wrong_time_key(self):[0m
[30;1m939 | [0m[35m        token = {[0m
[30;1m940 | [0m[35m            "access_token": "my_token",[0m
[30;1m941 | [0m[35m            "expires_on": 0,[0m

[31m--[ [0m[34mMatch #[0m[33m99[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m933 | [0m[35m    @pytest.mark.parametrize("access_token, token_type", [("my_token", None), ("my_token", "not bear[0m
[30;1m934 | [0m[35m    def test_is_oauth_token_valid_raises_invalid_type(self, access_token, token_type):[0m
[30;1m935 | [0m[35m        with pytest.raises(AirflowException):[0m
[30;1m936 | [0m[35m            self.hook._is_oauth_token_valid({"access_token": access_token, "token_type": token_type}[0m
[30;1m937 | [0m[35m[0m
[30;1m938 | [0m[35m    def test_is_oauth_token_valid_raises_wrong_time_key(self):[0m
[30;1m939 | [0m[35m        token = {[0m

[31m--[ [0m[34mMatch #[0m[33m100[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m931 | [0m[35m            self.hook._is_oauth_token_valid({})[0m
[30;1m932 | [0m[35m[0m
[30;1m933 | [0m[35m    @pytest.mark.parametrize("access_token, token_type", [("my_token", None), ("my_token", "not bear[0m
[30;1m934 | [0m[35m    def test_is_oauth_token_valid_raises_invalid_type(self, access_token, token_type):[0m
[30;1m935 | [0m[35m        with pytest.raises(AirflowException):[0m
[30;1m936 | [0m[35m            self.hook._is_oauth_token_valid({"access_token": access_token, "token_type": token_type}[0m
[30;1m937 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m101[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m928 | [0m[35m[0m
[30;1m929 | [0m[35m    def test_is_oauth_token_valid_raises_missing_token(self):[0m
[30;1m930 | [0m[35m        with pytest.raises(AirflowException):[0m
[30;1m931 | [0m[35m            self.hook._is_oauth_token_valid({})[0m
[30;1m932 | [0m[35m[0m
[30;1m933 | [0m[35m    @pytest.mark.parametrize("access_token, token_type", [("my_token", None), ("my_token", "not bear[0m
[30;1m934 | [0m[35m    def test_is_oauth_token_valid_raises_invalid_type(self, access_token, token_type):[0m

[31m--[ [0m[34mMatch #[0m[33m102[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m926 | [0m[35m        }[0m
[30;1m927 | [0m[35m        assert not self.hook._is_oauth_token_valid(token)[0m
[30;1m928 | [0m[35m[0m
[30;1m929 | [0m[35m    def test_is_oauth_token_valid_raises_missing_token(self):[0m
[30;1m930 | [0m[35m        with pytest.raises(AirflowException):[0m
[30;1m931 | [0m[35m            self.hook._is_oauth_token_valid({})[0m
[30;1m932 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m103[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m924 | [0m[35m            "expires_on": int(time.time()),[0m
[30;1m925 | [0m[35m            "token_type": "Bearer",[0m
[30;1m926 | [0m[35m        }[0m
[30;1m927 | [0m[35m        assert not self.hook._is_oauth_token_valid(token)[0m
[30;1m928 | [0m[35m[0m
[30;1m929 | [0m[35m    def test_is_oauth_token_valid_raises_missing_token(self):[0m
[30;1m930 | [0m[35m        with pytest.raises(AirflowException):[0m

[31m--[ [0m[34mMatch #[0m[33m104[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m918 | [0m[35m        }[0m
[30;1m919 | [0m[35m        assert self.hook._is_oauth_token_valid(token)[0m
[30;1m920 | [0m[35m[0m
[30;1m921 | [0m[35m    def test_is_oauth_token_valid_returns_false(self):[0m
[30;1m922 | [0m[35m        token = {[0m
[30;1m923 | [0m[35m            "access_token": "my_token",[0m
[30;1m924 | [0m[35m            "expires_on": int(time.time()),[0m

[31m--[ [0m[34mMatch #[0m[33m105[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m916 | [0m[35m            "expires_on": int(time.time()) + TOKEN_REFRESH_LEAD_TIME + 10,[0m
[30;1m917 | [0m[35m            "token_type": "Bearer",[0m
[30;1m918 | [0m[35m        }[0m
[30;1m919 | [0m[35m        assert self.hook._is_oauth_token_valid(token)[0m
[30;1m920 | [0m[35m[0m
[30;1m921 | [0m[35m    def test_is_oauth_token_valid_returns_false(self):[0m
[30;1m922 | [0m[35m        token = {[0m

[31m--[ [0m[34mMatch #[0m[33m106[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m910 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m911 | [0m[35m        )[0m
[30;1m912 | [0m[35m[0m
[30;1m913 | [0m[35m    def test_is_oauth_token_valid_returns_true(self):[0m
[30;1m914 | [0m[35m        token = {[0m
[30;1m915 | [0m[35m            "access_token": "my_token",[0m
[30;1m916 | [0m[35m            "expires_on": int(time.time()) + TOKEN_REFRESH_LEAD_TIME + 10,[0m

[31m--[ [0m[34mMatch #[0m[33m107[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m905 | [0m[35m            uninstall_endpoint(HOST),[0m
[30;1m906 | [0m[35m            json={"cluster_id": CLUSTER_ID, "libraries": LIBRARIES},[0m
[30;1m907 | [0m[35m            params=None,[0m
[30;1m908 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m909 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m910 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m911 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m108[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m886 | [0m[35m            install_endpoint(HOST),[0m
[30;1m887 | [0m[35m            json={"cluster_id": CLUSTER_ID, "libraries": LIBRARIES},[0m
[30;1m888 | [0m[35m            params=None,[0m
[30;1m889 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m890 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m891 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m892 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m109[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m867 | [0m[35m            terminate_cluster_endpoint(HOST),[0m
[30;1m868 | [0m[35m            json={"cluster_id": CLUSTER_ID},[0m
[30;1m869 | [0m[35m            params=None,[0m
[30;1m870 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m871 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m872 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m873 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m110[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m849 | [0m[35m            restart_cluster_endpoint(HOST),[0m
[30;1m850 | [0m[35m            json={"cluster_id": CLUSTER_ID},[0m
[30;1m851 | [0m[35m            params=None,[0m
[30;1m852 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m853 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m854 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m855 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m111[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m831 | [0m[35m            start_cluster_endpoint(HOST),[0m
[30;1m832 | [0m[35m            json={"cluster_id": CLUSTER_ID},[0m
[30;1m833 | [0m[35m            params=None,[0m
[30;1m834 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m835 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m836 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m837 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m112[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m813 | [0m[35m            get_cluster_endpoint(HOST),[0m
[30;1m814 | [0m[35m            json=None,[0m
[30;1m815 | [0m[35m            params={"cluster_id": CLUSTER_ID},[0m
[30;1m816 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m817 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m818 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m819 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m113[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m720 | [0m[35m            repair_run_endpoint(HOST),[0m
[30;1m721 | [0m[35m            json=json,[0m
[30;1m722 | [0m[35m            params=None,[0m
[30;1m723 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m724 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m725 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m726 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m114[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m689 | [0m[35m            delete_run_endpoint(HOST),[0m
[30;1m690 | [0m[35m            json={"run_id": RUN_ID},[0m
[30;1m691 | [0m[35m            params=None,[0m
[30;1m692 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m693 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m694 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m695 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m115[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m674 | [0m[35m            cancel_all_runs_endpoint(HOST),[0m
[30;1m675 | [0m[35m            json={"job_id": JOB_ID},[0m
[30;1m676 | [0m[35m            params=None,[0m
[30;1m677 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m678 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m679 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m680 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m116[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m659 | [0m[35m            cancel_run_endpoint(HOST),[0m
[30;1m660 | [0m[35m            json={"run_id": RUN_ID},[0m
[30;1m661 | [0m[35m            params=None,[0m
[30;1m662 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m663 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m664 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m665 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m117[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m620 | [0m[35m            get_run_endpoint(HOST),[0m
[30;1m621 | [0m[35m            json=None,[0m
[30;1m622 | [0m[35m            params={"run_id": RUN_ID},[0m
[30;1m623 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m624 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m625 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m626 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m118[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m604 | [0m[35m            get_run_output_endpoint(HOST),[0m
[30;1m605 | [0m[35m            json=None,[0m
[30;1m606 | [0m[35m            params={"run_id": RUN_ID},[0m
[30;1m607 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m608 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m609 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m610 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m119[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m588 | [0m[35m            get_run_endpoint(HOST),[0m
[30;1m589 | [0m[35m            json=None,[0m
[30;1m590 | [0m[35m            params={"run_id": RUN_ID},[0m
[30;1m591 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m592 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m593 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m594 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m120[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m572 | [0m[35m            get_run_endpoint(HOST),[0m
[30;1m573 | [0m[35m            json=None,[0m
[30;1m574 | [0m[35m            params={"run_id": RUN_ID},[0m
[30;1m575 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m576 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m577 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m578 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m121[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m556 | [0m[35m            run_now_endpoint(HOST),[0m
[30;1m557 | [0m[35m            json={"notebook_params": NOTEBOOK_PARAMS, "jar_params": JAR_PARAMS, "job_id": JOB_ID},[0m
[30;1m558 | [0m[35m            params=None,[0m
[30;1m559 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m560 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m561 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m562 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m122[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m536 | [0m[35m                "new_cluster": NEW_CLUSTER,[0m
[30;1m537 | [0m[35m            },[0m
[30;1m538 | [0m[35m            params=None,[0m
[30;1m539 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m540 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m541 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m542 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m123[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m517 | [0m[35m                "new_cluster": NEW_CLUSTER,[0m
[30;1m518 | [0m[35m            },[0m
[30;1m519 | [0m[35m            params=None,[0m
[30;1m520 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m521 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m522 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m523 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m124[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m498 | [0m[35m            update_endpoint(HOST),[0m
[30;1m499 | [0m[35m            json={"job_id": JOB_ID, "new_settings": {"name": "test"}},[0m
[30;1m500 | [0m[35m            params=None,[0m
[30;1m501 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m502 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m503 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m504 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m125[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m481 | [0m[35m            reset_endpoint(HOST),[0m
[30;1m482 | [0m[35m            json={"job_id": JOB_ID, "new_settings": {"name": "test"}},[0m
[30;1m483 | [0m[35m            params=None,[0m
[30;1m484 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m485 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m486 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m487 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m126[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m464 | [0m[35m            create_endpoint(HOST),[0m
[30;1m465 | [0m[35m            json={"name": "test"},[0m
[30;1m466 | [0m[35m            params=None,[0m
[30;1m467 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m468 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m469 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m470 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m127[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m444 | [0m[35m            submit_run_endpoint(HOST),[0m
[30;1m445 | [0m[35m            json={"cluster_name": "new_name"},[0m
[30;1m446 | [0m[35m            params=None,[0m
[30;1m447 | [0m[35m            auth=HTTPBasicAuth(LOGIN, PASSWORD),[0m
[30;1m448 | [0m[35m            headers=self.hook.user_agent_header,[0m
[30;1m449 | [0m[35m            timeout=self.hook.timeout_seconds,[0m
[30;1m450 | [0m[35m        )[0m

[31m--[ [0m[34mMatch #[0m[33m128[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m326 | [0m[35m        conn.schema = None[0m
[30;1m327 | [0m[35m        conn.port = None[0m
[30;1m328 | [0m[35m        conn.login = LOGIN[0m
[30;1m329 | [0m[35m        conn.password = PASSWORD[0m
[30;1m330 | [0m[35m        conn.extra = None[0m
[30;1m331 | [0m[35m        session.commit()[0m
[30;1m332 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m129[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m326 | [0m[35m        conn.schema = None[0m
[30;1m327 | [0m[35m        conn.port = None[0m
[30;1m328 | [0m[35m        conn.login = LOGIN[0m
[30;1m329 | [0m[35m        conn.password = PASSWORD[0m
[30;1m330 | [0m[35m        conn.extra = None[0m
[30;1m331 | [0m[35m        session.commit()[0m
[30;1m332 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m130[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m77 | [0m[35mHOST = "xx.cloud.databricks.com"[0m
[30;1m78 | [0m[35mHOST_WITH_SCHEME = "https://xx.cloud.databricks.com"[0m
[30;1m79 | [0m[35mLOGIN = "login"[0m
[30;1m80 | [0m[35mPASSWORD = "password"[0m
[30;1m81 | [0m[35mTOKEN = "token"[0m
[30;1m82 | [0m[35mAZURE_DEFAULT_AD_ENDPOINT = "https://login.microsoftonline.com"[0m
[30;1m83 | [0m[35mAZURE_TOKEN_SERVICE_URL = "{}/{}/oauth2/token"[0m

[31m--[ [0m[34mMatch #[0m[33m131[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000701[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Token[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m(npm owner|password|htpasswd|auth_?token|secret_?key|private_?key|authorized_keys?|npmrc|\.ssh|usersecrets?|api_?keys|nuget\.config|\.identityservice)[0m
[30;1m77 | [0m[35mHOST = "xx.cloud.databricks.com"[0m
[30;1m78 | [0m[35mHOST_WITH_SCHEME = "https://xx.cloud.databricks.com"[0m
[30;1m79 | [0m[35mLOGIN = "login"[0m
[30;1m80 | [0m[35mPASSWORD = "password"[0m
[30;1m81 | [0m[35mTOKEN = "token"[0m
[30;1m82 | [0m[35mAZURE_DEFAULT_AD_ENDPOINT = "https://login.microsoftonline.com"[0m
[30;1m83 | [0m[35mAZURE_TOKEN_SERVICE_URL = "{}/{}/oauth2/token"[0m

[31m--[ [0m[34mMatch #[0m[33m132[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000702[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Environment[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_sql.py[0m
   Pattern: [32m(env|environment).{1,50}(get|post|curl|nc|invoke-restmethod)[0m
[30;1m37 | [0m[35m    DatabricksSqlOperator,[0m
[30;1m38 | [0m[35m)[0m
[30;1m39 | [0m[35m[0m
[30;1m40 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m41 | [0m[35mDAG_ID = "example_databricks_sql_operator"[0m
[30;1m42 | [0m[35m[0m
[30;1m43 | [0m[35mwith DAG([0m

[31m--[ [0m[34mMatch #[0m[33m133[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000702[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Environment[0m
  Severity: [36mImportant[0m, Confidence: [36mHigh[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_repos.py[0m
   Pattern: [32m(env|environment).{1,50}(get|post|curl|nc|invoke-restmethod)[0m
[30;1m32 | [0m[35m    "databricks_conn_id": "databricks",[0m
[30;1m33 | [0m[35m}[0m
[30;1m34 | [0m[35m[0m
[30;1m35 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m36 | [0m[35mDAG_ID = "example_databricks_repos_operator"[0m
[30;1m37 | [0m[35m[0m
[30;1m38 | [0m[35mwith DAG([0m

[31m--[ [0m[34mMatch #[0m[33m134[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m1079 | [0m[35m   * ``Remove Backport Providers (#14886)``[0m
[30;1m1080 | [0m[35m   * ``Updated documentation for June 2021 provider release (#16294)``[0m
[30;1m1081 | [0m[35m   * ``Add documentation for Databricks connection (#15410)``[0m
[30;1m1082 | [0m[35m   * ``More documentation update for June providers release (#16405)``[0m
[30;1m1083 | [0m[35m   * ``Synchronizes updated changelog after buggfix release (#16464)``[0m
[30;1m1084 | [0m[35m[0m
[30;1m1085 | [0m[35m1.0.1[0m

[31m--[ [0m[34mMatch #[0m[33m135[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m1069 | [0m[35m[0m
[30;1m1070 | [0m[35m.. warning:: Due to apply_default decorator removal, this version of the provider requires Airflow 2[0m
[30;1m1071 | [0m[35m   If your Airflow version is < 2.1.0, and you want to install this provider version, first upgrade[0m
[30;1m1072 | [0m[35m   Airflow to at least version 2.1.0. Otherwise your Airflow package version will be upgraded[0m
[30;1m1073 | [0m[35m   automatically and you will have to manually run ``airflow upgrade db`` to complete the migration.[0m
[30;1m1074 | [0m[35m[0m
[30;1m1075 | [0m[35m.. Below changes are excluded from the changelog. Move them to[0m

[31m--[ [0m[34mMatch #[0m[33m136[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m815 | [0m[35mFeatures[0m
[30;1m816 | [0m[35m~~~~~~~~[0m
[30;1m817 | [0m[35m[0m
[30;1m818 | [0m[35m* ``Databricks: update user-agent string (#25578)``[0m
[30;1m819 | [0m[35m* ``More improvements in the Databricks operators (#25260)``[0m
[30;1m820 | [0m[35m* ``Improved telemetry for Databricks provider (#25115)``[0m
[30;1m821 | [0m[35m* ``Unify DbApiHook.run() method with the methods which override it (#23971)``[0m

[31m--[ [0m[34mMatch #[0m[33m137[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m689 | [0m[35m   * ``Move TaskInstanceKey to a separate file (#31033)``[0m
[30;1m690 | [0m[35m   * ``Use 'AirflowProviderDeprecationWarning' in providers (#30975)``[0m
[30;1m691 | [0m[35m   * ``Add full automation for min Airflow version for providers (#30994)``[0m
[30;1m692 | [0m[35m   * ``Add cli cmd to list the provider trigger info (#30822)``[0m
[30;1m693 | [0m[35m   * ``Use '__version__' in providers not 'version' (#31393)``[0m
[30;1m694 | [0m[35m   * ``Fixing circular import error in providers caused by airflow version check (#31379)``[0m
[30;1m695 | [0m[35m   * ``Prepare docs for May 2023 wave of Providers (#31252)``[0m

[31m--[ [0m[34mMatch #[0m[33m138[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m385 | [0m[35m[0m
[30;1m386 | [0m[35m* ``Fix remaining D401 checks (#37434)``[0m
[30;1m387 | [0m[35m* ``Update ACL during job reset (#38741)``[0m
[30;1m388 | [0m[35m* ``Remove extra slash from update permission endpoint (#38918)``[0m
[30;1m389 | [0m[35m* ``DatabricksRunNowOperator: fix typo in latest_repair_id (#39050)``[0m
[30;1m390 | [0m[35m[0m
[30;1m391 | [0m[35mMisc[0m

[31m--[ [0m[34mMatch #[0m[33m139[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m378 | [0m[35m[0m
[30;1m379 | [0m[35m* ``Add cancel_previous_run to DatabricksRunNowOperator (#38702)``[0m
[30;1m380 | [0m[35m* ``add repair_run support to DatabricksRunNowOperator in deferrable mode (#38619)``[0m
[30;1m381 | [0m[35m* ``Adds job_id as path param in update permission (#38962)``[0m
[30;1m382 | [0m[35m[0m
[30;1m383 | [0m[35mBug Fixes[0m
[30;1m384 | [0m[35m~~~~~~~~~[0m

[31m--[ [0m[34mMatch #[0m[33m140[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m37 | [0m[35m[0m
[30;1m38 | [0m[35m.. Below changes are excluded from the changelog. Move them to[0m
[30;1m39 | [0m[35m   appropriate section above if needed. Do not delete the lines(!):[0m
[30;1m40 | [0m[35m   * ``Remove unnecessary entries in get_provider_info and update the schema (#48849)``[0m
[30;1m41 | [0m[35m   * ``Remove fab from preinstalled providers (#48457)``[0m
[30;1m42 | [0m[35m   * ``Fix static checks in mock_databricks_hook (#48869)``[0m
[30;1m43 | [0m[35m   * ``Improve documentation building iteration (#48760)``[0m

[31m--[ [0m[34mMatch #[0m[33m141[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m142[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1074 | [0m[35m[0m
[30;1m1075 | [0m[35m.. Below changes are excluded from the changelog. Move them to[0m
[30;1m1076 | [0m[35m   appropriate section above if needed. Do not delete the lines(!):[0m
[30;1m1077 | [0m[35m   * ``Prepares provider release after PIP 21 compatibility (#15576)``[0m
[30;1m1078 | [0m[35m   * ``An initial rework of the 'Concepts' docs (#15444)``[0m
[30;1m1079 | [0m[35m   * ``Remove Backport Providers (#14886)``[0m
[30;1m1080 | [0m[35m   * ``Updated documentation for June 2021 provider release (#16294)``[0m

[31m--[ [0m[34mMatch #[0m[33m143[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1022 | [0m[35m~~~~~~~~~[0m
[30;1m1023 | [0m[35m[0m
[30;1m1024 | [0m[35m* ``Fixup string concatenations (#19099)``[0m
[30;1m1025 | [0m[35m* ``Databricks hook: fix expiration time check (#20036)``[0m
[30;1m1026 | [0m[35m[0m
[30;1m1027 | [0m[35m.. Below changes are excluded from the changelog. Move them to[0m
[30;1m1028 | [0m[35m   appropriate section above if needed. Do not delete the lines(!):[0m

[31m--[ [0m[34mMatch #[0m[33m144[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/changelog.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m575 | [0m[35mFeatures[0m
[30;1m576 | [0m[35m~~~~~~~~[0m
[30;1m577 | [0m[35m[0m
[30;1m578 | [0m[35m* ``Add Service Principal OAuth for Databricks. (#33005)``[0m
[30;1m579 | [0m[35m[0m
[30;1m580 | [0m[35mMisc[0m
[30;1m581 | [0m[35m~~~~[0m

[31m--[ [0m[34mMatch #[0m[33m145[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m146[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m757 | [0m[35m        if isinstance(exception, requests_exceptions.HTTPError):[0m
[30;1m758 | [0m[35m            try:[0m
[30;1m759 | [0m[35m                jsn = exception.response.json()[0m
[30;1m760 | [0m[35m                return jsn.get("error_code", "")[0m
[30;1m761 | [0m[35m            except JSONDecodeError:[0m
[30;1m762 | [0m[35m                pass[0m
[30;1m763 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m147[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m602 | [0m[35m            self.log.debug("Using AzureDefaultCredential for authentication.")[0m
[30;1m603 | [0m[35m[0m
[30;1m604 | [0m[35m            return await self._a_get_aad_token_for_default_az_credential(DEFAULT_DATABRICKS_SCOPE)[0m
[30;1m605 | [0m[35m        elif self.databricks_conn.extra_dejson.get("service_principal_oauth", False):[0m
[30;1m606 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m607 | [0m[35m                raise AirflowException("Service Principal credentials aren't provided")[0m
[30;1m608 | [0m[35m            self.log.debug("Using Service Principal Token.")[0m

[31m--[ [0m[34mMatch #[0m[33m148[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m598 | [0m[35m            self.log.debug("Using AAD Token for managed identity.")[0m
[30;1m599 | [0m[35m            await self._a_check_azure_metadata_service()[0m
[30;1m600 | [0m[35m            return await self._a_get_aad_token(DEFAULT_DATABRICKS_SCOPE)[0m
[30;1m601 | [0m[35m        elif self.databricks_conn.extra_dejson.get(DEFAULT_AZURE_CREDENTIAL_SETTING_KEY, False):[0m
[30;1m602 | [0m[35m            self.log.debug("Using AzureDefaultCredential for authentication.")[0m
[30;1m603 | [0m[35m[0m
[30;1m604 | [0m[35m            return await self._a_get_aad_token_for_default_az_credential(DEFAULT_DATABRICKS_SCOPE)[0m

[31m--[ [0m[34mMatch #[0m[33m149[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m594 | [0m[35m                raise AirflowException("Azure SPN credentials aren't provided")[0m
[30;1m595 | [0m[35m            self.log.debug("Using AAD Token for SPN.")[0m
[30;1m596 | [0m[35m            return await self._a_get_aad_token(DEFAULT_DATABRICKS_SCOPE)[0m
[30;1m597 | [0m[35m        elif self.databricks_conn.extra_dejson.get("use_azure_managed_identity", False):[0m
[30;1m598 | [0m[35m            self.log.debug("Using AAD Token for managed identity.")[0m
[30;1m599 | [0m[35m            await self._a_check_azure_metadata_service()[0m
[30;1m600 | [0m[35m            return await self._a_get_aad_token(DEFAULT_DATABRICKS_SCOPE)[0m

[31m--[ [0m[34mMatch #[0m[33m150[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m570 | [0m[35m        elif self.databricks_conn.extra_dejson.get(DEFAULT_AZURE_CREDENTIAL_SETTING_KEY, False):[0m
[30;1m571 | [0m[35m            self.log.debug("Using default Azure Credential authentication.")[0m
[30;1m572 | [0m[35m            return self._get_aad_token_for_default_az_credential(DEFAULT_DATABRICKS_SCOPE)[0m
[30;1m573 | [0m[35m        elif self.databricks_conn.extra_dejson.get("service_principal_oauth", False):[0m
[30;1m574 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m575 | [0m[35m                raise AirflowException("Service Principal credentials aren't provided")[0m
[30;1m576 | [0m[35m            self.log.debug("Using Service Principal Token.")[0m

[31m--[ [0m[34mMatch #[0m[33m151[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m567 | [0m[35m            self.log.debug("Using AAD Token for managed identity.")[0m
[30;1m568 | [0m[35m            self._check_azure_metadata_service()[0m
[30;1m569 | [0m[35m            return self._get_aad_token(DEFAULT_DATABRICKS_SCOPE)[0m
[30;1m570 | [0m[35m        elif self.databricks_conn.extra_dejson.get(DEFAULT_AZURE_CREDENTIAL_SETTING_KEY, False):[0m
[30;1m571 | [0m[35m            self.log.debug("Using default Azure Credential authentication.")[0m
[30;1m572 | [0m[35m            return self._get_aad_token_for_default_az_credential(DEFAULT_DATABRICKS_SCOPE)[0m
[30;1m573 | [0m[35m        elif self.databricks_conn.extra_dejson.get("service_principal_oauth", False):[0m

[31m--[ [0m[34mMatch #[0m[33m152[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m563 | [0m[35m                raise AirflowException("Azure SPN credentials aren't provided")[0m
[30;1m564 | [0m[35m            self.log.debug("Using AAD Token for SPN.")[0m
[30;1m565 | [0m[35m            return self._get_aad_token(DEFAULT_DATABRICKS_SCOPE)[0m
[30;1m566 | [0m[35m        elif self.databricks_conn.extra_dejson.get("use_azure_managed_identity", False):[0m
[30;1m567 | [0m[35m            self.log.debug("Using AAD Token for managed identity.")[0m
[30;1m568 | [0m[35m            self._check_azure_metadata_service()[0m
[30;1m569 | [0m[35m            return self._get_aad_token(DEFAULT_DATABRICKS_SCOPE)[0m

[31m--[ [0m[34mMatch #[0m[33m153[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m535 | [0m[35m    async def _a_check_azure_metadata_service(self):[0m
[30;1m536 | [0m[35m        """Async version of `_check_azure_metadata_service()`."""[0m
[30;1m537 | [0m[35m        try:[0m
[30;1m538 | [0m[35m            async with self._session.get([0m
[30;1m539 | [0m[35m                url=AZURE_METADATA_SERVICE_INSTANCE_URL,[0m
[30;1m540 | [0m[35m                params={"api-version": "2021-02-01"},[0m
[30;1m541 | [0m[35m                headers={"Metadata": "true"},[0m

[31m--[ [0m[34mMatch #[0m[33m154[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m519 | [0m[35m        https://docs.microsoft.com/en-us/azure/virtual-machines/linux/instance-metadata-service[0m
[30;1m520 | [0m[35m        """[0m
[30;1m521 | [0m[35m        try:[0m
[30;1m522 | [0m[35m            jsn = requests.get([0m
[30;1m523 | [0m[35m                AZURE_METADATA_SERVICE_INSTANCE_URL,[0m
[30;1m524 | [0m[35m                params={"api-version": "2021-02-01"},[0m
[30;1m525 | [0m[35m                headers={"Metadata": "true"},[0m

[31m--[ [0m[34mMatch #[0m[33m155[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m506 | [0m[35m        :param time_key: name of the key that holds the time of expiration[0m
[30;1m507 | [0m[35m        :return: true if token is valid, false otherwise[0m
[30;1m508 | [0m[35m        """[0m
[30;1m509 | [0m[35m        if "access_token" not in token or token.get("token_type", "") != "Bearer" or time_key not in[0m
[30;1m510 | [0m[35m            raise AirflowException(f"Can't get necessary data from OAuth token: {token}")[0m
[30;1m511 | [0m[35m[0m
[30;1m512 | [0m[35m        return int(token[time_key]) > (int(time.time()) + TOKEN_REFRESH_LEAD_TIME)[0m

[31m--[ [0m[34mMatch #[0m[33m156[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m430 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m431 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m432 | [0m[35m        """[0m
[30;1m433 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m434 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m435 | [0m[35m            return aad_token["access_token"][0m
[30;1m436 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m157[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m387 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m388 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m389 | [0m[35m        """[0m
[30;1m390 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m391 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m392 | [0m[35m            return aad_token["access_token"][0m
[30;1m393 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m158[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m353 | [0m[35m[0m
[30;1m354 | [0m[35m            async for attempt in self._a_get_retry_object():[0m
[30;1m355 | [0m[35m                with attempt:[0m
[30;1m356 | [0m[35m                    if self.databricks_conn.extra_dejson.get("use_azure_managed_identity", False):[0m
[30;1m357 | [0m[35m                        token = await AsyncManagedIdentityCredential().get_token(f"{resource}/.defau[0m
[30;1m358 | [0m[35m                    else:[0m
[30;1m359 | [0m[35m                        credential = AsyncClientSecretCredential([0m

[31m--[ [0m[34mMatch #[0m[33m159[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m340 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m341 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m342 | [0m[35m        """[0m
[30;1m343 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m344 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m345 | [0m[35m            return aad_token["access_token"][0m
[30;1m346 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m160[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m306 | [0m[35m[0m
[30;1m307 | [0m[35m            for attempt in self._get_retry_object():[0m
[30;1m308 | [0m[35m                with attempt:[0m
[30;1m309 | [0m[35m                    if self.databricks_conn.extra_dejson.get("use_azure_managed_identity", False):[0m
[30;1m310 | [0m[35m                        token = ManagedIdentityCredential().get_token(f"{resource}/.default")[0m
[30;1m311 | [0m[35m                    else:[0m
[30;1m312 | [0m[35m                        credential = ClientSecretCredential([0m

[31m--[ [0m[34mMatch #[0m[33m161[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m296 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m297 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m298 | [0m[35m        """[0m
[30;1m299 | [0m[35m        aad_token = self.oauth_tokens.get(resource)[0m
[30;1m300 | [0m[35m        if aad_token and self._is_oauth_token_valid(aad_token):[0m
[30;1m301 | [0m[35m            return aad_token["access_token"][0m
[30;1m302 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m162[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m263 | [0m[35m        try:[0m
[30;1m264 | [0m[35m            async for attempt in self._a_get_retry_object():[0m
[30;1m265 | [0m[35m                with attempt:[0m
[30;1m266 | [0m[35m                    async with self._session.post([0m
[30;1m267 | [0m[35m                        resource,[0m
[30;1m268 | [0m[35m                        auth=aiohttp.BasicAuth(self.databricks_conn.login, self.databricks_conn.pass[0m
[30;1m269 | [0m[35m                        data="grant_type=client_credentials&scope=all-apis",[0m

[31m--[ [0m[34mMatch #[0m[33m163[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m255 | [0m[35m[0m
[30;1m256 | [0m[35m    async def _a_get_sp_token(self, resource: str) -> str:[0m
[30;1m257 | [0m[35m        """Async version of `_get_sp_token()`."""[0m
[30;1m258 | [0m[35m        sp_token = self.oauth_tokens.get(resource)[0m
[30;1m259 | [0m[35m        if sp_token and self._is_oauth_token_valid(sp_token):[0m
[30;1m260 | [0m[35m            return sp_token["access_token"][0m
[30;1m261 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m164[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m227 | [0m[35m        try:[0m
[30;1m228 | [0m[35m            for attempt in self._get_retry_object():[0m
[30;1m229 | [0m[35m                with attempt:[0m
[30;1m230 | [0m[35m                    resp = requests.post([0m
[30;1m231 | [0m[35m                        resource,[0m
[30;1m232 | [0m[35m                        auth=HTTPBasicAuth(self.databricks_conn.login, self.databricks_conn.password[0m
[30;1m233 | [0m[35m                        data="grant_type=client_credentials&scope=all-apis",[0m

[31m--[ [0m[34mMatch #[0m[33m165[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m219 | [0m[35m[0m
[30;1m220 | [0m[35m    def _get_sp_token(self, resource: str) -> str:[0m
[30;1m221 | [0m[35m        """Get Service Principal token."""[0m
[30;1m222 | [0m[35m        sp_token = self.oauth_tokens.get(resource)[0m
[30;1m223 | [0m[35m        if sp_token and self._is_oauth_token_valid(sp_token):[0m
[30;1m224 | [0m[35m            return sp_token["access_token"][0m
[30;1m225 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m166[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000704[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Hostname[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m.hostname[0m
[30;1m193 | [0m[35m            assert h._parse_host('xx.cloud.databricks.com') == 'xx.cloud.databricks.com'[0m
[30;1m194 | [0m[35m[0m
[30;1m195 | [0m[35m        """[0m
[30;1m196 | [0m[35m        urlparse_host = urlsplit(host).hostname[0m
[30;1m197 | [0m[35m        if urlparse_host:[0m
[30;1m198 | [0m[35m            # In this case, host = https://xx.cloud.databricks.com[0m
[30;1m199 | [0m[35m            return urlparse_host[0m

[31m--[ [0m[34mMatch #[0m[33m167[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000704[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Hostname[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m.hostname[0m
[30;1m193 | [0m[35m            assert h._parse_host('xx.cloud.databricks.com') == 'xx.cloud.databricks.com'[0m
[30;1m194 | [0m[35m[0m
[30;1m195 | [0m[35m        """[0m
[30;1m196 | [0m[35m        urlparse_host = urlsplit(host).hostname[0m
[30;1m197 | [0m[35m        if urlparse_host:[0m
[30;1m198 | [0m[35m            # In this case, host = https://xx.cloud.databricks.com[0m
[30;1m199 | [0m[35m            return urlparse_host[0m

[31m--[ [0m[34mMatch #[0m[33m168[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m605 | [0m[35m        elif self.databricks_conn.extra_dejson.get("service_principal_oauth", False):[0m
[30;1m606 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m607 | [0m[35m                raise AirflowException("Service Principal credentials aren't provided")[0m
[30;1m608 | [0m[35m            self.log.debug("Using Service Principal Token.")[0m
[30;1m609 | [0m[35m            return await self._a_get_sp_token(OIDC_TOKEN_SERVICE_URL.format(self.databricks_conn.hos[0m
[30;1m610 | [0m[35m        elif raise_error:[0m
[30;1m611 | [0m[35m            raise AirflowException("Token authentication isn't configured")[0m

[31m--[ [0m[34mMatch #[0m[33m169[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m573 | [0m[35m        elif self.databricks_conn.extra_dejson.get("service_principal_oauth", False):[0m
[30;1m574 | [0m[35m            if self.databricks_conn.login == "" or self.databricks_conn.password == "":[0m
[30;1m575 | [0m[35m                raise AirflowException("Service Principal credentials aren't provided")[0m
[30;1m576 | [0m[35m            self.log.debug("Using Service Principal Token.")[0m
[30;1m577 | [0m[35m            return self._get_sp_token(OIDC_TOKEN_SERVICE_URL.format(self.databricks_conn.host))[0m
[30;1m578 | [0m[35m        elif raise_error:[0m
[30;1m579 | [0m[35m            raise AirflowException("Token authentication isn't configured")[0m

[31m--[ [0m[34mMatch #[0m[33m170[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m503 | [0m[35m        Check if an OAuth token is valid and hasn't expired yet.[0m
[30;1m504 | [0m[35m[0m
[30;1m505 | [0m[35m        :param sp_token: dict with properties of OAuth token[0m
[30;1m506 | [0m[35m        :param time_key: name of the key that holds the time of expiration[0m
[30;1m507 | [0m[35m        :return: true if token is valid, false otherwise[0m
[30;1m508 | [0m[35m        """[0m
[30;1m509 | [0m[35m        if "access_token" not in token or token.get("token_type", "") != "Bearer" or time_key not in[0m

[31m--[ [0m[34mMatch #[0m[33m171[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m442 | [0m[35m[0m
[30;1m443 | [0m[35m            for attempt in self._get_retry_object():[0m
[30;1m444 | [0m[35m                with attempt:[0m
[30;1m445 | [0m[35m                    # This only works in an Azure Kubernetes Service Cluster given the following env[0m
[30;1m446 | [0m[35m                    # AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_FEDERATED_TOKEN_FILE[0m
[30;1m447 | [0m[35m                    #[0m
[30;1m448 | [0m[35m                    # While there is a WorkloadIdentityCredential class, the below class is advised [0m

[31m--[ [0m[34mMatch #[0m[33m172[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m426 | [0m[35m        """[0m
[30;1m427 | [0m[35m        Get AAD token for given resource for workload identity.[0m
[30;1m428 | [0m[35m[0m
[30;1m429 | [0m[35m        Supports managed identity or service principal auth.[0m
[30;1m430 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m431 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m432 | [0m[35m        """[0m

[31m--[ [0m[34mMatch #[0m[33m173[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m397 | [0m[35m[0m
[30;1m398 | [0m[35m            for attempt in self._get_retry_object():[0m
[30;1m399 | [0m[35m                with attempt:[0m
[30;1m400 | [0m[35m                    # This only works in an Azure Kubernetes Service Cluster given the following env[0m
[30;1m401 | [0m[35m                    # AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_FEDERATED_TOKEN_FILE[0m
[30;1m402 | [0m[35m                    #[0m
[30;1m403 | [0m[35m                    # While there is a WorkloadIdentityCredential class, the below class is advised [0m

[31m--[ [0m[34mMatch #[0m[33m174[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m383 | [0m[35m        """[0m
[30;1m384 | [0m[35m        Get AAD token for given resource for workload identity.[0m
[30;1m385 | [0m[35m[0m
[30;1m386 | [0m[35m        Supports managed identity or service principal auth.[0m
[30;1m387 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m388 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m389 | [0m[35m        """[0m

[31m--[ [0m[34mMatch #[0m[33m175[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m292 | [0m[35m        """[0m
[30;1m293 | [0m[35m        Get AAD token for given resource.[0m
[30;1m294 | [0m[35m[0m
[30;1m295 | [0m[35m        Supports managed identity or service principal auth.[0m
[30;1m296 | [0m[35m        :param resource: resource to issue token to[0m
[30;1m297 | [0m[35m        :return: AAD token, or raise an exception[0m
[30;1m298 | [0m[35m        """[0m

[31m--[ [0m[34mMatch #[0m[33m176[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m259 | [0m[35m        if sp_token and self._is_oauth_token_valid(sp_token):[0m
[30;1m260 | [0m[35m            return sp_token["access_token"][0m
[30;1m261 | [0m[35m[0m
[30;1m262 | [0m[35m        self.log.info("Existing Service Principal token is expired, or going to expire soon. Refresh[0m
[30;1m263 | [0m[35m        try:[0m
[30;1m264 | [0m[35m            async for attempt in self._a_get_retry_object():[0m
[30;1m265 | [0m[35m                with attempt:[0m

[31m--[ [0m[34mMatch #[0m[33m177[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m223 | [0m[35m        if sp_token and self._is_oauth_token_valid(sp_token):[0m
[30;1m224 | [0m[35m            return sp_token["access_token"][0m
[30;1m225 | [0m[35m[0m
[30;1m226 | [0m[35m        self.log.info("Existing Service Principal token is expired, or going to expire soon. Refresh[0m
[30;1m227 | [0m[35m        try:[0m
[30;1m228 | [0m[35m            for attempt in self._get_retry_object():[0m
[30;1m229 | [0m[35m                with attempt:[0m

[31m--[ [0m[34mMatch #[0m[33m178[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m218 | [0m[35m        return AsyncRetrying(**self.retry_args)[0m
[30;1m219 | [0m[35m[0m
[30;1m220 | [0m[35m    def _get_sp_token(self, resource: str) -> str:[0m
[30;1m221 | [0m[35m        """Get Service Principal token."""[0m
[30;1m222 | [0m[35m        sp_token = self.oauth_tokens.get(resource)[0m
[30;1m223 | [0m[35m        if sp_token and self._is_oauth_token_valid(sp_token):[0m
[30;1m224 | [0m[35m            return sp_token["access_token"][0m

[31m--[ [0m[34mMatch #[0m[33m179[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m76 | [0m[35m    :param timeout_seconds: The amount of time in seconds the requests library[0m
[30;1m77 | [0m[35m        will wait before timing-out.[0m
[30;1m78 | [0m[35m    :param retry_limit: The number of times to retry the connection in case of[0m
[30;1m79 | [0m[35m        service outages.[0m
[30;1m80 | [0m[35m    :param retry_delay: The number of seconds to wait between retries (it[0m
[30;1m81 | [0m[35m        might be a floating point number).[0m
[30;1m82 | [0m[35m    :param retry_args: An optional dictionary with arguments passed to ``tenacity.Retrying`` class.[0m

[31m--[ [0m[34mMatch #[0m[33m180[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m73 | [0m[35m    Base for interaction with Databricks.[0m
[30;1m74 | [0m[35m[0m
[30;1m75 | [0m[35m    :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databr[0m
[30;1m76 | [0m[35m    :param timeout_seconds: The amount of time in seconds the requests library[0m
[30;1m77 | [0m[35m        will wait before timing-out.[0m
[30;1m78 | [0m[35m    :param retry_limit: The number of times to retry the connection in case of[0m
[30;1m79 | [0m[35m        service outages.[0m

[31m--[ [0m[34mMatch #[0m[33m181[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m27 | [0m[35m[0m
[30;1m28 | [0m[35mimport copy[0m
[30;1m29 | [0m[35mimport platform[0m
[30;1m30 | [0m[35mimport time[0m
[30;1m31 | [0m[35mfrom asyncio.exceptions import TimeoutError[0m
[30;1m32 | [0m[35mfrom functools import cached_property[0m
[30;1m33 | [0m[35mfrom typing import TYPE_CHECKING, Any[0m
[30;1m34 | [0m[35mfrom urllib.parse import urlsplit[0m

[31m--[ [0m[34mMatch #[0m[33m182[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_base.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m183[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/test_exceptions.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m184[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/version_compat.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m185[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m186[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/utils/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m187[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m106 | [0m[35m[0m
[30;1m107 | [0m[35mFor example:[0m
[30;1m108 | [0m[35m[0m
[30;1m109 | [0m[35m.. code-block:: bash[0m
[30;1m110 | [0m[35m[0m
[30;1m111 | [0m[35m   export AIRFLOW_CONN_DATABRICKS_DEFAULT='databricks://@host-url?token=yourtoken'[0m

[31m--[ [0m[34mMatch #[0m[33m188[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m189[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m106 | [0m[35m[0m
[30;1m107 | [0m[35mFor example:[0m
[30;1m108 | [0m[35m[0m
[30;1m109 | [0m[35m.. code-block:: bash[0m
[30;1m110 | [0m[35m[0m
[30;1m111 | [0m[35m   export AIRFLOW_CONN_DATABRICKS_DEFAULT='databricks://@host-url?token=yourtoken'[0m

[31m--[ [0m[34mMatch #[0m[33m190[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m88 | [0m[35meds to be used instead of[0m
[30;1m89 | [0m[35m      service principal[0m
[30;1m90 | [0m[35m    * ``use_default_azure_credential``: required boolean flag to specify if the `DefaultAzureCredent[0m
[30;1m91 | [0m[35m    * ``azure_resource_id``: optional Resource ID of the Azure Databricks workspace (required if man[0m
[30;1m92 | [0m[35m      a user inside workspace)[0m
[30;1m93 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m191[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m84 | [0m[35mtain a protocol. For example: ``https://login.microsoftonline.de``.[0m
[30;1m85 | [0m[35m[0m
[30;1m86 | [0m[35m    Following parameters are necessary if using authentication with AAD token for Azure managed iden[0m
[30;1m87 | [0m[35m[0m
[30;1m88 | [0m[35m    * ``use_azure_managed_identity``: required boolean flag to specify if managed identity needs to [0m
[30;1m89 | [0m[35m      service principal[0m

[31m--[ [0m[34mMatch #[0m[33m192[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m77 | [0m[35mtabricks.com/en/dev-tools/authentication-oauth.html>`_.[0m
[30;1m78 | [0m[35m[0m
[30;1m79 | [0m[35m    Following parameters are necessary if using authentication with AAD token:[0m
[30;1m80 | [0m[35m[0m
[30;1m81 | [0m[35m    * ``azure_tenant_id``: ID of the Azure Active Directory tenant[0m
[30;1m82 | [0m[35m    * ``azure_resource_id``: optional Resource ID of the Azure Databricks workspace (required if Ser[0m
[30;1m83 | [0m[35m      a user inside workspace)[0m

[31m--[ [0m[34mMatch #[0m[33m193[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m74 | [0m[35m[0m
[30;1m75 | [0m[35m    Following parameters are necessary if using authentication with OAuth token for AWS Databricks S[0m
[30;1m76 | [0m[35m[0m
[30;1m77 | [0m[35m    * ``service_principal_oauth``: required boolean flag.  If specified as ``true``, use the Client [0m
[30;1m78 | [0m[35m[0m
[30;1m79 | [0m[35m    Following parameters are necessary if using authentication with AAD token:[0m
[30;1m80 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m194[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m72 | [0m[35m[0m
[30;1m73 | [0m[35m    * ``token``: Specify PAT to use. Consider to switch to specification of PAT in the Password fiel[0m
[30;1m74 | [0m[35m[0m
[30;1m75 | [0m[35m    Following parameters are necessary if using authentication with OAuth token for AWS Databricks S[0m
[30;1m76 | [0m[35m[0m
[30;1m77 | [0m[35m    * ``service_principal_oauth``: required boolean flag.  If specified as ``true``, use the Client [0m
[30;1m78 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m195[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m63 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``password`` us[0m
[30;1m64 | [0m[35m    * If authentication with *Azure Service Principal* is used then specify the secret of the Azure [0m
[30;1m65 | [0m[35m    * If authentication with *PAT* is used, then specify PAT (recommended)[0m
[30;1m66 | [0m[35m    * If authentication with *Databricks Service Principal OAuth* is used then specify the secret of[0m
[30;1m67 | [0m[35m[0m
[30;1m68 | [0m[35mExtra (optional)[0m
[30;1m69 | [0m[35m    Specify the extra parameter (as json dictionary) that can be used in the Databricks connection.[0m

[31m--[ [0m[34mMatch #[0m[33m196[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m63 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``password`` us[0m
[30;1m64 | [0m[35m    * If authentication with *Azure Service Principal* is used then specify the secret of the Azure [0m
[30;1m65 | [0m[35m    * If authentication with *PAT* is used, then specify PAT (recommended)[0m
[30;1m66 | [0m[35m    * If authentication with *Databricks Service Principal OAuth* is used then specify the secret of[0m
[30;1m67 | [0m[35m[0m
[30;1m68 | [0m[35mExtra (optional)[0m
[30;1m69 | [0m[35m    Specify the extra parameter (as json dictionary) that can be used in the Databricks connection.[0m

[31m--[ [0m[34mMatch #[0m[33m197[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m61 | [0m[35m[0m
[30;1m62 | [0m[35mPassword (optional)[0m
[30;1m63 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``password`` us[0m
[30;1m64 | [0m[35m    * If authentication with *Azure Service Principal* is used then specify the secret of the Azure [0m
[30;1m65 | [0m[35m    * If authentication with *PAT* is used, then specify PAT (recommended)[0m
[30;1m66 | [0m[35m    * If authentication with *Databricks Service Principal OAuth* is used then specify the secret of[0m
[30;1m67 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m198[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m61 | [0m[35m[0m
[30;1m62 | [0m[35mPassword (optional)[0m
[30;1m63 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``password`` us[0m
[30;1m64 | [0m[35m    * If authentication with *Azure Service Principal* is used then specify the secret of the Azure [0m
[30;1m65 | [0m[35m    * If authentication with *PAT* is used, then specify PAT (recommended)[0m
[30;1m66 | [0m[35m    * If authentication with *Databricks Service Principal OAuth* is used then specify the secret of[0m
[30;1m67 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m199[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m59 | [0m[35mt header as Bearer token, if login is 'token' then it will be sent using Basic Auth which is allowed[0m
[30;1m60 | [0m[35m    * If authentication with *Databricks Service Principal OAuth* is used then specify the ID of the[0m
[30;1m61 | [0m[35m[0m
[30;1m62 | [0m[35mPassword (optional)[0m
[30;1m63 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``password`` us[0m
[30;1m64 | [0m[35m    * If authentication with *Azure Service Principal* is used then specify the secret of the Azure [0m

[31m--[ [0m[34mMatch #[0m[33m200[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m59 | [0m[35m is that if login is empty then token will be sent in request header as Bearer token, if login is 't[0m
[30;1m60 | [0m[35m    * If authentication with *Databricks Service Principal OAuth* is used then specify the ID of the[0m
[30;1m61 | [0m[35m[0m
[30;1m62 | [0m[35mPassword (optional)[0m
[30;1m63 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``password`` us[0m

[31m--[ [0m[34mMatch #[0m[33m201[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m51 | [0m[35m-[0m
[30;1m52 | [0m[35m[0m
[30;1m53 | [0m[35mHost (required)[0m
[30;1m54 | [0m[35m    Specify the Databricks workspace URL[0m
[30;1m55 | [0m[35m[0m
[30;1m56 | [0m[35mLogin (optional)[0m
[30;1m57 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``username`` us[0m
[30;1m58 | [0m[35m    * If authentication with *Azure Service Principal* is used then specify the ID of the Azure Serv[0m

[31m--[ [0m[34mMatch #[0m[33m202[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m48 | [0m[35mfault.[0m
[30;1m49 | [0m[35m[0m
[30;1m50 | [0m[35mConfiguring the Connection[0m
[30;1m51 | [0m[35m--------------------------[0m
[30;1m52 | [0m[35m[0m
[30;1m53 | [0m[35mHost (required)[0m
[30;1m54 | [0m[35m    Specify the Databricks workspace URL[0m
[30;1m55 | [0m[35m[0m
[30;1m56 | [0m[35mLogin (optional)[0m
[30;1m57 | [0m[35m    * If authentication with *Databricks login credentials* is used then specify the ``username`` us[0m
[30;1m58 | [0m[35m    * If authentication with *Azure Service Principal* is used then specify the ID of the Azure Serv[0m

[31m--[ [0m[34mMatch #[0m[33m203[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m37 | [0m[35mNote that username/password authentication is discouraged and not supported for[0m
[30;1m38 | [0m[35m   :class:`~airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator`.[0m
[30;1m39 | [0m[35m3. Using Azure Active Directory (AAD) token generated from Azure Service Principal's ID and secret[0m
[30;1m40 | [0m[35m   (only on Azure Databricks).  Service principal could be defined as a[0m

[31m--[ [0m[34mMatch #[0m[33m204[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/connections/databricks.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m36 | [0m[35m to login to the Databricks account to the Airflow connection.[0m
[30;1m37 | [0m[35m   Note that username/password authentication is discouraged and not supported for[0m
[30;1m38 | [0m[35m   :class:`~airflow.providers.databricks.operators.databricks_sql.DatabricksSqlOperator`.[0m
[30;1m39 | [0m[35m3. Using Azure Active Directory (AAD) token generated from Azure Service Principal's ID and secret[0m
[30;1m40 | [0m[35m   (only on Azure Databricks).  Service principal could be defined as a[0m

[31m--[ [0m[34mMatch #[0m[33m205[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m267 | [0m[35mncurrent_runs: The maximum number of concurrent runs for this workflow.[0m
[30;1m268 | [0m[35m    :param notebook_packages: A list of dictionary of Python packages to be installed. Packages defi[0m
[30;1m269 | [0m[35m        at the workflow task group level are installed for each of the notebook tasks under it. And[0m
[30;1m270 | [0m[35m        packages defined at the notebook task level are installed specific for the notebook task.[0m
[30;1m271 | [0m[35m    :param notebook_params: A dictionary of notebook parameters to pass to the workflow. These param[0m
[30;1m272 | [0m[35m        will be passed to all notebook tasks in the workflow.[0m

[31m--[ [0m[34mMatch #[0m[33m206[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m265 | [0m[35m   tasks in the workflow.[0m
[30;1m266 | [0m[35m    :param job_clusters: A list of job clusters to use for this workflow.[0m
[30;1m267 | [0m[35m    :param max_concurrent_runs: The maximum number of concurrent runs for this workflow.[0m
[30;1m268 | [0m[35m    :param notebook_packages: A list of dictionary of Python packages to be installed. Packages defi[0m
[30;1m269 | [0m[35m        at the workflow task group level are installed for each of the notebook tasks under it. And[0m
[30;1m270 | [0m[35m        packages defined at the notebook task level are installed specific for the notebook task.[0m
[30;1m271 | [0m[35m    :param notebook_params: A dictionary of notebook parameters to pass to the workflow. These param[0m

[31m--[ [0m[34mMatch #[0m[33m207[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m254 | [0m[35m    do not contain this method then the Taskgroup will raise an error at parse time.[0m
[30;1m255 | [0m[35m[0m
[30;1m256 | [0m[35m    .. seealso::[0m
[30;1m257 | [0m[35m        For more information on how to use this operator, take a look at the guide:[0m
[30;1m258 | [0m[35m        :ref:`howto/operator:DatabricksWorkflowTaskGroup`[0m
[30;1m259 | [0m[35m[0m
[30;1m260 | [0m[35m    :param databricks_conn_id: The name of the databricks connection to use.[0m

[31m--[ [0m[34mMatch #[0m[33m208[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m251 | [0m[35m    The DatabricksWorkflowTaskGroup takes a list of tasks and creates a databricks workflow[0m
[30;1m252 | [0m[35m    based on the metadata produced by those tasks. For a task to be eligible for this[0m
[30;1m253 | [0m[35m    TaskGroup, it must contain the ``_convert_to_databricks_workflow_task`` method. If any tasks[0m
[30;1m254 | [0m[35m    do not contain this method then the Taskgroup will raise an error at parse time.[0m
[30;1m255 | [0m[35m[0m
[30;1m256 | [0m[35m    .. seealso::[0m
[30;1m257 | [0m[35m        For more information on how to use this operator, take a look at the guide:[0m

[31m--[ [0m[34mMatch #[0m[33m209[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m181 | [0m[35m[0m
[30;1m182 | [0m[35m    def _wait_for_job_to_start(self, run_id: int) -> None:[0m
[30;1m183 | [0m[35m        run_url = self._hook.get_run_page_url(run_id)[0m
[30;1m184 | [0m[35m        self.log.info("Check the progress of the Databricks job at %s", run_url)[0m
[30;1m185 | [0m[35m        life_cycle_state = self._hook.get_run_state(run_id).life_cycle_state[0m
[30;1m186 | [0m[35m        if life_cycle_state not in ([0m
[30;1m187 | [0m[35m            RunLifeCycleState.PENDING.value,[0m

[31m--[ [0m[34mMatch #[0m[33m210[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m211[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_workflow.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m59 | [0m[35mdef _flatten_node([0m
[30;1m60 | [0m[35m    node: TaskGroup | BaseOperator | DAGNode, tasks: list[BaseOperator] | None = None[0m
[30;1m61 | [0m[35m) -> list[BaseOperator]:[0m
[30;1m62 | [0m[35m    """Flatten a node (either a TaskGroup or Operator) to a list of nodes."""[0m
[30;1m63 | [0m[35m    if tasks is None:[0m
[30;1m64 | [0m[35m        tasks = [][0m
[30;1m65 | [0m[35m    if isinstance(node, BaseOperator):[0m

[31m--[ [0m[34mMatch #[0m[33m212[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_workflow.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m18 | [0m[35mfrom __future__ import annotations[0m
[30;1m19 | [0m[35m[0m
[30;1m20 | [0m[35mimport json[0m
[30;1m21 | [0m[35mimport time[0m
[30;1m22 | [0m[35mfrom dataclasses import dataclass[0m
[30;1m23 | [0m[35mfrom functools import cached_property[0m
[30;1m24 | [0m[35mfrom typing import TYPE_CHECKING, Any[0m
[30;1m25 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m213[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/utils/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m214[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/workflow.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m65 | [0m[35m.. image:: ../img/workflow_run_databricks_graph_view.png[0m
[30;1m66 | [0m[35m[0m
[30;1m67 | [0m[35m[0m
[30;1m68 | [0m[35mTo minimize update conflicts, we recommend that you keep parameters in the ``notebook_params`` of th[0m
[30;1m69 | [0m[35m``DatabricksWorkflowTaskGroup`` and not in the ``DatabricksNotebookOperator`` whenever possible.[0m
[30;1m70 | [0m[35mThis is because, tasks in the ``DatabricksWorkflowTaskGroup`` are passed in on the job trigger time [0m
[30;1m71 | [0m[35mdo not modify the job definition.[0m

[31m--[ [0m[34mMatch #[0m[33m215[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/workflow.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m32 | [0m[35m===========  =============================================  =================================[0m
[30;1m33 | [0m[35mWorkflow compute pricing                 ✅                                             ✅[0m
[30;1m34 | [0m[35mNotebook code in source control          ✅                                             ✅[0m
[30;1m35 | [0m[35mWorkflow structure in source control     ✅                                             ✅[0m
[30;1m36 | [0m[35mRetry from beginning                     ✅                                             ✅[0m
[30;1m37 | [0m[35mRetry single task                        ✅                                             ✅[0m

[31m--[ [0m[34mMatch #[0m[33m216[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/workflow.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m31 | [0m[35mWeb-based with Databricks UI)  via Airflow(Code with Airflow DAG)[0m
[30;1m32 | [0m[35m=======================================  =============================================  ============[0m
[30;1m33 | [0m[35mWorkflow compute pricing                 ✅                                             ✅[0m
[30;1m34 | [0m[35mNotebook code in source control          ✅                                             ✅[0m
[30;1m35 | [0m[35mWorkflow structure in source control     ✅                                             ✅[0m
[30;1m36 | [0m[35mRetry from beginning                     ✅                                             ✅[0m

[31m--[ [0m[34mMatch #[0m[33m217[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/workflow.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m218[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/workflow.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m67 | [0m[35m[0m
[30;1m68 | [0m[35mTo minimize update conflicts, we recommend that you keep parameters in the ``notebook_params`` of th[0m
[30;1m69 | [0m[35m``DatabricksWorkflowTaskGroup`` and not in the ``DatabricksNotebookOperator`` whenever possible.[0m
[30;1m70 | [0m[35mThis is because, tasks in the ``DatabricksWorkflowTaskGroup`` are passed in on the job trigger time [0m
[30;1m71 | [0m[35mdo not modify the job definition.[0m

[31m--[ [0m[34mMatch #[0m[33m219[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/sensors/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m220[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/notebook.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m221[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks_base.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m222[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/get_provider_info.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m223[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/plugins/test_databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m224[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/plugins/index.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m225[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/triggers/test_databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m226[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/triggers/test_databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m17 | [0m[35m# under the License.[0m
[30;1m18 | [0m[35mfrom __future__ import annotations[0m
[30;1m19 | [0m[35m[0m
[30;1m20 | [0m[35mimport time[0m
[30;1m21 | [0m[35mfrom unittest import mock[0m
[30;1m22 | [0m[35m[0m
[30;1m23 | [0m[35mimport pytest[0m
[30;1m24 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m227[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/sensors/test_databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m228[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_sql.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m148 | [0m[35m            self._token = new_token[0m
[30;1m149 | [0m[35m[0m
[30;1m150 | [0m[35m        if not self.session_config:[0m
[30;1m151 | [0m[35m            self.session_config = self.databricks_conn.extra_dejson.get("session_configuration")[0m
[30;1m152 | [0m[35m[0m
[30;1m153 | [0m[35m        if not self._sql_conn or prev_token != new_token:[0m
[30;1m154 | [0m[35m            if self._sql_conn:  # close already existing connection[0m

[31m--[ [0m[34mMatch #[0m[33m229[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_sql.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m222 | [0m[35m        :param return_last: Whether to return result for only last statement or for all after split[0m
[30;1m223 | [0m[35m        :return: return only result of the LAST SQL expression if handler was provided unless return[0m
[30;1m224 | [0m[35m            is set to False.[0m
[30;1m225 | [0m[35m        :param execution_timeout: max time allowed for the execution of this task instance, if it go[0m
[30;1m226 | [0m[35m            it will raise and fail.[0m
[30;1m227 | [0m[35m        """[0m
[30;1m228 | [0m[35m        self.descriptions = [][0m

[31m--[ [0m[34mMatch #[0m[33m230[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_sql.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m123 | [0m[35m        try:[0m
[30;1m124 | [0m[35m            endpoint = next(endpoint for endpoint in result["endpoints"] if endpoint["name"] == endp[0m
[30;1m125 | [0m[35m        except StopIteration:[0m
[30;1m126 | [0m[35m            raise AirflowException(f"Can't find Databricks SQL endpoint with name '{endpoint_name}'"[0m
[30;1m127 | [0m[35m        else:[0m
[30;1m128 | [0m[35m            return endpoint[0m
[30;1m129 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m231[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m232[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m50 | [0m[35mDAG_ID = "example_databricks_operator"[0m
[30;1m51 | [0m[35m[0m
[30;1m52 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "c9cf6468-babe-41a6-abc3-10ac358c71ee")[0m
[30;1m53 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "cf414a2206dfb397")[0m
[30;1m54 | [0m[35m[0m
[30;1m55 | [0m[35mwith DAG([0m
[30;1m56 | [0m[35m    dag_id=DAG_ID,[0m

[31m--[ [0m[34mMatch #[0m[33m233[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m49 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m50 | [0m[35mDAG_ID = "example_databricks_operator"[0m
[30;1m51 | [0m[35m[0m
[30;1m52 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "c9cf6468-babe-41a6-abc3-10ac358c71ee")[0m
[30;1m53 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "cf414a2206dfb397")[0m
[30;1m54 | [0m[35m[0m
[30;1m55 | [0m[35mwith DAG([0m

[31m--[ [0m[34mMatch #[0m[33m234[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m46 | [0m[35m    DatabricksTaskOperator,[0m
[30;1m47 | [0m[35m)[0m
[30;1m48 | [0m[35m[0m
[30;1m49 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m50 | [0m[35mDAG_ID = "example_databricks_operator"[0m
[30;1m51 | [0m[35m[0m
[30;1m52 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "c9cf6468-babe-41a6-abc3-10ac358c71ee")[0m

[31m--[ [0m[34mMatch #[0m[33m235[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m18 | [0m[35m"""[0m
[30;1m19 | [0m[35mThis is an example DAG which uses the DatabricksSubmitRunOperator.[0m
[30;1m20 | [0m[35mIn this example, we create two tasks which execute sequentially.[0m
[30;1m21 | [0m[35mThe first task is to run a notebook at the workspace path "/test"[0m
[30;1m22 | [0m[35mand the second task is to run a JAR uploaded to DBFS. Both,[0m
[30;1m23 | [0m[35mtasks use new clusters.[0m
[30;1m24 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m236[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m237[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/utils/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m238[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/utils/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m58 | [0m[35m    keys_to_check = ["run_id", "run_page_url", "run_state", "errors"][0m
[30;1m59 | [0m[35m    for key in keys_to_check:[0m
[30;1m60 | [0m[35m        if key not in event:[0m
[30;1m61 | [0m[35m            raise AirflowException(f"Could not find `{key}` in the event: {event}")[0m
[30;1m62 | [0m[35m[0m
[30;1m63 | [0m[35m    try:[0m
[30;1m64 | [0m[35m        RunState.from_json(event["run_state"])[0m

[31m--[ [0m[34mMatch #[0m[33m239[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/sensors/test_databricks_partition.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m240[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/operators/test_databricks_copy.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m241[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/utils/test_databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m242[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m243[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m244[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/operators/test_databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m245[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/sql_statements.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m246[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/security.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m247[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m248[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/triggers/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m249[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/task.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m250[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/conf.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m6 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m7 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m8 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m9 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m12 | [0m[35m#[0m
[30;1m13 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m251[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/index.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m119 | [0m[35m[0m
[30;1m120 | [0m[35mYou can install such cross-provider dependencies when installing from PyPI. For example:[0m
[30;1m121 | [0m[35m[0m
[30;1m122 | [0m[35m.. code-block:: bash[0m
[30;1m123 | [0m[35m[0m
[30;1m124 | [0m[35m    pip install apache-airflow-providers-databricks[common.sql][0m
[30;1m125 | [0m[35m[0m
[30;1m126 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m252[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/index.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m61 | [0m[35m    PyPI Repository <https://pypi.org/project/apache-airflow-providers-databricks/>[0m
[30;1m62 | [0m[35m    Installing from sources <installing-providers-from-sources>[0m
[30;1m63 | [0m[35m[0m
[30;1m64 | [0m[35m.. THE REMAINDER OF THE FILE IS AUTOMATICALLY GENERATED. IT WILL BE OVERWRITTEN AT RELEASE TIME![0m
[30;1m65 | [0m[35m[0m
[30;1m66 | [0m[35m[0m
[30;1m67 | [0m[35m.. toctree::[0m

[31m--[ [0m[34mMatch #[0m[33m253[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/index.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m[0m
[30;1m10 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m[0m
[30;1m12 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m254[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/index.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m121 | [0m[35m[0m
[30;1m122 | [0m[35m.. code-block:: bash[0m
[30;1m123 | [0m[35m[0m
[30;1m124 | [0m[35m    pip install apache-airflow-providers-databricks[common.sql][0m
[30;1m125 | [0m[35m[0m
[30;1m126 | [0m[35m[0m
[30;1m127 | [0m[35m====================================================================================================[0m

[31m--[ [0m[34mMatch #[0m[33m255[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/index.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m119 | [0m[35m[0m
[30;1m120 | [0m[35mYou can install such cross-provider dependencies when installing from PyPI. For example:[0m
[30;1m121 | [0m[35m[0m
[30;1m122 | [0m[35m.. code-block:: bash[0m
[30;1m123 | [0m[35m[0m
[30;1m124 | [0m[35m    pip install apache-airflow-providers-databricks[common.sql][0m
[30;1m125 | [0m[35m[0m
[30;1m126 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m256[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/index.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m98 | [0m[35m[0m
[30;1m99 | [0m[35mThe minimum Apache Airflow version supported by this provider distribution is ``2.9.0``.[0m
[30;1m100 | [0m[35m[0m
[30;1m101 | [0m[35m=======================================  ==================[0m
[30;1m102 | [0m[35mPIP package                              Version required[0m
[30;1m103 | [0m[35m=======================================  ==================[0m
[30;1m104 | [0m[35m``apache-airflow``                       ``>=2.9.0``[0m
[30;1m105 | [0m[35m``apache-airflow-providers-common-sql``  ``>=1.20.0``[0m

[31m--[ [0m[34mMatch #[0m[33m257[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/index.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m89 | [0m[35mInstallation[0m
[30;1m90 | [0m[35m------------[0m
[30;1m91 | [0m[35m[0m
[30;1m92 | [0m[35mYou can install this package on top of an existing Airflow 2 installation via[0m
[30;1m93 | [0m[35m``pip install apache-airflow-providers-databricks``.[0m
[30;1m94 | [0m[35mFor the minimum Airflow version supported, see ``Requirements`` below.[0m
[30;1m95 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m258[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_sensors.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m26 | [0m[35mfrom airflow.providers.databricks.sensors.databricks_sql import DatabricksSqlSensor[0m
[30;1m27 | [0m[35m[0m
[30;1m28 | [0m[35m# [Env variable to be used from the OS][0m
[30;1m29 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m30 | [0m[35m# [DAG name to be shown on Airflow UI][0m
[30;1m31 | [0m[35mDAG_ID = "example_databricks_sensor"[0m
[30;1m32 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m259[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_sensors.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m260[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/index.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m261[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_create.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m28 | [0m[35mUsing the Operator[0m
[30;1m29 | [0m[35m^^^^^^^^^^^^^^^^^^[0m
[30;1m30 | [0m[35m[0m
[30;1m31 | [0m[35mTo use this operator you need to provide at least ``git_url`` parameter.[0m
[30;1m32 | [0m[35m[0m
[30;1m33 | [0m[35m.. list-table::[0m
[30;1m34 | [0m[35m   :widths: 15 25[0m

[31m--[ [0m[34mMatch #[0m[33m262[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_create.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m263[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_create.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m43 | [0m[35m   * - branch: str[0m
[30;1m44 | [0m[35m     - Optional name of the existing Git branch to checkout.[0m
[30;1m45 | [0m[35m   * - tag: str[0m
[30;1m46 | [0m[35m     - Optional name of the existing Git tag to checkout.[0m
[30;1m47 | [0m[35m   * - repo_path: str[0m
[30;1m48 | [0m[35m     - Optional path to a Databricks Repos, like, ``/Repos/<user_email>/repo_name``. If not specifie[0m
[30;1m49 | [0m[35m   * - ignore_existing_repo: bool[0m

[31m--[ [0m[34mMatch #[0m[33m264[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_create.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m41 | [0m[35m   * - git_provider: str[0m
[30;1m42 | [0m[35m     - Optional name of Git provider. Must be provided if we can't guess its name from URL. See API [0m
[30;1m43 | [0m[35m   * - branch: str[0m
[30;1m44 | [0m[35m     - Optional name of the existing Git branch to checkout.[0m
[30;1m45 | [0m[35m   * - tag: str[0m
[30;1m46 | [0m[35m     - Optional name of the existing Git tag to checkout.[0m
[30;1m47 | [0m[35m   * - repo_path: str[0m

[31m--[ [0m[34mMatch #[0m[33m265[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_create.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m39 | [0m[35m   * - git_url: str[0m
[30;1m40 | [0m[35m     - Required HTTPS URL of a Git repository[0m
[30;1m41 | [0m[35m   * - git_provider: str[0m
[30;1m42 | [0m[35m     - Optional name of Git provider. Must be provided if we can't guess its name from URL. See API [0m
[30;1m43 | [0m[35m   * - branch: str[0m
[30;1m44 | [0m[35m     - Optional name of the existing Git branch to checkout.[0m
[30;1m45 | [0m[35m   * - tag: str[0m

[31m--[ [0m[34mMatch #[0m[33m266[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_create.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m39 | [0m[35m   * - git_url: str[0m
[30;1m40 | [0m[35m     - Required HTTPS URL of a Git repository[0m
[30;1m41 | [0m[35m   * - git_provider: str[0m
[30;1m42 | [0m[35m     - Optional name of Git provider. Must be provided if we can't guess its name from URL. See API [0m
[30;1m43 | [0m[35m   * - branch: str[0m
[30;1m44 | [0m[35m     - Optional name of the existing Git branch to checkout.[0m
[30;1m45 | [0m[35m   * - tag: str[0m

[31m--[ [0m[34mMatch #[0m[33m267[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_create.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m37 | [0m[35m   * - Parameter[0m
[30;1m38 | [0m[35m     - Input[0m
[30;1m39 | [0m[35m   * - git_url: str[0m
[30;1m40 | [0m[35m     - Required HTTPS URL of a Git repository[0m
[30;1m41 | [0m[35m   * - git_provider: str[0m
[30;1m42 | [0m[35m     - Optional name of Git provider. Must be provided if we can't guess its name from URL. See API [0m
[30;1m43 | [0m[35m   * - branch: str[0m

[31m--[ [0m[34mMatch #[0m[33m268[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/run_now.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m269[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/run_now.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m31 | [0m[35mto call the ``api/2.1/jobs/run-now`` endpoint and pass it directly to our ``DatabricksRunNowOperator[0m
[30;1m32 | [0m[35m[0m
[30;1m33 | [0m[35mAnother way to accomplish the same thing is to use the named parameters of the ``DatabricksRunNowOpe[0m
[30;1m34 | [0m[35mNote that there is exactly one named parameter for each top level parameter in the ``jobs/run-now`` [0m
[30;1m35 | [0m[35m[0m
[30;1m36 | [0m[35mThe only required parameters are either:[0m
[30;1m37 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m270[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_workflow.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m39 | [0m[35mUSER = os.environ.get("USER")[0m
[30;1m40 | [0m[35m[0m
[30;1m41 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "d3773b5a-56f9-422c-ae60-048eaa90aa33")[0m
[30;1m42 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "368fe30b92228713")[0m
[30;1m43 | [0m[35m[0m
[30;1m44 | [0m[35m# job_cluster_spec example for Databricks on Azure[0m
[30;1m45 | [0m[35mjob_cluster_spec = [[0m

[31m--[ [0m[34mMatch #[0m[33m271[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_workflow.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m38 | [0m[35mGROUP_ID = os.getenv("DATABRICKS_GROUP_ID", "1234").replace(".", "_")[0m
[30;1m39 | [0m[35mUSER = os.environ.get("USER")[0m
[30;1m40 | [0m[35m[0m
[30;1m41 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "d3773b5a-56f9-422c-ae60-048eaa90aa33")[0m
[30;1m42 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "368fe30b92228713")[0m
[30;1m43 | [0m[35m[0m
[30;1m44 | [0m[35m# job_cluster_spec example for Databricks on Azure[0m

[31m--[ [0m[34mMatch #[0m[33m272[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_workflow.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m36 | [0m[35mDATABRICKS_NOTIFICATION_EMAIL = os.getenv("DATABRICKS_NOTIFICATION_EMAIL", "your_email@serviceprovid[0m
[30;1m37 | [0m[35m[0m
[30;1m38 | [0m[35mGROUP_ID = os.getenv("DATABRICKS_GROUP_ID", "1234").replace(".", "_")[0m
[30;1m39 | [0m[35mUSER = os.environ.get("USER")[0m
[30;1m40 | [0m[35m[0m
[30;1m41 | [0m[35mQUERY_ID = os.environ.get("QUERY_ID", "d3773b5a-56f9-422c-ae60-048eaa90aa33")[0m
[30;1m42 | [0m[35mWAREHOUSE_ID = os.environ.get("WAREHOUSE_ID", "368fe30b92228713")[0m

[31m--[ [0m[34mMatch #[0m[33m273[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m274[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/README.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m71 | [0m[35m[0m
[30;1m72 | [0m[35mYou can install such cross-provider dependencies when installing from PyPI. For example:[0m
[30;1m73 | [0m[35m[0m
[30;1m74 | [0m[35m.. code-block:: bash[0m
[30;1m75 | [0m[35m[0m
[30;1m76 | [0m[35m    pip install apache-airflow-providers-databricks[common.sql][0m
[30;1m77 | [0m[35m[0m
[30;1m78 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m275[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/README.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m   regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m   to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m   "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m   with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m[0m
[30;1m10 | [0m[35m..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m[0m
[30;1m12 | [0m[35m.. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m276[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/README.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m73 | [0m[35m[0m
[30;1m74 | [0m[35m.. code-block:: bash[0m
[30;1m75 | [0m[35m[0m
[30;1m76 | [0m[35m    pip install apache-airflow-providers-databricks[common.sql][0m
[30;1m77 | [0m[35m[0m
[30;1m78 | [0m[35m[0m
[30;1m79 | [0m[35m====================================================================================================[0m

[31m--[ [0m[34mMatch #[0m[33m277[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/README.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m71 | [0m[35m[0m
[30;1m72 | [0m[35mYou can install such cross-provider dependencies when installing from PyPI. For example:[0m
[30;1m73 | [0m[35m[0m
[30;1m74 | [0m[35m.. code-block:: bash[0m
[30;1m75 | [0m[35m[0m
[30;1m76 | [0m[35m    pip install apache-airflow-providers-databricks[common.sql][0m
[30;1m77 | [0m[35m[0m
[30;1m78 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m278[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/README.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m50 | [0m[35mRequirements[0m
[30;1m51 | [0m[35m------------[0m
[30;1m52 | [0m[35m[0m
[30;1m53 | [0m[35m=======================================  ==================[0m
[30;1m54 | [0m[35mPIP package                              Version required[0m
[30;1m55 | [0m[35m=======================================  ==================[0m
[30;1m56 | [0m[35m``apache-airflow``                       ``>=2.9.0``[0m
[30;1m57 | [0m[35m``apache-airflow-providers-common-sql``  ``>=1.20.0``[0m

[31m--[ [0m[34mMatch #[0m[33m279[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/README.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m41 | [0m[35mInstallation[0m
[30;1m42 | [0m[35m------------[0m
[30;1m43 | [0m[35m[0m
[30;1m44 | [0m[35mYou can install this package on top of an existing Airflow 2 installation (see ``Requirements`` belo[0m
[30;1m45 | [0m[35mfor the minimum Airflow version supported) via[0m
[30;1m46 | [0m[35m``pip install apache-airflow-providers-databricks``[0m
[30;1m47 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m280[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/README.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m35 | [0m[35mThis is a provider package for ``databricks`` provider. All classes for this provider package[0m
[30;1m36 | [0m[35mare in ``airflow.providers.databricks`` python package.[0m
[30;1m37 | [0m[35m[0m
[30;1m38 | [0m[35mYou can find package information and changelog for the provider[0m
[30;1m39 | [0m[35min the `documentation <https://airflow.apache.org/docs/apache-airflow-providers-databricks/7.3.1/>`_[0m
[30;1m40 | [0m[35m[0m
[30;1m41 | [0m[35mInstallation[0m

[31m--[ [0m[34mMatch #[0m[33m281[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m823 | [0m[35m        """Test the Databricks connectivity from UI."""[0m
[30;1m824 | [0m[35m        hook = DatabricksHook(databricks_conn_id=self.databricks_conn_id)[0m
[30;1m825 | [0m[35m        try:[0m
[30;1m826 | [0m[35m            hook._do_api_call(endpoint_info=SPARK_VERSIONS_ENDPOINT).get("versions")[0m
[30;1m827 | [0m[35m            status = True[0m
[30;1m828 | [0m[35m            message = "Connection successfully tested"[0m
[30;1m829 | [0m[35m        except Exception as e:[0m

[31m--[ [0m[34mMatch #[0m[33m282[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m806 | [0m[35m        response = await self._a_do_api_call(get_sql_statement_endpoint)[0m
[30;1m807 | [0m[35m        state = response["status"]["state"][0m
[30;1m808 | [0m[35m        error_code = response["status"].get("error", {}).get("error_code", "")[0m
[30;1m809 | [0m[35m        error_message = response["status"].get("error", {}).get("message", "")[0m
[30;1m810 | [0m[35m        return SQLStatementState(state, error_code, error_message)[0m
[30;1m811 | [0m[35m[0m
[30;1m812 | [0m[35m    def cancel_sql_statement(self, statement_id: str) -> None:[0m

[31m--[ [0m[34mMatch #[0m[33m283[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m806 | [0m[35m        response = await self._a_do_api_call(get_sql_statement_endpoint)[0m
[30;1m807 | [0m[35m        state = response["status"]["state"][0m
[30;1m808 | [0m[35m        error_code = response["status"].get("error", {}).get("error_code", "")[0m
[30;1m809 | [0m[35m        error_message = response["status"].get("error", {}).get("message", "")[0m
[30;1m810 | [0m[35m        return SQLStatementState(state, error_code, error_message)[0m
[30;1m811 | [0m[35m[0m
[30;1m812 | [0m[35m    def cancel_sql_statement(self, statement_id: str) -> None:[0m

[31m--[ [0m[34mMatch #[0m[33m284[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m805 | [0m[35m        get_sql_statement_endpoint = ("GET", f"{SQL_STATEMENTS_ENDPOINT}/{statement_id}")[0m
[30;1m806 | [0m[35m        response = await self._a_do_api_call(get_sql_statement_endpoint)[0m
[30;1m807 | [0m[35m        state = response["status"]["state"][0m
[30;1m808 | [0m[35m        error_code = response["status"].get("error", {}).get("error_code", "")[0m
[30;1m809 | [0m[35m        error_message = response["status"].get("error", {}).get("message", "")[0m
[30;1m810 | [0m[35m        return SQLStatementState(state, error_code, error_message)[0m
[30;1m811 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m285[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m805 | [0m[35m        get_sql_statement_endpoint = ("GET", f"{SQL_STATEMENTS_ENDPOINT}/{statement_id}")[0m
[30;1m806 | [0m[35m        response = await self._a_do_api_call(get_sql_statement_endpoint)[0m
[30;1m807 | [0m[35m        state = response["status"]["state"][0m
[30;1m808 | [0m[35m        error_code = response["status"].get("error", {}).get("error_code", "")[0m
[30;1m809 | [0m[35m        error_message = response["status"].get("error", {}).get("message", "")[0m
[30;1m810 | [0m[35m        return SQLStatementState(state, error_code, error_message)[0m
[30;1m811 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m286[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m792 | [0m[35m        response = self._do_api_call(get_statement_endpoint)[0m
[30;1m793 | [0m[35m        state = response["status"]["state"][0m
[30;1m794 | [0m[35m        error_code = response["status"].get("error", {}).get("error_code", "")[0m
[30;1m795 | [0m[35m        error_message = response["status"].get("error", {}).get("message", "")[0m
[30;1m796 | [0m[35m        return SQLStatementState(state, error_code, error_message)[0m
[30;1m797 | [0m[35m[0m
[30;1m798 | [0m[35m    async def a_get_sql_statement_state(self, statement_id: str) -> SQLStatementState:[0m

[31m--[ [0m[34mMatch #[0m[33m287[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m792 | [0m[35m        response = self._do_api_call(get_statement_endpoint)[0m
[30;1m793 | [0m[35m        state = response["status"]["state"][0m
[30;1m794 | [0m[35m        error_code = response["status"].get("error", {}).get("error_code", "")[0m
[30;1m795 | [0m[35m        error_message = response["status"].get("error", {}).get("message", "")[0m
[30;1m796 | [0m[35m        return SQLStatementState(state, error_code, error_message)[0m
[30;1m797 | [0m[35m[0m
[30;1m798 | [0m[35m    async def a_get_sql_statement_state(self, statement_id: str) -> SQLStatementState:[0m

[31m--[ [0m[34mMatch #[0m[33m288[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m791 | [0m[35m        get_statement_endpoint = ("GET", f"{SQL_STATEMENTS_ENDPOINT}/{statement_id}")[0m
[30;1m792 | [0m[35m        response = self._do_api_call(get_statement_endpoint)[0m
[30;1m793 | [0m[35m        state = response["status"]["state"][0m
[30;1m794 | [0m[35m        error_code = response["status"].get("error", {}).get("error_code", "")[0m
[30;1m795 | [0m[35m        error_message = response["status"].get("error", {}).get("message", "")[0m
[30;1m796 | [0m[35m        return SQLStatementState(state, error_code, error_message)[0m
[30;1m797 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m289[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m791 | [0m[35m        get_statement_endpoint = ("GET", f"{SQL_STATEMENTS_ENDPOINT}/{statement_id}")[0m
[30;1m792 | [0m[35m        response = self._do_api_call(get_statement_endpoint)[0m
[30;1m793 | [0m[35m        state = response["status"]["state"][0m
[30;1m794 | [0m[35m        error_code = response["status"].get("error", {}).get("error_code", "")[0m
[30;1m795 | [0m[35m        error_message = response["status"].get("error", {}).get("message", "")[0m
[30;1m796 | [0m[35m        return SQLStatementState(state, error_code, error_message)[0m
[30;1m797 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m290[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m753 | [0m[35m        """[0m
[30;1m754 | [0m[35m        try:[0m
[30;1m755 | [0m[35m            result = self._do_api_call(WORKSPACE_GET_STATUS_ENDPOINT, {"path": path}, wrap_http_erro[0m
[30;1m756 | [0m[35m            if result.get("object_type", "") == "REPO":[0m
[30;1m757 | [0m[35m                return str(result["object_id"])[0m
[30;1m758 | [0m[35m        except requests_exceptions.HTTPError as e:[0m
[30;1m759 | [0m[35m            if e.response.status_code != 404:[0m

[31m--[ [0m[34mMatch #[0m[33m291[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m419 | [0m[35m            if next_token is not None:[0m
[30;1m420 | [0m[35m                payload = {**payload, "page_token": next_token}[0m
[30;1m421 | [0m[35m            response = self._do_api_call(LIST_PIPELINES_ENDPOINT, payload)[0m
[30;1m422 | [0m[35m            pipelines = response.get("statuses", [])[0m
[30;1m423 | [0m[35m            all_pipelines += pipelines[0m
[30;1m424 | [0m[35m            if "next_page_token" in response:[0m
[30;1m425 | [0m[35m                next_token = response["next_page_token"][0m

[31m--[ [0m[34mMatch #[0m[33m292[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m364 | [0m[35m                all_jobs += jobs[0m
[30;1m365 | [0m[35m            has_more = response.get("has_more", False)[0m
[30;1m366 | [0m[35m            if has_more:[0m
[30;1m367 | [0m[35m                page_token = response.get("next_page_token", "")[0m
[30;1m368 | [0m[35m[0m
[30;1m369 | [0m[35m        return all_jobs[0m
[30;1m370 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m293[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m362 | [0m[35m                all_jobs += [j for j in jobs if j["settings"]["name"] == job_name][0m
[30;1m363 | [0m[35m            else:[0m
[30;1m364 | [0m[35m                all_jobs += jobs[0m
[30;1m365 | [0m[35m            has_more = response.get("has_more", False)[0m
[30;1m366 | [0m[35m            if has_more:[0m
[30;1m367 | [0m[35m                page_token = response.get("next_page_token", "")[0m
[30;1m368 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m294[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m357 | [0m[35m            if job_name:[0m
[30;1m358 | [0m[35m                payload["name"] = job_name[0m
[30;1m359 | [0m[35m            response = self._do_api_call(LIST_JOBS_ENDPOINT, payload)[0m
[30;1m360 | [0m[35m            jobs = response.get("jobs", [])[0m
[30;1m361 | [0m[35m            if job_name:[0m
[30;1m362 | [0m[35m                all_jobs += [j for j in jobs if j["settings"]["name"] == job_name][0m
[30;1m363 | [0m[35m            else:[0m

[31m--[ [0m[34mMatch #[0m[33m295[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m763 | [0m[35m[0m
[30;1m764 | [0m[35m    def update_job_permission(self, job_id: int, json: dict[str, Any]) -> dict:[0m
[30;1m765 | [0m[35m        """[0m
[30;1m766 | [0m[35m        Update databricks job permission.[0m
[30;1m767 | [0m[35m[0m
[30;1m768 | [0m[35m        :param job_id: job id[0m
[30;1m769 | [0m[35m        :param json: payload[0m

[31m--[ [0m[34mMatch #[0m[33m296[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m719 | [0m[35m[0m
[30;1m720 | [0m[35m        :param repo_id: ID of Databricks Repos[0m
[30;1m721 | [0m[35m        :param json: payload[0m
[30;1m722 | [0m[35m        :return: metadata from update[0m
[30;1m723 | [0m[35m        """[0m
[30;1m724 | [0m[35m        repos_endpoint = ("PATCH", f"api/2.0/repos/{repo_id}")[0m
[30;1m725 | [0m[35m        return self._do_api_call(repos_endpoint, json)[0m
[30;1m726 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m297[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m715 | [0m[35m[0m
[30;1m716 | [0m[35m    def update_repo(self, repo_id: str, json: dict[str, Any]) -> dict:[0m
[30;1m717 | [0m[35m        """[0m
[30;1m718 | [0m[35m        Update given Databricks Repos.[0m
[30;1m719 | [0m[35m[0m
[30;1m720 | [0m[35m        :param repo_id: ID of Databricks Repos[0m
[30;1m721 | [0m[35m        :param json: payload[0m

[31m--[ [0m[34mMatch #[0m[33m298[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m339 | [0m[35m        :param limit: The limit/batch size used to retrieve jobs.[0m
[30;1m340 | [0m[35m        :param expand_tasks: Whether to include task and cluster details in the response.[0m
[30;1m341 | [0m[35m        :param job_name: Optional name of a job to search.[0m
[30;1m342 | [0m[35m        :param page_token: The optional page token pointing at the first first job to return.[0m
[30;1m343 | [0m[35m        :return: A list of jobs.[0m
[30;1m344 | [0m[35m        """[0m
[30;1m345 | [0m[35m        has_more = True[0m

[31m--[ [0m[34mMatch #[0m[33m299[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m300[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m430 | [0m[35m[0m
[30;1m431 | [0m[35m    def find_pipeline_id_by_name(self, pipeline_name: str) -> str | None:[0m
[30;1m432 | [0m[35m        """[0m
[30;1m433 | [0m[35m        Find pipeline id by its name; if multiple pipelines with the same name, raise AirflowExcepti[0m
[30;1m434 | [0m[35m[0m
[30;1m435 | [0m[35m        :param pipeline_name: The name of the pipeline to look up.[0m
[30;1m436 | [0m[35m        :return: The pipeline_id as a GUID string or None if no pipeline was found.[0m

[31m--[ [0m[34mMatch #[0m[33m301[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m370 | [0m[35m[0m
[30;1m371 | [0m[35m    def find_job_id_by_name(self, job_name: str) -> int | None:[0m
[30;1m372 | [0m[35m        """[0m
[30;1m373 | [0m[35m        Find job id by its name; if there are multiple jobs with the same name, raise AirflowExcepti[0m
[30;1m374 | [0m[35m[0m
[30;1m375 | [0m[35m        :param job_name: The name of the job to look up.[0m
[30;1m376 | [0m[35m        :return: The job_id as an int or None if no job was found.[0m

[31m--[ [0m[34mMatch #[0m[33m302[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m259 | [0m[35m    :param timeout_seconds: The amount of time in seconds the requests library[0m
[30;1m260 | [0m[35m        will wait before timing-out.[0m
[30;1m261 | [0m[35m    :param retry_limit: The number of times to retry the connection in case of[0m
[30;1m262 | [0m[35m        service outages.[0m
[30;1m263 | [0m[35m    :param retry_delay: The number of seconds to wait between retries (it[0m
[30;1m264 | [0m[35m        might be a floating point number).[0m
[30;1m265 | [0m[35m    :param retry_args: An optional dictionary with arguments passed to ``tenacity.Retrying`` class.[0m

[31m--[ [0m[34mMatch #[0m[33m303[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m256 | [0m[35m    Interact with Databricks.[0m
[30;1m257 | [0m[35m[0m
[30;1m258 | [0m[35m    :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databr[0m
[30;1m259 | [0m[35m    :param timeout_seconds: The amount of time in seconds the requests library[0m
[30;1m260 | [0m[35m        will wait before timing-out.[0m
[30;1m261 | [0m[35m    :param retry_limit: The number of times to retry the connection in case of[0m
[30;1m262 | [0m[35m        service outages.[0m

[31m--[ [0m[34mMatch #[0m[33m304[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m305[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_sql.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m140 | [0m[35m                    csv_params = self._csv_params[0m
[30;1m141 | [0m[35m                else:[0m
[30;1m142 | [0m[35m                    csv_params = {}[0m
[30;1m143 | [0m[35m                write_header = csv_params.get("header", True)[0m
[30;1m144 | [0m[35m                if "header" in csv_params:[0m
[30;1m145 | [0m[35m                    del csv_params["header"][0m
[30;1m146 | [0m[35m                writer = csv.DictWriter(file, fieldnames=field_names, **csv_params)[0m

[31m--[ [0m[34mMatch #[0m[33m306[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m200 | [0m[35m    :param storage_credential: optional Unity Catalog storage credential for destination.[0m
[30;1m201 | [0m[35m    :param encryption: optional encryption configuration for a specified location.[0m
[30;1m202 | [0m[35m    :param format_options: optional dictionary with options specific for a given file format.[0m
[30;1m203 | [0m[35m    :param force_copy: optional bool to control forcing of data import[0m
[30;1m204 | [0m[35m        (could be also specified in ``copy_options``).[0m
[30;1m205 | [0m[35m    :param validate: optional configuration for schema & data validation. ``True`` forces validation[0m
[30;1m206 | [0m[35m        of all rows, integer number - validate only N first rows[0m

[31m--[ [0m[34mMatch #[0m[33m307[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m172 | [0m[35m    `documentation <https://docs.databricks.com/sql/language-manual/delta-copy-into.html>`_.[0m
[30;1m173 | [0m[35m[0m
[30;1m174 | [0m[35m    .. seealso::[0m
[30;1m175 | [0m[35m        For more information on how to use this operator, take a look at the guide:[0m
[30;1m176 | [0m[35m        :ref:`howto/operator:DatabricksSqlCopyIntoOperator`[0m
[30;1m177 | [0m[35m[0m
[30;1m178 | [0m[35m    :param table_name: Required name of the table. (templated)[0m

[31m--[ [0m[34mMatch #[0m[33m308[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m40 | [0m[35m    Executes SQL code in a Databricks SQL endpoint or a Databricks cluster.[0m
[30;1m41 | [0m[35m[0m
[30;1m42 | [0m[35m    .. seealso::[0m
[30;1m43 | [0m[35m        For more information on how to use this operator, take a look at the guide:[0m
[30;1m44 | [0m[35m        :ref:`howto/operator:DatabricksSqlOperator`[0m
[30;1m45 | [0m[35m[0m
[30;1m46 | [0m[35m    :param databricks_conn_id: Reference to[0m

[31m--[ [0m[34mMatch #[0m[33m309[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m310[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_repos.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m113 | [0m[35m        try:[0m
[30;1m114 | [0m[35m            netloc = urlsplit(url).netloc.lower()[0m
[30;1m115 | [0m[35m            _, _, netloc = netloc.rpartition("@")[0m
[30;1m116 | [0m[35m            provider = DatabricksReposCreateOperator.__git_providers__.get(netloc)[0m
[30;1m117 | [0m[35m            if provider is None and DatabricksReposCreateOperator.__aws_code_commit_regexp__.match(n[0m
[30;1m118 | [0m[35m                provider = "awsCodeCommit"[0m
[30;1m119 | [0m[35m        except ValueError:[0m

[31m--[ [0m[34mMatch #[0m[33m311[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_repos.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m172 | [0m[35m    See: https://docs.databricks.com/dev-tools/api/latest/repos.html#operation/update-repo[0m
[30;1m173 | [0m[35m[0m
[30;1m174 | [0m[35m    :param branch: optional name of branch to update to. Should be specified if ``tag`` is omitted[0m
[30;1m175 | [0m[35m    :param tag: optional name of tag to update to. Should be specified if ``branch`` is omitted[0m
[30;1m176 | [0m[35m    :param repo_id: optional ID of existing repository. Should be specified if ``repo_path`` is omit[0m
[30;1m177 | [0m[35m    :param repo_path: optional path of existing repository. Should be specified if ``repo_id`` is om[0m
[30;1m178 | [0m[35m    :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databr[0m

[31m--[ [0m[34mMatch #[0m[33m312[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_repos.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m171 | [0m[35m[0m
[30;1m172 | [0m[35m    See: https://docs.databricks.com/dev-tools/api/latest/repos.html#operation/update-repo[0m
[30;1m173 | [0m[35m[0m
[30;1m174 | [0m[35m    :param branch: optional name of branch to update to. Should be specified if ``tag`` is omitted[0m
[30;1m175 | [0m[35m    :param tag: optional name of tag to update to. Should be specified if ``branch`` is omitted[0m
[30;1m176 | [0m[35m    :param repo_id: optional ID of existing repository. Should be specified if ``repo_path`` is omit[0m
[30;1m177 | [0m[35m    :param repo_path: optional path of existing repository. Should be specified if ``repo_id`` is om[0m

[31m--[ [0m[34mMatch #[0m[33m313[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_repos.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m156 | [0m[35m            repo_id = result["id"][0m
[30;1m157 | [0m[35m        else:[0m
[30;1m158 | [0m[35m            repo_id = existing_repo_id[0m
[30;1m159 | [0m[35m        # update repo if necessary[0m
[30;1m160 | [0m[35m        if self.branch is not None:[0m
[30;1m161 | [0m[35m            self._hook.update_repo(str(repo_id), {"branch": str(self.branch)})[0m
[30;1m162 | [0m[35m        elif self.tag is not None:[0m

[31m--[ [0m[34mMatch #[0m[33m314[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_repos.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m315[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_repos.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m297 | [0m[35m        if self.repo_path is not None:[0m
[30;1m298 | [0m[35m            self.repo_id = self._hook.get_repo_by_path(self.repo_path)[0m
[30;1m299 | [0m[35m            if self.repo_id is None:[0m
[30;1m300 | [0m[35m                raise AirflowException(f"Can't find Repo ID for path '{self.repo_path}'")[0m
[30;1m301 | [0m[35m[0m
[30;1m302 | [0m[35m        self._hook.delete_repo(str(self.repo_id))[0m

[31m--[ [0m[34mMatch #[0m[33m316[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_repos.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m231 | [0m[35m        if self.repo_path is not None:[0m
[30;1m232 | [0m[35m            self.repo_id = self._hook.get_repo_by_path(self.repo_path)[0m
[30;1m233 | [0m[35m            if self.repo_id is None:[0m
[30;1m234 | [0m[35m                raise AirflowException(f"Can't find Repo ID for path '{self.repo_path}'")[0m
[30;1m235 | [0m[35m        if self.branch is not None:[0m
[30;1m236 | [0m[35m            payload = {"branch": str(self.branch)}[0m
[30;1m237 | [0m[35m        else:[0m

[31m--[ [0m[34mMatch #[0m[33m317[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_repos.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m44 | [0m[35m     See: https://docs.databricks.com/dev-tools/api/latest/repos.html#operation/create-repo[0m
[30;1m45 | [0m[35m[0m
[30;1m46 | [0m[35m    :param git_url: Required HTTPS URL of a Git repository[0m
[30;1m47 | [0m[35m    :param git_provider: Optional name of Git provider. Must be provided if we can't guess its name [0m
[30;1m48 | [0m[35m    :param repo_path: optional path for a repository. Must be in the format ``/Repos/{folder}/{repo-[0m
[30;1m49 | [0m[35m        If not specified, it will be created in the user's directory.[0m
[30;1m50 | [0m[35m    :param branch: optional name of branch to check out.[0m

[31m--[ [0m[34mMatch #[0m[33m318[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks_repos.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m43 | [0m[35m[0m
[30;1m44 | [0m[35m     See: https://docs.databricks.com/dev-tools/api/latest/repos.html#operation/create-repo[0m
[30;1m45 | [0m[35m[0m
[30;1m46 | [0m[35m    :param git_url: Required HTTPS URL of a Git repository[0m
[30;1m47 | [0m[35m    :param git_provider: Optional name of Git provider. Must be provided if we can't guess its name [0m
[30;1m48 | [0m[35m    :param repo_path: optional path for a repository. Must be in the format ``/Repos/{folder}/{repo-[0m
[30;1m49 | [0m[35m        If not specified, it will be created in the user's directory.[0m

[31m--[ [0m[34mMatch #[0m[33m319[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/pyproject.toml[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m320[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/pyproject.toml[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m70 | [0m[35m# The optional dependencies should be modified in place in the generated file[0m
[30;1m71 | [0m[35m# Any change in the dependencies is preserved when the file is regenerated[0m
[30;1m72 | [0m[35m[project.optional-dependencies][0m
[30;1m73 | [0m[35m# pip install apache-airflow-providers-databricks[sdk][0m
[30;1m74 | [0m[35m"sdk" = [[0m
[30;1m75 | [0m[35m    "databricks-sdk==0.10.0",[0m
[30;1m76 | [0m[35m][0m

[31m--[ [0m[34mMatch #[0m[33m321[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/sensors/databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m322[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m323[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/plugins/databricks_workflow.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m424 | [0m[35m            return redirect(return_url)[0m
[30;1m425 | [0m[35m[0m
[30;1m426 | [0m[35m        databricks_conn_id = request.values.get("databricks_conn_id")[0m
[30;1m427 | [0m[35m        databricks_run_id = request.values.get("databricks_run_id")[0m
[30;1m428 | [0m[35m[0m
[30;1m429 | [0m[35m        if not databricks_conn_id:[0m
[30;1m430 | [0m[35m            flash("No Databricks connection ID provided. Cannot repair tasks.")[0m

[31m--[ [0m[34mMatch #[0m[33m324[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/plugins/databricks_workflow.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m423 | [0m[35m            flash("No tasks to repair. Not sending repair request.")[0m
[30;1m424 | [0m[35m            return redirect(return_url)[0m
[30;1m425 | [0m[35m[0m
[30;1m426 | [0m[35m        databricks_conn_id = request.values.get("databricks_conn_id")[0m
[30;1m427 | [0m[35m        databricks_run_id = request.values.get("databricks_run_id")[0m
[30;1m428 | [0m[35m[0m
[30;1m429 | [0m[35m        if not databricks_conn_id:[0m

[31m--[ [0m[34mMatch #[0m[33m325[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/plugins/databricks_workflow.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m417 | [0m[35m    def repair(self, dag_id: str, run_id: str):[0m
[30;1m418 | [0m[35m        return_url = self._get_return_url(dag_id, run_id)[0m
[30;1m419 | [0m[35m[0m
[30;1m420 | [0m[35m        tasks_to_repair = request.values.get("tasks_to_repair")[0m
[30;1m421 | [0m[35m        self.log.info("Tasks to repair: %s", tasks_to_repair)[0m
[30;1m422 | [0m[35m        if not tasks_to_repair:[0m
[30;1m423 | [0m[35m            flash("No tasks to repair. Not sending repair request.")[0m

[31m--[ [0m[34mMatch #[0m[33m326[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/plugins/databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m467 | [0m[35m    Databricks Workflows plugin for Airflow.[0m
[30;1m468 | [0m[35m[0m
[30;1m469 | [0m[35m    .. seealso::[0m
[30;1m470 | [0m[35m        For more information on how to use this plugin, take a look at the guide:[0m
[30;1m471 | [0m[35m        :ref:`howto/plugin:DatabricksWorkflowPlugin`[0m
[30;1m472 | [0m[35m    """[0m
[30;1m473 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m327[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/plugins/databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m328[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/plugins/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m329[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m101 | [0m[35m                if run_state.result_state == "FAILED":[0m
[30;1m102 | [0m[35m                    run_info = await self.hook.a_get_run(self.run_id)[0m
[30;1m103 | [0m[35m                    for task in run_info.get("tasks", []):[0m
[30;1m104 | [0m[35m                        if task.get("state", {}).get("result_state", "") == "FAILED":[0m
[30;1m105 | [0m[35m                            task_run_id = task["run_id"][0m
[30;1m106 | [0m[35m                            task_key = task["task_key"][0m
[30;1m107 | [0m[35m                            run_output = await self.hook.a_get_run_output(task_run_id)[0m

[31m--[ [0m[34mMatch #[0m[33m330[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m101 | [0m[35m                if run_state.result_state == "FAILED":[0m
[30;1m102 | [0m[35m                    run_info = await self.hook.a_get_run(self.run_id)[0m
[30;1m103 | [0m[35m                    for task in run_info.get("tasks", []):[0m
[30;1m104 | [0m[35m                        if task.get("state", {}).get("result_state", "") == "FAILED":[0m
[30;1m105 | [0m[35m                            task_run_id = task["run_id"][0m
[30;1m106 | [0m[35m                            task_key = task["task_key"][0m
[30;1m107 | [0m[35m                            run_output = await self.hook.a_get_run_output(task_run_id)[0m

[31m--[ [0m[34mMatch #[0m[33m331[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m100 | [0m[35m                failed_tasks = [][0m
[30;1m101 | [0m[35m                if run_state.result_state == "FAILED":[0m
[30;1m102 | [0m[35m                    run_info = await self.hook.a_get_run(self.run_id)[0m
[30;1m103 | [0m[35m                    for task in run_info.get("tasks", []):[0m
[30;1m104 | [0m[35m                        if task.get("state", {}).get("result_state", "") == "FAILED":[0m
[30;1m105 | [0m[35m                            task_run_id = task["run_id"][0m
[30;1m106 | [0m[35m                            task_key = task["task_key"][0m

[31m--[ [0m[34mMatch #[0m[33m332[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m333[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m214 | [0m[35m                    "state": statement_state.to_json(),[0m
[30;1m215 | [0m[35m                    "error": {[0m
[30;1m216 | [0m[35m                        "error_code": "TIMEOUT",[0m
[30;1m217 | [0m[35m                        "error_message": f"Statement ID {self.statement_id} timed out after set end [0m
[30;1m218 | [0m[35m                    },[0m
[30;1m219 | [0m[35m                }[0m
[30;1m220 | [0m[35m            )[0m

[31m--[ [0m[34mMatch #[0m[33m334[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m131 | [0m[35m    :param end_time: The end time (set based on timeout supplied for the operator) for the SQL state[0m
[30;1m132 | [0m[35m    :param polling_period_seconds: Controls the rate of the poll for the result of this run.[0m
[30;1m133 | [0m[35m        By default, the trigger will poll every 30 seconds.[0m
[30;1m134 | [0m[35m    :param retry_limit: The number of times to retry the connection in case of service outages.[0m
[30;1m135 | [0m[35m    :param retry_delay: The number of seconds to wait between retries.[0m
[30;1m136 | [0m[35m    :param retry_args: An optional dictionary with arguments passed to ``tenacity.Retrying`` class.[0m
[30;1m137 | [0m[35m    """[0m

[31m--[ [0m[34mMatch #[0m[33m335[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m128 | [0m[35m[0m
[30;1m129 | [0m[35m    :param statement_id: ID of the SQL statement.[0m
[30;1m130 | [0m[35m    :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databr[0m
[30;1m131 | [0m[35m    :param end_time: The end time (set based on timeout supplied for the operator) for the SQL state[0m
[30;1m132 | [0m[35m    :param polling_period_seconds: Controls the rate of the poll for the result of this run.[0m
[30;1m133 | [0m[35m        By default, the trigger will poll every 30 seconds.[0m
[30;1m134 | [0m[35m    :param retry_limit: The number of times to retry the connection in case of service outages.[0m

[31m--[ [0m[34mMatch #[0m[33m336[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m128 | [0m[35m[0m
[30;1m129 | [0m[35m    :param statement_id: ID of the SQL statement.[0m
[30;1m130 | [0m[35m    :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databr[0m
[30;1m131 | [0m[35m    :param end_time: The end time (set based on timeout supplied for the operator) for the SQL state[0m
[30;1m132 | [0m[35m    :param polling_period_seconds: Controls the rate of the poll for the result of this run.[0m
[30;1m133 | [0m[35m        By default, the trigger will poll every 30 seconds.[0m
[30;1m134 | [0m[35m    :param retry_limit: The number of times to retry the connection in case of service outages.[0m

[31m--[ [0m[34mMatch #[0m[33m337[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m33 | [0m[35m    :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databr[0m
[30;1m34 | [0m[35m    :param polling_period_seconds: Controls the rate of the poll for the result of this run.[0m
[30;1m35 | [0m[35m        By default, the trigger will poll every 30 seconds.[0m
[30;1m36 | [0m[35m    :param retry_limit: The number of times to retry the connection in case of service outages.[0m
[30;1m37 | [0m[35m    :param retry_delay: The number of seconds to wait between retries.[0m
[30;1m38 | [0m[35m    :param retry_args: An optional dictionary with arguments passed to ``tenacity.Retrying`` class.[0m
[30;1m39 | [0m[35m    :param run_page_url: The run page url.[0m

[31m--[ [0m[34mMatch #[0m[33m338[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m18 | [0m[35mfrom __future__ import annotations[0m
[30;1m19 | [0m[35m[0m
[30;1m20 | [0m[35mimport asyncio[0m
[30;1m21 | [0m[35mimport time[0m
[30;1m22 | [0m[35mfrom typing import Any[0m
[30;1m23 | [0m[35m[0m
[30;1m24 | [0m[35mfrom airflow.providers.databricks.hooks.databricks import DatabricksHook[0m
[30;1m25 | [0m[35mfrom airflow.triggers.base import BaseTrigger, TriggerEvent[0m

[31m--[ [0m[34mMatch #[0m[33m339[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/plugins/workflow.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m33 | [0m[35m[0m
[30;1m34 | [0m[35m- **Task-Level Links**: Within the workflow, each task includes links to the job run and a repair li[0m
[30;1m35 | [0m[35m[0m
[30;1m36 | [0m[35m- **Workflow-Level Links**: At the workflow level, for the job launch task, the plugin provides a li[0m
[30;1m37 | [0m[35m[0m
[30;1m38 | [0m[35mExamples[0m
[30;1m39 | [0m[35m--------[0m

[31m--[ [0m[34mMatch #[0m[33m340[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/plugins/workflow.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m341[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_delete.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m342[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m343[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/sensors/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m344[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/operators/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m345[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/hooks/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m346[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m956 | [0m[35m                        or is_repair_reason_match_exist(self, run_state)[0m
[30;1m957 | [0m[35m                    )[0m
[30;1m958 | [0m[35m            _handle_deferrable_databricks_operator_completion(event, self.log)[0m
[30;1m959 | [0m[35m            if event.get("repair_run"):[0m
[30;1m960 | [0m[35m                self.repair_run = False[0m
[30;1m961 | [0m[35m                self.run_id = event["run_id"][0m
[30;1m962 | [0m[35m                job_id = self._hook.get_job_id(self.run_id)[0m

[31m--[ [0m[34mMatch #[0m[33m347[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m950 | [0m[35m        if event:[0m
[30;1m951 | [0m[35m            if event.get("run_state"):[0m
[30;1m952 | [0m[35m                run_state = RunState.from_json(event["run_state"])[0m
[30;1m953 | [0m[35m                if event.get("repair_run"):[0m
[30;1m954 | [0m[35m                    event["repair_run"] = event["repair_run"] and ([0m
[30;1m955 | [0m[35m                        not self.databricks_repair_reason_new_settings[0m
[30;1m956 | [0m[35m                        or is_repair_reason_match_exist(self, run_state)[0m

[31m--[ [0m[34mMatch #[0m[33m348[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m948 | [0m[35m[0m
[30;1m949 | [0m[35m    def execute_complete(self, context: Context, event: dict[str, Any] | None = None) -> None:[0m
[30;1m950 | [0m[35m        if event:[0m
[30;1m951 | [0m[35m            if event.get("run_state"):[0m
[30;1m952 | [0m[35m                run_state = RunState.from_json(event["run_state"])[0m
[30;1m953 | [0m[35m                if event.get("repair_run"):[0m
[30;1m954 | [0m[35m                    event["repair_run"] = event["repair_run"] and ([0m

[31m--[ [0m[34mMatch #[0m[33m349[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m631 | [0m[35m        if ([0m
[30;1m632 | [0m[35m            "pipeline_task" in self.json[0m
[30;1m633 | [0m[35m            and self.json["pipeline_task"].get("pipeline_id") is None[0m
[30;1m634 | [0m[35m            and self.json["pipeline_task"].get("pipeline_name")[0m
[30;1m635 | [0m[35m        ):[0m
[30;1m636 | [0m[35m            # If pipeline_id is not provided, we need to fetch it from the pipeline_name[0m
[30;1m637 | [0m[35m            pipeline_name = self.json["pipeline_task"]["pipeline_name"][0m

[31m--[ [0m[34mMatch #[0m[33m350[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m630 | [0m[35m    def execute(self, context: Context):[0m
[30;1m631 | [0m[35m        if ([0m
[30;1m632 | [0m[35m            "pipeline_task" in self.json[0m
[30;1m633 | [0m[35m            and self.json["pipeline_task"].get("pipeline_id") is None[0m
[30;1m634 | [0m[35m            and self.json["pipeline_task"].get("pipeline_name")[0m
[30;1m635 | [0m[35m        ):[0m
[30;1m636 | [0m[35m            # If pipeline_id is not provided, we need to fetch it from the pipeline_name[0m

[31m--[ [0m[34mMatch #[0m[33m351[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m397 | [0m[35m        if job_id is None:[0m
[30;1m398 | [0m[35m            return self._hook.create_job(self.json)[0m
[30;1m399 | [0m[35m        self._hook.reset_job(str(job_id), self.json)[0m
[30;1m400 | [0m[35m        if (access_control_list := self.json.get("access_control_list")) is not None:[0m
[30;1m401 | [0m[35m            acl_json = {"access_control_list": access_control_list}[0m
[30;1m402 | [0m[35m            self._hook.update_job_permission(job_id, normalise_json_content(acl_json))[0m
[30;1m403 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m352[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m239 | [0m[35m[0m
[30;1m240 | [0m[35m    error_message = f"Job run failed with terminal state: {run_state} and with the errors {errors}"[0m
[30;1m241 | [0m[35m[0m
[30;1m242 | [0m[35m    if event.get("repair_run"):[0m
[30;1m243 | [0m[35m        log.warning([0m
[30;1m244 | [0m[35m            "%s but since repair run is set, repairing the run with all failed tasks",[0m
[30;1m245 | [0m[35m            error_message,[0m

[31m--[ [0m[34mMatch #[0m[33m353[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m97 | [0m[35m                if run_state.result_state == "FAILED":[0m
[30;1m98 | [0m[35m                    failed_tasks = [][0m
[30;1m99 | [0m[35m                    for task in run_info.get("tasks", []):[0m
[30;1m100 | [0m[35m                        if task.get("state", {}).get("result_state", "") == "FAILED":[0m
[30;1m101 | [0m[35m                            task_run_id = task["run_id"][0m
[30;1m102 | [0m[35m                            task_key = task["task_key"][0m
[30;1m103 | [0m[35m                            run_output = hook.get_run_output(task_run_id)[0m

[31m--[ [0m[34mMatch #[0m[33m354[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m97 | [0m[35m                if run_state.result_state == "FAILED":[0m
[30;1m98 | [0m[35m                    failed_tasks = [][0m
[30;1m99 | [0m[35m                    for task in run_info.get("tasks", []):[0m
[30;1m100 | [0m[35m                        if task.get("state", {}).get("result_state", "") == "FAILED":[0m
[30;1m101 | [0m[35m                            task_run_id = task["run_id"][0m
[30;1m102 | [0m[35m                            task_key = task["task_key"][0m
[30;1m103 | [0m[35m                            run_output = hook.get_run_output(task_run_id)[0m

[31m--[ [0m[34mMatch #[0m[33m355[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m96 | [0m[35m                    return[0m
[30;1m97 | [0m[35m                if run_state.result_state == "FAILED":[0m
[30;1m98 | [0m[35m                    failed_tasks = [][0m
[30;1m99 | [0m[35m                    for task in run_info.get("tasks", []):[0m
[30;1m100 | [0m[35m                        if task.get("state", {}).get("result_state", "") == "FAILED":[0m
[30;1m101 | [0m[35m                            task_run_id = task["run_id"][0m
[30;1m102 | [0m[35m                            task_key = task["task_key"][0m

[31m--[ [0m[34mMatch #[0m[33m356[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1532 | [0m[35m        execution_timeout is not defined, the task continues to run indefinitely. Therefore,[0m
[30;1m1533 | [0m[35m        to mirror this behavior in the Databricks Jobs API, we set the timeout to 0, indicating[0m
[30;1m1534 | [0m[35m        that the job should run indefinitely. This aligns with the default behavior of Databricks jo[0m
[30;1m1535 | [0m[35m        where a timeout seconds value of 0 signifies an indefinite run duration.[0m
[30;1m1536 | [0m[35m        More details can be found in the Databricks documentation:[0m
[30;1m1537 | [0m[35m        See https://docs.databricks.com/api/workspace/jobs/submit#timeout_seconds[0m
[30;1m1538 | [0m[35m        """[0m

[31m--[ [0m[34mMatch #[0m[33m357[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1530 | [0m[35m[0m
[30;1m1531 | [0m[35m        By default, tasks in Airflow have an execution_timeout set to None. In Airflow, when[0m
[30;1m1532 | [0m[35m        execution_timeout is not defined, the task continues to run indefinitely. Therefore,[0m
[30;1m1533 | [0m[35m        to mirror this behavior in the Databricks Jobs API, we set the timeout to 0, indicating[0m
[30;1m1534 | [0m[35m        that the job should run indefinitely. This aligns with the default behavior of Databricks jo[0m
[30;1m1535 | [0m[35m        where a timeout seconds value of 0 signifies an indefinite run duration.[0m
[30;1m1536 | [0m[35m        More details can be found in the Databricks documentation:[0m

[31m--[ [0m[34mMatch #[0m[33m358[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1526 | [0m[35m[0m
[30;1m1527 | [0m[35m    def _get_task_timeout_seconds(self) -> int:[0m
[30;1m1528 | [0m[35m        """[0m
[30;1m1529 | [0m[35m        Get the timeout seconds value for the Databricks job based on the execution timeout value pr[0m
[30;1m1530 | [0m[35m[0m
[30;1m1531 | [0m[35m        By default, tasks in Airflow have an execution_timeout set to None. In Airflow, when[0m
[30;1m1532 | [0m[35m        execution_timeout is not defined, the task continues to run indefinitely. Therefore,[0m

[31m--[ [0m[34mMatch #[0m[33m359[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1526 | [0m[35m[0m
[30;1m1527 | [0m[35m    def _get_task_timeout_seconds(self) -> int:[0m
[30;1m1528 | [0m[35m        """[0m
[30;1m1529 | [0m[35m        Get the timeout seconds value for the Databricks job based on the execution timeout value pr[0m
[30;1m1530 | [0m[35m[0m
[30;1m1531 | [0m[35m        By default, tasks in Airflow have an execution_timeout set to None. In Airflow, when[0m
[30;1m1532 | [0m[35m        execution_timeout is not defined, the task continues to run indefinitely. Therefore,[0m

[31m--[ [0m[34mMatch #[0m[33m360[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1459 | [0m[35mram source: Optional location type of the notebook. When set to WORKSPACE, the notebook will be retr[0m
[30;1m1460 | [0m[35m            from the local Databricks workspace. When set to GIT, the notebook will be retrieved fro[0m
[30;1m1461 | [0m[35m            defined in git_source. If the value is empty, the task will use GIT if git_source is def[0m
[30;1m1462 | [0m[35m            and WORKSPACE otherwise. For more information please visit[0m
[30;1m1463 | [0m[35m            https://docs.databricks.com/dev-tools/api/latest/jobs.html#operation/JobsCreate[0m
[30;1m1464 | [0m[35m    :param databricks_conn_id: The name of the Airflow connection to use.[0m

[31m--[ [0m[34mMatch #[0m[33m361[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1457 | [0m[35m[0m
[30;1m1458 | [0m[35m    :param notebook_path: The path to the notebook in Databricks.[0m
[30;1m1459 | [0m[35m    :param source: Optional location type of the notebook. When set to WORKSPACE, the notebook will [0m
[30;1m1460 | [0m[35m            from the local Databricks workspace. When set to GIT, the notebook will be retrieved fro[0m
[30;1m1461 | [0m[35m            defined in git_source. If the value is empty, the task will use GIT if git_source is def[0m
[30;1m1462 | [0m[35m            and WORKSPACE otherwise. For more information please visit[0m
[30;1m1463 | [0m[35m            https://docs.databricks.com/dev-tools/api/latest/jobs.html#operation/JobsCreate[0m

[31m--[ [0m[34mMatch #[0m[33m362[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1346 | [0m[35m        tasks = self._hook.get_run(self.databricks_run_id)["tasks"][0m
[30;1m1347 | [0m[35m[0m
[30;1m1348 | [0m[35m        # Because the task_key remains the same across multiple runs, and the Databricks API does no[0m
[30;1m1349 | [0m[35m        # tasks sorted by their attempts/start time, we sort the tasks by start time. This ensures t[0m
[30;1m1350 | [0m[35m        # map the latest attempt (whose status is to be monitored) of the task run to the task_key w[0m
[30;1m1351 | [0m[35m        # building the {task_key: task} map below.[0m
[30;1m1352 | [0m[35m        sorted_task_runs = sorted(tasks, key=lambda x: x["start_time"])[0m

[31m--[ [0m[34mMatch #[0m[33m363[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1133 | [0m[35m            "catalog": self.catalog,[0m
[30;1m1134 | [0m[35m            "schema": self.schema,[0m
[30;1m1135 | [0m[35m            "parameters": self.parameters,[0m
[30;1m1136 | [0m[35m            # We set the wait timeout to 0s as that seems the appropriate way for our deferrable ver[0m
[30;1m1137 | [0m[35m            # support of the operator. For synchronous version, we still poll on the statement[0m
[30;1m1138 | [0m[35m            # execution state.[0m
[30;1m1139 | [0m[35m            "wait_timeout": "0s",[0m

[31m--[ [0m[34mMatch #[0m[33m364[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1057 | [0m[35m        # This variable will be used in case our task gets killed.[0m
[30;1m1058 | [0m[35m        self.statement_id: str | None = None[0m
[30;1m1059 | [0m[35m[0m
[30;1m1060 | [0m[35m        self.timeout = timeout[0m
[30;1m1061 | [0m[35m        self.do_xcom_push = do_xcom_push[0m
[30;1m1062 | [0m[35m[0m
[30;1m1063 | [0m[35m    @cached_property[0m
[30;1m1064 | [0m[35m    def _hook(self):[0m

[31m--[ [0m[34mMatch #[0m[33m365[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1009 | [0m[35m            might be a floating point number).[0m
[30;1m1010 | [0m[35m    :param databricks_retry_args: An optional dictionary with arguments passed to ``tenacity.Retryin[0m
[30;1m1011 | [0m[35m    :param do_xcom_push: Whether we should push statement_id to xcom.:[0m
[30;1m1012 | [0m[35m    :param timeout: The timeout for the Airflow task executing the SQL statement. By default a value[0m
[30;1m1013 | [0m[35m    :param deferrable: Run operator in the deferrable mode.[0m
[30;1m1014 | [0m[35m    """[0m
[30;1m1015 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m366[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m803 | [0m[35m            https://docs.databricks.com/dev-tools/api/latest/jobs.html#operation/JobsRunNow[0m
[30;1m804 | [0m[35m    :param spark_submit_params: A list of parameters for jobs with spark submit task,[0m
[30;1m805 | [0m[35m        e.g. "spark_submit_params": ["--class", "org.apache.spark.examples.SparkPi"].[0m
[30;1m806 | [0m[35m        The parameters will be passed to spark-submit script as command line parameters.[0m
[30;1m807 | [0m[35m        If specified upon run-now, it would overwrite the parameters specified[0m
[30;1m808 | [0m[35m        in job setting.[0m
[30;1m809 | [0m[35m        The json representation of this field cannot exceed 10,000 bytes.[0m

[31m--[ [0m[34mMatch #[0m[33m367[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m748 | [0m[35m        (i.e. ``notebook_params``, ``spark_submit_params``..) to this operator will[0m
[30;1m749 | [0m[35m        be merged with this json dictionary if they are provided.[0m
[30;1m750 | [0m[35m        If there are conflicts during the merge, the named parameters will[0m
[30;1m751 | [0m[35m        take precedence and override the top level json keys. (templated)[0m
[30;1m752 | [0m[35m[0m
[30;1m753 | [0m[35m        .. seealso::[0m
[30;1m754 | [0m[35m            For more information about templating see :ref:`concepts:jinja-templating`.[0m

[31m--[ [0m[34mMatch #[0m[33m368[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m705 | [0m[35m[0m
[30;1m706 | [0m[35m    In the case where both the json parameter **AND** the named parameters[0m
[30;1m707 | [0m[35m    are provided, they will be merged together. If there are conflicts during the merge,[0m
[30;1m708 | [0m[35m    the named parameters will take precedence and override the top level ``json`` keys.[0m
[30;1m709 | [0m[35m[0m
[30;1m710 | [0m[35m    Currently the named parameters that ``DatabricksRunNowOperator`` supports are[0m
[30;1m711 | [0m[35m        - ``job_id``[0m

[31m--[ [0m[34mMatch #[0m[33m369[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m679 | [0m[35m[0m
[30;1m680 | [0m[35m    Another way to accomplish the same thing is to use the named parameters[0m
[30;1m681 | [0m[35m    of the ``DatabricksRunNowOperator`` directly. Note that there is exactly[0m
[30;1m682 | [0m[35m    one named parameter for each top level parameter in the ``run-now``[0m
[30;1m683 | [0m[35m    endpoint. In this method, your code would look like this: ::[0m
[30;1m684 | [0m[35m[0m
[30;1m685 | [0m[35m        job_id = 42[0m

[31m--[ [0m[34mMatch #[0m[33m370[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m517 | [0m[35m            might be a floating point number).[0m
[30;1m518 | [0m[35m    :param databricks_retry_args: An optional dictionary with arguments passed to ``tenacity.Retryin[0m
[30;1m519 | [0m[35m    :param do_xcom_push: Whether we should push run_id and run_page_url to xcom.[0m
[30;1m520 | [0m[35m    :param git_source: Optional specification of a remote git repository from which[0m
[30;1m521 | [0m[35m        supported task types are retrieved.[0m
[30;1m522 | [0m[35m    :param deferrable: Run operator in the deferrable mode.[0m
[30;1m523 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m371[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m502 | [0m[35m        users, or ``group_name`` for groups), and ``permission_level`` for that subject.  See Jobs A[0m
[30;1m503 | [0m[35m        documentation for more details.[0m
[30;1m504 | [0m[35m    :param wait_for_termination: if we should wait for termination of the job run. ``True`` by defau[0m
[30;1m505 | [0m[35m    :param timeout_seconds: The timeout for this run. By default a value of 0 is used[0m
[30;1m506 | [0m[35m        which means to have no timeout.[0m
[30;1m507 | [0m[35m        This field will be templated.[0m
[30;1m508 | [0m[35m    :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databr[0m

[31m--[ [0m[34mMatch #[0m[33m372[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m425 | [0m[35m        (i.e. ``spark_jar_task``, ``notebook_task``..) to this operator will[0m
[30;1m426 | [0m[35m        be merged with this json dictionary if they are provided.[0m
[30;1m427 | [0m[35m        If there are conflicts during the merge, the named parameters will[0m
[30;1m428 | [0m[35m        take precedence and override the top level json keys. (templated)[0m
[30;1m429 | [0m[35m[0m
[30;1m430 | [0m[35m        .. seealso::[0m
[30;1m431 | [0m[35m            For more information about templating see :ref:`concepts:jinja-templating`.[0m

[31m--[ [0m[34mMatch #[0m[33m373[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m289 | [0m[35m    :param email_notifications: Object (JobEmailNotifications).[0m
[30;1m290 | [0m[35m    :param webhook_notifications: Object (WebhookNotifications).[0m
[30;1m291 | [0m[35m    :param notification_settings: Optional notification settings.[0m
[30;1m292 | [0m[35m    :param timeout_seconds: An optional timeout applied to each run of this job.[0m
[30;1m293 | [0m[35m    :param schedule: Object (CronSchedule).[0m
[30;1m294 | [0m[35m    :param max_concurrent_runs: An optional maximum allowed number of concurrent runs of the job.[0m
[30;1m295 | [0m[35m    :param git_source: An optional specification for a remote repository containing the notebooks[0m

[31m--[ [0m[34mMatch #[0m[33m374[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m275 | [0m[35m        (i.e. ``name``, ``tags``, ``tasks``, etc.) to this operator will[0m
[30;1m276 | [0m[35m        be merged with this json dictionary if they are provided.[0m
[30;1m277 | [0m[35m        If there are conflicts during the merge, the named parameters will[0m
[30;1m278 | [0m[35m        take precedence and override the top level json keys. (templated)[0m
[30;1m279 | [0m[35m[0m
[30;1m280 | [0m[35m        .. seealso::[0m
[30;1m281 | [0m[35m            For more information about templating see :ref:`concepts:jinja-templating`.[0m

[31m--[ [0m[34mMatch #[0m[33m375[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m20 | [0m[35mfrom __future__ import annotations[0m
[30;1m21 | [0m[35m[0m
[30;1m22 | [0m[35mimport hashlib[0m
[30;1m23 | [0m[35mimport time[0m
[30;1m24 | [0m[35mfrom abc import ABC, abstractmethod[0m
[30;1m25 | [0m[35mfrom collections.abc import Sequence[0m
[30;1m26 | [0m[35mfrom functools import cached_property[0m
[30;1m27 | [0m[35mfrom logging import Logger[0m

[31m--[ [0m[34mMatch #[0m[33m376[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m1601 | [0m[35m    allows users to run their tasks on cheaper clusters that can be shared between tasks.[0m
[30;1m1602 | [0m[35m[0m
[30;1m1603 | [0m[35m    .. seealso::[0m
[30;1m1604 | [0m[35m        For more information on how to use this operator, take a look at the guide:[0m
[30;1m1605 | [0m[35m        :ref:`howto/operator:DatabricksTaskOperator`[0m
[30;1m1606 | [0m[35m[0m
[30;1m1607 | [0m[35m    :param task_config: The configuration of the task to be run on Databricks.[0m

[31m--[ [0m[34mMatch #[0m[33m377[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m1452 | [0m[35m    clusters, which allows users to run their tasks on cheaper clusters that can be shared between t[0m
[30;1m1453 | [0m[35m[0m
[30;1m1454 | [0m[35m    .. seealso::[0m
[30;1m1455 | [0m[35m        For more information on how to use this operator, take a look at the guide:[0m
[30;1m1456 | [0m[35m        :ref:`howto/operator:DatabricksNotebookOperator`[0m
[30;1m1457 | [0m[35m[0m
[30;1m1458 | [0m[35m    :param notebook_path: The path to the notebook in Databricks.[0m

[31m--[ [0m[34mMatch #[0m[33m378[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m985 | [0m[35m    See: https://docs.databricks.com/api/workspace/statementexecution[0m
[30;1m986 | [0m[35m[0m
[30;1m987 | [0m[35m    .. seealso::[0m
[30;1m988 | [0m[35m        For more information on how to use this operator, take a look at the guide:[0m
[30;1m989 | [0m[35m        :ref:`howto/operator:DatabricksSQLStatementsOperator`[0m
[30;1m990 | [0m[35m[0m
[30;1m991 | [0m[35m    :param statement: The SQL statement to execute. The statement can optionally be parameterized, s[0m

[31m--[ [0m[34mMatch #[0m[33m379[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m832 | [0m[35mngs JSON object for which[0m
[30;1m833 | [0m[35m            to repair the run. `None` by default. `None` means to repair at all cases with existing [0m
[30;1m834 | [0m[35m            settings otherwise check whether `RunState` state_message contains reason and[0m
[30;1m835 | [0m[35m            update job settings as per new_settings using databricks partial job update endpoint[0m
[30;1m836 | [0m[35m            (https://docs.databricks.com/api/workspace/jobs/update). If nothing is matched, then rep[0m
[30;1m837 | [0m[35m            will not get triggered.[0m
[30;1m838 | [0m[35m    :param cancel_previous_runs: Cancel all existing running jobs before submitting new one.[0m
[30;1m839 | [0m[35m    """[0m
[30;1m840 | [0m[35m[0m
[30;1m841 | [0m[35m    # Used in airflow.models.BaseOperator[0m

[31m--[ [0m[34mMatch #[0m[33m380[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m832 | [0m[35mdatabricks_repair_reason_new_settings: A dict of reason and new_settings JSON object for which[0m
[30;1m833 | [0m[35m            to repair the run. `None` by default. `None` means to repair at all cases with existing [0m
[30;1m834 | [0m[35m            settings otherwise check whether `RunState` state_message contains reason and[0m
[30;1m835 | [0m[35m            update job settings as per new_settings using databricks partial job update endpoint[0m
[30;1m836 | [0m[35m            (https://docs.databricks.com/api/workspace/jobs/update). If nothing is matched, then rep[0m
[30;1m837 | [0m[35m            will not get triggered.[0m

[31m--[ [0m[34mMatch #[0m[33m381[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m830 | [0m[35mram deferrable: Run operator in the deferrable mode.[0m
[30;1m831 | [0m[35m    :param repair_run: Repair the databricks run in case of failure.[0m
[30;1m832 | [0m[35m    :param databricks_repair_reason_new_settings: A dict of reason and new_settings JSON object for [0m
[30;1m833 | [0m[35m            to repair the run. `None` by default. `None` means to repair at all cases with existing [0m
[30;1m834 | [0m[35m            settings otherwise check whether `RunState` state_message contains reason and[0m
[30;1m835 | [0m[35m            update job settings as per new_settings using databricks partial job update endpoint[0m

[31m--[ [0m[34mMatch #[0m[33m382[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m813 | [0m[35mn/JobsRunNow[0m
[30;1m814 | [0m[35m    :param idempotency_token: an optional token that can be used to guarantee the idempotency of job[0m
[30;1m815 | [0m[35m        requests. If a run with the provided token already exists, the request does not create a new[0m
[30;1m816 | [0m[35m        returns the ID of the existing run instead.  This token must have at most 64 characters.[0m
[30;1m817 | [0m[35m    :param databricks_conn_id: Reference to the :ref:`Databricks connection <howto/connection:databr[0m
[30;1m818 | [0m[35m        By default and in the common case this will be ``databricks_default``. To use[0m

[31m--[ [0m[34mMatch #[0m[33m383[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m497 | [0m[35my of job run[0m
[30;1m498 | [0m[35m        requests. If a run with the provided token already exists, the request does not create a new[0m
[30;1m499 | [0m[35m        returns the ID of the existing run instead.  This token must have at most 64 characters.[0m
[30;1m500 | [0m[35m    :param access_control_list: optional list of dictionaries representing Access Control List (ACL)[0m
[30;1m501 | [0m[35m        a given job run.  Each dictionary consists of following field - specific subject (``user_nam[0m
[30;1m502 | [0m[35m        users, or ``group_name`` for groups), and ``permission_level`` for that subject.  See Jobs A[0m
[30;1m503 | [0m[35m        documentation for more details.[0m

[31m--[ [0m[34mMatch #[0m[33m384[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m496 | [0m[35me templated.[0m
[30;1m497 | [0m[35m    :param idempotency_token: an optional token that can be used to guarantee the idempotency of job[0m
[30;1m498 | [0m[35m        requests. If a run with the provided token already exists, the request does not create a new[0m
[30;1m499 | [0m[35m        returns the ID of the existing run instead.  This token must have at most 64 characters.[0m
[30;1m500 | [0m[35m    :param access_control_list: optional list of dictionaries representing Access Control List (ACL)[0m
[30;1m501 | [0m[35m        a given job run.  Each dictionary consists of following field - specific subject (``user_nam[0m

[31m--[ [0m[34mMatch #[0m[33m385[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m468 | [0m[35m        .. seealso::[0m
[30;1m469 | [0m[35m            https://docs.databricks.com/dev-tools/api/2.0/jobs.html#jobspipelinetask[0m
[30;1m470 | [0m[35m    :param dbt_task: Parameters needed to execute a dbt task.[0m
[30;1m471 | [0m[35m        The provided dictionary must contain at least the ``commands`` field and the[0m
[30;1m472 | [0m[35m        ``git_source`` parameter also needs to be set.[0m
[30;1m473 | [0m[35m        *EITHER* ``spark_jar_task`` *OR* ``notebook_task`` *OR* ``spark_python_task``[0m
[30;1m474 | [0m[35m        *OR* ``spark_submit_task`` *OR* ``pipeline_task`` *OR* ``dbt_task`` should be specified.[0m

[31m--[ [0m[34mMatch #[0m[33m386[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m460 | [0m[35m        .. seealso::[0m
[30;1m461 | [0m[35m            https://docs.databricks.com/dev-tools/api/2.0/jobs.html#jobssparksubmittask[0m
[30;1m462 | [0m[35m    :param pipeline_task: Parameters needed to execute a Delta Live Tables pipeline task.[0m
[30;1m463 | [0m[35m        The provided dictionary must contain at least ``pipeline_id`` field![0m
[30;1m464 | [0m[35m        *EITHER* ``spark_jar_task`` *OR* ``notebook_task`` *OR* ``spark_python_task``[0m
[30;1m465 | [0m[35m        *OR* ``spark_submit_task`` *OR* ``pipeline_task`` *OR* ``dbt_task`` should be specified.[0m
[30;1m466 | [0m[35m        This field will be templated.[0m

[31m--[ [0m[34mMatch #[0m[33m387[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m413 | [0m[35m    There are three ways to instantiate this operator.[0m
[30;1m414 | [0m[35m[0m
[30;1m415 | [0m[35m    .. seealso::[0m
[30;1m416 | [0m[35m        For more information on how to use this operator, take a look at the guide:[0m
[30;1m417 | [0m[35m        :ref:`howto/operator:DatabricksSubmitRunOperator`[0m
[30;1m418 | [0m[35m[0m
[30;1m419 | [0m[35m    :param tasks: Array of Objects(RunSubmitTaskSettings) <= 100 items.[0m

[31m--[ [0m[34mMatch #[0m[33m388[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m231 | [0m[35m    run_state = RunState.from_json(event["run_state"])[0m
[30;1m232 | [0m[35m    run_page_url = event["run_page_url"][0m
[30;1m233 | [0m[35m    errors = event["errors"][0m
[30;1m234 | [0m[35m    log.info("View run status, Spark UI, and logs at %s", run_page_url)[0m
[30;1m235 | [0m[35m[0m
[30;1m236 | [0m[35m    if run_state.is_successful:[0m
[30;1m237 | [0m[35m        log.info("Job run completed successfully.")[0m

[31m--[ [0m[34mMatch #[0m[33m389[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m202 | [0m[35m    run_page_url = hook.get_run_page_url(operator.run_id)[0m
[30;1m203 | [0m[35m    if operator.do_xcom_push and context is not None:[0m
[30;1m204 | [0m[35m        context["ti"].xcom_push(key=XCOM_RUN_PAGE_URL_KEY, value=run_page_url)[0m
[30;1m205 | [0m[35m    log.info("View run status, Spark UI, and logs at %s", run_page_url)[0m
[30;1m206 | [0m[35m[0m
[30;1m207 | [0m[35m    if operator.wait_for_termination:[0m
[30;1m208 | [0m[35m        run_info = hook.get_run(operator.run_id)[0m

[31m--[ [0m[34mMatch #[0m[33m390[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m163 | [0m[35m[0m
[30;1m164 | [0m[35mdef update_job_for_repair(operator: Any, hook: Any, job_id: int, run_state: RunState) -> None:[0m
[30;1m165 | [0m[35m    """[0m
[30;1m166 | [0m[35m    Update job settings(partial) to repair the run with all failed tasks.[0m
[30;1m167 | [0m[35m[0m
[30;1m168 | [0m[35m    :param operator: Databricks operator being handled[0m
[30;1m169 | [0m[35m    :param hook: Databricks hook[0m

[31m--[ [0m[34mMatch #[0m[33m391[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m147 | [0m[35m            log.info("Sleeping for %s seconds.", operator.polling_period_seconds)[0m
[30;1m148 | [0m[35m            time.sleep(operator.polling_period_seconds)[0m
[30;1m149 | [0m[35m[0m
[30;1m150 | [0m[35m    log.info("View run status, Spark UI, and logs at %s", run_page_url)[0m
[30;1m151 | [0m[35m[0m
[30;1m152 | [0m[35m[0m
[30;1m153 | [0m[35mdef is_repair_reason_match_exist(operator: Any, run_state: RunState) -> bool:[0m

[31m--[ [0m[34mMatch #[0m[33m392[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m143 | [0m[35m                raise AirflowException(error_message)[0m
[30;1m144 | [0m[35m[0m
[30;1m145 | [0m[35m            log.info("%s in run state: %s", operator.task_id, run_state)[0m
[30;1m146 | [0m[35m            log.info("View run status, Spark UI, and logs at %s", run_page_url)[0m
[30;1m147 | [0m[35m            log.info("Sleeping for %s seconds.", operator.polling_period_seconds)[0m
[30;1m148 | [0m[35m            time.sleep(operator.polling_period_seconds)[0m
[30;1m149 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m393[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m92 | [0m[35m            if run_state.is_terminal:[0m
[30;1m93 | [0m[35m                if run_state.is_successful:[0m
[30;1m94 | [0m[35m                    log.info("%s completed successfully.", operator.task_id)[0m
[30;1m95 | [0m[35m                    log.info("View run status, Spark UI, and logs at %s", run_page_url)[0m
[30;1m96 | [0m[35m                    return[0m
[30;1m97 | [0m[35m                if run_state.result_state == "FAILED":[0m
[30;1m98 | [0m[35m                    failed_tasks = [][0m

[31m--[ [0m[34mMatch #[0m[33m394[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/operators/databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m395[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000704[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration.Hostname[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks_sql.py[0m
   Pattern: [32m.hostname[0m
[30;1m83 | [0m[35m                "id": "1264e5078741679a",[0m
[30;1m84 | [0m[35m                "name": "Test",[0m
[30;1m85 | [0m[35m                "odbc_params": {[0m
[30;1m86 | [0m[35m                    "hostname": "xx.cloud.databricks.com",[0m
[30;1m87 | [0m[35m                    "path": "/sql/1.0/endpoints/1264e5078741679a",[0m
[30;1m88 | [0m[35m                },[0m
[30;1m89 | [0m[35m            }[0m

[31m--[ [0m[34mMatch #[0m[33m396[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks_sql.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m413 | [0m[35m        rowcount=1,[0m
[30;1m414 | [0m[35m        description=get_cursor_descriptions(cursor_descriptions),[0m
[30;1m415 | [0m[35m    )[0m
[30;1m416 | [0m[35m    timeout = timedelta(seconds=1)[0m
[30;1m417 | [0m[35m    thread = create_timeout_thread(cur=cur, execution_timeout=timeout)[0m
[30;1m418 | [0m[35m    mock_timer.assert_called_once_with(timeout.total_seconds(), cur.connection.cancel)[0m
[30;1m419 | [0m[35m    assert thread is not None[0m

[31m--[ [0m[34mMatch #[0m[33m397[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks_sql.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m381 | [0m[35m            description=get_cursor_descriptions(cursor_descriptions),[0m
[30;1m382 | [0m[35m        )[0m
[30;1m383 | [0m[35m[0m
[30;1m384 | [0m[35m        # Simulate a timeout[0m
[30;1m385 | [0m[35m        mock_create_timeout_thread.return_value = threading.Timer(cur, execution_timeout)[0m
[30;1m386 | [0m[35m[0m
[30;1m387 | [0m[35m        mock_run_command.side_effect = Exception("Mocked exception")[0m
[30;1m388 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m398[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m399[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/conftest.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m400[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m401[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks_azure_workload_identity.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m402[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m934 | [0m[35m12304)``[0m
[30;1m935 | [0m[35m`b027223132 <https://github.com/apache/airflow/commit/b0272231320a4975cc39968dec8f0abf7a5cca11>`__  [0m
[30;1m936 | [0m[35m`85a18e13d9 <https://github.com/apache/airflow/commit/85a18e13d9dec84275283ff69e34704b60d54a75>`__  [0m
[30;1m937 | [0m[35m`59eb5de78c <https://github.com/apache/airflow/commit/59eb5de78c70ee9c7ae6e4cba5c7a2babb8103ca>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m403[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m888 | [0m[35m<https://github.com/apache/airflow/commit/cbf8001d7630530773f623a786f9eb319783b33c>`__  2021-06-16  [0m
[30;1m889 | [0m[35m`1fba5402bb <https://github.com/apache/airflow/commit/1fba5402bb14b3ffa6429fdc683121935f88472f>`__  [0m
[30;1m890 | [0m[35m`9c94b72d44 <https://github.com/apache/airflow/commit/9c94b72d440b18a9e42123d20d48b951712038f9>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m404[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m667 | [0m[35m6c7cfb <https://github.com/apache/airflow/commit/e5ac6c7cfb189c33e3b247f7d5aec59fe5e89a00>`__  2022-[0m
[30;1m668 | [0m[35m`52f2f5bfa8 <https://github.com/apache/airflow/commit/52f2f5bfa8ac83b5514f82ba22c710d659dc0b2f>`__  [0m
[30;1m669 | [0m[35m`0255a0a5e7 <https://github.com/apache/airflow/commit/0255a0a5e7b93f2daa3a51792cd38d19d6a373c0>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m405[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m569 | [0m[35m#30994)``[0m
[30;1m570 | [0m[35m`a7eb32a5b2 <https://github.com/apache/airflow/commit/a7eb32a5b222e236454d3e474eec478ded7c368d>`__  [0m
[30;1m571 | [0m[35m`9409446097 <https://github.com/apache/airflow/commit/940944609751e2584b191aa776b6221aa78703d3>`__  [0m
[30;1m572 | [0m[35m`ecb9a9ea78 <https://github.com/apache/airflow/commit/ecb9a9ea78203bd1ce2f2d645d554409651ba8c1>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m406[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m313 | [0m[35mdcc82fb6 <https://github.com/apache/airflow/commit/f9dcc82fb690777e0cb4951f5ae5a4bde1e15c54>`__  202[0m
[30;1m314 | [0m[35m`4a669fb1a9 <https://github.com/apache/airflow/commit/4a669fb1a9891809932a7fdba202c6baa369d537>`__  [0m
[30;1m315 | [0m[35m`5fa80b6aea <https://github.com/apache/airflow/commit/5fa80b6aea60f93cdada66f160e2b54f723865ca>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m407[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m310 | [0m[35m054)``[0m
[30;1m311 | [0m[35m`66df296a6e <https://github.com/apache/airflow/commit/66df296a6e54d42909231230a1c76f260dd15d0b>`__  [0m
[30;1m312 | [0m[35m`629545bea2 <https://github.com/apache/airflow/commit/629545bea2afa55dbda9b839734b4851d9da566e>`__  [0m
[30;1m313 | [0m[35m`f9dcc82fb6 <https://github.com/apache/airflow/commit/f9dcc82fb690777e0cb4951f5ae5a4bde1e15c54>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m408[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m44 | [0m[35m=================================  ===========  ====================================================[0m
[30;1m45 | [0m[35m`7b2ec33c7a <https://github.com/apache/airflow/commit/7b2ec33c7ad4998d9c9735b79593fcdcd3b9dd1f>`__  [0m
[30;1m46 | [0m[35m`139673d3ce <https://github.com/apache/airflow/commit/139673d3ce5552c2cf8bcb2d202e97342c4b237c>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m409[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m[0m
[30;1m10 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m[0m
[30;1m12 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m410[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m977 | [0m[35mb.com/apache/airflow/commit/83c037873ff694eed67ba8b30f2d9c88b2c7c6f2>`__  2020-01-30   ``[AIRFLOW-66[0m
[30;1m978 | [0m[35m`c42a375e79 <https://github.com/apache/airflow/commit/c42a375e799e5adb3f9536616372dc90ff47e6c8>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m411[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m910 | [0m[35megrations (#13717)``[0m
[30;1m911 | [0m[35m`295d66f914 <https://github.com/apache/airflow/commit/295d66f91446a69610576d040ba687b38f1c5d0a>`__  [0m
[30;1m912 | [0m[35m`6cf76d7ac0 <https://github.com/apache/airflow/commit/6cf76d7ac01270930de7f105fb26428763ee1d4e>`__  [0m
[30;1m913 | [0m[35m`f6448b4e48 <https://github.com/apache/airflow/commit/f6448b4e482fd96339ae65c26d08e6a2bdb51aaf>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m412[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m909 | [0m[35m#13732)``[0m
[30;1m910 | [0m[35m`3fd5ef3555 <https://github.com/apache/airflow/commit/3fd5ef355556cf0ad7896bb570bbe4b2eabbf46e>`__  [0m
[30;1m911 | [0m[35m`295d66f914 <https://github.com/apache/airflow/commit/295d66f91446a69610576d040ba687b38f1c5d0a>`__  [0m
[30;1m912 | [0m[35m`6cf76d7ac0 <https://github.com/apache/airflow/commit/6cf76d7ac01270930de7f105fb26428763ee1d4e>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m413[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m892 | [0m[35mca00 <https://github.com/apache/airflow/commit/37681bca0081dd228ac4047c17631867bba7a66f>`__  2021-05[0m
[30;1m893 | [0m[35m`807ad32ce5 <https://github.com/apache/airflow/commit/807ad32ce59e001cb3532d98a05fa7d0d7fabb95>`__  [0m
[30;1m894 | [0m[35m`df143aee8d <https://github.com/apache/airflow/commit/df143aee8d9e7e0089b747bdd27addf63bb4962f>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m414[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m832 | [0m[35m)``[0m
[30;1m833 | [0m[35m`728e94a47e <https://github.com/apache/airflow/commit/728e94a47e0048829ce67096235d34019be9fac7>`__  [0m
[30;1m834 | [0m[35m`4925b37b66 <https://github.com/apache/airflow/commit/4925b37b661a1117dc9f1a10be11f03e67e1a413>`__  [0m
[30;1m835 | [0m[35m`43de625d42 <https://github.com/apache/airflow/commit/43de625d4246af7014f64941f8effb09997731cb>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m415[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/commits.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m480 | [0m[35m(#33569)``[0m
[30;1m481 | [0m[35m`a91ee7ac2f <https://github.com/apache/airflow/commit/a91ee7ac2fe29f460a4e4b0d8c1346f40672be43>`__  [0m
[30;1m482 | [0m[35m`8bf53dd554 <https://github.com/apache/airflow/commit/8bf53dd5545ecda0e5bbffbc4cc803cbbde719a9>`__  [0m
[30;1m483 | [0m[35m`5f8f25b34c <https://github.com/apache/airflow/commit/5f8f25b34c9e8c0d4845b014fc8f1b00cc2e766f>`__  [0m

[31m--[ [0m[34mMatch #[0m[33m416[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m1828 | [0m[35m        mock_get.return_value.__aenter__.return_value.json = AsyncMock(return_value=GET_RUN_OUTPUT_R[0m
[30;1m1829 | [0m[35m        async with self.hook:[0m
[30;1m1830 | [0m[35m            run_output = await self.hook.a_get_run_output(RUN_ID)[0m
[30;1m1831 | [0m[35m            run_output_error = run_output.get("error")[0m
[30;1m1832 | [0m[35m[0m
[30;1m1833 | [0m[35m        assert run_output_error == ERROR_MESSAGE[0m
[30;1m1834 | [0m[35m        mock_get.assert_called_once_with([0m

[31m--[ [0m[34mMatch #[0m[33m417[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m597 | [0m[35m    def test_get_run_output(self, mock_requests):[0m
[30;1m598 | [0m[35m        mock_requests.get.return_value.json.return_value = GET_RUN_OUTPUT_RESPONSE[0m
[30;1m599 | [0m[35m[0m
[30;1m600 | [0m[35m        run_output_error = self.hook.get_run_output(RUN_ID).get("error")[0m
[30;1m601 | [0m[35m[0m
[30;1m602 | [0m[35m        assert run_output_error == ERROR_MESSAGE[0m
[30;1m603 | [0m[35m        mock_requests.get.assert_called_once_with([0m

[31m--[ [0m[34mMatch #[0m[33m418[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m149 | [0m[35m[0m
[30;1m150 | [0m[35mdef update_endpoint(host):[0m
[30;1m151 | [0m[35m    """[0m
[30;1m152 | [0m[35m    Utility function to generate the update endpoint given the host.[0m
[30;1m153 | [0m[35m    """[0m
[30;1m154 | [0m[35m    return f"https://{host}/api/2.1/jobs/update"[0m
[30;1m155 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m419[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m420[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m2098 | [0m[35m@pytest.mark.db_test[0m
[30;1m2099 | [0m[35mclass TestDatabricksHookAsyncSpToken:[0m
[30;1m2100 | [0m[35m    """[0m
[30;1m2101 | [0m[35m    Tests for DatabricksHook using async methods when auth is done with Service[0m
[30;1m2102 | [0m[35m    Principal Oauth token.[0m
[30;1m2103 | [0m[35m    """[0m
[30;1m2104 | [0m[35m[0m
[30;1m2105 | [0m[35m    @provide_session[0m

[31m--[ [0m[34mMatch #[0m[33m421[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m2058 | [0m[35m@pytest.mark.db_test[0m
[30;1m2059 | [0m[35mclass TestDatabricksHookSpToken:[0m
[30;1m2060 | [0m[35m    """[0m
[30;1m2061 | [0m[35m    Tests for DatabricksHook when auth is done with Service Principal Oauth token.[0m
[30;1m2062 | [0m[35m    """[0m
[30;1m2063 | [0m[35m[0m
[30;1m2064 | [0m[35m    @provide_session[0m

[31m--[ [0m[34mMatch #[0m[33m422[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m20 | [0m[35mimport itertools[0m
[30;1m21 | [0m[35mimport json[0m
[30;1m22 | [0m[35mimport ssl[0m
[30;1m23 | [0m[35mimport time[0m
[30;1m24 | [0m[35mfrom asyncio.exceptions import TimeoutError[0m
[30;1m25 | [0m[35mfrom unittest import mock[0m
[30;1m26 | [0m[35mfrom unittest.mock import AsyncMock[0m
[30;1m27 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m423[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/exceptions.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m424[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/hooks/test_databricks_azure_workload_identity_async.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m425[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/sensors/databricks_partition.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m426[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/operators/test_databricks.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m427[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/operators/test_databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m1214 | [0m[35m    def test_init_with_merging(self):[0m
[30;1m1215 | [0m[35m        """[0m
[30;1m1216 | [0m[35m        Test the initializer when json and other named parameters are both[0m
[30;1m1217 | [0m[35m        provided. The named parameters should override top level keys in the[0m
[30;1m1218 | [0m[35m        json dict.[0m
[30;1m1219 | [0m[35m        """[0m
[30;1m1220 | [0m[35m        override_notebook_params = {"workers": "999"}[0m

[31m--[ [0m[34mMatch #[0m[33m428[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/operators/test_databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m789 | [0m[35m    def test_init_with_merging(self):[0m
[30;1m790 | [0m[35m        """[0m
[30;1m791 | [0m[35m        Test the initializer when json and other named parameters are both[0m
[30;1m792 | [0m[35m        provided. The named parameters should override top level keys in the[0m
[30;1m793 | [0m[35m        json dict.[0m
[30;1m794 | [0m[35m        """[0m
[30;1m795 | [0m[35m        override_new_cluster = {"workers": 999}[0m

[31m--[ [0m[34mMatch #[0m[33m429[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/operators/test_databricks.py[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m372 | [0m[35m    def test_init_with_merging(self):[0m
[30;1m373 | [0m[35m        """[0m
[30;1m374 | [0m[35m        Test the initializer when json and other named parameters are both[0m
[30;1m375 | [0m[35m        provided. The named parameters should override top level keys in the[0m
[30;1m376 | [0m[35m        json dict.[0m
[30;1m377 | [0m[35m        """[0m
[30;1m378 | [0m[35m        override_name = "override"[0m

[31m--[ [0m[34mMatch #[0m[33m430[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/triggers/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m431[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/PKG-INFO[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m117 | [0m[35m[0m
[30;1m118 | [0m[35mYou can install such cross-provider dependencies when installing from PyPI. For example:[0m
[30;1m119 | [0m[35m[0m
[30;1m120 | [0m[35m.. code-block:: bash[0m
[30;1m121 | [0m[35m[0m
[30;1m122 | [0m[35m    pip install apache-airflow-providers-databricks[common.sql][0m
[30;1m123 | [0m[35m[0m
[30;1m124 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m432[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/PKG-INFO[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m51 | [0m[35m   regarding copyright ownership.  The ASF licenses this file[0m
[30;1m52 | [0m[35m   to you under the Apache License, Version 2.0 (the[0m
[30;1m53 | [0m[35m   "License"); you may not use this file except in compliance[0m
[30;1m54 | [0m[35m   with the License.  You may obtain a copy of the License at[0m
[30;1m55 | [0m[35m[0m
[30;1m56 | [0m[35m..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m57 | [0m[35m[0m
[30;1m58 | [0m[35m.. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m433[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/PKG-INFO[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m119 | [0m[35m[0m
[30;1m120 | [0m[35m.. code-block:: bash[0m
[30;1m121 | [0m[35m[0m
[30;1m122 | [0m[35m    pip install apache-airflow-providers-databricks[common.sql][0m
[30;1m123 | [0m[35m[0m
[30;1m124 | [0m[35m[0m
[30;1m125 | [0m[35m====================================================================================================[0m

[31m--[ [0m[34mMatch #[0m[33m434[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/PKG-INFO[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m117 | [0m[35m[0m
[30;1m118 | [0m[35mYou can install such cross-provider dependencies when installing from PyPI. For example:[0m
[30;1m119 | [0m[35m[0m
[30;1m120 | [0m[35m.. code-block:: bash[0m
[30;1m121 | [0m[35m[0m
[30;1m122 | [0m[35m    pip install apache-airflow-providers-databricks[common.sql][0m
[30;1m123 | [0m[35m[0m
[30;1m124 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m435[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/PKG-INFO[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m96 | [0m[35mRequirements[0m
[30;1m97 | [0m[35m------------[0m
[30;1m98 | [0m[35m[0m
[30;1m99 | [0m[35m=======================================  ==================[0m
[30;1m100 | [0m[35mPIP package                              Version required[0m
[30;1m101 | [0m[35m=======================================  ==================[0m
[30;1m102 | [0m[35m``apache-airflow``                       ``>=2.9.0``[0m
[30;1m103 | [0m[35m``apache-airflow-providers-common-sql``  ``>=1.20.0``[0m

[31m--[ [0m[34mMatch #[0m[33m436[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/PKG-INFO[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m87 | [0m[35mInstallation[0m
[30;1m88 | [0m[35m------------[0m
[30;1m89 | [0m[35m[0m
[30;1m90 | [0m[35mYou can install this package on top of an existing Airflow 2 installation (see ``Requirements`` belo[0m
[30;1m91 | [0m[35mfor the minimum Airflow version supported) via[0m
[30;1m92 | [0m[35m``pip install apache-airflow-providers-databricks``[0m
[30;1m93 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m437[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/PKG-INFO[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m81 | [0m[35mThis is a provider package for ``databricks`` provider. All classes for this provider package[0m
[30;1m82 | [0m[35mare in ``airflow.providers.databricks`` python package.[0m
[30;1m83 | [0m[35m[0m
[30;1m84 | [0m[35mYou can find package information and changelog for the provider[0m
[30;1m85 | [0m[35min the `documentation <https://airflow.apache.org/docs/apache-airflow-providers-databricks/7.3.1/>`_[0m
[30;1m86 | [0m[35m[0m
[30;1m87 | [0m[35mInstallation[0m

[31m--[ [0m[34mMatch #[0m[33m438[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/copy_into.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m439[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_update.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m40 | [0m[35m   * - branch: str[0m
[30;1m41 | [0m[35m     - Name of the existing Git branch to update to (required if ``tag`` isn't provided).[0m
[30;1m42 | [0m[35m   * - tag: str[0m
[30;1m43 | [0m[35m     - Name of the existing Git tag to update to (required if ``branch`` isn't provided).[0m
[30;1m44 | [0m[35m   * - repo_path: str[0m
[30;1m45 | [0m[35m     - Path to existing Databricks Repos, like, ``/Repos/<user_email>/repo_name`` (required if ``rep[0m
[30;1m46 | [0m[35m   * - repo_id: str[0m

[31m--[ [0m[34mMatch #[0m[33m440[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_update.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m38 | [0m[35m   * - Parameter[0m
[30;1m39 | [0m[35m     - Input[0m
[30;1m40 | [0m[35m   * - branch: str[0m
[30;1m41 | [0m[35m     - Name of the existing Git branch to update to (required if ``tag`` isn't provided).[0m
[30;1m42 | [0m[35m   * - tag: str[0m
[30;1m43 | [0m[35m     - Name of the existing Git tag to update to (required if ``branch`` isn't provided).[0m
[30;1m44 | [0m[35m   * - repo_path: str[0m

[31m--[ [0m[34mMatch #[0m[33m441[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_update.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m28 | [0m[35mUsing the Operator[0m
[30;1m29 | [0m[35m^^^^^^^^^^^^^^^^^^[0m
[30;1m30 | [0m[35m[0m
[30;1m31 | [0m[35mUsually this operator is used to update a source code of the Databricks job before its execution.[0m
[30;1m32 | [0m[35mTo use this operator you need to provide either ``branch`` or ``tag`` and either ``repo_path`` or ``[0m
[30;1m33 | [0m[35m[0m
[30;1m34 | [0m[35m.. list-table::[0m

[31m--[ [0m[34mMatch #[0m[33m442[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_update.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m20 | [0m[35mDatabricksReposUpdateOperator[0m
[30;1m21 | [0m[35m=============================[0m
[30;1m22 | [0m[35m[0m
[30;1m23 | [0m[35mUse the :class:`~airflow.providers.databricks.operators.DatabricksReposUpdateOperator` to update cod[0m
[30;1m24 | [0m[35m`Databricks Repos <https://docs.databricks.com/repos/index.html>`_ to a given Git branch or tag[0m
[30;1m25 | [0m[35mvia `api/2.0/repos/ <https://docs.databricks.com/dev-tools/api/latest/repos.html#operation/update-re[0m
[30;1m26 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m443[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_update.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m444[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_update.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m40 | [0m[35m   * - branch: str[0m
[30;1m41 | [0m[35m     - Name of the existing Git branch to update to (required if ``tag`` isn't provided).[0m
[30;1m42 | [0m[35m   * - tag: str[0m
[30;1m43 | [0m[35m     - Name of the existing Git tag to update to (required if ``branch`` isn't provided).[0m
[30;1m44 | [0m[35m   * - repo_path: str[0m
[30;1m45 | [0m[35m     - Path to existing Databricks Repos, like, ``/Repos/<user_email>/repo_name`` (required if ``rep[0m
[30;1m46 | [0m[35m   * - repo_id: str[0m

[31m--[ [0m[34mMatch #[0m[33m445[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_update.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m38 | [0m[35m   * - Parameter[0m
[30;1m39 | [0m[35m     - Input[0m
[30;1m40 | [0m[35m   * - branch: str[0m
[30;1m41 | [0m[35m     - Name of the existing Git branch to update to (required if ``tag`` isn't provided).[0m
[30;1m42 | [0m[35m   * - tag: str[0m
[30;1m43 | [0m[35m     - Name of the existing Git tag to update to (required if ``branch`` isn't provided).[0m
[30;1m44 | [0m[35m   * - repo_path: str[0m

[31m--[ [0m[34mMatch #[0m[33m446[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/repos_update.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m21 | [0m[35m=============================[0m
[30;1m22 | [0m[35m[0m
[30;1m23 | [0m[35mUse the :class:`~airflow.providers.databricks.operators.DatabricksReposUpdateOperator` to update cod[0m
[30;1m24 | [0m[35m`Databricks Repos <https://docs.databricks.com/repos/index.html>`_ to a given Git branch or tag[0m
[30;1m25 | [0m[35mvia `api/2.0/repos/ <https://docs.databricks.com/dev-tools/api/latest/repos.html#operation/update-re[0m
[30;1m26 | [0m[35m[0m
[30;1m27 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m447[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/submit_run.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m32 | [0m[35m[0m
[30;1m33 | [0m[35mThere are three ways to instantiate this operator. In the first way, you can take the JSON payload t[0m
[30;1m34 | [0m[35mto call the ``api/2.1/jobs/runs/submit`` endpoint and pass it directly to our ``DatabricksSubmitRunO[0m
[30;1m35 | [0m[35m``json`` parameter.  With this approach you get full control over the underlying payload to Jobs RES[0m
[30;1m36 | [0m[35mexecution of Databricks jobs with multiple tasks, but it's harder to detect errors because of the la[0m
[30;1m37 | [0m[35m[0m
[30;1m38 | [0m[35m.. code-block:: python[0m

[31m--[ [0m[34mMatch #[0m[33m448[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/submit_run.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m449[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/submit_run.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m65 | [0m[35m[0m
[30;1m66 | [0m[35mIn the case where both the json parameter **AND** the named parameters[0m
[30;1m67 | [0m[35mare provided, they will be merged together. If there are conflicts during the merge,[0m
[30;1m68 | [0m[35mthe named parameters will take precedence and override the top level ``json`` keys.[0m
[30;1m69 | [0m[35m[0m
[30;1m70 | [0m[35mCurrently the named parameters that ``DatabricksSubmitRunOperator`` supports are[0m
[30;1m71 | [0m[35m    - ``spark_jar_task``[0m

[31m--[ [0m[34mMatch #[0m[33m450[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/submit_run.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m46 | [0m[35m  notebook_run = DatabricksSubmitRunOperator(task_id="notebook_run", json=json)[0m
[30;1m47 | [0m[35m[0m
[30;1m48 | [0m[35mThe second way to accomplish the same thing is to use the named parameters of the ``DatabricksSubmit[0m
[30;1m49 | [0m[35mone named parameter for each top level parameter in the ``runs/submit`` endpoint.  When using named [0m
[30;1m50 | [0m[35m[0m
[30;1m51 | [0m[35m* Task specification - it should be one of:[0m
[30;1m52 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m451[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/jobs_create.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m31 | [0m[35m------[0m
[30;1m32 | [0m[35m[0m
[30;1m33 | [0m[35mThere are three ways to instantiate this operator. In the first way, you can take the JSON payload t[0m
[30;1m34 | [0m[35mto call the ``api/2.1/jobs/create`` endpoint and pass it directly to our ``DatabricksCreateJobsOpera[0m
[30;1m35 | [0m[35m``json`` parameter.  With this approach you get full control over the underlying payload to Jobs RES[0m
[30;1m36 | [0m[35mexecution of Databricks jobs with multiple tasks, but it's harder to detect errors because of the la[0m
[30;1m37 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m452[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/jobs_create.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m22 | [0m[35m[0m
[30;1m23 | [0m[35mUse the :class:`~airflow.providers.databricks.operators.DatabricksCreateJobsOperator` to create[0m
[30;1m24 | [0m[35m(or reset) a Databricks job. This operator relies on past XComs to remember the ``job_id`` that[0m
[30;1m25 | [0m[35mwas created so that repeated calls with this operator will update the existing job rather than[0m
[30;1m26 | [0m[35mcreating new ones. When paired with the DatabricksRunNowOperator all runs will fall under the same[0m
[30;1m27 | [0m[35mjob within the Databricks UI.[0m
[30;1m28 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m453[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/jobs_create.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m454[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/jobs_create.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m40 | [0m[35m[0m
[30;1m41 | [0m[35mThe third way is to use both the json parameter **AND** the named parameters. They will be merged[0m
[30;1m42 | [0m[35mtogether. If there are conflicts during the merge, the named parameters will take precedence and[0m
[30;1m43 | [0m[35moverride the top level ``json`` keys.[0m
[30;1m44 | [0m[35m[0m
[30;1m45 | [0m[35mCurrently the named parameters that ``DatabricksCreateJobsOperator`` supports are:[0m
[30;1m46 | [0m[35m  - ``name``[0m

[31m--[ [0m[34mMatch #[0m[33m455[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/jobs_create.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m36 | [0m[35mexecution of Databricks jobs with multiple tasks, but it's harder to detect errors because of the la[0m
[30;1m37 | [0m[35m[0m
[30;1m38 | [0m[35mThe second way to accomplish the same thing is to use the named parameters of the ``DatabricksCreate[0m
[30;1m39 | [0m[35mone named parameter for each top level parameter in the ``api/2.1/jobs/create`` endpoint.[0m
[30;1m40 | [0m[35m[0m
[30;1m41 | [0m[35mThe third way is to use both the json parameter **AND** the named parameters. They will be merged[0m
[30;1m42 | [0m[35mtogether. If there are conflicts during the merge, the named parameters will take precedence and[0m

[31m--[ [0m[34mMatch #[0m[33m456[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/operators/test_databricks_workflow.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m457[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/sql.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m458[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/sql.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m128 | [0m[35my do is wait until something happens, and then succeed so their downstream tasks can run.[0m
[30;1m129 | [0m[35m[0m
[30;1m130 | [0m[35mFor the Databricks Partition Sensor, we check if a partition and its related value exists and if not[0m
[30;1m131 | [0m[35m[0m
[30;1m132 | [0m[35mUse the :class:`~airflow.providers.databricks.sensors.partition.DatabricksPartitionSensor` to run th[0m
[30;1m133 | [0m[35mfor a table accessible via a Databricks SQL warehouse or interactive cluster.[0m
[30;1m134 | [0m[35m[0m
[30;1m135 | [0m[35mUsing the Sensor[0m
[30;1m136 | [0m[35m----------------[0m
[30;1m137 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m459[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000610[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Linux[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/operators/sql.rst[0m
   Pattern: [32m\s(apt|apt\-get|aria2c|arp|ash|awk|base64|bash|bpftrace|busybox|cat|chmod|chown|cp|cpan|cpulimit|crontab|csh|curl|cut|dash|dd|diff|dmesg|dmsetup|dnf|docker|dpkg|easy_install|ed|emacs|env|expand|expect|facter|find|finger|flock|fmt|ftp|gawk|gdb|gimp|git|grep|head|iftop|ionice|ip|irb|jjs|journalctl|jrunscript|ksh|ld\.so|ldconfig|logsave|ltrace|lua|mail|mawk|mount|mtr|mv|mysql|nano|nawk|nc|nice|nl|nmap|node|od|openssl|perl|pg|php|pic|pico|pip|puppet|readelf|red|rlogin|rlwrap|rpm|rpmquery|rsync|ruby|run\-mailcap|run\-parts|rvim|scp|screen|script|sed|service|setarch|sftp|shuf|smbclient|socat|sort|sqlite3|ssh|start\-stop\-daemon|stdbuf|strace|systemctl|tail|tar|taskset|tclsh|tcpdump|tee|telnet|tftp|time|timeout|tmux|top|ul|unexpand|uniq|unshare|vi|vim|watch|wget|whois|wish|xargs|xxd|yum|zsh|zypper)\s[0m
[30;1m128 | [0m[35maiting for a file, or an external event, but all they do is wait until something happens, and then s[0m
[30;1m129 | [0m[35m[0m
[30;1m130 | [0m[35mFor the Databricks Partition Sensor, we check if a partition and its related value exists and if not[0m
[30;1m131 | [0m[35m[0m
[30;1m132 | [0m[35mUse the :class:`~airflow.providers.databricks.sensors.partition.DatabricksPartitionSensor` to run th[0m
[30;1m133 | [0m[35mfor a table accessible via a Databricks SQL warehouse or interactive cluster.[0m
[30;1m134 | [0m[35m[0m

[31m--[ [0m[34mMatch #[0m[33m460[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_sql.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m37 | [0m[35m    DatabricksSqlOperator,[0m
[30;1m38 | [0m[35m)[0m
[30;1m39 | [0m[35m[0m
[30;1m40 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m41 | [0m[35mDAG_ID = "example_databricks_sql_operator"[0m
[30;1m42 | [0m[35m[0m
[30;1m43 | [0m[35mwith DAG([0m

[31m--[ [0m[34mMatch #[0m[33m461[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_sql.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m462[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000700[0m
       Tag: [34mSecurity.Backdoor.DataExfiltration[0m
  Severity: [36mImportant[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_repos.py[0m
   Pattern: [32m\.(request|post|get)\([0m
[30;1m32 | [0m[35m    "databricks_conn_id": "databricks",[0m
[30;1m33 | [0m[35m}[0m
[30;1m34 | [0m[35m[0m
[30;1m35 | [0m[35mENV_ID = os.environ.get("SYSTEM_TESTS_ENV_ID")[0m
[30;1m36 | [0m[35mDAG_ID = "example_databricks_repos_operator"[0m
[30;1m37 | [0m[35m[0m
[30;1m38 | [0m[35mwith DAG([0m

[31m--[ [0m[34mMatch #[0m[33m463[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/system/databricks/example_databricks_repos.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m464[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/tests/unit/databricks/operators/test_databricks_repos.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m5 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m6 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m7 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m8 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m9 | [0m[35m#[0m
[30;1m10 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m11 | [0m[35m#[0m
[30;1m12 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m465[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/docs/installing-providers-from-sources.rst[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m    regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m    to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m    "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m    with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m[0m
[30;1m9 | [0m[35m ..   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m[0m
[30;1m11 | [0m[35m .. Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m466[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/src/airflow/providers/databricks/plugins/__init__.py[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

[31m--[ [0m[34mMatch #[0m[33m467[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/provider.yaml[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m23 | [0m[35m[0m
[30;1m24 | [0m[35mstate: ready[0m
[30;1m25 | [0m[35msource-date-epoch: 1744281606[0m
[30;1m26 | [0m[35m# note that those versions are maintained by release manager - do not update them manually[0m
[30;1m27 | [0m[35mversions:[0m
[30;1m28 | [0m[35m  - 7.3.1[0m
[30;1m29 | [0m[35m  - 7.3.0[0m

[31m--[ [0m[34mMatch #[0m[33m468[0m[34m of [0m[33m468[0m[31m ]--[0m
   Rule Id: [34mBD000600[0m
       Tag: [34mSecurity.Backdoor.LOLBAS.Windows[0m
  Severity: [36mModerate[0m, Confidence: [36mLow[0m
  Filename: [33m/apache_airflow_providers_databricks-7.3.1rc1/provider.yaml[0m
   Pattern: [32m\s(advpack\.dll|appvlp|at|atbroker|bash|bginfo|bitsadmin|cdb|certutil|cl_invocation\.ps1|cl_mutexverifiers\.ps1|cmd|cmdkey|cmstp|comsvcs\.dll|control|csc|cscript|csi|devtoolslauncher|dfsvc|diskshadow|dnscmd|dnx|dotnet|dxcap|esentutl|eventvwr|excel|expand|extexport|extrac32|findstr|forfiles|ftp|gfxdownloadwrapper|gpscript|hh|ie4uinit|ieadvpack\.dll|ieaframe\.dll|ic|infdefaultinstall|installutil|jsc|makecab|manage-bde\.wsf|mavinject|mftrace|microsoft\.workflow\.compiler|mmc|msbuild|msconfig|msdeploy|msdt|mshta|mshtml\.dll|msc|msxsl|netsh|odbcconf|pcalua|pcwrun|pcwutl\.dll|pester\.bat|powerpnt|presentationhost|pubprn\.vbs|rcsi|reg|regasm|regedit|register-cimprovider|regsvcs|regsvr32|rpcping|rundll32|runonce|runscripthelper|sc|schtasks|scriptrunner|setupapi\.dll|shdocvw\.dll|shell32\.dll|slmgr\.vbs|sqldumper|sqlps|sqltoolsps|squirrel|syncappvpublishingserver|syncappvpublishingserver\.vbs|syssetup\.dll|te|tracker|tttracer|update|url\.dll|verclsid|vsjitdebugger|wab|winrm\.vbs|winword|wmic|wscript|wsl|wsreset|xwizard|zipfldr\.dll)\s[0m
[30;1m4 | [0m[35m# regarding copyright ownership.  The ASF licenses this file[0m
[30;1m5 | [0m[35m# to you under the Apache License, Version 2.0 (the[0m
[30;1m6 | [0m[35m# "License"); you may not use this file except in compliance[0m
[30;1m7 | [0m[35m# with the License.  You may obtain a copy of the License at[0m
[30;1m8 | [0m[35m#[0m
[30;1m9 | [0m[35m#   http://www.apache.org/licenses/LICENSE-2.0[0m
[30;1m10 | [0m[35m#[0m
[30;1m11 | [0m[35m# Unless required by applicable law or agreed to in writing,[0m

468 matches found.
