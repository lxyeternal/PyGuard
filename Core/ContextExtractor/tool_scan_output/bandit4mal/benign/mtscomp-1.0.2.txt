Run started:2025-04-12 10:46:43.405243

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
60	CRITICAL_ERROR_URL = \
61	    "https://github.com/int-brain-lab/mtscomp/issues/new?title=Critical+error"
62	
63	
64	#------------------------------------------------------------------------------
65	# Misc utils
66	#------------------------------------------------------------------------------
67	
68	# Set a null handler on the root logger
69	logger = logging.getLogger('mtscomp')
70	logger.setLevel(logging.INFO)

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:456
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
455	        # Create the thread pool.
456	        self.pool = ThreadPool(self.batch_size)
457	        logger.debug('\n'.join('%s = %s' % (k, v) for (k, v) in self.config.items()))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:476
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
475	                    uncompressed_chunk, compressed_chunk = compressed_chunks[chunk_idx]
476	                    fb.write(compressed_chunk)
477	                    # Append the chunk offsets.

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:609
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
608	            # this call is thread-safe.
609	            cbuffer = os.pread(self.cdata.fileno(), chunk_length, chunk_start)
610	        else:  # pragma: no cover

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:615
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
614	                self.cdata.seek(chunk_start)
615	                cbuffer = self.cdata.read(chunk_length)
616	        assert len(cbuffer) == chunk_length

--------------------------------------------------
>> Issue: [B816:decompress] zlib.decompress
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:619
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b816_decompress.html
618	        try:
619	            buffer = zlib.decompress(cbuffer)
620	        except Exception:  # pragma: no cover

--------------------------------------------------
>> Issue: [B306:blacklist] zlib.decompress
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:619
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b306-zlib-decompress
618	        try:
619	            buffer = zlib.decompress(cbuffer)
620	        except Exception:  # pragma: no cover

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:691
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
690	        logging.debug("Starting thread pool with %d CPUs.", self.batch_size)
691	        self.pool = ThreadPool(self.batch_size)
692	        return self.pool

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:734
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
733	                    decompressed_chunk = decompressed_chunks[chunk_idx]
734	                    fb.write(decompressed_chunk)
735	            dsize = fb.tell()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:774
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
773	                    self.cdata.seek(offset)
774	                    cbuffer = self.cdata.read(chunk_length)
775	                assert len(cbuffer) == chunk_length

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:776
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
775	                assert len(cbuffer) == chunk_length
776	                f.write(cbuffer)
777	                offset += chunk_length

--------------------------------------------------
>> Issue: [B816:decompress] zlib.decompress
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:868
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b816_decompress.html
867	    """Check that the compressed data matches the original array byte per byte."""
868	    unc = decompress(out, outmeta)
869	    try:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:956
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
955	    w.open(path, sample_rate=sample_rate, n_channels=n_channels, dtype=dtype)
956	    length = w.write(out, outmeta)
957	    w.close()

--------------------------------------------------
>> Issue: [B816:decompress] zlib.decompress
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/mtscomp.py:1118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b816_decompress.html
1117	    add_default_handler('DEBUG' if pargs.debug else 'INFO')
1118	    decompress(
1119	        pargs.cdata, pargs.cmeta, out=pargs.out,
1120	        # check_after_decompress=config.check_after_compress,
1121	        write_output=True,
1122	        overwrite=pargs.overwrite,
1123	        **config
1124	    )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/setup.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
22	with open(op.join(curdir, 'README.md')) as f:
23	    readme = f.read()
24	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/setup.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
28	with open(filename, 'r') as f:
29	    version = re.search(r"__version__ = '([^']+)'", f.read()).group(1)
30	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mtscomp-1.0.2/mtscomp-1.0.2/setup.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	    author_email='cyrille.rossant@gmail.com',
41	    url='https://github.com/int-brain-lab/mtscomp',
42	    py_modules=['mtscomp'],

--------------------------------------------------

Code scanned:
	Total lines of code: 922
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 3.0
		High: 14.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 16.0
		High: 1.0
Files skipped (0):
