Run started:2025-04-12 18:07:15.484490

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/examples/crawl.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
48	    greedy_crawler = GreedyImageCrawler(parser_threads=4, storage={"root_dir": "images/greedy"})
49	    greedy_crawler.crawl("http://www.bbc.com/news", max_num=10, min_size=(100, 100))
50	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/builtin/baidu.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
69	    def feed(self, keyword, offset, max_num, filters=None):
70	        base_url = "http://image.baidu.com/search/acjson?tn=resultjson_com" "&ipn=rj&word={}&pn={}&rn=30"
71	        self.filter = self.get_filter()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/builtin/bing.py:106
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
105	    def feed(self, keyword, offset, max_num, filters=None):
106	        base_url = "https://www.bing.com/images/async?q={}&first={}"
107	        self.filter = self.get_filter()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/builtin/flickr.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
14	            self.logger.warning("max_num exceeds 4000, set it to 4000 automatically.")
15	        base_url = "https://api.flickr.com/services/rest/?"
16	        params = {"method": "flickr.photos.search", "api_key": apikey, "format": "json", "nojsoncallback": 1}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/builtin/flickr.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
88	            photo_id = photo["id"]
89	            base_url = "https://api.flickr.com/services/rest/?"
90	            params = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/builtin/google.py:132
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
131	    def feed(self, keyword, offset, max_num, language=None, filters=None):
132	        base_url = "https://www.google.com/search?"
133	        self.filter = self.get_filter()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/feeder.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
40	        self.feed(**kwargs)
41	        self.logger.info(f"thread {current_thread().name} exit")
42	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/storage/filesystem.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
27	        with open(filepath, mode) as fout:
28	            fout.write(data)
29	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:80
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
79	        self.idx = {"http": 0, "https": 0}
80	        self.test_url = {"http": "http://www.sina.com.cn", "https": "https://www.taobao.com"}
81	        self.proxies = {"http": {}, "https": {}}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:80
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
79	        self.idx = {"http": 0, "https": 0}
80	        self.test_url = {"http": "http://www.sina.com.cn", "https": "https://www.taobao.com"}
81	        self.proxies = {"http": {}, "https": {}}

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:213
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
212	        try:
213	            r = requests.get(self.test_url[protocol], timeout=timeout, proxies={protocol: "http://" + addr})
214	        except KeyboardInterrupt:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:238
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
237	            try:
238	                candidate_proxy = proxy_scanner.proxy_queue.get(timeout=queue_timeout)
239	            except queue.Empty:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:392
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
391	        """
392	        self.logger.info("start scanning http://ip84.com for proxy list...")
393	        for i in range(1, page + 1):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:395
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
394	            if region == "mainland":
395	                url = f"http://ip84.com/dlgn/{i}"
396	            elif region == "overseas":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:397
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
396	            elif region == "overseas":
397	                url = f"http://ip84.com/gwgn/{i}"
398	            else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:399
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
398	            else:
399	                url = f"http://ip84.com/gn/{i}"
400	            response = requests.get(url)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:400
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
399	                url = f"http://ip84.com/gn/{i}"
400	            response = requests.get(url)
401	            soup = BeautifulSoup(response.content, "lxml")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:418
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
417	        """
418	        self.logger.info("start scanning http://mimiip.com for proxy list...")
419	        for i in range(1, page + 1):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:421
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
420	            if region == "mainland":
421	                url = f"http://www.mimiip.com/gngao/{i}"
422	            elif region == "overseas":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:423
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
422	            elif region == "overseas":
423	                url = f"http://www.mimiip.com/hw/{i}"
424	            else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:425
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
424	            else:
425	                url = f"http://www.mimiip.com/gngao/{i}"
426	            response = requests.get(url)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:426
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
425	                url = f"http://www.mimiip.com/gngao/{i}"
426	            response = requests.get(url)
427	            soup = BeautifulSoup(response.content, "lxml")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:439
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
438	        """Scan candidate (mainland) proxies from http://cn-proxy.com"""
439	        self.logger.info("start scanning http://cn-proxy.com for proxy list...")
440	        response = requests.get("http://cn-proxy.com")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:440
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
439	        self.logger.info("start scanning http://cn-proxy.com for proxy list...")
440	        response = requests.get("http://cn-proxy.com")
441	        soup = BeautifulSoup(response.content, "lxml")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:440
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
439	        self.logger.info("start scanning http://cn-proxy.com for proxy list...")
440	        response = requests.get("http://cn-proxy.com")
441	        soup = BeautifulSoup(response.content, "lxml")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:451
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
450	        """Scan candidate (overseas) proxies from http://free-proxy-list.net"""
451	        self.logger.info("start scanning http://free-proxy-list.net " "for proxy list...")
452	        response = requests.get("http://free-proxy-list.net")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:452
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
451	        self.logger.info("start scanning http://free-proxy-list.net " "for proxy list...")
452	        response = requests.get("http://free-proxy-list.net")
453	        soup = BeautifulSoup(response.content, "lxml")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/proxy_pool.py:452
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
451	        self.logger.info("start scanning http://free-proxy-list.net " "for proxy list...")
452	        response = requests.get("http://free-proxy-list.net")
453	        soup = BeautifulSoup(response.content, "lxml")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/session.py:17
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
16	        if proxy is None:
17	            return super().get(url, **kwargs)
18	        try:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/session.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
18	        try:
19	            response = super().get(url, proxies=proxy.format(), **kwargs)
20	        except requests.exceptions.ConnectionError:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/session.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
31	        if proxy is None:
32	            return super().get(url, data, json, **kwargs)
33	        try:

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/icrawler/utils/session.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
33	        try:
34	            response = super().post(url, data, json, proxies=proxy.format(), **kwargs)
35	        except requests.exceptions.ConnectionError:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/icrawler-0.6.10/icrawler-0.6.10/tests/test_todo.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	    greedy_crawler = GreedyImageCrawler(parser_threads=2, storage={"root_dir": img_dir})
37	    greedy_crawler.crawl("http://www.bbc.com/news", max_num=5, min_size=(100, 100))
38	

--------------------------------------------------

Code scanned:
	Total lines of code: 2258
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 21.0
		High: 12.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 33.0
		High: 0.0
Files skipped (0):
