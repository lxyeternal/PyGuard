Run started:2025-04-12 13:33:38.983537

Test results:
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/setup.py:130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
129	    description="HuggingFace community-driven open-source library of evaluation",
130	    long_description=open("README.md", encoding="utf-8").read(),
131	    long_description_content_type="text/markdown",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/setup.py:134
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
133	    author_email="leandro@huggingface.co",
134	    url="https://github.com/huggingface/evaluate",
135	    download_url="https://github.com/huggingface/evaluate/tags",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/setup.py:135
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
134	    url="https://github.com/huggingface/evaluate",
135	    download_url="https://github.com/huggingface/evaluate/tags",
136	    license="Apache 2.0",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/commands/evaluate_cli.py:88
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
87	    args["namespace"] = namespace
88	    repo_url = f"https://huggingface.co/spaces/{namespace}/{module_slug}"
89	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/commands/evaluate_cli.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
111	    cookiecutter(
112	        "https://github.com/huggingface/evaluate/",
113	        directory="templates",
114	        no_input=True,
115	        extra_context=args,
116	        output_dir=output_dir,
117	        overwrite_if_exists=True,
118	    )
119	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/config.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
14	# Metrics
15	S3_METRICS_BUCKET_PREFIX = "https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics"
16	CLOUDFRONT_METRICS_DISTRIB_PREFIX = "https://cdn-datasets.huggingface.co/datasets/metric"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/config.py:16
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
15	S3_METRICS_BUCKET_PREFIX = "https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics"
16	CLOUDFRONT_METRICS_DISTRIB_PREFIX = "https://cdn-datasets.huggingface.co/datasets/metric"
17	REPO_METRICS_URL = "https://raw.githubusercontent.com/huggingface/evaluate/{revision}/metrics/{path}/{name}"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/config.py:17
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
16	CLOUDFRONT_METRICS_DISTRIB_PREFIX = "https://cdn-datasets.huggingface.co/datasets/metric"
17	REPO_METRICS_URL = "https://raw.githubusercontent.com/huggingface/evaluate/{revision}/metrics/{path}/{name}"
18	REPO_MEASUREMENTS_URL = "https://raw.githubusercontent.com/huggingface/evaluate/{revision}/measurements/{path}/{name}"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/config.py:18
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
17	REPO_METRICS_URL = "https://raw.githubusercontent.com/huggingface/evaluate/{revision}/metrics/{path}/{name}"
18	REPO_MEASUREMENTS_URL = "https://raw.githubusercontent.com/huggingface/evaluate/{revision}/measurements/{path}/{name}"
19	REPO_COMPARISONS_URL = "https://raw.githubusercontent.com/huggingface/evaluate/{revision}/comparisons/{path}/{name}"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/config.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
18	REPO_MEASUREMENTS_URL = "https://raw.githubusercontent.com/huggingface/evaluate/{revision}/measurements/{path}/{name}"
19	REPO_COMPARISONS_URL = "https://raw.githubusercontent.com/huggingface/evaluate/{revision}/comparisons/{path}/{name}"
20	
21	# Evaluation module types
22	EVALUATION_MODULE_TYPES = ["metric", "comparison", "measurement"]

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/config.py:25
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
24	# Hub
25	HF_ENDPOINT = os.environ.get("HF_ENDPOINT", "https://huggingface.co")
26	HF_LIST_ENDPOINT = HF_ENDPOINT + "/api/spaces?filter={type}"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/evaluator/audio_classification.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
29	
30	TASK_DOCUMENTATION = r"""
31	    Examples:
32	
33	    <Tip>
34	
35	    Remember that, in order to process audio files, you need ffmpeg installed (https://ffmpeg.org/download.html)
36	
37	    </Tip>
38	
39	    ```python
40	    >>> from evaluate import evaluator
41	    >>> from datasets import load_dataset
42	
43	    >>> task_evaluator = evaluator("audio-classification")
44	    >>> data = load_dataset("superb", 'ks', split="test[:40]")
45	    >>> results = task_evaluator.compute(
46	    >>>     model_or_pipeline=""superb/wav2vec2-base-superb-ks"",
47	    >>>     data=data,
48	    >>>     label_column="label",
49	    >>>     input_column="file",
50	    >>>     metric="accuracy",
51	    >>>     label_mapping={0: "yes", 1: "no", 2: "up", 3: "down"}
52	    >>> )
53	    ```
54	
55	    <Tip>
56	
57	    The evaluator supports raw audio data as well, in the form of a numpy array. However, be aware that calling
58	    the audio column automatically decodes and resamples the audio files, which can be slow for large datasets.
59	
60	    </Tip>
61	
62	    ```python
63	    >>> from evaluate import evaluator
64	    >>> from datasets import load_dataset
65	
66	    >>> task_evaluator = evaluator("audio-classification")
67	    >>> data = load_dataset("superb", 'ks', split="test[:40]")
68	    >>> data = data.map(lambda example: {"audio": example["audio"]["array"]})
69	    >>> results = task_evaluator.compute(
70	    >>>     model_or_pipeline=""superb/wav2vec2-base-superb-ks"",
71	    >>>     data=data,
72	    >>>     label_column="label",
73	    >>>     input_column="audio",
74	    >>>     metric="accuracy",
75	    >>>     label_mapping={0: "yes", 1: "no", 2: "up", 3: "down"}
76	    >>> )
77	    ```
78	"""
79	
80	
81	class AudioClassificationEvaluator(Evaluator):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/evaluator/automatic_speech_recognition.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	
29	TASK_DOCUMENTATION = r"""
30	    Examples:
31	    ```python
32	    >>> from evaluate import evaluator
33	    >>> from datasets import load_dataset
34	    >>> task_evaluator = evaluator("automatic-speech-recognition")
35	    >>> data = load_dataset("mozilla-foundation/common_voice_11_0", "en", split="validation[:40]")
36	    >>> results = task_evaluator.compute(
37	    >>>     model_or_pipeline="https://huggingface.co/openai/whisper-tiny.en",
38	    >>>     data=data,
39	    >>>     input_column="path",
40	    >>>     label_column="sentence",
41	    >>>     metric="wer",
42	    >>> )
43	    ```
44	"""
45	
46	
47	class AutomaticSpeechRecognitionEvaluator(Evaluator):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/evaluator/base.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
52	
53	EVALUTOR_COMPUTE_START_DOCSTRING = r"""
54	    Compute the metric for a given pipeline and dataset combination.
55	    Args:
56	        model_or_pipeline (`str` or `Pipeline` or `Callable` or `PreTrainedModel` or `TFPreTrainedModel`, defaults to `None`):
57	            If the argument in not specified, we initialize the default pipeline for the task (in this case
58	            `text-classification` or its alias - `sentiment-analysis`). If the argument is of the type `str` or
59	            is a model instance, we use it to initialize a new `Pipeline` with the given model. Otherwise we assume the
60	            argument specifies a pre-initialized pipeline.
61	        data (`str` or `Dataset`, defaults to `None`):
62	            Specifies the dataset we will run evaluation on. If it is of type `str`, we treat it as the dataset
63	            name, and load it. Otherwise we assume it represents a pre-loaded dataset.
64	        subset (`str`, defaults to `None`):
65	            Defines which dataset subset to load. If `None` is passed the default subset is loaded.
66	        split (`str`, defaults to `None`):
67	            Defines which dataset split to load. If `None` is passed, infers based on the `choose_split` function.
68	        metric (`str` or `EvaluationModule`, defaults to `None`):
69	            Specifies the metric we use in evaluator. If it is of type `str`, we treat it as the metric name, and
70	            load it. Otherwise we assume it represents a pre-loaded metric.
71	        tokenizer (`str` or `PreTrainedTokenizer`, *optional*, defaults to `None`):
72	            Argument can be used to overwrite a default tokenizer if `model_or_pipeline` represents a model for
73	            which we build a pipeline. If `model_or_pipeline` is `None` or a pre-initialized pipeline, we ignore
74	            this argument.
75	        strategy (`Literal["simple", "bootstrap"]`, defaults to "simple"):
76	            specifies the evaluation strategy. Possible values are:
77	            - `"simple"` - we evaluate the metric and return the scores.
78	            - `"bootstrap"` - on top of computing the metric scores, we calculate the confidence interval for each
79	            of the returned metric keys, using `scipy`'s `bootstrap` method
80	            https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html.
81	        confidence_level (`float`, defaults to `0.95`):
82	            The `confidence_level` value passed to `bootstrap` if `"bootstrap"` strategy is chosen.
83	        n_resamples (`int`, defaults to `9999`):
84	            The `n_resamples` value passed to `bootstrap` if `"bootstrap"` strategy is chosen.
85	        device (`int`, defaults to `None`):
86	            Device ordinal for CPU/GPU support of the pipeline. Setting this to -1 will leverage CPU, a positive
87	            integer will run the model on the associated CUDA device ID. If `None` is provided it will be inferred and
88	            CUDA:0 used if available, CPU otherwise.
89	        random_state (`int`, *optional*, defaults to `None`):
90	            The `random_state` value passed to `bootstrap` if `"bootstrap"` strategy is chosen. Useful for
91	            debugging.
92	"""
93	
94	EVALUATOR_COMPUTE_RETURN_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/evaluator/token_classification.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
29	
30	TASK_DOCUMENTATION = r"""
31	    The dataset input and label columns are expected to be formatted as a list of words and a list of labels respectively, following [conll2003 dataset](https://huggingface.co/datasets/conll2003). Datasets whose inputs are single strings, and labels are a list of offset are not supported.
32	
33	    Examples:
34	    ```python
35	    >>> from evaluate import evaluator
36	    >>> from datasets import load_dataset
37	    >>> task_evaluator = evaluator("token-classification")
38	    >>> data = load_dataset("conll2003", split="validation[:2]")
39	    >>> results = task_evaluator.compute(
40	    >>>     model_or_pipeline="elastic/distilbert-base-uncased-finetuned-conll03-english",
41	    >>>     data=data,
42	    >>>     metric="seqeval",
43	    >>> )
44	    ```
45	
46	    <Tip>
47	
48	    For example, the following dataset format is accepted by the evaluator:
49	
50	    ```python
51	    dataset = Dataset.from_dict(
52	        mapping={
53	            "tokens": [["New", "York", "is", "a", "city", "and", "Felix", "a", "person", "."]],
54	            "ner_tags": [[1, 2, 0, 0, 0, 0, 3, 0, 0, 0]],
55	        },
56	        features=Features({
57	            "tokens": Sequence(feature=Value(dtype="string")),
58	            "ner_tags": Sequence(feature=ClassLabel(names=["O", "B-LOC", "I-LOC", "B-PER", "I-PER"])),
59	            }),
60	    )
61	    ```
62	
63	    </Tip>
64	
65	    <Tip warning={true}>
66	
67	    For example, the following dataset format is **not** accepted by the evaluator:
68	
69	    ```python
70	    dataset = Dataset.from_dict(
71	        mapping={
72	            "tokens": [["New York is a city and Felix a person."]],
73	            "starts": [[0, 23]],
74	            "ends": [[7, 27]],
75	            "ner_tags": [["LOC", "PER"]],
76	        },
77	        features=Features({
78	            "tokens": Value(dtype="string"),
79	            "starts": Sequence(feature=Value(dtype="int32")),
80	            "ends": Sequence(feature=Value(dtype="int32")),
81	            "ner_tags": Sequence(feature=Value(dtype="string")),
82	        }),
83	    )
84	    ```
85	
86	    </Tip>
87	"""
88	
89	
90	class TokenClassificationEvaluator(Evaluator):

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/info.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
89	        with open(os.path.join(metric_info_dir, config.LICENSE_FILENAME), "w", encoding="utf-8") as f:
90	            f.write(self.license)
91	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/inspect.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
75	
76	    r = requests.get(HF_LIST_ENDPOINT.format(type=module_type))
77	    r.raise_for_status()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/inspect.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
96	                "community": element["community"],
97	                "likes": element.get("likes", 0),
98	            }

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/loading.py:125
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
124	            repo_owner, repo_name = repo_info.split("/")
125	            url_path = f"https://github.com/{repo_owner}/{repo_name}/archive/{branch}.zip"
126	            sub_directory = f"{repo_name}-{branch}"

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/loading.py:308
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
307	        if download_mode == DownloadMode.FORCE_REDOWNLOAD and os.path.exists(importable_directory_path):
308	            shutil.rmtree(importable_directory_path)
309	        os.makedirs(importable_directory_path, exist_ok=True)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/module.py:578
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
577	            example = self.selected_feature_format.encode_example(example)
578	            self.writer.write(example)
579	        except (pa.ArrowInvalid, TypeError):

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:307
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
306	        try:
307	            response = requests.request(method=method.upper(), url=url, timeout=timeout, **params)
308	            success = True

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:322
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
321	    try:
322	        with closing(urllib.request.urlopen(url, timeout=timeout)) as r:
323	            r.read(1)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:323
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
322	        with closing(urllib.request.urlopen(url, timeout=timeout)) as r:
323	            r.read(1)
324	    except Exception:

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:333
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
332	        logger.info(f"Getting through FTP {url} into {temp_file.name}")
333	        with closing(urllib.request.urlopen(url, timeout=timeout)) as r:
334	            shutil.copyfileobj(r, temp_file)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:343
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
342	    headers = copy.deepcopy(headers) or {}
343	    headers["user-agent"] = get_datasets_user_agent(user_agent=headers.get("user-agent"))
344	    if resume_size > 0:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:358
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
357	        return
358	    content_length = response.headers.get("Content-Length")
359	    total = resume_size + int(content_length) if content_length is not None else None

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:370
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
369	            progress.update(len(chunk))
370	            temp_file.write(chunk)
371	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:370
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
369	            progress.update(len(chunk))
370	            temp_file.write(chunk)
371	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:377
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
376	    headers = copy.deepcopy(headers) or {}
377	    headers["user-agent"] = get_datasets_user_agent(user_agent=headers.get("user-agent"))
378	    response = _request_with_retry(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:395
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
394	    response.raise_for_status()
395	    etag = response.headers.get("ETag") if response.ok else None
396	    return etag

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:466
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
465	            if response.status_code == 200:  # ok
466	                etag = response.headers.get("ETag") if use_etag else None
467	                for k, v in response.cookies.items():

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:484
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
483	                        re.match(r"^https?://github.com/.*?/.*?/releases/download/.*?/.*?$", url)
484	                        or re.match(r"^https://.*?s3.*?amazonaws.com/.*?$", response.url)
485	                    )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:556
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
555	            if url.startswith("ftp://"):
556	                ftp_get(url, temp_file)
557	            else:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:558
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
557	            else:
558	                http_get(
559	                    url,
560	                    temp_file,
561	                    proxies=proxies,
562	                    resume_size=resume_size,
563	                    headers=headers,
564	                    cookies=cookies,
565	                    max_retries=max_retries,
566	                    desc=download_desc,
567	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/file_utils.py:605
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
604	    while True:
605	        b = f.read(1)
606	        if not b:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/evaluate-0.4.3/evaluate-0.4.3/src/evaluate/utils/gradio.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
48	    with open(filepath, "r") as f:
49	        text = f.read()
50	        match = REGEX_YAML_BLOCK.search(text)

--------------------------------------------------

Code scanned:
	Total lines of code: 5003
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 16.0
		High: 21.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 37.0
		High: 0.0
Files skipped (0):
