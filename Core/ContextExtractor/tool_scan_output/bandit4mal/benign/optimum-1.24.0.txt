Run started:2025-04-12 19:50:23.033252

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/bettertransformer/models/attention.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	        raise ValueError(
29	            "layer_head_mask (or head_mask) different than None is unsupported for now with BetterTransformer, please"
30	            "open a PR or an issue at https://github.com/huggingface/optimum."
31	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/bettertransformer/transformation.py:173
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
172	    raise Exception(
173	        f"The transformation of the model {model.__class__.__name__} to BetterTransformer failed while it should not. Please fill"
174	        " a bug report or open a PR to support this model at https://github.com/huggingface/optimum/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/bettertransformer/transformation.py:222
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
221	            raise ValueError(
222	                f"Transformers now supports natively BetterTransformer optimizations (torch.nn.functional.scaled_dot_product_attention) for the model type {hf_config.model_type}. "
223	                "As such, there is no need to use `model.to_bettertransformers()` or `BetterTransformer.transform(model)` from the Optimum library. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/bettertransformer/transformation.py:230
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
229	            raise ValueError(
230	                "This model already uses BetterTransformer optimizations from Transformers (torch.nn.functional.scaled_dot_product_attention). "
231	                "As such, there is no need to use `model.to_bettertransformers()` or `BetterTransformer.transform(model)` from the Optimum library. "
232	                "Details: https://huggingface.co/docs/transformers/perf_infer_gpu_one#pytorch-scaled-dot-product-attention."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/bettertransformer/transformation.py:248
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
247	            raise NotImplementedError(
248	                f"The model type {model.config.model_type} is not yet supported to be used with BetterTransformer. Feel free"
249	                f" to open an issue at https://github.com/huggingface/optimum/issues if you would like this model type to be supported."
250	                f" Currently supported models are: {BetterTransformerManager.MODEL_MAPPING.keys()}."
251	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/bettertransformer/transformation.py:319
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
318	        logger.warning(
319	            "The BetterTransformer implementation"
320	            " does not support padding during training, as the fused kernels do not support"
321	            " attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/bettertransformer/transformation.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
189	        "1.13.99",
190	        "Please upgrade PyTorch following https://pytorch.org/get-started/locally/ in order to use BetterTransformer.",
191	    )
192	    def transform(
193	        model: torch.nn.Module,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/configuration_utils.py:307
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
306	                raise EnvironmentError(
307	                    f"Can't load the configuration of '{pretrained_model_name_or_path}'. If you were trying to load it"
308	                    " from 'https://huggingface.co/models', make sure you don't have a local directory with the same"
309	                    f" name. Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory"
310	                    f" containing a {configuration_file} file"
311	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/__main__.py:297
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
296	            raise ValueError(
297	                f"Asked to export a {model_type} model for the task {task}{autodetected_message}, but the Optimum ONNX exporter only supports the tasks {', '.join(model_tasks.keys())} for {model_type}. Please use a supported task. Please open an issue at https://github.com/huggingface/optimum/issues if you would like the task {task} to be supported in the ONNX export for {model_type}."
298	            )

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/convert.py:206
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
205	
206	        io_process = ValidationProcess(
207	            config, reference_model, onnx_model, onnx_named_outputs, atol, input_shapes, device, model_kwargs
208	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/convert.py:413
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
412	        if isinstance(config, SpeechT5OnnxConfig):
413	            atol_msg += "\nIMPORTANT NOTE: SpeechT5 uses a dropout at inference and the output validation of ONNX Runtime inference vs PyTorch is expected to fail. Reference: https://github.com/huggingface/transformers/blob/v4.33.2/src/transformers/models/speecht5/modeling_speecht5.py#L727"
414	        raise AtolError(atol_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/convert.py:1034
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1033	        raise ValueError(
1034	            f"Trying to export a {model_type} model, that is a custom or unsupported architecture, but no custom onnx configuration was passed as `custom_onnx_configs`. Please refer to https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#custom-export-of-transformers-models for an example on how to export custom models. Please open an issue at https://github.com/huggingface/optimum/issues if you would like the model type {model_type} to be supported natively in the ONNX export."
1035	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/convert.py:1039
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1038	        raise ValueError(
1039	            f"model.config.is_encoder_decoder is True and task is `{task}`, which are incompatible. If the task was auto-inferred, please fill a bug report"
1040	            f"at https://github.com/huggingface/optimum, if --task was explicitely passed, make sure you selected the right task for the model,"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/convert.py:1046
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1045	        logger.warning(
1046	            f"legacy=True was specified in the ONNX export, although the model {model_type} requires position_ids for batched inference. Passing `legacy=True` is strongly discouraged, and this option will be removed in a future release. Reference: https://github.com/huggingface/optimum/pull/1381"
1047	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:1835
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1834	    VARIANTS = {
1835	        "text-conditional-with-past": "Exports Musicgen to ONNX to generate audio samples conditioned on a text prompt (Reference: https://huggingface.co/docs/transformers/model_doc/musicgen#text-conditional-generation). This uses the decoder KV cache. The following subcomponents are exported:\n\t\t* text_encoder.onnx: corresponds to the text encoder part in https://github.com/huggingface/transformers/blob/v4.39.1/src/transformers/models/musicgen/modeling_musicgen.py#L1457.\n\t\t* encodec_decode.onnx: corresponds to the Encodec audio encoder part in https://github.com/huggingface/transformers/blob/v4.39.1/src/transformers/models/musicgen/modeling_musicgen.py#L2472-L2480.\n\t\t* decoder_model.onnx: The Musicgen decoder, without past key values input, and computing cross attention. Not required at inference (use decoder_model_merged.onnx instead).\n\t\t* decoder_with_past_model.onnx: The Musicgen decoder, with past_key_values input (KV cache filled), not computing cross attention. Not required at inference (use decoder_model_merged.onnx instead).\n\t\t* decoder_model_merged.onnx: The two previous models fused in one, to avoid duplicating weights. A boolean input `use_cache_branch` allows to select the branch to use. In the first forward pass where the KV cache is empty, dummy past key values inputs need to be passed and are ignored with use_cache_branch=False.\n\t\t* build_delay_pattern_mask.onnx: A model taking as input `input_ids`, `pad_token_id`, `max_length`, and building a delayed pattern mask to the input_ids. Implements https://github.com/huggingface/transformers/blob/v4.39.3/src/transformers/models/musicgen/modeling_musicgen.py#L1054.",
1836	    }
1837	    # TODO: support audio-prompted generation (- audio_encoder_encode.onnx: corresponds to the audio encoder part in https://github.com/huggingface/transformers/blob/f01e1609bf4dba146d1347c1368c8c49df8636f6/src/transformers/models/musicgen/modeling_musicgen.py#L2087.\n\t)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:1885
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1884	            raise ValueError(
1885	                f"model_part is {model_part} and behavior is {behavior}. This is not supported, please open an issue at https://github.com/huggingface/optimum/issues."
1886	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:1890
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1889	            raise ValueError(
1890	                f"model_part is {model_part} and behavior is {behavior}. This is not supported, please open an issue at https://github.com/huggingface/optimum/issues."
1891	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:1895
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1894	            raise ValueError(
1895	                "Musicgen does not support behavior=ConfigBehavior.MONOLITH. Please open an issue at https://github.com/huggingface/optimum/issues."
1896	            )
1897	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:1900
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1899	            raise ValueError(
1900	                f"Optimum ONNX export for Musicgen supports only Encodec as the audio encoder, got: {config.audio_encoder.model_type}. Please open an issue at https://github.com/huggingface/optimum/issues."
1901	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:1906
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1905	            raise ValueError(
1906	                f"Musicgen ONNX export currently does not support audio_encoder.chunk_length_s not None (got {config.audio_encoder.chunk_length_s}). Please open an issue at https://github.com/huggingface/optimum/issues."
1907	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:1964
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1963	            raise ValueError(
1964	                "This should not happen. Please open an issue at https://github.com/huggingface/optimum/issues."
1965	            )
1966	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:1990
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1989	            raise ValueError(
1990	                "This should not happen. Please open an issue at https://github.com/huggingface/optimum/issues."
1991	            )
1992	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:2139
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2138	    VARIANTS = {
2139	        "with-past": "The export follows the Transformers implementation using the KV cache, with the following components exported:\n\t - encoder_model.onnx: corresponds to the encoding part in https://github.com/huggingface/transformers/blob/v4.33.2/src/transformers/models/speecht5/modeling_speecht5.py#L2544-L2556.\n\t - decoder_model.onnx: corresponds to the decoder part in https://github.com/huggingface/transformers/blob/v4.33.2/src/transformers/models/speecht5/modeling_speecht5.py#L2572-L2602.\n\t - decoder_with_past_model.onnx: same as the above, with past_key_values input (KV cache filled).\n\t - decoder_postnet_and_vocoder.onnx: Decoder speech postnet and vocoder (e.g. a SpeechT5HifiGan) to generate speech from the spectrogram, as in https://github.com/huggingface/transformers/blob/v4.33.2/src/transformers/models/speecht5/modeling_speecht5.py#L2605-L2614.",
2140	        "without-past": "The same as `with-past`, just without KV cache support. This is not a recommended export as slower than `with-past`.",
2141	    }
2142	    DEFAULT_VARIANT = "with-past"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/onnx/model_configs.py:2170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2169	            raise ValueError(
2170	                "The ONNX export of SpeechT5 in float16 is currently not supported due to a bug in PyTorch: https://github.com/pytorch/pytorch/pull/110078. Please open an issue in Optimum if you would like to export SpeechT5 in float16."
2171	            )
2172	        self.is_postnet_and_vocoder = is_postnet_and_vocoder

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/tasks.py:1368
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1367	
1368	                mapping = supported_model_type_for_library.get(model_type, {})
1369	                mapping_backend = mapping.get(backend, {})

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/tasks.py:1369
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1368	                mapping = supported_model_type_for_library.get(model_type, {})
1369	                mapping_backend = mapping.get(backend, {})
1370	                for task in supported_tasks:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/tasks.py:1825
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1824	                elif model_config is not None:
1825	                    if model_config is not None and model_config.get("diffusers", None) is not None:
1826	                        diffusers_class_name = model_config["diffusers"]["_class_name"]

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/tasks.py:1842
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1841	                elif transformers_info is not None:
1842	                    transformers_pipeline_tag = transformers_info.get("pipeline_tag", None)
1843	                    transformers_auto_model = transformers_info.get("auto_model", None)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/tasks.py:1843
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1842	                    transformers_pipeline_tag = transformers_info.get("pipeline_tag", None)
1843	                    transformers_auto_model = transformers_info.get("auto_model", None)
1844	                    if transformers_pipeline_tag is not None:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/tasks.py:2232
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
2231	            config = DiffusionPipeline.load_config(model_name_or_path, **kwargs)
2232	            class_name = config.get("_class_name", None)
2233	            loaded_library = importlib.import_module(library_name)

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/exporters/tflite/convert.py:374
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
373	    with open(output, "wb") as fp:
374	        fp.write(tflite_model)
375	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnx/transformations_utils.py:227
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
226	                        raise ValueError(
227	                            f"Too few outputs of model2 were found to match with {model_output_1.name}."
228	                            f" Please try to pass strict=False, or fill a bug report at https://github.com/huggingface/optimum."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/modeling_decoder.py:461
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
460	                raise ValueError(
461	                    f"ONNX Runtime inference using {ONNX_DECODER_WITH_PAST_NAME} has been deprecated for {config.model_type} architecture. Please re-export your model with optimum>=1.14.0 or set use_cache=False. For details about the deprecation, please refer to https://github.com/huggingface/optimum/releases/tag/v1.14.0."
462	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/modeling_ort.py:99
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
98	
99	ONNX_TEXT_INPUTS_DOCSTRING = r"""
100	    Args:
101	        input_ids (`Union[torch.Tensor, np.ndarray, None]` of shape `({0})`, defaults to `None`):
102	            Indices of input sequence tokens in the vocabulary.
103	            Indices can be obtained using [`AutoTokenizer`](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer).
104	            See [`PreTrainedTokenizer.encode`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.encode) and
105	            [`PreTrainedTokenizer.__call__`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerBase.__call__) for details.
106	            [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)
107	        attention_mask (`Union[torch.Tensor, np.ndarray, None]` of shape `({0})`, defaults to `None`):
108	            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:
109	            - 1 for tokens that are **not masked**,
110	            - 0 for tokens that are **masked**.
111	            [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)
112	        token_type_ids (`Union[torch.Tensor, np.ndarray, None]` of shape `({0})`, defaults to `None`):
113	            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0, 1]`:
114	            - 1 for tokens that are **sentence A**,
115	            - 0 for tokens that are **sentence B**.
116	            [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)
117	"""
118	
119	ONNX_IMAGE_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/modeling_ort.py:119
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
118	
119	ONNX_IMAGE_INPUTS_DOCSTRING = r"""
120	    Args:
121	        pixel_values (`Union[torch.Tensor, np.ndarray, None]` of shape `({0})`, defaults to `None`):
122	            Pixel values corresponding to the images in the current batch.
123	            Pixel values can be obtained from encoded images using [`AutoFeatureExtractor`](https://huggingface.co/docs/transformers/autoclass_tutorial#autofeatureextractor).
124	"""
125	
126	ONNX_AUDIO_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/modeling_ort.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
125	
126	ONNX_AUDIO_INPUTS_DOCSTRING = r"""
127	    Args:
128	        input_values (`torch.Tensor` of shape `({0})`):
129	            Float values of input raw speech waveform..
130	            Input values can be obtained from audio file loaded into an array using [`AutoFeatureExtractor`](https://huggingface.co/docs/transformers/autoclass_tutorial#autofeatureextractor).
131	"""
132	
133	
134	class classproperty:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/modeling_ort.py:1663
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1662	
1663	IMAGE_CLASSIFICATION_EXAMPLE = r"""
1664	    Example of image classification:
1665	
1666	    ```python
1667	    >>> import requests
1668	    >>> from PIL import Image
1669	    >>> from optimum.onnxruntime import {model_class}
1670	    >>> from transformers import {processor_class}
1671	
1672	    >>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
1673	    >>> image = Image.open(requests.get(url, stream=True).raw)
1674	
1675	    >>> preprocessor = {processor_class}.from_pretrained("{checkpoint}")
1676	    >>> model = {model_class}.from_pretrained("{checkpoint}")
1677	
1678	    >>> inputs = preprocessor(images=image, return_tensors="np")
1679	
1680	    >>> outputs = model(**inputs)
1681	    >>> logits = outputs.logits
1682	    ```
1683	
1684	    Example using `transformers.pipeline`:
1685	
1686	    ```python
1687	    >>> import requests
1688	    >>> from PIL import Image
1689	    >>> from transformers import {processor_class}, pipeline
1690	    >>> from optimum.onnxruntime import {model_class}
1691	
1692	    >>> preprocessor = {processor_class}.from_pretrained("{checkpoint}")
1693	    >>> model = {model_class}.from_pretrained("{checkpoint}")
1694	    >>> onnx_image_classifier = pipeline("image-classification", model=model, feature_extractor=preprocessor)
1695	
1696	    >>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
1697	    >>> pred = onnx_image_classifier(url)
1698	    ```
1699	"""
1700	
1701	
1702	@add_end_docstrings(ONNX_MODEL_END_DOCSTRING)
1703	class ORTModelForImageClassification(ORTModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/modeling_ort.py:1753
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1752	
1753	SEMANTIC_SEGMENTATION_EXAMPLE = r"""
1754	    Example of semantic segmentation:
1755	
1756	    ```python
1757	    >>> import requests
1758	    >>> from PIL import Image
1759	    >>> from optimum.onnxruntime import {model_class}
1760	    >>> from transformers import {processor_class}
1761	
1762	    >>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
1763	    >>> image = Image.open(requests.get(url, stream=True).raw)
1764	
1765	    >>> preprocessor = {processor_class}.from_pretrained("{checkpoint}")
1766	    >>> model = {model_class}.from_pretrained("{checkpoint}")
1767	
1768	    >>> inputs = preprocessor(images=image, return_tensors="np")
1769	
1770	    >>> outputs = model(**inputs)
1771	    >>> logits = outputs.logits
1772	    ```
1773	
1774	    Example using `transformers.pipeline`:
1775	
1776	    ```python
1777	    >>> import requests
1778	    >>> from PIL import Image
1779	    >>> from transformers import {processor_class}, pipeline
1780	    >>> from optimum.onnxruntime import {model_class}
1781	
1782	    >>> preprocessor = {processor_class}.from_pretrained("{checkpoint}")
1783	    >>> model = {model_class}.from_pretrained("{checkpoint}")
1784	    >>> onnx_image_segmenter = pipeline("image-segmentation", model=model, feature_extractor=preprocessor)
1785	
1786	    >>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
1787	    >>> pred = onnx_image_segmenter(url)
1788	    ```
1789	"""
1790	
1791	
1792	@add_end_docstrings(ONNX_MODEL_END_DOCSTRING)
1793	class ORTModelForSemanticSegmentation(ORTModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/modeling_seq2seq.py:279
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
278	
279	IMAGE_TO_TEXT_EXAMPLE = r"""
280	    Example of text generation:
281	
282	    ```python
283	    >>> from transformers import {processor_class}, {tokenizer_class}
284	    >>> from optimum.onnxruntime import {model_class}
285	    >>> from PIL import Image
286	    >>> import requests
287	
288	
289	    >>> processor = {processor_class}.from_pretrained("{checkpoint}")
290	    >>> tokenizer = {tokenizer_class}.from_pretrained("{checkpoint}")
291	    >>> model = {model_class}.from_pretrained("{checkpoint}", export=True)
292	
293	    >>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
294	    >>> image = Image.open(requests.get(url, stream=True).raw)
295	    >>> inputs = processor(image, return_tensors="pt")
296	
297	    >>> gen_tokens = model.generate(**inputs)
298	    >>> outputs = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)
299	
300	    ```
301	
302	    Example using `transformers.pipeline`:
303	
304	    ```python
305	    >>> from transformers import {processor_class}, {tokenizer_class}, pipeline
306	    >>> from optimum.onnxruntime import {model_class}
307	    >>> from PIL import Image
308	    >>> import requests
309	
310	
311	    >>> processor = {processor_class}.from_pretrained("{checkpoint}")
312	    >>> tokenizer = {tokenizer_class}.from_pretrained("{checkpoint}")
313	    >>> model = {model_class}.from_pretrained("{checkpoint}", export=True)
314	
315	    >>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
316	    >>> image = Image.open(requests.get(url, stream=True).raw)
317	
318	    >>> image_to_text = pipeline("image-to-text", model=model, tokenizer=tokenizer, feature_extractor=processor, image_processor=processor)
319	    >>> pred = image_to_text(image)
320	    ```
321	"""
322	
323	PIX2STRUCT_EXAMPLE = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/modeling_seq2seq.py:323
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
322	
323	PIX2STRUCT_EXAMPLE = r"""
324	    Example of pix2struct:
325	
326	    ```python
327	    >>> from transformers import {processor_class}
328	    >>> from optimum.onnxruntime import {model_class}
329	    >>> from PIL import Image
330	    >>> import requests
331	
332	    >>> processor = {processor_class}.from_pretrained("{checkpoint}")
333	    >>> model = {model_class}.from_pretrained("{checkpoint}", export=True, use_io_binding=True)
334	
335	    >>> url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/ai2d-demo.jpg"
336	    >>> image = Image.open(requests.get(url, stream=True).raw)
337	    >>> question = "What does the label 15 represent? (1) lava (2) core (3) tunnel (4) ash cloud"
338	    >>> inputs = processor(images=image, text=question, return_tensors="pt")
339	
340	    >>> gen_tokens = model.generate(**inputs)
341	    >>> outputs = processor.batch_decode(gen_tokens, skip_special_tokens=True)
342	    ```
343	"""
344	
345	
346	class ORTEncoderForSpeech(ORTEncoder):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/optimization.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
70	            raise NotImplementedError(
71	                f"Tried to use ORTOptimizer for the model type {self.model_type}, but it is not available yet. Please open an issue"
72	                " or submit a PR at https://github.com/huggingface/optimum."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/quantization.py:358
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
357	                raise ValueError(
358	                    "ONNX Runtime version v1.16.0 is not compatible with quantization for models with subgraphs, please downgrade to 1.15.1 or upgrade to a higher version. Reference: https://github.com/microsoft/onnxruntime/pull/17651"
359	                )
360	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/subpackage/commands/optimize.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	        action="store_true",
47	        help="Basic general optimizations (see: https://huggingface.co/docs/optimum/onnxruntime/usage_guides/optimization for more details).",
48	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/subpackage/commands/optimize.py:52
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
51	        action="store_true",
52	        help="Basic and extended general optimizations, transformers-specific fusions (see: https://huggingface.co/docs/optimum/onnxruntime/usage_guides/optimization for more details).",
53	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/subpackage/commands/optimize.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	        action="store_true",
57	        help="Same as O2 with Gelu approximation (see: https://huggingface.co/docs/optimum/onnxruntime/usage_guides/optimization for more details).",
58	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/subpackage/commands/optimize.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
61	        action="store_true",
62	        help="Same as O3 with mixed precision (see: https://huggingface.co/docs/optimum/onnxruntime/usage_guides/optimization for more details).",
63	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/subpackage/commands/quantize.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
96	            raise ValueError(
97	                "TensorRT quantization relies on static quantization that requires calibration, which is currently not supported through optimum-cli. Please adapt Optimum static quantization examples to run static quantization for TensorRT: https://github.com/huggingface/optimum/tree/main/examples/onnxruntime/quantization"
98	            )
99	        else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/trainer.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	    raise ImportError(
47	        "The package `accelerate` is required to use the ORTTrainer. Please install it following https://huggingface.co/docs/accelerate/basic_tutorials/install."
48	    )
49	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/trainer.py:332
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
331	            raise ImportError(
332	                "You need to install `onnxruntime-training` to use `ORTTrainer` for training. Check out "
333	                "https://huggingface.co/docs/optimum/onnxruntime/usage_guides/trainer#install-onnx-runtime."
334	            )

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/trainer.py:884
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
883	                    logger.info(f"Deleting older checkpoint [{checkpoint}] due to args.save_total_limit")
884	                    shutil.rmtree(checkpoint)
885	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/trainer_seq2seq.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
32	    raise ImportError(
33	        "The package `accelerate` is required to use the ORTTrainer. Please install it following https://huggingface.co/docs/accelerate/basic_tutorials/install."
34	    )
35	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/training_args.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
198	            logger.info(
199	                f"Found safetensors installation, but --save_safetensors={self.save_safetensors}. "
200	                f"Safetensors should be a preferred weights saving format due to security and performance reasons. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/utils.py:185
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
184	            raise NotImplementedError(
185	                f"ONNX Runtime doesn't support the graph optimization of {model_type} yet. Only {list(cls._conf.keys())} are supported. "
186	                f"If you want to support {model_type} please propose a PR or open up an issue in ONNX Runtime: https://github.com/microsoft/onnxruntime."
187	            )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/utils.py:257
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
256	        with open(path_dependecy_loading, "r") as f:
257	            file_string = f.read()
258	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/utils.py:277
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
276	                    raise ImportError(
277	                        "`onnxruntime-gpu` package is installed, but CUDA requirements could not be loaded. Make sure to meet the required dependencies: https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html"
278	                    )
279	            if provider == "TensorrtExecutionProvider":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/onnxruntime/utils.py:282
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
281	                    raise ImportError(
282	                        "`onnxruntime-gpu` package is installed, but TensorRT requirements could not be loaded. Make sure to meet the required dependencies following https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html and https://hf.co/docs/optimum/onnxruntime/usage_guides/gpu#tensorrtexecutionprovider ."
283	                    )
284	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/runs_base.py:82
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
81	            optimum_hash = subprocess.check_output(
82	                "git ls-remote https://github.com/huggingface/optimum.git HEAD | awk '{ print $1}'", shell=True
83	            )
84	            optimum_hash = optimum_hash.decode("utf-8").strip("\n")

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/utils/runs.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
75	def cpu_info_command():
76	    if platform.system() == "Linux":
77	        return "lscpu"

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/utils/runs.py:76
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
75	def cpu_info_command():
76	    if platform.system() == "Linux":
77	        return "lscpu"

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/utils/runs.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
77	        return "lscpu"
78	    elif platform.system() == "Darwin":
79	        return "sysctl -a | grep machdep.cpu"

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/utils/runs.py:78
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
77	        return "lscpu"
78	    elif platform.system() == "Darwin":
79	        return "sysctl -a | grep machdep.cpu"

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/utils/testing_utils.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
200	        if os.name == "nt":
201	            os.system(f"rmdir /S /Q {dirpath}")
202	        else:

--------------------------------------------------
>> Issue: [B316:blacklist] os.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/utils/testing_utils.py:201
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b313-b320-os-system
200	        if os.name == "nt":
201	            os.system(f"rmdir /S /Q {dirpath}")
202	        else:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/optimum/utils/testing_utils.py:203
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
202	        else:
203	            shutil.rmtree(dirpath)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/setup.py:138
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
137	    "habana, graphcore, neural compressor, ipu, hpu",
138	    url="https://github.com/huggingface/optimum",
139	    author="HuggingFace Inc. Special Ops Team",

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/tests/test_modeling_base.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
50	                tmpdirname,
51	                token=os.environ.get("HF_AUTH_TOKEN", None),
52	                push_to_hub=True,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/tests/test_modeling_base.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
55	            # folder contains all config files and pytorch_model.bin
56	            url = "https://huggingface.co/philschmid/unit_test_save_model/raw/main/config.json"
57	            response = r.get(url)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum-1.24.0/optimum-1.24.0/tests/test_modeling_base.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
56	            url = "https://huggingface.co/philschmid/unit_test_save_model/raw/main/config.json"
57	            response = r.get(url)
58	            self.assertEqual(remote_hash, response.json()["from_local"])

--------------------------------------------------

Code scanned:
	Total lines of code: 32530
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 52.0
		High: 16.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 65.0
		High: 3.0
Files skipped (0):
