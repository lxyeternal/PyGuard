Run started:2025-04-12 16:55:26.693190

Test results:
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/abc/evaluation/evaluator.py:472
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
471	            for metric in metrics:
472	                f.write(f"## {metric}\n\n")
473	                results_df = AbsEvaluator.get_results_df(metric, eval_results_dict)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/abc/evaluation/evaluator.py:476
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
475	                splits = results_df.columns
476	                f.write(f"| Model | Reranker | {' | '.join(splits)} |\n")
477	                f.write(f"| :---- | :---- | {' | '.join([':---:' for _ in splits])} |\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/abc/evaluation/evaluator.py:477
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
476	                f.write(f"| Model | Reranker | {' | '.join(splits)} |\n")
477	                f.write(f"| :---- | :---- | {' | '.join([':---:' for _ in splits])} |\n")
478	                for i, row in results_df.iterrows():

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/abc/evaluation/evaluator.py:488
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
487	                                line += f'**{v*100:.3f}** | '
488	                    f.write(line + "\n")
489	                f.write("\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/abc/evaluation/evaluator.py:489
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
488	                    f.write(line + "\n")
489	                f.write("\n")
490	        logger.info(f"Results saved to {output_path}")

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/abc/inference/AbsEmbedder.py:332
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
331	        for device_id in tqdm(self.target_devices, desc='initial target device'):
332	            p = ctx.Process(
333	                target=process_target_func,
334	                args=(device_id, self, input_queue, output_queue),
335	                daemon=True,
336	            )

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/abc/inference/AbsReranker.py:270
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
269	        for device_id in tqdm(self.target_devices, desc='initial target device'):
270	            p = ctx.Process(
271	                target=AbsReranker._encode_multi_process_worker,
272	                args=(device_id, self, input_queue, output_queue),
273	                daemon=True,
274	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/air_bench/__main__.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	    print("For computing metrics, please refer to the official AIR-Bench docs:")
32	    print("- https://github.com/AIR-Bench/AIR-Bench/blob/main/docs/submit_to_leaderboard.md")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/beir/data_loader.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
95	                        }
96	                        f.write(json.dumps(_data, ensure_ascii=False) + "\n")
97	                logging.info(f"{self.eval_name} {dataset_name} corpus saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/beir/data_loader.py:101
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
100	        else:
101	            url = "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip".format(dataset_name)
102	            data_path = util.download_and_unzip(url, self.cache_dir)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/beir/data_loader.py:121
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
120	                        }
121	                        f.write(json.dumps(_data, ensure_ascii=False) + "\n")
122	                logging.info(f"{self.eval_name} {dataset_name} corpus saved to {save_path}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/beir/data_loader.py:169
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
168	                        qrels_dict[qid][docid] = rel
169	                        f.write(json.dumps(_data, ensure_ascii=False) + "\n")
170	                logging.info(f"{self.eval_name} {dataset_name} qrels saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/beir/data_loader.py:179
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
178	        else:
179	            url = "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip".format(dataset_name)
180	            data_path = util.download_and_unzip(url, self.cache_dir)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/beir/data_loader.py:200
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
199	                            qrels_dict[qid][docid] = rel
200	                            f.write(json.dumps(_data, ensure_ascii=False) + "\n")
201	                logging.info(f"{self.eval_name} {dataset_name} qrels saved to {save_path}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/beir/data_loader.py:254
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
253	                        queries_dict[qid] = query
254	                        f.write(json.dumps(_data, ensure_ascii=False) + "\n")
255	                logging.info(f"{self.eval_name} {dataset_name} queries saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/beir/data_loader.py:263
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
262	        else:
263	            url = "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip".format(dataset_name)
264	            data_path = util.download_and_unzip(url, self.cache_dir)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/beir/data_loader.py:281
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
280	                        queries_dict[qid] = query
281	                        f.write(json.dumps(_data, ensure_ascii=False) + "\n")
282	                logging.info(f"{self.eval_name} {dataset_name} queries saved to {save_path}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/miracl/data_loader.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
77	                    }
78	                    f.write(json.dumps(_data, ensure_ascii=False) + "\n")
79	            logging.info(f"{self.eval_name} {dataset_name} corpus saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/miracl/data_loader.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
99	        """
100	        endpoint = f"{os.getenv('HF_ENDPOINT', 'https://huggingface.co')}/datasets/miracl/miracl"
101	        qrels_download_url = f"{endpoint}/resolve/main/miracl-v1.0-{dataset_name}/qrels/qrels.miracl-v1.0-{dataset_name}-{split}.tsv"

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/miracl/data_loader.py:122
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
121	                        qrels_dict[qid][docid] = rel
122	                        f1.write(json.dumps(_data, ensure_ascii=False) + "\n")
123	            logging.info(f"{self.eval_name} {dataset_name} qrels saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/miracl/data_loader.py:151
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
150	        """
151	        endpoint = f"{os.getenv('HF_ENDPOINT', 'https://huggingface.co')}/datasets/miracl/miracl"
152	        queries_download_url = f"{endpoint}/resolve/main/miracl-v1.0-{dataset_name}/topics/topics.miracl-v1.0-{dataset_name}-{split}.tsv"

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/miracl/data_loader.py:170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
169	                        queries_dict[qid] = query
170	                        f1.write(json.dumps(_data, ensure_ascii=False) + "\n")
171	            logging.info(f"{self.eval_name} {dataset_name} queries saved to {save_path}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/mkqa/data_loader.py:120
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
119	                    }
120	                    f.write(json.dumps(_data, ensure_ascii=False) + "\n")
121	            logging.info(f"{self.eval_name} corpus saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/mkqa/data_loader.py:148
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
147	        """
148	        endpoint = f"{os.getenv('HF_ENDPOINT', 'https://huggingface.co')}/datasets/Shitao/bge-m3-data"
149	        queries_download_url = f"{endpoint}/resolve/main/MKQA_test-data.zip"

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/mkqa/data_loader.py:170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
169	                        qrels_dict[qid] = answers
170	                        f1.write(json.dumps(_data, ensure_ascii=False) + "\n")
171	            logging.info(f"{self.eval_name} {dataset_name} qrels saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/mkqa/data_loader.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
198	        """
199	        endpoint = f"{os.getenv('HF_ENDPOINT', 'https://huggingface.co')}/datasets/Shitao/bge-m3-data"
200	        queries_download_url = f"{endpoint}/resolve/main/MKQA_test-data.zip"

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/mkqa/data_loader.py:219
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
218	                        queries_dict[qid] = query
219	                        f1.write(json.dumps(_data, ensure_ascii=False) + "\n")
220	            logging.info(f"{self.eval_name} {dataset_name} queries saved to {save_path}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/mldr/data_loader.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
70	                    corpus_dict[docid] = {"text": text}
71	                    f.write(json.dumps(_data, ensure_ascii=False) + "\n")
72	            logging.info(f"{self.eval_name} {dataset_name} corpus saved to {save_path}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/mldr/data_loader.py:117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
116	                        qrels_dict[qid][docid] = 1
117	                        f.write(json.dumps(_data, ensure_ascii=False) + "\n")
118	                    for doc in data["negative_passages"]:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/mldr/data_loader.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
125	                        qrels_dict[qid][docid] = 0
126	                        f.write(json.dumps(_data, ensure_ascii=False) + "\n")
127	            logging.info(f"{self.eval_name} {dataset_name} qrels saved to {save_path}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/mldr/data_loader.py:177
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
176	                    queries_dict[qid] = query
177	                    f.write(json.dumps(_data, ensure_ascii=False) + "\n")
178	            logging.info(f"{self.eval_name} {dataset_name} queries saved to {save_path}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
94	                        }
95	                    f.write(json.dumps(_data, ensure_ascii=False) + "\n")
96	            logging.info(f"{self.eval_name} {dataset_name} corpus saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:131
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
130	            elif split == 'dl19':
131	                qrels_download_url = "https://trec.nist.gov/data/deep/2019qrels-pass.txt"
132	            else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:133
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
132	            else:
133	                qrels_download_url = "https://trec.nist.gov/data/deep/2020qrels-pass.txt"
134	        else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:136
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
135	            if split == 'dev':
136	                qrels_download_url = "https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-docdev-qrels.tsv.gz"
137	            elif split == 'dl19':

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:138
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
137	            elif split == 'dl19':
138	                qrels_download_url = "https://trec.nist.gov/data/deep/2019qrels-docs.txt"
139	            else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:140
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
139	            else:
140	                qrels_download_url = "https://trec.nist.gov/data/deep/2020qrels-docs.txt"
141	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:165
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
164	                            qrels_dict[qid][docid] = rel
165	                            f1.write(json.dumps(_data, ensure_ascii=False) + "\n")
166	            else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:178
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
177	                        qrels_dict[qid][docid] = rel
178	                        f.write(json.dumps(_data, ensure_ascii=False) + "\n")
179	            logging.info(f"{self.eval_name} {dataset_name} qrels saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
224	            else:
225	                queries_download_url = "https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-docdev-qrels.tsv.gz"
226	                queries_save_path = self._download_gz_file(queries_download_url, self.cache_dir)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:229
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
228	            year = split.replace("dl", "")
229	            queries_download_url = f"https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test20{year}-queries.tsv.gz"
230	            queries_save_path = self._download_gz_file(queries_download_url, self.cache_dir)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:250
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
249	                            queries_dict[qid] = query
250	                            f1.write(json.dumps(_data, ensure_ascii=False) + "\n")
251	            else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/evaluation/msmarco/data_loader.py:261
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
260	                        queries_dict[qid] = query
261	                        f.write(json.dumps(_data, ensure_ascii=False) + "\n")
262	            logging.info(f"{self.eval_name} {dataset_name} queries saved to {save_path}")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/finetune/reranker/decoder_only/layerwise/modeling_minicpm_reranker.py:841
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
840	
841	MINICPM_START_DOCSTRING = r"""
842	    This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the
843	    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
844	    etc.)
845	
846	    This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.
847	    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
848	    and behavior.
849	
850	    Parameters:
851	        config ([`LayerWiseMiniCPMConfig`]):
852	            Model configuration class with all the parameters of the model. Initializing with a config file does not
853	            load the weights associated with the model, only the configuration. Check out the
854	            [`~PreTrainedModel.from_pretrained`] method to load the model weights.
855	"""
856	
857	
858	@add_start_docstrings(
859	    "The bare MiniCPM Model outputting raw hidden-states without any specific head on top.",
860	    MINICPM_START_DOCSTRING,
861	)
862	class MiniCPMPreTrainedModel(PreTrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/finetune/reranker/decoder_only/layerwise/modeling_minicpm_reranker.py:884
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
883	
884	MINICPM_INPUTS_DOCSTRING = r"""
885	    Args:
886	        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):
887	            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide
888	            it.
889	
890	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
891	            [`PreTrainedTokenizer.__call__`] for details.
892	
893	            [What are input IDs?](../glossary#input-ids)
894	        attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):
895	            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:
896	
897	            - 1 for tokens that are **not masked**,
898	            - 0 for tokens that are **masked**.
899	
900	            [What are attention masks?](../glossary#attention-mask)
901	
902	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
903	            [`PreTrainedTokenizer.__call__`] for details.
904	
905	            If `past_key_values` is used, optionally only the last `input_ids` have to be input (see
906	            `past_key_values`).
907	
908	            If you want to change padding behavior, you should read [`modeling_opt._prepare_decoder_attention_mask`]
909	            and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more
910	            information on the default strategy.
911	
912	            - 1 indicates the head is **not masked**,
913	            - 0 indicates the head is **masked**.
914	        position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):
915	            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,
916	            config.n_positions - 1]`.
917	
918	            [What are position IDs?](../glossary#position-ids)
919	        past_key_values (`Cache` or `tuple(tuple(torch.FloatTensor))`, *optional*):
920	            Pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
921	            blocks) that can be used to speed up sequential decoding. This typically consists in the `past_key_values`
922	            returned by the model at a previous stage of decoding, when `use_cache=True` or `config.use_cache=True`.
923	
924	            Two formats are allowed:
925	            - a [`~cache_utils.Cache`] instance;
926	            - Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of
927	            shape `(batch_size, num_heads, sequence_length, embed_size_per_head)`). This is also known as the legacy
928	            cache format.
929	
930	            The model will output the same cache format that is fed as input. If no `past_key_values` are passed, the
931	            legacy cache format will be returned.
932	
933	            If `past_key_values` are used, the user can optionally input only the last `input_ids` (those that don't
934	            have their past key value states given to this model) of shape `(batch_size, 1)` instead of all `input_ids`
935	            of shape `(batch_size, sequence_length)`.
936	        inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):
937	            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
938	            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the
939	            model's internal embedding lookup matrix.
940	        use_cache (`bool`, *optional*):
941	            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see
942	            `past_key_values`).
943	        output_attentions (`bool`, *optional*):
944	            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned
945	            tensors for more detail.
946	        output_hidden_states (`bool`, *optional*):
947	            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for
948	            more detail.
949	        return_dict (`bool`, *optional*):
950	            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.
951	"""
952	
953	
954	@add_start_docstrings(
955	    "The bare MiniCPM Model outputting raw hidden-states without any specific head on top.",
956	    MINICPM_START_DOCSTRING,
957	)
958	class LayerWiseMiniCPMModel(MiniCPMPreTrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/inference/auto_embedder.py:84
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
83	                raise ValueError(
84	                    f"Model name '{model_name}' not found in the model mapping. You can pull request to add the model to "
85	                    "`https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/inference/embedder/model_mapping.py`. " 

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/inference/auto_reranker.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
62	                raise ValueError(
63	                    f"Model name '{model_name}' not found in the model mapping. You can pull request to add the model to "
64	                    "`https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/inference/reranker/model_mapping.py`. " 

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py:844
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
843	
844	MINICPM_START_DOCSTRING = r"""
845	    This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the
846	    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
847	    etc.)
848	
849	    This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.
850	    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
851	    and behavior.
852	
853	    Parameters:
854	        config ([`LayerWiseMiniCPMConfig`]):
855	            Model configuration class with all the parameters of the model. Initializing with a config file does not
856	            load the weights associated with the model, only the configuration. Check out the
857	            [`~PreTrainedModel.from_pretrained`] method to load the model weights.
858	"""
859	
860	
861	@add_start_docstrings(
862	    "The bare MiniCPM Model outputting raw hidden-states without any specific head on top.",
863	    MINICPM_START_DOCSTRING,
864	)
865	class MiniCPMPreTrainedModel(PreTrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py:887
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
886	
887	MINICPM_INPUTS_DOCSTRING = r"""
888	    Args:
889	        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):
890	            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide
891	            it.
892	
893	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
894	            [`PreTrainedTokenizer.__call__`] for details.
895	
896	            [What are input IDs?](../glossary#input-ids)
897	        attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):
898	            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:
899	
900	            - 1 for tokens that are **not masked**,
901	            - 0 for tokens that are **masked**.
902	
903	            [What are attention masks?](../glossary#attention-mask)
904	
905	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
906	            [`PreTrainedTokenizer.__call__`] for details.
907	
908	            If `past_key_values` is used, optionally only the last `input_ids` have to be input (see
909	            `past_key_values`).
910	
911	            If you want to change padding behavior, you should read [`modeling_opt._prepare_decoder_attention_mask`]
912	            and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more
913	            information on the default strategy.
914	
915	            - 1 indicates the head is **not masked**,
916	            - 0 indicates the head is **masked**.
917	        position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):
918	            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,
919	            config.n_positions - 1]`.
920	
921	            [What are position IDs?](../glossary#position-ids)
922	        past_key_values (`Cache` or `tuple(tuple(torch.FloatTensor))`, *optional*):
923	            Pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
924	            blocks) that can be used to speed up sequential decoding. This typically consists in the `past_key_values`
925	            returned by the model at a previous stage of decoding, when `use_cache=True` or `config.use_cache=True`.
926	
927	            Two formats are allowed:
928	            - a [`~cache_utils.Cache`] instance;
929	            - Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of
930	            shape `(batch_size, num_heads, sequence_length, embed_size_per_head)`). This is also known as the legacy
931	            cache format.
932	
933	            The model will output the same cache format that is fed as input. If no `past_key_values` are passed, the
934	            legacy cache format will be returned.
935	
936	            If `past_key_values` are used, the user can optionally input only the last `input_ids` (those that don't
937	            have their past key value states given to this model) of shape `(batch_size, 1)` instead of all `input_ids`
938	            of shape `(batch_size, sequence_length)`.
939	        inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):
940	            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
941	            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the
942	            model's internal embedding lookup matrix.
943	        use_cache (`bool`, *optional*):
944	            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see
945	            `past_key_values`).
946	        output_attentions (`bool`, *optional*):
947	            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned
948	            tensors for more detail.
949	        output_hidden_states (`bool`, *optional*):
950	            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for
951	            more detail.
952	        return_dict (`bool`, *optional*):
953	            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.
954	"""
955	
956	
957	@add_start_docstrings(
958	    "The bare MiniCPM Model outputting raw hidden-states without any specific head on top.",
959	    MINICPM_START_DOCSTRING,
960	)
961	class LayerWiseMiniCPMModel(MiniCPMPreTrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/flagembedding-1.3.4/FlagEmbedding-1.3.4/setup.py:13
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
12	    author_email='2906698981@qq.com',
13	    url='https://github.com/FlagOpen/FlagEmbedding',
14	    packages=find_packages(),

--------------------------------------------------

Code scanned:
	Total lines of code: 17002
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 22.0
		High: 28.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 50.0
		High: 0.0
Files skipped (0):
