Run started:2025-04-12 10:53:07.316140

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/_stereo_matching.py:580
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
579	    def _download_dataset(self, root: Union[str, Path]) -> None:
580	        base_url = "https://vision.middlebury.edu/stereo/data/scenes2014/zip"
581	        # train and additional splits have 2 different calibration settings
582	        root = Path(root) / "Middlebury2014"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/_stereo_matching.py:603
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
602	                # test split is downloaded from a different location
603	                test_set_url = "https://vision.middlebury.edu/stereo/submit3/zip/MiddEval3-data-F.zip"
604	                # the unzip is going to produce a directory MiddEval3 with two subdirectories trainingF and testF
605	                # we want to move the contents from testF into the  directory
606	                download_and_extract_archive(url=test_set_url, download_root=str(root), remove_finished=True)

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/_stereo_matching.py:615
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
614	                # cleanup MiddEval3 directory
615	                shutil.rmtree(str(root / "MiddEval3"))
616	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/caltech.py:136
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
135	        download_and_extract_archive(
136	            "https://drive.google.com/file/d/137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp",
137	            self.root,
138	            filename="101_ObjectCategories.tar.gz",
139	            md5="b224c7392d521a49829488ab0f1120d9",
140	        )
141	        download_and_extract_archive(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/caltech.py:142
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
141	        download_and_extract_archive(
142	            "https://drive.google.com/file/d/175kQy3UsZ0wUEHZjqkUDdNVssr7bgh_m",
143	            self.root,
144	            filename="Annotations.tar",
145	            md5="6f83eeb1f24d99cab4eb377263132c91",
146	        )
147	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/caltech.py:236
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
235	        download_and_extract_archive(
236	            "https://drive.google.com/file/d/1r6o0pSROcV1_VwT4oSjA2FBUSCWGuxLK",
237	            self.root,
238	            filename="256_ObjectCategories.tar",
239	            md5="67b4f42ca05d46448c6bb8ecd2220f6d",
240	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/cifar.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	    base_folder = "cifar-10-batches-py"
32	    url = "https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
33	    filename = "cifar-10-python.tar.gz"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/cifar.py:153
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
152	    base_folder = "cifar-100-python"
153	    url = "https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz"
154	    filename = "cifar-100-python.tar.gz"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/clevr.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
27	
28	    _URL = "https://dl.fbaipublicfiles.com/clevr/CLEVR_v1.0.zip"
29	    _MD5 = "b11922020e72d0cd9154779b2d3d07d2"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/country211.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	    _URL = "https://openaipublic.azureedge.net/clip/data/country211.tgz"
27	    _MD5 = "84988d7644798601126c29e9877aab6a"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/dtd.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	
32	    _URL = "https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz"
33	    _MD5 = "fff73e5086ae6bdbea199a49dfb8a4c1"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/eurosat.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
58	        download_and_extract_archive(
59	            "https://huggingface.co/datasets/torchgeo/eurosat/resolve/c877bcd43f099cd0196738f714544e355477f3fd/EuroSAT.zip",
60	            download_root=self._base_folder,
61	            md5="c8fa014336c82ac7804f0398fcb19387",
62	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/fer2013.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	            raise RuntimeError(
78	                f"{file_name} not found in {base_folder} or corrupted. "
79	                f"You can download it from "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/fgvc_aircraft.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	
41	    _URL = "https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz"
42	
43	    def __init__(

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/flickr.py:81
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
80	        with open(self.ann_file) as fh:
81	            parser.feed(fh.read())
82	        self.annotations = parser.annotations

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/flowers102.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
34	
35	    _download_url_prefix = "https://www.robots.ox.ac.uk/~vgg/data/flowers/102/"
36	    _file_dict = {  # filename, md5

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/food101.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	
32	    _URL = "http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz"
33	    _MD5 = "85eeb15f3717b99a5da872d97d918f87"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/gtsrb.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
84	
85	        base_url = "https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/"
86	
87	        if self._split == "train":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/hmdb51.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
52	
53	    data_url = "https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar"
54	    splits = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/hmdb51.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
54	    splits = {
55	        "url": "https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar",
56	        "md5": "15e67781e70dcfbdce2d7dbb9b3344b5",
57	    }
58	    TRAIN_TAG = 1

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/imagenet.py:140
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
139	        finally:
140	            shutil.rmtree(tmp_dir)
141	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/imagenette.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	    _ARCHIVES = {
32	        "full": ("https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz", "fe2fc210e6bb7c5664d602c3cd71e612"),
33	        "320px": ("https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz", "3df6f0d01a2c9592104656642f5e78a3"),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/imagenette.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
32	        "full": ("https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz", "fe2fc210e6bb7c5664d602c3cd71e612"),
33	        "320px": ("https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz", "3df6f0d01a2c9592104656642f5e78a3"),
34	        "160px": ("https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz", "e793b78cc4c9e9a4ccc0c1155377a412"),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/imagenette.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
33	        "320px": ("https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz", "3df6f0d01a2c9592104656642f5e78a3"),
34	        "160px": ("https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz", "e793b78cc4c9e9a4ccc0c1155377a412"),
35	    }

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/inaturalist.py:14
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
13	DATASET_URLS = {
14	    "2017": "https://ml-inat-competition-datasets.s3.amazonaws.com/2017/train_val_images.tar.gz",
15	    "2018": "https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train_val2018.tar.gz",
16	    "2019": "https://ml-inat-competition-datasets.s3.amazonaws.com/2019/train_val2019.tar.gz",
17	    "2021_train": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz",
18	    "2021_train_mini": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz",
19	    "2021_valid": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz",
20	}
21	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/inaturalist.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
14	    "2017": "https://ml-inat-competition-datasets.s3.amazonaws.com/2017/train_val_images.tar.gz",
15	    "2018": "https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train_val2018.tar.gz",
16	    "2019": "https://ml-inat-competition-datasets.s3.amazonaws.com/2019/train_val2019.tar.gz",
17	    "2021_train": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz",
18	    "2021_train_mini": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz",
19	    "2021_valid": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz",
20	}
21	
22	DATASET_MD5 = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/inaturalist.py:16
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
15	    "2018": "https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train_val2018.tar.gz",
16	    "2019": "https://ml-inat-competition-datasets.s3.amazonaws.com/2019/train_val2019.tar.gz",
17	    "2021_train": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz",
18	    "2021_train_mini": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz",
19	    "2021_valid": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz",
20	}
21	
22	DATASET_MD5 = {
23	    "2017": "7c784ea5e424efaec655bd392f87301f",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/inaturalist.py:17
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
16	    "2019": "https://ml-inat-competition-datasets.s3.amazonaws.com/2019/train_val2019.tar.gz",
17	    "2021_train": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz",
18	    "2021_train_mini": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz",
19	    "2021_valid": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz",
20	}
21	
22	DATASET_MD5 = {
23	    "2017": "7c784ea5e424efaec655bd392f87301f",
24	    "2018": "b1c6952ce38f31868cc50ea72d066cc3",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/inaturalist.py:18
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
17	    "2021_train": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz",
18	    "2021_train_mini": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz",
19	    "2021_valid": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz",
20	}
21	
22	DATASET_MD5 = {
23	    "2017": "7c784ea5e424efaec655bd392f87301f",
24	    "2018": "b1c6952ce38f31868cc50ea72d066cc3",
25	    "2019": "c60a6e2962c9b8ccbd458d12c8582644",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/inaturalist.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
18	    "2021_train_mini": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz",
19	    "2021_valid": "https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz",
20	}
21	
22	DATASET_MD5 = {
23	    "2017": "7c784ea5e424efaec655bd392f87301f",
24	    "2018": "b1c6952ce38f31868cc50ea72d066cc3",
25	    "2019": "c60a6e2962c9b8ccbd458d12c8582644",
26	    "2021_train": "e0526d53c7f7b2e3167b2b43bb2690ed",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kinetics.py:81
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
80	    _TAR_URLS = {
81	        "400": "https://s3.amazonaws.com/kinetics/400/{split}/k400_{split}_path.txt",
82	        "600": "https://s3.amazonaws.com/kinetics/600/{split}/k600_{split}_path.txt",
83	        "700": "https://s3.amazonaws.com/kinetics/700_2020/{split}/k700_2020_{split}_path.txt",
84	    }
85	    _ANNOTATION_URLS = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kinetics.py:82
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
81	        "400": "https://s3.amazonaws.com/kinetics/400/{split}/k400_{split}_path.txt",
82	        "600": "https://s3.amazonaws.com/kinetics/600/{split}/k600_{split}_path.txt",
83	        "700": "https://s3.amazonaws.com/kinetics/700_2020/{split}/k700_2020_{split}_path.txt",
84	    }
85	    _ANNOTATION_URLS = {
86	        "400": "https://s3.amazonaws.com/kinetics/400/annotations/{split}.csv",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kinetics.py:83
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
82	        "600": "https://s3.amazonaws.com/kinetics/600/{split}/k600_{split}_path.txt",
83	        "700": "https://s3.amazonaws.com/kinetics/700_2020/{split}/k700_2020_{split}_path.txt",
84	    }
85	    _ANNOTATION_URLS = {
86	        "400": "https://s3.amazonaws.com/kinetics/400/annotations/{split}.csv",
87	        "600": "https://s3.amazonaws.com/kinetics/600/annotations/{split}.csv",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kinetics.py:86
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
85	    _ANNOTATION_URLS = {
86	        "400": "https://s3.amazonaws.com/kinetics/400/annotations/{split}.csv",
87	        "600": "https://s3.amazonaws.com/kinetics/600/annotations/{split}.csv",
88	        "700": "https://s3.amazonaws.com/kinetics/700_2020/annotations/{split}.csv",
89	    }
90	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kinetics.py:87
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
86	        "400": "https://s3.amazonaws.com/kinetics/400/annotations/{split}.csv",
87	        "600": "https://s3.amazonaws.com/kinetics/600/annotations/{split}.csv",
88	        "700": "https://s3.amazonaws.com/kinetics/700_2020/annotations/{split}.csv",
89	    }
90	
91	    def __init__(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kinetics.py:88
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
87	        "600": "https://s3.amazonaws.com/kinetics/600/annotations/{split}.csv",
88	        "700": "https://s3.amazonaws.com/kinetics/700_2020/annotations/{split}.csv",
89	    }
90	
91	    def __init__(
92	        self,

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kinetics.py:178
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
177	        with open(split_url_filepath) as file:
178	            list_video_urls = [urllib.parse.quote(line, safe="/,:") for line in file.read().splitlines()]
179	

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kinetics.py:185
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
184	            part = partial(_dl_wrap, tar_path, self.split_folder)
185	            poolproc = Pool(self.num_download_workers)
186	            poolproc.map(part, list_video_urls)

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kinetics.py:185
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
184	            part = partial(_dl_wrap, tar_path, self.split_folder)
185	            poolproc = Pool(self.num_download_workers)
186	            poolproc.map(part, list_video_urls)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/kitti.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	
45	    data_url = "https://s3.eu-central-1.amazonaws.com/avg-kitti/"
46	    resources = [

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/lfw.py:14
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
13	    base_folder = "lfw-py"
14	    download_url_prefix = "http://vis-www.cs.umass.edu/lfw/"
15	
16	    file_dict = {

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/lsun.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
40	        buf = io.BytesIO()
41	        buf.write(imgbuf)
42	        buf.seek(0)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
37	    mirrors = [
38	        "http://yann.lecun.com/exdb/mnist/",
39	        "https://ossci-datasets.s3.amazonaws.com/mnist/",
40	    ]
41	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	        "http://yann.lecun.com/exdb/mnist/",
39	        "https://ossci-datasets.s3.amazonaws.com/mnist/",
40	    ]
41	
42	    resources = [

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:221
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
220	
221	    mirrors = ["http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/"]
222	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:249
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
248	
249	    mirrors = ["http://codh.rois.ac.jp/kmnist/dataset/kmnist/"]
250	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:280
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
279	
280	    url = "https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip"
281	    md5 = "58c8d27c78d21e728a6bc7b3cc06412e"

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:341
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
340	                extract_archive(os.path.join(gzip_folder, gzip_file), self.raw_folder)
341	        shutil.rmtree(gzip_folder)
342	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:378
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
377	            (
378	                "https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-images-idx3-ubyte.gz",
379	                "ed72d4157d28c017586c42bc6afe6370",
380	            ),
381	            (
382	                "https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-labels-idx2-int.gz",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:382
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
381	            (
382	                "https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-labels-idx2-int.gz",
383	                "0058f8dd561b90ffdd0f734c6a30e5e4",
384	            ),
385	        ],

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:388
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
387	            (
388	                "https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-images-idx3-ubyte.gz",
389	                "1394631089c404de565df7b7aeaf9412",
390	            ),
391	            (
392	                "https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-labels-idx2-int.gz",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:392
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
391	            (
392	                "https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-labels-idx2-int.gz",
393	                "5b5b05890a5e13444e108efe57b788aa",
394	            ),
395	        ],

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:398
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
397	            (
398	                "https://raw.githubusercontent.com/facebookresearch/qmnist/master/xnist-images-idx3-ubyte.xz",
399	                "7f124b3b8ab81486c9d8c2749c17f834",
400	            ),
401	            (
402	                "https://raw.githubusercontent.com/facebookresearch/qmnist/master/xnist-labels-idx2-int.xz",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:402
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
401	            (
402	                "https://raw.githubusercontent.com/facebookresearch/qmnist/master/xnist-labels-idx2-int.xz",
403	                "5ed0e788978e45d4a8bd4b7caec3d79d",
404	            ),
405	        ],

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/mnist.py:514
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
513	    with open(path, "rb") as f:
514	        data = f.read()
515	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/moving_mnist.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
27	
28	    _URL = "http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy"
29	
30	    def __init__(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/omniglot.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	    folder = "omniglot-py"
29	    download_url_prefix = "https://raw.githubusercontent.com/brendenlake/omniglot/master/python"
30	    zips_md5 = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/oxford_iiit_pet.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
34	    _RESOURCES = (
35	        ("https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz", "5c4f3ee8e5d25df40f4fd59a7f44e54c"),
36	        ("https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz", "95a8c909bbe2e81eed6a22bccdf3f68f"),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/oxford_iiit_pet.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	        ("https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz", "5c4f3ee8e5d25df40f4fd59a7f44e54c"),
36	        ("https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz", "95a8c909bbe2e81eed6a22bccdf3f68f"),
37	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/phototour.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	        "notredame_harris": [
40	            "http://matthewalunbrown.com/patchdata/notredame_harris.zip",
41	            "notredame_harris.zip",
42	            "69f8c90f78e171349abdf0307afefe4d",
43	        ],
44	        "yosemite_harris": [
45	            "http://matthewalunbrown.com/patchdata/yosemite_harris.zip",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/phototour.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	        "yosemite_harris": [
45	            "http://matthewalunbrown.com/patchdata/yosemite_harris.zip",
46	            "yosemite_harris.zip",
47	            "a73253d1c6fbd3ba2613c45065c00d46",
48	        ],
49	        "liberty_harris": [
50	            "http://matthewalunbrown.com/patchdata/liberty_harris.zip",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/phototour.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	        "liberty_harris": [
50	            "http://matthewalunbrown.com/patchdata/liberty_harris.zip",
51	            "liberty_harris.zip",
52	            "c731fcfb3abb4091110d0ae8c7ba182c",
53	        ],
54	        "notredame": [
55	            "http://icvl.ee.ic.ac.uk/vbalnt/notredame.zip",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/phototour.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
54	        "notredame": [
55	            "http://icvl.ee.ic.ac.uk/vbalnt/notredame.zip",
56	            "notredame.zip",
57	            "509eda8535847b8c0a90bbb210c83484",
58	        ],
59	        "yosemite": ["http://icvl.ee.ic.ac.uk/vbalnt/yosemite.zip", "yosemite.zip", "533b2e8eb7ede31be40abc317b2fd4f0"],
60	        "liberty": ["http://icvl.ee.ic.ac.uk/vbalnt/liberty.zip", "liberty.zip", "fdd9152f138ea5ef2091746689176414"],

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/phototour.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
58	        ],
59	        "yosemite": ["http://icvl.ee.ic.ac.uk/vbalnt/yosemite.zip", "yosemite.zip", "533b2e8eb7ede31be40abc317b2fd4f0"],
60	        "liberty": ["http://icvl.ee.ic.ac.uk/vbalnt/liberty.zip", "liberty.zip", "fdd9152f138ea5ef2091746689176414"],

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/phototour.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
59	        "yosemite": ["http://icvl.ee.ic.ac.uk/vbalnt/yosemite.zip", "yosemite.zip", "533b2e8eb7ede31be40abc317b2fd4f0"],
60	        "liberty": ["http://icvl.ee.ic.ac.uk/vbalnt/liberty.zip", "liberty.zip", "fdd9152f138ea5ef2091746689176414"],
61	    }

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/places365.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	    _SPLITS = ("train-standard", "train-challenge", "val")
40	    _BASE_URL = "http://data.csail.mit.edu/places/places365/"
41	    # {variant: (archive, md5)}
42	    _DEVKIT_META = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/rendered_sst2.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
32	
33	    _URL = "https://openaipublic.azureedge.net/clip/data/rendered-sst2.tgz"
34	    _MD5 = "2384d08e9dcfa4bd55b324e610496ee5"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/sbd.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	
45	    url = "https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz"
46	    md5 = "82b4d87ceb2ed10f6038a1cba92111cb"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/sbd.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
48	
49	    voc_train_url = "https://www.cs.cornell.edu/~bharathh/train_noval.txt"
50	    voc_split_filename = "train_noval.txt"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/sbu.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	    url = "https://www.cs.rice.edu/~vo9/sbucaptions/SBUCaptionedPhotoDataset.tar.gz"
27	    filename = "SBUCaptionedPhotoDataset.tar.gz"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/semeion.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
26	    """
27	    url = "http://archive.ics.uci.edu/ml/machine-learning-databases/semeion/semeion.data"
28	    filename = "semeion.data"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/stanford_cars.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
72	            raise RuntimeError(
73	                "Dataset not found. Try to manually download following the instructions in "
74	                "https://github.com/pytorch/vision/issues/7545#issuecomment-1631441616."
75	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/stanford_cars.py:110
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
109	        raise ValueError(
110	            "The original URL is broken so the StanfordCars dataset is not available for automatic "
111	            "download anymore. You can try to download it manually following "
112	            "https://github.com/pytorch/vision/issues/7545#issuecomment-1631441616, "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/stl10.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
32	    base_folder = "stl10_binary"
33	    url = "http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz"
34	    filename = "stl10_binary.tar.gz"

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/stl10.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
88	            with open(class_file) as f:
89	                self.classes = f.read().splitlines()
90	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/stl10.py:170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
169	        with open(path_to_folds) as f:
170	            str_idx = f.read().splitlines()[folds]
171	            list_idx = np.fromstring(str_idx, dtype=np.int64, sep=" ")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/sun397.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	
26	    _DATASET_URL = "http://vision.princeton.edu/projects/2010/SUN/SUN397.tar.gz"
27	    _DATASET_MD5 = "8ca2778205c41d23104230ba66911c7a"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/svhn.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
37	        "train": [
38	            "http://ufldl.stanford.edu/housenumbers/train_32x32.mat",
39	            "train_32x32.mat",
40	            "e26dedcc434d2e4c54c9b2d4a06d8373",
41	        ],
42	        "test": [
43	            "http://ufldl.stanford.edu/housenumbers/test_32x32.mat",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/svhn.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	        "test": [
43	            "http://ufldl.stanford.edu/housenumbers/test_32x32.mat",
44	            "test_32x32.mat",
45	            "eb5a983be6a315427106f1b164d9cef3",
46	        ],
47	        "extra": [
48	            "http://ufldl.stanford.edu/housenumbers/extra_32x32.mat",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/svhn.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
47	        "extra": [
48	            "http://ufldl.stanford.edu/housenumbers/extra_32x32.mat",
49	            "extra_32x32.mat",
50	            "a93ce644f1a588dc4d68dda5feec44a7",
51	        ],
52	    }

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/usps.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
33	        "train": [
34	            "https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2",
35	            "usps.bz2",
36	            "ec16c51db3855ca6c91edd34d0e9b197",
37	        ],
38	        "test": [
39	            "https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/usps.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	        "test": [
39	            "https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2",
40	            "usps.t.bz2",
41	            "8ea070ee2aca1ac39742fdd1ef5ed118",
42	        ],
43	    }

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
27	def _urlretrieve(url: str, filename: Union[str, pathlib.Path], chunk_size: int = 1024 * 32) -> None:
28	    with urllib.request.urlopen(urllib.request.Request(url, headers={"User-Agent": USER_AGENT})) as response:
29	        with open(filename, "wb") as fh, tqdm(total=response.length, unit="B", unit_scale=True) as pbar:

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
27	def _urlretrieve(url: str, filename: Union[str, pathlib.Path], chunk_size: int = 1024 * 32) -> None:
28	    with urllib.request.urlopen(urllib.request.Request(url, headers={"User-Agent": USER_AGENT})) as response:
29	        with open(filename, "wb") as fh, tqdm(total=response.length, unit="B", unit_scale=True) as pbar:

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
28	    with urllib.request.urlopen(urllib.request.Request(url, headers={"User-Agent": USER_AGENT})) as response:
29	        with open(filename, "wb") as fh, tqdm(total=response.length, unit="B", unit_scale=True) as pbar:
30	            while chunk := response.read(chunk_size):

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
29	        with open(filename, "wb") as fh, tqdm(total=response.length, unit="B", unit_scale=True) as pbar:
30	            while chunk := response.read(chunk_size):
31	                fh.write(chunk)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
30	            while chunk := response.read(chunk_size):
31	                fh.write(chunk)
32	                pbar.update(len(chunk))

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
42	        md5 = hashlib.md5()
43	    with open(fpath, "rb") as f:
44	        while chunk := f.read(chunk_size):

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
43	    with open(fpath, "rb") as f:
44	        while chunk := f.read(chunk_size):
45	            md5.update(chunk)

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
65	    for _ in range(max_hops + 1):
66	        with urllib.request.urlopen(urllib.request.Request(url, headers=headers)) as response:
67	            if response.url == url or response.url is None:

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
65	    for _ in range(max_hops + 1):
66	        with urllib.request.urlopen(urllib.request.Request(url, headers=headers)) as response:
67	            if response.url == url or response.url is None:

--------------------------------------------------
>> Issue: [B819:urlretrieve] urllib.request.urlretrieve
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b819_urlretrieve.html
129	        try:
130	            _urlretrieve(url, fpath)
131	        except (urllib.error.URLError, OSError) as e:  # type: ignore[attr-defined]

--------------------------------------------------
>> Issue: [B819:urlretrieve] urllib.request.urlretrieve
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:134
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b819_urlretrieve.html
133	                url = url.replace("https:", "http:")
134	                _urlretrieve(url, fpath)
135	            else:

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:215
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
214	) -> None:
215	    with tarfile.open(from_path, f"r:{compression[1:]}" if compression else "r") as tar:
216	        tar.extractall(to_path)

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:320
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
319	
320	    with compressed_file_opener(from_path, "rb") as rfh, open(to_path, "wb") as wfh:
321	        wfh.write(rfh.read())

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:321
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
320	    with compressed_file_opener(from_path, "rb") as rfh, open(to_path, "wb") as wfh:
321	        wfh.write(rfh.read())
322	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:321
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
320	    with compressed_file_opener(from_path, "rb") as rfh, open(to_path, "wb") as wfh:
321	        wfh.write(rfh.read())
322	

--------------------------------------------------
>> Issue: [B834:open] tarfile.open
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/utils.py:441
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b834_open.html
440	
441	    with open(file_name, "rb") as f:
442	        header = f.readline().rstrip()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/voc.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
18	    "2012": {
19	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar",
20	        "filename": "VOCtrainval_11-May-2012.tar",
21	        "md5": "6cd6e144f989b92b3379bac3b3de84fd",
22	        "base_dir": os.path.join("VOCdevkit", "VOC2012"),
23	    },
24	    "2011": {
25	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2011/VOCtrainval_25-May-2011.tar",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/voc.py:25
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
24	    "2011": {
25	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2011/VOCtrainval_25-May-2011.tar",
26	        "filename": "VOCtrainval_25-May-2011.tar",
27	        "md5": "6c3384ef61512963050cb5d687e5bf1e",
28	        "base_dir": os.path.join("TrainVal", "VOCdevkit", "VOC2011"),
29	    },
30	    "2010": {
31	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2010/VOCtrainval_03-May-2010.tar",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/voc.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
30	    "2010": {
31	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2010/VOCtrainval_03-May-2010.tar",
32	        "filename": "VOCtrainval_03-May-2010.tar",
33	        "md5": "da459979d0c395079b5c75ee67908abb",
34	        "base_dir": os.path.join("VOCdevkit", "VOC2010"),
35	    },
36	    "2009": {
37	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/voc.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	    "2009": {
37	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar",
38	        "filename": "VOCtrainval_11-May-2009.tar",
39	        "md5": "a3e00b113cfcfebf17e343f59da3caa1",
40	        "base_dir": os.path.join("VOCdevkit", "VOC2009"),
41	    },
42	    "2008": {
43	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2008/VOCtrainval_14-Jul-2008.tar",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/voc.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	    "2008": {
43	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2008/VOCtrainval_14-Jul-2008.tar",
44	        "filename": "VOCtrainval_11-May-2012.tar",
45	        "md5": "2629fa636546599198acfcfbfcf1904a",
46	        "base_dir": os.path.join("VOCdevkit", "VOC2008"),
47	    },
48	    "2007": {
49	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/voc.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
48	    "2007": {
49	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar",
50	        "filename": "VOCtrainval_06-Nov-2007.tar",
51	        "md5": "c52e279531787c972589f7e41ab4ae64",
52	        "base_dir": os.path.join("VOCdevkit", "VOC2007"),
53	    },
54	    "2007-test": {
55	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/voc.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
54	    "2007-test": {
55	        "url": "http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar",
56	        "filename": "VOCtest_06-Nov-2007.tar",
57	        "md5": "b6e924de25625d8de591ea690078ad9f",
58	        "base_dir": os.path.join("VOCdevkit", "VOC2007"),
59	    },
60	}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/datasets/widerface.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
52	    ANNOTATIONS_FILE = (
53	        "http://shuoyang1213.me/WIDERFACE/support/bbx_annotation/wider_face_split.zip",
54	        "0e3767bcf0e326556d407bf5bff5d27c",
55	        "wider_face_split.zip",
56	    )
57	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/extension.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	        raise RuntimeError(
47	            "Couldn't load custom C++ ops. This can happen if your PyTorch and "
48	            "torchvision versions are incompatible, or if you had errors while compiling "
49	            "torchvision from source. For further information on the compatible versions, check "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/io/image.py:426
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
425	        raise RuntimeError(
426	            "In order to enable the AVIF and HEIC decoding capabilities of "
427	            "torchvision, you need to `pip install torchvision-extra-decoders`. "
428	            "Just install the package, you don't need to update your code. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/io/video.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
20	        av = ImportError(
21	            """\
22	Your version of PyAV is too old for the necessary video operations in torchvision.
23	If you are on Python 3.5, you will have to build from source (the conda-forge

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/io/video.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
34	    av = ImportError(
35	        """\
36	PyAV is not installed, and is necessary for the video operations in torchvision.
37	See https://github.com/mikeboers/PyAV#installation for instructions on how to

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/io/video_reader.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	        av = ImportError(
29	            """\
30	Your version of PyAV is too old for the necessary video operations in torchvision.
31	If you are on Python 3.5, you will have to build from source (the conda-forge

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/io/video_reader.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	    av = ImportError(
39	        """\
40	PyAV is not installed, and is necessary for the video operations in torchvision.
41	See https://github.com/mikeboers/PyAV#installation for instructions on how to

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/alexnet.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	    IMAGENET1K_V1 = Weights(
57	        url="https://download.pytorch.org/models/alexnet-owt-7be5be79.pth",
58	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/alexnet.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
62	            "categories": _IMAGENET_CATEGORIES,
63	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg",
64	            "_metrics": {
65	                "ImageNet-1K": {
66	                    "acc@1": 56.522,
67	                    "acc@5": 79.066,
68	                }
69	            },
70	            "_ops": 0.714,
71	            "_file_size": 233.087,
72	            "_docs": """
73	                These weights reproduce closely the results of the paper using a simplified training recipe.
74	            """,
75	        },
76	    )
77	    DEFAULT = IMAGENET1K_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/convnext.py:200
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
199	    "categories": _IMAGENET_CATEGORIES,
200	    "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#convnext",
201	    "_docs": """
202	        These weights improve upon the results of the original paper by using a modified version of TorchVision's
203	        `new training recipe
204	        <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
205	    """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/convnext.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
200	    "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#convnext",
201	    "_docs": """
202	        These weights improve upon the results of the original paper by using a modified version of TorchVision's
203	        `new training recipe
204	        <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
205	    """,
206	}

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/convnext.py:211
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
210	    IMAGENET1K_V1 = Weights(
211	        url="https://download.pytorch.org/models/convnext_tiny-983f1562.pth",
212	        transforms=partial(ImageClassification, crop_size=224, resize_size=236),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/convnext.py:231
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
230	    IMAGENET1K_V1 = Weights(
231	        url="https://download.pytorch.org/models/convnext_small-0c510722.pth",
232	        transforms=partial(ImageClassification, crop_size=224, resize_size=230),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/convnext.py:251
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
250	    IMAGENET1K_V1 = Weights(
251	        url="https://download.pytorch.org/models/convnext_base-6075fbad.pth",
252	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/convnext.py:271
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
270	    IMAGENET1K_V1 = Weights(
271	        url="https://download.pytorch.org/models/convnext_large-ea097f82.pth",
272	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/densenet.py:262
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
261	    "categories": _IMAGENET_CATEGORIES,
262	    "recipe": "https://github.com/pytorch/vision/pull/116",
263	    "_docs": """These weights are ported from LuaTorch.""",
264	}
265	
266	
267	class DenseNet121_Weights(WeightsEnum):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/densenet.py:269
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
268	    IMAGENET1K_V1 = Weights(
269	        url="https://download.pytorch.org/models/densenet121-a639ec97.pth",
270	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/densenet.py:289
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
288	    IMAGENET1K_V1 = Weights(
289	        url="https://download.pytorch.org/models/densenet161-8d451a50.pth",
290	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/densenet.py:309
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
308	    IMAGENET1K_V1 = Weights(
309	        url="https://download.pytorch.org/models/densenet169-b2777c0a.pth",
310	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/densenet.py:329
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
328	    IMAGENET1K_V1 = Weights(
329	        url="https://download.pytorch.org/models/densenet201-c1103571.pth",
330	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/faster_rcnn.py:383
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
382	    COCO_V1 = Weights(
383	        url="https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth",
384	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/faster_rcnn.py:388
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
387	            "num_params": 41755286,
388	            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#faster-r-cnn-resnet-50-fpn",
389	            "_metrics": {
390	                "COCO-val2017": {
391	                    "box_map": 37.0,
392	                }
393	            },
394	            "_ops": 134.38,
395	            "_file_size": 159.743,
396	            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
397	        },
398	    )
399	    DEFAULT = COCO_V1
400	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/faster_rcnn.py:404
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
403	    COCO_V1 = Weights(
404	        url="https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth",
405	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/faster_rcnn.py:409
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
408	            "num_params": 43712278,
409	            "recipe": "https://github.com/pytorch/vision/pull/5763",
410	            "_metrics": {
411	                "COCO-val2017": {
412	                    "box_map": 46.7,
413	                }
414	            },
415	            "_ops": 280.371,
416	            "_file_size": 167.104,
417	            "_docs": """These weights were produced using an enhanced training recipe to boost the model accuracy.""",
418	        },
419	    )
420	    DEFAULT = COCO_V1
421	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/faster_rcnn.py:425
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
424	    COCO_V1 = Weights(
425	        url="https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth",
426	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/faster_rcnn.py:430
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
429	            "num_params": 19386354,
430	            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#faster-r-cnn-mobilenetv3-large-fpn",
431	            "_metrics": {
432	                "COCO-val2017": {
433	                    "box_map": 32.8,
434	                }
435	            },
436	            "_ops": 4.494,
437	            "_file_size": 74.239,
438	            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
439	        },
440	    )
441	    DEFAULT = COCO_V1
442	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/faster_rcnn.py:446
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
445	    COCO_V1 = Weights(
446	        url="https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_320_fpn-907ea3f9.pth",
447	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/faster_rcnn.py:451
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
450	            "num_params": 19386354,
451	            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#faster-r-cnn-mobilenetv3-large-320-fpn",
452	            "_metrics": {
453	                "COCO-val2017": {
454	                    "box_map": 22.8,
455	                }
456	            },
457	            "_ops": 0.719,
458	            "_file_size": 74.239,
459	            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
460	        },
461	    )
462	    DEFAULT = COCO_V1
463	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/fcos.py:657
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
656	    COCO_V1 = Weights(
657	        url="https://download.pytorch.org/models/fcos_resnet50_fpn_coco-99b0c9b7.pth",
658	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/fcos.py:663
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
662	            "min_size": (1, 1),
663	            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#fcos-resnet-50-fpn",
664	            "_metrics": {
665	                "COCO-val2017": {
666	                    "box_map": 39.2,
667	                }
668	            },
669	            "_ops": 128.207,
670	            "_file_size": 123.608,
671	            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
672	        },
673	    )
674	    DEFAULT = COCO_V1
675	
676	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/keypoint_rcnn.py:321
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
320	    COCO_LEGACY = Weights(
321	        url="https://download.pytorch.org/models/keypointrcnn_resnet50_fpn_coco-9f466800.pth",
322	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/keypoint_rcnn.py:326
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
325	            "num_params": 59137258,
326	            "recipe": "https://github.com/pytorch/vision/issues/1606",
327	            "_metrics": {
328	                "COCO-val2017": {
329	                    "box_map": 50.6,
330	                    "kp_map": 61.1,
331	                }
332	            },
333	            "_ops": 133.924,
334	            "_file_size": 226.054,
335	            "_docs": """
336	                These weights were produced by following a similar training recipe as on the paper but use a checkpoint
337	                from an early epoch.
338	            """,
339	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/keypoint_rcnn.py:342
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
341	    COCO_V1 = Weights(
342	        url="https://download.pytorch.org/models/keypointrcnn_resnet50_fpn_coco-fc266e95.pth",
343	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/keypoint_rcnn.py:347
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
346	            "num_params": 59137258,
347	            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#keypoint-r-cnn",
348	            "_metrics": {
349	                "COCO-val2017": {
350	                    "box_map": 54.6,
351	                    "kp_map": 65.0,
352	                }
353	            },
354	            "_ops": 137.42,
355	            "_file_size": 226.054,
356	            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
357	        },
358	    )
359	    DEFAULT = COCO_V1
360	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/mask_rcnn.py:364
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
363	    COCO_V1 = Weights(
364	        url="https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth",
365	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/mask_rcnn.py:369
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
368	            "num_params": 44401393,
369	            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#mask-r-cnn",
370	            "_metrics": {
371	                "COCO-val2017": {
372	                    "box_map": 37.9,
373	                    "mask_map": 34.6,
374	                }
375	            },
376	            "_ops": 134.38,
377	            "_file_size": 169.84,
378	            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
379	        },
380	    )
381	    DEFAULT = COCO_V1
382	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/mask_rcnn.py:386
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
385	    COCO_V1 = Weights(
386	        url="https://download.pytorch.org/models/maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth",
387	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/mask_rcnn.py:391
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
390	            "num_params": 46359409,
391	            "recipe": "https://github.com/pytorch/vision/pull/5773",
392	            "_metrics": {
393	                "COCO-val2017": {
394	                    "box_map": 47.4,
395	                    "mask_map": 41.8,
396	                }
397	            },
398	            "_ops": 333.577,
399	            "_file_size": 177.219,
400	            "_docs": """These weights were produced using an enhanced training recipe to boost the model accuracy.""",
401	        },
402	    )
403	    DEFAULT = COCO_V1
404	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/retinanet.py:686
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
685	    COCO_V1 = Weights(
686	        url="https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth",
687	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/retinanet.py:691
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
690	            "num_params": 34014999,
691	            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#retinanet",
692	            "_metrics": {
693	                "COCO-val2017": {
694	                    "box_map": 36.4,
695	                }
696	            },
697	            "_ops": 151.54,
698	            "_file_size": 130.267,
699	            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
700	        },
701	    )
702	    DEFAULT = COCO_V1
703	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/retinanet.py:707
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
706	    COCO_V1 = Weights(
707	        url="https://download.pytorch.org/models/retinanet_resnet50_fpn_v2_coco-5905b1c5.pth",
708	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/retinanet.py:712
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
711	            "num_params": 38198935,
712	            "recipe": "https://github.com/pytorch/vision/pull/5756",
713	            "_metrics": {
714	                "COCO-val2017": {
715	                    "box_map": 41.5,
716	                }
717	            },
718	            "_ops": 152.238,
719	            "_file_size": 146.037,
720	            "_docs": """These weights were produced using an enhanced training recipe to boost the model accuracy.""",
721	        },
722	    )
723	    DEFAULT = COCO_V1
724	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/ssd.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
29	    COCO_V1 = Weights(
30	        url="https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth",
31	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/ssd.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	            "min_size": (1, 1),
36	            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#ssd300-vgg16",
37	            "_metrics": {
38	                "COCO-val2017": {
39	                    "box_map": 25.1,
40	                }
41	            },
42	            "_ops": 34.858,
43	            "_file_size": 135.988,
44	            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
45	        },
46	    )
47	    DEFAULT = COCO_V1
48	
49	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/ssdlite.py:189
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
188	    COCO_V1 = Weights(
189	        url="https://download.pytorch.org/models/ssdlite320_mobilenet_v3_large_coco-a79551df.pth",
190	        transforms=ObjectDetection,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/detection/ssdlite.py:195
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
194	            "min_size": (1, 1),
195	            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#ssdlite320-mobilenetv3-large",
196	            "_metrics": {
197	                "COCO-val2017": {
198	                    "box_map": 21.3,
199	                }
200	            },
201	            "_ops": 0.583,
202	            "_file_size": 13.418,
203	            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
204	        },
205	    )
206	    DEFAULT = COCO_V1
207	
208	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:428
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
427	    "min_size": (1, 1),
428	    "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v1",
429	}
430	
431	
432	_COMMON_META_V2 = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:435
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
434	    "min_size": (33, 33),
435	    "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v2",
436	}
437	
438	
439	class EfficientNet_B0_Weights(WeightsEnum):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:442
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
441	        # Weights ported from https://github.com/rwightman/pytorch-image-models/
442	        url="https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth",
443	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:466
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
465	        # Weights ported from https://github.com/rwightman/pytorch-image-models/
466	        url="https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth",
467	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:485
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
484	    IMAGENET1K_V2 = Weights(
485	        url="https://download.pytorch.org/models/efficientnet_b1-c27df63c.pth",
486	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:492
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
491	            "num_params": 7794184,
492	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-lr-wd-crop-tuning",
493	            "_metrics": {
494	                "ImageNet-1K": {
495	                    "acc@1": 79.838,
496	                    "acc@5": 94.934,
497	                }
498	            },
499	            "_ops": 0.687,
500	            "_file_size": 30.136,
501	            "_docs": """
502	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
503	                `new training recipe
504	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
505	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:501
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
500	            "_file_size": 30.136,
501	            "_docs": """
502	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
503	                `new training recipe
504	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
505	            """,
506	        },
507	    )
508	    DEFAULT = IMAGENET1K_V2
509	
510	
511	class EfficientNet_B2_Weights(WeightsEnum):
512	    IMAGENET1K_V1 = Weights(
513	        # Weights ported from https://github.com/rwightman/pytorch-image-models/
514	        url="https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:514
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
513	        # Weights ported from https://github.com/rwightman/pytorch-image-models/
514	        url="https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth",
515	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:538
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
537	        # Weights ported from https://github.com/rwightman/pytorch-image-models/
538	        url="https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth",
539	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:562
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
561	        # Weights ported from https://github.com/rwightman/pytorch-image-models/
562	        url="https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth",
563	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:586
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
585	        # Weights ported from https://github.com/lukemelas/EfficientNet-PyTorch/
586	        url="https://download.pytorch.org/models/efficientnet_b5_lukemelas-1a07897c.pth",
587	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:610
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
609	        # Weights ported from https://github.com/lukemelas/EfficientNet-PyTorch/
610	        url="https://download.pytorch.org/models/efficientnet_b6_lukemelas-24a108a5.pth",
611	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:634
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
633	        # Weights ported from https://github.com/lukemelas/EfficientNet-PyTorch/
634	        url="https://download.pytorch.org/models/efficientnet_b7_lukemelas-c5b4e57e.pth",
635	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:657
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
656	    IMAGENET1K_V1 = Weights(
657	        url="https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth",
658	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:675
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
674	            "_file_size": 82.704,
675	            "_docs": """
676	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
677	                `new training recipe
678	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
679	            """,
680	        },
681	    )
682	    DEFAULT = IMAGENET1K_V1
683	
684	
685	class EfficientNet_V2_M_Weights(WeightsEnum):
686	    IMAGENET1K_V1 = Weights(
687	        url="https://download.pytorch.org/models/efficientnet_v2_m-dc08266a.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:687
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
686	    IMAGENET1K_V1 = Weights(
687	        url="https://download.pytorch.org/models/efficientnet_v2_m-dc08266a.pth",
688	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:705
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
704	            "_file_size": 208.01,
705	            "_docs": """
706	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
707	                `new training recipe
708	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
709	            """,
710	        },
711	    )
712	    DEFAULT = IMAGENET1K_V1
713	
714	
715	class EfficientNet_V2_L_Weights(WeightsEnum):
716	    # Weights ported from https://github.com/google/automl/tree/master/efficientnetv2
717	    IMAGENET1K_V1 = Weights(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/efficientnet.py:718
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
717	    IMAGENET1K_V1 = Weights(
718	        url="https://download.pytorch.org/models/efficientnet_v2_l-59c71312.pth",
719	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/feature_extraction.py:538
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
537	            raise ValueError(
538	                "There are duplicate nodes! Please raise an issue https://github.com/pytorch/vision/issues"
539	            )
540	        # Check that all outputs in return_nodes are present in the model

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/googlenet.py:280
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
279	    IMAGENET1K_V1 = Weights(
280	        url="https://download.pytorch.org/models/googlenet-1378be20.pth",
281	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/googlenet.py:286
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
285	            "categories": _IMAGENET_CATEGORIES,
286	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#googlenet",
287	            "_metrics": {
288	                "ImageNet-1K": {
289	                    "acc@1": 69.778,
290	                    "acc@5": 89.530,
291	                }
292	            },
293	            "_ops": 1.498,
294	            "_file_size": 49.731,
295	            "_docs": """These weights are ported from the original paper.""",
296	        },
297	    )
298	    DEFAULT = IMAGENET1K_V1
299	
300	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/inception.py:412
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
411	    IMAGENET1K_V1 = Weights(
412	        url="https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth",
413	        transforms=partial(ImageClassification, crop_size=299, resize_size=342),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/inception.py:418
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
417	            "categories": _IMAGENET_CATEGORIES,
418	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#inception-v3",
419	            "_metrics": {
420	                "ImageNet-1K": {
421	                    "acc@1": 77.294,
422	                    "acc@5": 93.450,
423	                }
424	            },
425	            "_ops": 5.713,
426	            "_file_size": 103.903,
427	            "_docs": """These weights are ported from the original paper.""",
428	        },
429	    )
430	    DEFAULT = IMAGENET1K_V1
431	
432	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/maxvit.py:774
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
773	        # URL empty until official release
774	        url="https://download.pytorch.org/models/maxvit_t-bc5ab103.pth",
775	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/maxvit.py:782
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
781	            "min_size": (224, 224),
782	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#maxvit",
783	            "_metrics": {
784	                "ImageNet-1K": {
785	                    "acc@1": 83.700,
786	                    "acc@5": 96.722,
787	                }
788	            },
789	            "_ops": 5.558,
790	            "_file_size": 118.769,
791	            "_docs": """These weights reproduce closely the results of the paper using a similar training recipe.
792	            They were trained with a BatchNorm2D momentum of 0.99 instead of the more correct 0.01.""",
793	        },
794	    )
795	    DEFAULT = IMAGENET1K_V1
796	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mnasnet.py:217
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
216	    "categories": _IMAGENET_CATEGORIES,
217	    "recipe": "https://github.com/1e100/mnasnet_trainer",
218	}
219	
220	
221	class MNASNet0_5_Weights(WeightsEnum):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mnasnet.py:223
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
222	    IMAGENET1K_V1 = Weights(
223	        url="https://download.pytorch.org/models/mnasnet0.5_top1_67.823-3ffadce67e.pth",
224	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mnasnet.py:244
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
243	    IMAGENET1K_V1 = Weights(
244	        url="https://download.pytorch.org/models/mnasnet0_75-7090bc5f.pth",
245	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mnasnet.py:248
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
247	            **_COMMON_META,
248	            "recipe": "https://github.com/pytorch/vision/pull/6019",
249	            "num_params": 3170208,
250	            "_metrics": {
251	                "ImageNet-1K": {
252	                    "acc@1": 71.180,
253	                    "acc@5": 90.496,
254	                }
255	            },
256	            "_ops": 0.215,
257	            "_file_size": 12.303,
258	            "_docs": """
259	                These weights were trained from scratch by using TorchVision's `new training recipe
260	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
261	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mnasnet.py:258
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
257	            "_file_size": 12.303,
258	            "_docs": """
259	                These weights were trained from scratch by using TorchVision's `new training recipe
260	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
261	            """,
262	        },
263	    )
264	    DEFAULT = IMAGENET1K_V1
265	
266	
267	class MNASNet1_0_Weights(WeightsEnum):
268	    IMAGENET1K_V1 = Weights(
269	        url="https://download.pytorch.org/models/mnasnet1.0_top1_73.512-f206786ef8.pth",
270	        transforms=partial(ImageClassification, crop_size=224),
271	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mnasnet.py:269
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
268	    IMAGENET1K_V1 = Weights(
269	        url="https://download.pytorch.org/models/mnasnet1.0_top1_73.512-f206786ef8.pth",
270	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mnasnet.py:290
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
289	    IMAGENET1K_V1 = Weights(
290	        url="https://download.pytorch.org/models/mnasnet1_3-a4c69d6f.pth",
291	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mnasnet.py:294
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
293	            **_COMMON_META,
294	            "recipe": "https://github.com/pytorch/vision/pull/6019",
295	            "num_params": 6282256,
296	            "_metrics": {
297	                "ImageNet-1K": {
298	                    "acc@1": 76.506,
299	                    "acc@5": 93.522,
300	                }
301	            },
302	            "_ops": 0.526,
303	            "_file_size": 24.246,
304	            "_docs": """
305	                These weights were trained from scratch by using TorchVision's `new training recipe
306	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
307	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mnasnet.py:304
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
303	            "_file_size": 24.246,
304	            "_docs": """
305	                These weights were trained from scratch by using TorchVision's `new training recipe
306	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
307	            """,
308	        },
309	    )
310	    DEFAULT = IMAGENET1K_V1
311	
312	
313	def _mnasnet(alpha: float, weights: Optional[WeightsEnum], progress: bool, **kwargs: Any) -> MNASNet:
314	    if weights is not None:
315	        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))
316	
317	    model = MNASNet(alpha, **kwargs)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv2.py:186
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
185	    IMAGENET1K_V1 = Weights(
186	        url="https://download.pytorch.org/models/mobilenet_v2-b0353104.pth",
187	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv2.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
189	            **_COMMON_META,
190	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#mobilenetv2",
191	            "_metrics": {
192	                "ImageNet-1K": {
193	                    "acc@1": 71.878,
194	                    "acc@5": 90.286,
195	                }
196	            },
197	            "_ops": 0.301,
198	            "_file_size": 13.555,
199	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
200	        },
201	    )
202	    IMAGENET1K_V2 = Weights(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv2.py:203
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
202	    IMAGENET1K_V2 = Weights(
203	        url="https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth",
204	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv2.py:207
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
206	            **_COMMON_META,
207	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-reg-tuning",
208	            "_metrics": {
209	                "ImageNet-1K": {
210	                    "acc@1": 72.154,
211	                    "acc@5": 90.822,
212	                }
213	            },
214	            "_ops": 0.301,
215	            "_file_size": 13.598,
216	            "_docs": """
217	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
218	                `new training recipe
219	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv2.py:216
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
215	            "_file_size": 13.598,
216	            "_docs": """
217	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
218	                `new training recipe
219	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
220	            """,
221	        },
222	    )
223	    DEFAULT = IMAGENET1K_V2
224	
225	
226	@register_model()
227	@handle_legacy_interface(weights=("pretrained", MobileNet_V2_Weights.IMAGENET1K_V1))
228	def mobilenet_v2(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv3.py:298
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
297	    IMAGENET1K_V1 = Weights(
298	        url="https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth",
299	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv3.py:303
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
302	            "num_params": 5483032,
303	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#mobilenetv3-large--small",
304	            "_metrics": {
305	                "ImageNet-1K": {
306	                    "acc@1": 74.042,
307	                    "acc@5": 91.340,
308	                }
309	            },
310	            "_ops": 0.217,
311	            "_file_size": 21.114,
312	            "_docs": """These weights were trained from scratch by using a simple training recipe.""",
313	        },
314	    )
315	    IMAGENET1K_V2 = Weights(
316	        url="https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv3.py:316
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
315	    IMAGENET1K_V2 = Weights(
316	        url="https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth",
317	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv3.py:321
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
320	            "num_params": 5483032,
321	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-reg-tuning",
322	            "_metrics": {
323	                "ImageNet-1K": {
324	                    "acc@1": 75.274,
325	                    "acc@5": 92.566,
326	                }
327	            },
328	            "_ops": 0.217,
329	            "_file_size": 21.107,
330	            "_docs": """
331	                These weights improve marginally upon the results of the original paper by using a modified version of
332	                TorchVision's `new training recipe
333	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
334	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv3.py:330
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
329	            "_file_size": 21.107,
330	            "_docs": """
331	                These weights improve marginally upon the results of the original paper by using a modified version of
332	                TorchVision's `new training recipe
333	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
334	            """,
335	        },
336	    )
337	    DEFAULT = IMAGENET1K_V2
338	
339	
340	class MobileNet_V3_Small_Weights(WeightsEnum):
341	    IMAGENET1K_V1 = Weights(
342	        url="https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth",
343	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv3.py:342
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
341	    IMAGENET1K_V1 = Weights(
342	        url="https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth",
343	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/mobilenetv3.py:347
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
346	            "num_params": 2542856,
347	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#mobilenetv3-large--small",
348	            "_metrics": {
349	                "ImageNet-1K": {
350	                    "acc@1": 67.668,
351	                    "acc@5": 87.402,
352	                }
353	            },
354	            "_ops": 0.057,
355	            "_file_size": 9.829,
356	            "_docs": """
357	                These weights improve upon the results of the original paper by using a simple training recipe.
358	            """,
359	        },
360	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:557
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
556	        # Weights ported from https://github.com/princeton-vl/RAFT
557	        url="https://download.pytorch.org/models/raft_large_C_T_V1-22a6c225.pth",
558	        transforms=OpticalFlow,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:562
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
561	            "num_params": 5257536,
562	            "recipe": "https://github.com/princeton-vl/RAFT",
563	            "_metrics": {
564	                "Sintel-Train-Cleanpass": {"epe": 1.4411},
565	                "Sintel-Train-Finalpass": {"epe": 2.7894},
566	                "Kitti-Train": {"per_image_epe": 5.0172, "fl_all": 17.4506},
567	            },
568	            "_ops": 211.007,
569	            "_file_size": 20.129,
570	            "_docs": """These weights were ported from the original paper. They
571	            are trained on :class:`~torchvision.datasets.FlyingChairs` +
572	            :class:`~torchvision.datasets.FlyingThings3D`.""",
573	        },
574	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:577
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
576	    C_T_V2 = Weights(
577	        url="https://download.pytorch.org/models/raft_large_C_T_V2-1bb1363a.pth",
578	        transforms=OpticalFlow,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:582
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
581	            "num_params": 5257536,
582	            "recipe": "https://github.com/pytorch/vision/tree/main/references/optical_flow",
583	            "_metrics": {
584	                "Sintel-Train-Cleanpass": {"epe": 1.3822},
585	                "Sintel-Train-Finalpass": {"epe": 2.7161},
586	                "Kitti-Train": {"per_image_epe": 4.5118, "fl_all": 16.0679},
587	            },
588	            "_ops": 211.007,
589	            "_file_size": 20.129,
590	            "_docs": """These weights were trained from scratch on
591	            :class:`~torchvision.datasets.FlyingChairs` +
592	            :class:`~torchvision.datasets.FlyingThings3D`.""",
593	        },
594	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:598
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
597	        # Weights ported from https://github.com/princeton-vl/RAFT
598	        url="https://download.pytorch.org/models/raft_large_C_T_SKHT_V1-0b8c9e55.pth",
599	        transforms=OpticalFlow,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:603
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
602	            "num_params": 5257536,
603	            "recipe": "https://github.com/princeton-vl/RAFT",
604	            "_metrics": {
605	                "Sintel-Test-Cleanpass": {"epe": 1.94},
606	                "Sintel-Test-Finalpass": {"epe": 3.18},
607	            },
608	            "_ops": 211.007,
609	            "_file_size": 20.129,
610	            "_docs": """
611	                These weights were ported from the original paper. They are
612	                trained on :class:`~torchvision.datasets.FlyingChairs` +
613	                :class:`~torchvision.datasets.FlyingThings3D` and fine-tuned on
614	                Sintel. The Sintel fine-tuning step is a combination of

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:624
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
623	    C_T_SKHT_V2 = Weights(
624	        url="https://download.pytorch.org/models/raft_large_C_T_SKHT_V2-ff5fadd5.pth",
625	        transforms=OpticalFlow,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:629
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
628	            "num_params": 5257536,
629	            "recipe": "https://github.com/pytorch/vision/tree/main/references/optical_flow",
630	            "_metrics": {
631	                "Sintel-Test-Cleanpass": {"epe": 1.819},
632	                "Sintel-Test-Finalpass": {"epe": 3.067},
633	            },
634	            "_ops": 211.007,
635	            "_file_size": 20.129,
636	            "_docs": """
637	                These weights were trained from scratch. They are
638	                pre-trained on :class:`~torchvision.datasets.FlyingChairs` +
639	                :class:`~torchvision.datasets.FlyingThings3D` and then
640	                fine-tuned on Sintel. The Sintel fine-tuning step is a

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:651
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
650	        # Weights ported from https://github.com/princeton-vl/RAFT
651	        url="https://download.pytorch.org/models/raft_large_C_T_SKHT_K_V1-4a6a5039.pth",
652	        transforms=OpticalFlow,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:656
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
655	            "num_params": 5257536,
656	            "recipe": "https://github.com/princeton-vl/RAFT",
657	            "_metrics": {
658	                "Kitti-Test": {"fl_all": 5.10},
659	            },
660	            "_ops": 211.007,
661	            "_file_size": 20.129,
662	            "_docs": """
663	                These weights were ported from the original paper. They are
664	                pre-trained on :class:`~torchvision.datasets.FlyingChairs` +
665	                :class:`~torchvision.datasets.FlyingThings3D`,
666	                fine-tuned on Sintel, and then fine-tuned on

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:674
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
673	    C_T_SKHT_K_V2 = Weights(
674	        url="https://download.pytorch.org/models/raft_large_C_T_SKHT_K_V2-b5c70766.pth",
675	        transforms=OpticalFlow,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:679
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
678	            "num_params": 5257536,
679	            "recipe": "https://github.com/pytorch/vision/tree/main/references/optical_flow",
680	            "_metrics": {
681	                "Kitti-Test": {"fl_all": 5.19},
682	            },
683	            "_ops": 211.007,
684	            "_file_size": 20.129,
685	            "_docs": """
686	                These weights were trained from scratch. They are
687	                pre-trained on :class:`~torchvision.datasets.FlyingChairs` +
688	                :class:`~torchvision.datasets.FlyingThings3D`,
689	                fine-tuned on Sintel, and then fine-tuned on

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:715
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
714	        # Weights ported from https://github.com/princeton-vl/RAFT
715	        url="https://download.pytorch.org/models/raft_small_C_T_V1-ad48884c.pth",
716	        transforms=OpticalFlow,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:720
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
719	            "num_params": 990162,
720	            "recipe": "https://github.com/princeton-vl/RAFT",
721	            "_metrics": {
722	                "Sintel-Train-Cleanpass": {"epe": 2.1231},
723	                "Sintel-Train-Finalpass": {"epe": 3.2790},
724	                "Kitti-Train": {"per_image_epe": 7.6557, "fl_all": 25.2801},
725	            },
726	            "_ops": 47.655,
727	            "_file_size": 3.821,
728	            "_docs": """These weights were ported from the original paper. They
729	            are trained on :class:`~torchvision.datasets.FlyingChairs` +
730	            :class:`~torchvision.datasets.FlyingThings3D`.""",
731	        },
732	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:734
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
733	    C_T_V2 = Weights(
734	        url="https://download.pytorch.org/models/raft_small_C_T_V2-01064c6d.pth",
735	        transforms=OpticalFlow,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/optical_flow/raft.py:739
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
738	            "num_params": 990162,
739	            "recipe": "https://github.com/pytorch/vision/tree/main/references/optical_flow",
740	            "_metrics": {
741	                "Sintel-Train-Cleanpass": {"epe": 1.9901},
742	                "Sintel-Train-Finalpass": {"epe": 3.2831},
743	                "Kitti-Train": {"per_image_epe": 7.5978, "fl_all": 25.2369},
744	            },
745	            "_ops": 47.655,
746	            "_file_size": 3.821,
747	            "_docs": """These weights were trained from scratch on
748	            :class:`~torchvision.datasets.FlyingChairs` +
749	            :class:`~torchvision.datasets.FlyingThings3D`.""",
750	        },
751	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/googlenet.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
110	    IMAGENET1K_FBGEMM_V1 = Weights(
111	        url="https://download.pytorch.org/models/quantized/googlenet_fbgemm-c81f6644.pth",
112	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/googlenet.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
117	            "backend": "fbgemm",
118	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#post-training-quantized-models",
119	            "unquantized": GoogLeNet_Weights.IMAGENET1K_V1,
120	            "_metrics": {
121	                "ImageNet-1K": {
122	                    "acc@1": 69.826,
123	                    "acc@5": 89.404,
124	                }
125	            },
126	            "_ops": 1.498,
127	            "_file_size": 12.618,
128	            "_docs": """
129	                These weights were produced by doing Post Training Quantization (eager mode) on top of the unquantized
130	                weights listed below.
131	            """,
132	        },
133	    )
134	    DEFAULT = IMAGENET1K_FBGEMM_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/inception.py:171
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
170	    IMAGENET1K_FBGEMM_V1 = Weights(
171	        url="https://download.pytorch.org/models/quantized/inception_v3_google_fbgemm-a2837893.pth",
172	        transforms=partial(ImageClassification, crop_size=299, resize_size=342),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/inception.py:178
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
177	            "backend": "fbgemm",
178	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#post-training-quantized-models",
179	            "unquantized": Inception_V3_Weights.IMAGENET1K_V1,
180	            "_metrics": {
181	                "ImageNet-1K": {
182	                    "acc@1": 77.176,
183	                    "acc@5": 93.354,
184	                }
185	            },
186	            "_ops": 5.713,
187	            "_file_size": 23.146,
188	            "_docs": """
189	                These weights were produced by doing Post Training Quantization (eager mode) on top of the unquantized
190	                weights listed below.
191	            """,
192	        },
193	    )
194	    DEFAULT = IMAGENET1K_FBGEMM_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/mobilenetv2.py:68
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
67	    IMAGENET1K_QNNPACK_V1 = Weights(
68	        url="https://download.pytorch.org/models/quantized/mobilenet_v2_qnnpack_37f702c5.pth",
69	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/mobilenetv2.py:75
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
74	            "backend": "qnnpack",
75	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#qat-mobilenetv2",
76	            "unquantized": MobileNet_V2_Weights.IMAGENET1K_V1,
77	            "_metrics": {
78	                "ImageNet-1K": {
79	                    "acc@1": 71.658,
80	                    "acc@5": 90.150,
81	                }
82	            },
83	            "_ops": 0.301,
84	            "_file_size": 3.423,
85	            "_docs": """
86	                These weights were produced by doing Quantization Aware Training (eager mode) on top of the unquantized
87	                weights listed below.
88	            """,
89	        },
90	    )
91	    DEFAULT = IMAGENET1K_QNNPACK_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/mobilenetv3.py:163
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
162	    IMAGENET1K_QNNPACK_V1 = Weights(
163	        url="https://download.pytorch.org/models/quantized/mobilenet_v3_large_qnnpack-5bcacf28.pth",
164	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/mobilenetv3.py:170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
169	            "backend": "qnnpack",
170	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#qat-mobilenetv3",
171	            "unquantized": MobileNet_V3_Large_Weights.IMAGENET1K_V1,
172	            "_metrics": {
173	                "ImageNet-1K": {
174	                    "acc@1": 73.004,
175	                    "acc@5": 90.858,
176	                }
177	            },
178	            "_ops": 0.217,
179	            "_file_size": 21.554,
180	            "_docs": """
181	                These weights were produced by doing Quantization Aware Training (eager mode) on top of the unquantized
182	                weights listed below.
183	            """,
184	        },
185	    )
186	    DEFAULT = IMAGENET1K_QNNPACK_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/resnet.py:156
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
155	    "backend": "fbgemm",
156	    "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#post-training-quantized-models",
157	    "_docs": """
158	        These weights were produced by doing Post Training Quantization (eager mode) on top of the unquantized
159	        weights listed below.
160	    """,
161	}
162	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/resnet.py:166
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
165	    IMAGENET1K_FBGEMM_V1 = Weights(
166	        url="https://download.pytorch.org/models/quantized/resnet18_fbgemm_16fa66dd.pth",
167	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/resnet.py:187
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
186	    IMAGENET1K_FBGEMM_V1 = Weights(
187	        url="https://download.pytorch.org/models/quantized/resnet50_fbgemm_bf931d71.pth",
188	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/resnet.py:204
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
203	    IMAGENET1K_FBGEMM_V2 = Weights(
204	        url="https://download.pytorch.org/models/quantized/resnet50_fbgemm-23753f79.pth",
205	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/resnet.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
224	    IMAGENET1K_FBGEMM_V1 = Weights(
225	        url="https://download.pytorch.org/models/quantized/resnext101_32x8_fbgemm_09835ccf.pth",
226	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/resnet.py:242
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
241	    IMAGENET1K_FBGEMM_V2 = Weights(
242	        url="https://download.pytorch.org/models/quantized/resnext101_32x8_fbgemm-ee16d00c.pth",
243	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/resnet.py:263
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
262	    IMAGENET1K_FBGEMM_V1 = Weights(
263	        url="https://download.pytorch.org/models/quantized/resnext101_64x4d_fbgemm-605a1cb3.pth",
264	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/resnet.py:268
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
267	            "num_params": 83455272,
268	            "recipe": "https://github.com/pytorch/vision/pull/5935",
269	            "unquantized": ResNeXt101_64X4D_Weights.IMAGENET1K_V1,
270	            "_metrics": {
271	                "ImageNet-1K": {
272	                    "acc@1": 82.898,
273	                    "acc@5": 96.326,
274	                }
275	            },
276	            "_ops": 15.46,
277	            "_file_size": 81.556,
278	        },
279	    )
280	    DEFAULT = IMAGENET1K_FBGEMM_V1
281	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/shufflenetv2.py:120
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
119	    "backend": "fbgemm",
120	    "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#post-training-quantized-models",
121	    "_docs": """
122	        These weights were produced by doing Post Training Quantization (eager mode) on top of the unquantized
123	        weights listed below.
124	    """,
125	}
126	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/shufflenetv2.py:130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
129	    IMAGENET1K_FBGEMM_V1 = Weights(
130	        url="https://download.pytorch.org/models/quantized/shufflenetv2_x0.5_fbgemm-00845098.pth",
131	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/shufflenetv2.py:151
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
150	    IMAGENET1K_FBGEMM_V1 = Weights(
151	        url="https://download.pytorch.org/models/quantized/shufflenetv2_x1_fbgemm-1e62bb32.pth",
152	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/shufflenetv2.py:172
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
171	    IMAGENET1K_FBGEMM_V1 = Weights(
172	        url="https://download.pytorch.org/models/quantized/shufflenetv2_x1_5_fbgemm-d7401f05.pth",
173	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/shufflenetv2.py:176
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
175	            **_COMMON_META,
176	            "recipe": "https://github.com/pytorch/vision/pull/5906",
177	            "num_params": 3503624,
178	            "unquantized": ShuffleNet_V2_X1_5_Weights.IMAGENET1K_V1,
179	            "_metrics": {
180	                "ImageNet-1K": {
181	                    "acc@1": 72.052,
182	                    "acc@5": 90.700,
183	                }
184	            },
185	            "_ops": 0.296,
186	            "_file_size": 3.672,
187	        },
188	    )
189	    DEFAULT = IMAGENET1K_FBGEMM_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/shufflenetv2.py:194
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
193	    IMAGENET1K_FBGEMM_V1 = Weights(
194	        url="https://download.pytorch.org/models/quantized/shufflenetv2_x2_0_fbgemm-5cac526c.pth",
195	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/quantization/shufflenetv2.py:198
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
197	            **_COMMON_META,
198	            "recipe": "https://github.com/pytorch/vision/pull/5906",
199	            "num_params": 7393996,
200	            "unquantized": ShuffleNet_V2_X2_0_Weights.IMAGENET1K_V1,
201	            "_metrics": {
202	                "ImageNet-1K": {
203	                    "acc@1": 75.354,
204	                    "acc@5": 92.488,
205	                }
206	            },
207	            "_ops": 0.583,
208	            "_file_size": 7.467,
209	        },
210	    )
211	    DEFAULT = IMAGENET1K_FBGEMM_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:412
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
411	    **_COMMON_META,
412	    "recipe": "https://github.com/facebookresearch/SWAG",
413	    "license": "https://github.com/facebookresearch/SWAG/blob/main/LICENSE",
414	}
415	
416	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:413
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
412	    "recipe": "https://github.com/facebookresearch/SWAG",
413	    "license": "https://github.com/facebookresearch/SWAG/blob/main/LICENSE",
414	}
415	
416	
417	class RegNet_Y_400MF_Weights(WeightsEnum):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:419
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
418	    IMAGENET1K_V1 = Weights(
419	        url="https://download.pytorch.org/models/regnet_y_400mf-c65dace8.pth",
420	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:424
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
423	            "num_params": 4344144,
424	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#small-models",
425	            "_metrics": {
426	                "ImageNet-1K": {
427	                    "acc@1": 74.046,
428	                    "acc@5": 91.716,
429	                }
430	            },
431	            "_ops": 0.402,
432	            "_file_size": 16.806,
433	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
434	        },
435	    )
436	    IMAGENET1K_V2 = Weights(
437	        url="https://download.pytorch.org/models/regnet_y_400mf-e6988f5f.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:437
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
436	    IMAGENET1K_V2 = Weights(
437	        url="https://download.pytorch.org/models/regnet_y_400mf-e6988f5f.pth",
438	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:442
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
441	            "num_params": 4344144,
442	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
443	            "_metrics": {
444	                "ImageNet-1K": {
445	                    "acc@1": 75.804,
446	                    "acc@5": 92.742,
447	                }
448	            },
449	            "_ops": 0.402,
450	            "_file_size": 16.806,
451	            "_docs": """
452	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
453	                `new training recipe
454	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
455	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:451
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
450	            "_file_size": 16.806,
451	            "_docs": """
452	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
453	                `new training recipe
454	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
455	            """,
456	        },
457	    )
458	    DEFAULT = IMAGENET1K_V2
459	
460	
461	class RegNet_Y_800MF_Weights(WeightsEnum):
462	    IMAGENET1K_V1 = Weights(
463	        url="https://download.pytorch.org/models/regnet_y_800mf-1b27b58c.pth",
464	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:463
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
462	    IMAGENET1K_V1 = Weights(
463	        url="https://download.pytorch.org/models/regnet_y_800mf-1b27b58c.pth",
464	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:468
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
467	            "num_params": 6432512,
468	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#small-models",
469	            "_metrics": {
470	                "ImageNet-1K": {
471	                    "acc@1": 76.420,
472	                    "acc@5": 93.136,
473	                }
474	            },
475	            "_ops": 0.834,
476	            "_file_size": 24.774,
477	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
478	        },
479	    )
480	    IMAGENET1K_V2 = Weights(
481	        url="https://download.pytorch.org/models/regnet_y_800mf-58fc7688.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:481
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
480	    IMAGENET1K_V2 = Weights(
481	        url="https://download.pytorch.org/models/regnet_y_800mf-58fc7688.pth",
482	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:486
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
485	            "num_params": 6432512,
486	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
487	            "_metrics": {
488	                "ImageNet-1K": {
489	                    "acc@1": 78.828,
490	                    "acc@5": 94.502,
491	                }
492	            },
493	            "_ops": 0.834,
494	            "_file_size": 24.774,
495	            "_docs": """
496	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
497	                `new training recipe
498	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
499	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:495
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
494	            "_file_size": 24.774,
495	            "_docs": """
496	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
497	                `new training recipe
498	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
499	            """,
500	        },
501	    )
502	    DEFAULT = IMAGENET1K_V2
503	
504	
505	class RegNet_Y_1_6GF_Weights(WeightsEnum):
506	    IMAGENET1K_V1 = Weights(
507	        url="https://download.pytorch.org/models/regnet_y_1_6gf-b11a554e.pth",
508	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:507
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
506	    IMAGENET1K_V1 = Weights(
507	        url="https://download.pytorch.org/models/regnet_y_1_6gf-b11a554e.pth",
508	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:512
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
511	            "num_params": 11202430,
512	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#small-models",
513	            "_metrics": {
514	                "ImageNet-1K": {
515	                    "acc@1": 77.950,
516	                    "acc@5": 93.966,
517	                }
518	            },
519	            "_ops": 1.612,
520	            "_file_size": 43.152,
521	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
522	        },
523	    )
524	    IMAGENET1K_V2 = Weights(
525	        url="https://download.pytorch.org/models/regnet_y_1_6gf-0d7bc02a.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:525
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
524	    IMAGENET1K_V2 = Weights(
525	        url="https://download.pytorch.org/models/regnet_y_1_6gf-0d7bc02a.pth",
526	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:530
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
529	            "num_params": 11202430,
530	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
531	            "_metrics": {
532	                "ImageNet-1K": {
533	                    "acc@1": 80.876,
534	                    "acc@5": 95.444,
535	                }
536	            },
537	            "_ops": 1.612,
538	            "_file_size": 43.152,
539	            "_docs": """
540	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
541	                `new training recipe
542	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
543	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:539
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
538	            "_file_size": 43.152,
539	            "_docs": """
540	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
541	                `new training recipe
542	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
543	            """,
544	        },
545	    )
546	    DEFAULT = IMAGENET1K_V2
547	
548	
549	class RegNet_Y_3_2GF_Weights(WeightsEnum):
550	    IMAGENET1K_V1 = Weights(
551	        url="https://download.pytorch.org/models/regnet_y_3_2gf-b5a9779c.pth",
552	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:551
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
550	    IMAGENET1K_V1 = Weights(
551	        url="https://download.pytorch.org/models/regnet_y_3_2gf-b5a9779c.pth",
552	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:556
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
555	            "num_params": 19436338,
556	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#medium-models",
557	            "_metrics": {
558	                "ImageNet-1K": {
559	                    "acc@1": 78.948,
560	                    "acc@5": 94.576,
561	                }
562	            },
563	            "_ops": 3.176,
564	            "_file_size": 74.567,
565	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
566	        },
567	    )
568	    IMAGENET1K_V2 = Weights(
569	        url="https://download.pytorch.org/models/regnet_y_3_2gf-9180c971.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:569
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
568	    IMAGENET1K_V2 = Weights(
569	        url="https://download.pytorch.org/models/regnet_y_3_2gf-9180c971.pth",
570	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:574
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
573	            "num_params": 19436338,
574	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
575	            "_metrics": {
576	                "ImageNet-1K": {
577	                    "acc@1": 81.982,
578	                    "acc@5": 95.972,
579	                }
580	            },
581	            "_ops": 3.176,
582	            "_file_size": 74.567,
583	            "_docs": """
584	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
585	                `new training recipe
586	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
587	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:583
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
582	            "_file_size": 74.567,
583	            "_docs": """
584	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
585	                `new training recipe
586	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
587	            """,
588	        },
589	    )
590	    DEFAULT = IMAGENET1K_V2
591	
592	
593	class RegNet_Y_8GF_Weights(WeightsEnum):
594	    IMAGENET1K_V1 = Weights(
595	        url="https://download.pytorch.org/models/regnet_y_8gf-d0d0e4a8.pth",
596	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:595
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
594	    IMAGENET1K_V1 = Weights(
595	        url="https://download.pytorch.org/models/regnet_y_8gf-d0d0e4a8.pth",
596	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:600
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
599	            "num_params": 39381472,
600	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#medium-models",
601	            "_metrics": {
602	                "ImageNet-1K": {
603	                    "acc@1": 80.032,
604	                    "acc@5": 95.048,
605	                }
606	            },
607	            "_ops": 8.473,
608	            "_file_size": 150.701,
609	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
610	        },
611	    )
612	    IMAGENET1K_V2 = Weights(
613	        url="https://download.pytorch.org/models/regnet_y_8gf-dc2b1b54.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:613
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
612	    IMAGENET1K_V2 = Weights(
613	        url="https://download.pytorch.org/models/regnet_y_8gf-dc2b1b54.pth",
614	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:618
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
617	            "num_params": 39381472,
618	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
619	            "_metrics": {
620	                "ImageNet-1K": {
621	                    "acc@1": 82.828,
622	                    "acc@5": 96.330,
623	                }
624	            },
625	            "_ops": 8.473,
626	            "_file_size": 150.701,
627	            "_docs": """
628	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
629	                `new training recipe
630	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
631	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:627
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
626	            "_file_size": 150.701,
627	            "_docs": """
628	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
629	                `new training recipe
630	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
631	            """,
632	        },
633	    )
634	    DEFAULT = IMAGENET1K_V2
635	
636	
637	class RegNet_Y_16GF_Weights(WeightsEnum):
638	    IMAGENET1K_V1 = Weights(
639	        url="https://download.pytorch.org/models/regnet_y_16gf-9e6ed7dd.pth",
640	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:639
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
638	    IMAGENET1K_V1 = Weights(
639	        url="https://download.pytorch.org/models/regnet_y_16gf-9e6ed7dd.pth",
640	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:644
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
643	            "num_params": 83590140,
644	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#large-models",
645	            "_metrics": {
646	                "ImageNet-1K": {
647	                    "acc@1": 80.424,
648	                    "acc@5": 95.240,
649	                }
650	            },
651	            "_ops": 15.912,
652	            "_file_size": 319.49,
653	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
654	        },
655	    )
656	    IMAGENET1K_V2 = Weights(
657	        url="https://download.pytorch.org/models/regnet_y_16gf-3e4a00f9.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:657
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
656	    IMAGENET1K_V2 = Weights(
657	        url="https://download.pytorch.org/models/regnet_y_16gf-3e4a00f9.pth",
658	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:662
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
661	            "num_params": 83590140,
662	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
663	            "_metrics": {
664	                "ImageNet-1K": {
665	                    "acc@1": 82.886,
666	                    "acc@5": 96.328,
667	                }
668	            },
669	            "_ops": 15.912,
670	            "_file_size": 319.49,
671	            "_docs": """
672	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
673	                `new training recipe
674	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
675	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:671
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
670	            "_file_size": 319.49,
671	            "_docs": """
672	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
673	                `new training recipe
674	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
675	            """,
676	        },
677	    )
678	    IMAGENET1K_SWAG_E2E_V1 = Weights(
679	        url="https://download.pytorch.org/models/regnet_y_16gf_swag-43afe44d.pth",
680	        transforms=partial(
681	            ImageClassification, crop_size=384, resize_size=384, interpolation=InterpolationMode.BICUBIC
682	        ),
683	        meta={
684	            **_COMMON_SWAG_META,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:679
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
678	    IMAGENET1K_SWAG_E2E_V1 = Weights(
679	        url="https://download.pytorch.org/models/regnet_y_16gf_swag-43afe44d.pth",
680	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:694
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
693	            "_file_size": 319.49,
694	            "_docs": """
695	                These weights are learnt via transfer learning by end-to-end fine-tuning the original
696	                `SWAG <https://arxiv.org/abs/2201.08371>`_ weights on ImageNet-1K data.
697	            """,
698	        },
699	    )
700	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
701	        url="https://download.pytorch.org/models/regnet_y_16gf_lc_swag-f3ec0043.pth",
702	        transforms=partial(
703	            ImageClassification, crop_size=224, resize_size=224, interpolation=InterpolationMode.BICUBIC
704	        ),
705	        meta={
706	            **_COMMON_SWAG_META,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:701
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
700	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
701	        url="https://download.pytorch.org/models/regnet_y_16gf_lc_swag-f3ec0043.pth",
702	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:707
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
706	            **_COMMON_SWAG_META,
707	            "recipe": "https://github.com/pytorch/vision/pull/5793",
708	            "num_params": 83590140,
709	            "_metrics": {
710	                "ImageNet-1K": {
711	                    "acc@1": 83.976,
712	                    "acc@5": 97.244,
713	                }
714	            },
715	            "_ops": 15.912,
716	            "_file_size": 319.49,
717	            "_docs": """
718	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
719	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
720	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:717
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
716	            "_file_size": 319.49,
717	            "_docs": """
718	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
719	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
720	            """,
721	        },
722	    )
723	    DEFAULT = IMAGENET1K_V2
724	
725	
726	class RegNet_Y_32GF_Weights(WeightsEnum):
727	    IMAGENET1K_V1 = Weights(
728	        url="https://download.pytorch.org/models/regnet_y_32gf-4dee3f7a.pth",
729	        transforms=partial(ImageClassification, crop_size=224),
730	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:728
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
727	    IMAGENET1K_V1 = Weights(
728	        url="https://download.pytorch.org/models/regnet_y_32gf-4dee3f7a.pth",
729	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:733
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
732	            "num_params": 145046770,
733	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#large-models",
734	            "_metrics": {
735	                "ImageNet-1K": {
736	                    "acc@1": 80.878,
737	                    "acc@5": 95.340,
738	                }
739	            },
740	            "_ops": 32.28,
741	            "_file_size": 554.076,
742	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
743	        },
744	    )
745	    IMAGENET1K_V2 = Weights(
746	        url="https://download.pytorch.org/models/regnet_y_32gf-8db6d4b5.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:746
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
745	    IMAGENET1K_V2 = Weights(
746	        url="https://download.pytorch.org/models/regnet_y_32gf-8db6d4b5.pth",
747	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:751
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
750	            "num_params": 145046770,
751	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
752	            "_metrics": {
753	                "ImageNet-1K": {
754	                    "acc@1": 83.368,
755	                    "acc@5": 96.498,
756	                }
757	            },
758	            "_ops": 32.28,
759	            "_file_size": 554.076,
760	            "_docs": """
761	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
762	                `new training recipe
763	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
764	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:760
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
759	            "_file_size": 554.076,
760	            "_docs": """
761	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
762	                `new training recipe
763	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
764	            """,
765	        },
766	    )
767	    IMAGENET1K_SWAG_E2E_V1 = Weights(
768	        url="https://download.pytorch.org/models/regnet_y_32gf_swag-04fdfa75.pth",
769	        transforms=partial(
770	            ImageClassification, crop_size=384, resize_size=384, interpolation=InterpolationMode.BICUBIC
771	        ),
772	        meta={
773	            **_COMMON_SWAG_META,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:768
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
767	    IMAGENET1K_SWAG_E2E_V1 = Weights(
768	        url="https://download.pytorch.org/models/regnet_y_32gf_swag-04fdfa75.pth",
769	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:783
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
782	            "_file_size": 554.076,
783	            "_docs": """
784	                These weights are learnt via transfer learning by end-to-end fine-tuning the original
785	                `SWAG <https://arxiv.org/abs/2201.08371>`_ weights on ImageNet-1K data.
786	            """,
787	        },
788	    )
789	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
790	        url="https://download.pytorch.org/models/regnet_y_32gf_lc_swag-e1583746.pth",
791	        transforms=partial(
792	            ImageClassification, crop_size=224, resize_size=224, interpolation=InterpolationMode.BICUBIC
793	        ),
794	        meta={
795	            **_COMMON_SWAG_META,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:790
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
789	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
790	        url="https://download.pytorch.org/models/regnet_y_32gf_lc_swag-e1583746.pth",
791	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:796
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
795	            **_COMMON_SWAG_META,
796	            "recipe": "https://github.com/pytorch/vision/pull/5793",
797	            "num_params": 145046770,
798	            "_metrics": {
799	                "ImageNet-1K": {
800	                    "acc@1": 84.622,
801	                    "acc@5": 97.480,
802	                }
803	            },
804	            "_ops": 32.28,
805	            "_file_size": 554.076,
806	            "_docs": """
807	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
808	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
809	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:806
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
805	            "_file_size": 554.076,
806	            "_docs": """
807	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
808	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
809	            """,
810	        },
811	    )
812	    DEFAULT = IMAGENET1K_V2
813	
814	
815	class RegNet_Y_128GF_Weights(WeightsEnum):
816	    IMAGENET1K_SWAG_E2E_V1 = Weights(
817	        url="https://download.pytorch.org/models/regnet_y_128gf_swag-c8ce3e52.pth",
818	        transforms=partial(
819	            ImageClassification, crop_size=384, resize_size=384, interpolation=InterpolationMode.BICUBIC

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:817
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
816	    IMAGENET1K_SWAG_E2E_V1 = Weights(
817	        url="https://download.pytorch.org/models/regnet_y_128gf_swag-c8ce3e52.pth",
818	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:832
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
831	            "_file_size": 2461.564,
832	            "_docs": """
833	                These weights are learnt via transfer learning by end-to-end fine-tuning the original
834	                `SWAG <https://arxiv.org/abs/2201.08371>`_ weights on ImageNet-1K data.
835	            """,
836	        },
837	    )
838	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
839	        url="https://download.pytorch.org/models/regnet_y_128gf_lc_swag-cbe8ce12.pth",
840	        transforms=partial(
841	            ImageClassification, crop_size=224, resize_size=224, interpolation=InterpolationMode.BICUBIC
842	        ),
843	        meta={
844	            **_COMMON_SWAG_META,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:839
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
838	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
839	        url="https://download.pytorch.org/models/regnet_y_128gf_lc_swag-cbe8ce12.pth",
840	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:845
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
844	            **_COMMON_SWAG_META,
845	            "recipe": "https://github.com/pytorch/vision/pull/5793",
846	            "num_params": 644812894,
847	            "_metrics": {
848	                "ImageNet-1K": {
849	                    "acc@1": 86.068,
850	                    "acc@5": 97.844,
851	                }
852	            },
853	            "_ops": 127.518,
854	            "_file_size": 2461.564,
855	            "_docs": """
856	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
857	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
858	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:855
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
854	            "_file_size": 2461.564,
855	            "_docs": """
856	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
857	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
858	            """,
859	        },
860	    )
861	    DEFAULT = IMAGENET1K_SWAG_E2E_V1
862	
863	
864	class RegNet_X_400MF_Weights(WeightsEnum):
865	    IMAGENET1K_V1 = Weights(
866	        url="https://download.pytorch.org/models/regnet_x_400mf-adf1edd5.pth",
867	        transforms=partial(ImageClassification, crop_size=224),
868	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:866
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
865	    IMAGENET1K_V1 = Weights(
866	        url="https://download.pytorch.org/models/regnet_x_400mf-adf1edd5.pth",
867	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:871
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
870	            "num_params": 5495976,
871	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#small-models",
872	            "_metrics": {
873	                "ImageNet-1K": {
874	                    "acc@1": 72.834,
875	                    "acc@5": 90.950,
876	                }
877	            },
878	            "_ops": 0.414,
879	            "_file_size": 21.258,
880	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
881	        },
882	    )
883	    IMAGENET1K_V2 = Weights(
884	        url="https://download.pytorch.org/models/regnet_x_400mf-62229a5f.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:884
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
883	    IMAGENET1K_V2 = Weights(
884	        url="https://download.pytorch.org/models/regnet_x_400mf-62229a5f.pth",
885	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:889
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
888	            "num_params": 5495976,
889	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
890	            "_metrics": {
891	                "ImageNet-1K": {
892	                    "acc@1": 74.864,
893	                    "acc@5": 92.322,
894	                }
895	            },
896	            "_ops": 0.414,
897	            "_file_size": 21.257,
898	            "_docs": """
899	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
900	                `new training recipe
901	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
902	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:898
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
897	            "_file_size": 21.257,
898	            "_docs": """
899	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
900	                `new training recipe
901	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
902	            """,
903	        },
904	    )
905	    DEFAULT = IMAGENET1K_V2
906	
907	
908	class RegNet_X_800MF_Weights(WeightsEnum):
909	    IMAGENET1K_V1 = Weights(
910	        url="https://download.pytorch.org/models/regnet_x_800mf-ad17e45c.pth",
911	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:910
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
909	    IMAGENET1K_V1 = Weights(
910	        url="https://download.pytorch.org/models/regnet_x_800mf-ad17e45c.pth",
911	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:915
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
914	            "num_params": 7259656,
915	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#small-models",
916	            "_metrics": {
917	                "ImageNet-1K": {
918	                    "acc@1": 75.212,
919	                    "acc@5": 92.348,
920	                }
921	            },
922	            "_ops": 0.8,
923	            "_file_size": 27.945,
924	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
925	        },
926	    )
927	    IMAGENET1K_V2 = Weights(
928	        url="https://download.pytorch.org/models/regnet_x_800mf-94a99ebd.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:928
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
927	    IMAGENET1K_V2 = Weights(
928	        url="https://download.pytorch.org/models/regnet_x_800mf-94a99ebd.pth",
929	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:933
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
932	            "num_params": 7259656,
933	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
934	            "_metrics": {
935	                "ImageNet-1K": {
936	                    "acc@1": 77.522,
937	                    "acc@5": 93.826,
938	                }
939	            },
940	            "_ops": 0.8,
941	            "_file_size": 27.945,
942	            "_docs": """
943	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
944	                `new training recipe
945	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
946	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:942
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
941	            "_file_size": 27.945,
942	            "_docs": """
943	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
944	                `new training recipe
945	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
946	            """,
947	        },
948	    )
949	    DEFAULT = IMAGENET1K_V2
950	
951	
952	class RegNet_X_1_6GF_Weights(WeightsEnum):
953	    IMAGENET1K_V1 = Weights(
954	        url="https://download.pytorch.org/models/regnet_x_1_6gf-e3633e7f.pth",
955	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:954
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
953	    IMAGENET1K_V1 = Weights(
954	        url="https://download.pytorch.org/models/regnet_x_1_6gf-e3633e7f.pth",
955	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:959
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
958	            "num_params": 9190136,
959	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#small-models",
960	            "_metrics": {
961	                "ImageNet-1K": {
962	                    "acc@1": 77.040,
963	                    "acc@5": 93.440,
964	                }
965	            },
966	            "_ops": 1.603,
967	            "_file_size": 35.339,
968	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
969	        },
970	    )
971	    IMAGENET1K_V2 = Weights(
972	        url="https://download.pytorch.org/models/regnet_x_1_6gf-a12f2b72.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:972
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
971	    IMAGENET1K_V2 = Weights(
972	        url="https://download.pytorch.org/models/regnet_x_1_6gf-a12f2b72.pth",
973	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:977
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
976	            "num_params": 9190136,
977	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
978	            "_metrics": {
979	                "ImageNet-1K": {
980	                    "acc@1": 79.668,
981	                    "acc@5": 94.922,
982	                }
983	            },
984	            "_ops": 1.603,
985	            "_file_size": 35.339,
986	            "_docs": """
987	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
988	                `new training recipe
989	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
990	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:986
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
985	            "_file_size": 35.339,
986	            "_docs": """
987	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
988	                `new training recipe
989	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
990	            """,
991	        },
992	    )
993	    DEFAULT = IMAGENET1K_V2
994	
995	
996	class RegNet_X_3_2GF_Weights(WeightsEnum):
997	    IMAGENET1K_V1 = Weights(
998	        url="https://download.pytorch.org/models/regnet_x_3_2gf-f342aeae.pth",
999	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:998
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
997	    IMAGENET1K_V1 = Weights(
998	        url="https://download.pytorch.org/models/regnet_x_3_2gf-f342aeae.pth",
999	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1003
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1002	            "num_params": 15296552,
1003	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#medium-models",
1004	            "_metrics": {
1005	                "ImageNet-1K": {
1006	                    "acc@1": 78.364,
1007	                    "acc@5": 93.992,
1008	                }
1009	            },
1010	            "_ops": 3.177,
1011	            "_file_size": 58.756,
1012	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
1013	        },
1014	    )
1015	    IMAGENET1K_V2 = Weights(
1016	        url="https://download.pytorch.org/models/regnet_x_3_2gf-7071aa85.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1016
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1015	    IMAGENET1K_V2 = Weights(
1016	        url="https://download.pytorch.org/models/regnet_x_3_2gf-7071aa85.pth",
1017	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1021
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1020	            "num_params": 15296552,
1021	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
1022	            "_metrics": {
1023	                "ImageNet-1K": {
1024	                    "acc@1": 81.196,
1025	                    "acc@5": 95.430,
1026	                }
1027	            },
1028	            "_ops": 3.177,
1029	            "_file_size": 58.756,
1030	            "_docs": """
1031	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
1032	                `new training recipe
1033	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
1034	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1030
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1029	            "_file_size": 58.756,
1030	            "_docs": """
1031	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
1032	                `new training recipe
1033	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
1034	            """,
1035	        },
1036	    )
1037	    DEFAULT = IMAGENET1K_V2
1038	
1039	
1040	class RegNet_X_8GF_Weights(WeightsEnum):
1041	    IMAGENET1K_V1 = Weights(
1042	        url="https://download.pytorch.org/models/regnet_x_8gf-03ceed89.pth",
1043	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1042
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1041	    IMAGENET1K_V1 = Weights(
1042	        url="https://download.pytorch.org/models/regnet_x_8gf-03ceed89.pth",
1043	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1047
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1046	            "num_params": 39572648,
1047	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#medium-models",
1048	            "_metrics": {
1049	                "ImageNet-1K": {
1050	                    "acc@1": 79.344,
1051	                    "acc@5": 94.686,
1052	                }
1053	            },
1054	            "_ops": 7.995,
1055	            "_file_size": 151.456,
1056	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
1057	        },
1058	    )
1059	    IMAGENET1K_V2 = Weights(
1060	        url="https://download.pytorch.org/models/regnet_x_8gf-2b70d774.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1060
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1059	    IMAGENET1K_V2 = Weights(
1060	        url="https://download.pytorch.org/models/regnet_x_8gf-2b70d774.pth",
1061	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1065
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1064	            "num_params": 39572648,
1065	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
1066	            "_metrics": {
1067	                "ImageNet-1K": {
1068	                    "acc@1": 81.682,
1069	                    "acc@5": 95.678,
1070	                }
1071	            },
1072	            "_ops": 7.995,
1073	            "_file_size": 151.456,
1074	            "_docs": """
1075	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
1076	                `new training recipe
1077	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
1078	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1074
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1073	            "_file_size": 151.456,
1074	            "_docs": """
1075	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
1076	                `new training recipe
1077	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
1078	            """,
1079	        },
1080	    )
1081	    DEFAULT = IMAGENET1K_V2
1082	
1083	
1084	class RegNet_X_16GF_Weights(WeightsEnum):
1085	    IMAGENET1K_V1 = Weights(
1086	        url="https://download.pytorch.org/models/regnet_x_16gf-2007eb11.pth",
1087	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1086
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1085	    IMAGENET1K_V1 = Weights(
1086	        url="https://download.pytorch.org/models/regnet_x_16gf-2007eb11.pth",
1087	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1091
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1090	            "num_params": 54278536,
1091	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#medium-models",
1092	            "_metrics": {
1093	                "ImageNet-1K": {
1094	                    "acc@1": 80.058,
1095	                    "acc@5": 94.944,
1096	                }
1097	            },
1098	            "_ops": 15.941,
1099	            "_file_size": 207.627,
1100	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
1101	        },
1102	    )
1103	    IMAGENET1K_V2 = Weights(
1104	        url="https://download.pytorch.org/models/regnet_x_16gf-ba3796d7.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1104
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1103	    IMAGENET1K_V2 = Weights(
1104	        url="https://download.pytorch.org/models/regnet_x_16gf-ba3796d7.pth",
1105	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1109
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1108	            "num_params": 54278536,
1109	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
1110	            "_metrics": {
1111	                "ImageNet-1K": {
1112	                    "acc@1": 82.716,
1113	                    "acc@5": 96.196,
1114	                }
1115	            },
1116	            "_ops": 15.941,
1117	            "_file_size": 207.627,
1118	            "_docs": """
1119	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
1120	                `new training recipe
1121	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
1122	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1117	            "_file_size": 207.627,
1118	            "_docs": """
1119	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
1120	                `new training recipe
1121	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
1122	            """,
1123	        },
1124	    )
1125	    DEFAULT = IMAGENET1K_V2
1126	
1127	
1128	class RegNet_X_32GF_Weights(WeightsEnum):
1129	    IMAGENET1K_V1 = Weights(
1130	        url="https://download.pytorch.org/models/regnet_x_32gf-9d47f8d0.pth",
1131	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1129	    IMAGENET1K_V1 = Weights(
1130	        url="https://download.pytorch.org/models/regnet_x_32gf-9d47f8d0.pth",
1131	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1135
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1134	            "num_params": 107811560,
1135	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#large-models",
1136	            "_metrics": {
1137	                "ImageNet-1K": {
1138	                    "acc@1": 80.622,
1139	                    "acc@5": 95.248,
1140	                }
1141	            },
1142	            "_ops": 31.736,
1143	            "_file_size": 412.039,
1144	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
1145	        },
1146	    )
1147	    IMAGENET1K_V2 = Weights(
1148	        url="https://download.pytorch.org/models/regnet_x_32gf-6eb8fdc6.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1148
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1147	    IMAGENET1K_V2 = Weights(
1148	        url="https://download.pytorch.org/models/regnet_x_32gf-6eb8fdc6.pth",
1149	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1153
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1152	            "num_params": 107811560,
1153	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
1154	            "_metrics": {
1155	                "ImageNet-1K": {
1156	                    "acc@1": 83.014,
1157	                    "acc@5": 96.288,
1158	                }
1159	            },
1160	            "_ops": 31.736,
1161	            "_file_size": 412.039,
1162	            "_docs": """
1163	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
1164	                `new training recipe
1165	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
1166	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/regnet.py:1162
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1161	            "_file_size": 412.039,
1162	            "_docs": """
1163	                These weights improve upon the results of the original paper by using a modified version of TorchVision's
1164	                `new training recipe
1165	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
1166	            """,
1167	        },
1168	    )
1169	    DEFAULT = IMAGENET1K_V2
1170	
1171	
1172	@register_model()
1173	@handle_legacy_interface(weights=("pretrained", RegNet_Y_400MF_Weights.IMAGENET1K_V1))
1174	def regnet_y_400mf(*, weights: Optional[RegNet_Y_400MF_Weights] = None, progress: bool = True, **kwargs: Any) -> RegNet:
1175	    """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:314
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
313	    IMAGENET1K_V1 = Weights(
314	        url="https://download.pytorch.org/models/resnet18-f37072fd.pth",
315	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:319
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
318	            "num_params": 11689512,
319	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
320	            "_metrics": {
321	                "ImageNet-1K": {
322	                    "acc@1": 69.758,
323	                    "acc@5": 89.078,
324	                }
325	            },
326	            "_ops": 1.814,
327	            "_file_size": 44.661,
328	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
329	        },
330	    )
331	    DEFAULT = IMAGENET1K_V1
332	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:336
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
335	    IMAGENET1K_V1 = Weights(
336	        url="https://download.pytorch.org/models/resnet34-b627a593.pth",
337	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:341
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
340	            "num_params": 21797672,
341	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
342	            "_metrics": {
343	                "ImageNet-1K": {
344	                    "acc@1": 73.314,
345	                    "acc@5": 91.420,
346	                }
347	            },
348	            "_ops": 3.664,
349	            "_file_size": 83.275,
350	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
351	        },
352	    )
353	    DEFAULT = IMAGENET1K_V1
354	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:358
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
357	    IMAGENET1K_V1 = Weights(
358	        url="https://download.pytorch.org/models/resnet50-0676ba61.pth",
359	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:363
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
362	            "num_params": 25557032,
363	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
364	            "_metrics": {
365	                "ImageNet-1K": {
366	                    "acc@1": 76.130,
367	                    "acc@5": 92.862,
368	                }
369	            },
370	            "_ops": 4.089,
371	            "_file_size": 97.781,
372	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
373	        },
374	    )
375	    IMAGENET1K_V2 = Weights(
376	        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:376
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
375	    IMAGENET1K_V2 = Weights(
376	        url="https://download.pytorch.org/models/resnet50-11ad3fa6.pth",
377	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:381
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
380	            "num_params": 25557032,
381	            "recipe": "https://github.com/pytorch/vision/issues/3995#issuecomment-1013906621",
382	            "_metrics": {
383	                "ImageNet-1K": {
384	                    "acc@1": 80.858,
385	                    "acc@5": 95.434,
386	                }
387	            },
388	            "_ops": 4.089,
389	            "_file_size": 97.79,
390	            "_docs": """
391	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
392	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
393	            """,
394	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:390
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
389	            "_file_size": 97.79,
390	            "_docs": """
391	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
392	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
393	            """,
394	        },
395	    )
396	    DEFAULT = IMAGENET1K_V2
397	
398	
399	class ResNet101_Weights(WeightsEnum):
400	    IMAGENET1K_V1 = Weights(
401	        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
402	        transforms=partial(ImageClassification, crop_size=224),
403	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:401
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
400	    IMAGENET1K_V1 = Weights(
401	        url="https://download.pytorch.org/models/resnet101-63fe2227.pth",
402	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:406
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
405	            "num_params": 44549160,
406	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
407	            "_metrics": {
408	                "ImageNet-1K": {
409	                    "acc@1": 77.374,
410	                    "acc@5": 93.546,
411	                }
412	            },
413	            "_ops": 7.801,
414	            "_file_size": 170.511,
415	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
416	        },
417	    )
418	    IMAGENET1K_V2 = Weights(
419	        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:419
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
418	    IMAGENET1K_V2 = Weights(
419	        url="https://download.pytorch.org/models/resnet101-cd907fc2.pth",
420	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:424
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
423	            "num_params": 44549160,
424	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
425	            "_metrics": {
426	                "ImageNet-1K": {
427	                    "acc@1": 81.886,
428	                    "acc@5": 95.780,
429	                }
430	            },
431	            "_ops": 7.801,
432	            "_file_size": 170.53,
433	            "_docs": """
434	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
435	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
436	            """,
437	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:433
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
432	            "_file_size": 170.53,
433	            "_docs": """
434	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
435	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
436	            """,
437	        },
438	    )
439	    DEFAULT = IMAGENET1K_V2
440	
441	
442	class ResNet152_Weights(WeightsEnum):
443	    IMAGENET1K_V1 = Weights(
444	        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
445	        transforms=partial(ImageClassification, crop_size=224),
446	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:444
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
443	    IMAGENET1K_V1 = Weights(
444	        url="https://download.pytorch.org/models/resnet152-394f9c45.pth",
445	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:449
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
448	            "num_params": 60192808,
449	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnet",
450	            "_metrics": {
451	                "ImageNet-1K": {
452	                    "acc@1": 78.312,
453	                    "acc@5": 94.046,
454	                }
455	            },
456	            "_ops": 11.514,
457	            "_file_size": 230.434,
458	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
459	        },
460	    )
461	    IMAGENET1K_V2 = Weights(
462	        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:462
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
461	    IMAGENET1K_V2 = Weights(
462	        url="https://download.pytorch.org/models/resnet152-f82ba261.pth",
463	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:467
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
466	            "num_params": 60192808,
467	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
468	            "_metrics": {
469	                "ImageNet-1K": {
470	                    "acc@1": 82.284,
471	                    "acc@5": 96.002,
472	                }
473	            },
474	            "_ops": 11.514,
475	            "_file_size": 230.474,
476	            "_docs": """
477	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
478	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
479	            """,
480	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:476
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
475	            "_file_size": 230.474,
476	            "_docs": """
477	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
478	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
479	            """,
480	        },
481	    )
482	    DEFAULT = IMAGENET1K_V2
483	
484	
485	class ResNeXt50_32X4D_Weights(WeightsEnum):
486	    IMAGENET1K_V1 = Weights(
487	        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
488	        transforms=partial(ImageClassification, crop_size=224),
489	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:487
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
486	    IMAGENET1K_V1 = Weights(
487	        url="https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth",
488	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:492
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
491	            "num_params": 25028904,
492	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
493	            "_metrics": {
494	                "ImageNet-1K": {
495	                    "acc@1": 77.618,
496	                    "acc@5": 93.698,
497	                }
498	            },
499	            "_ops": 4.23,
500	            "_file_size": 95.789,
501	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
502	        },
503	    )
504	    IMAGENET1K_V2 = Weights(
505	        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:505
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
504	    IMAGENET1K_V2 = Weights(
505	        url="https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth",
506	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:510
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
509	            "num_params": 25028904,
510	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
511	            "_metrics": {
512	                "ImageNet-1K": {
513	                    "acc@1": 81.198,
514	                    "acc@5": 95.340,
515	                }
516	            },
517	            "_ops": 4.23,
518	            "_file_size": 95.833,
519	            "_docs": """
520	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
521	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
522	            """,
523	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:519
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
518	            "_file_size": 95.833,
519	            "_docs": """
520	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
521	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
522	            """,
523	        },
524	    )
525	    DEFAULT = IMAGENET1K_V2
526	
527	
528	class ResNeXt101_32X8D_Weights(WeightsEnum):
529	    IMAGENET1K_V1 = Weights(
530	        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
531	        transforms=partial(ImageClassification, crop_size=224),
532	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:530
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
529	    IMAGENET1K_V1 = Weights(
530	        url="https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth",
531	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:535
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
534	            "num_params": 88791336,
535	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#resnext",
536	            "_metrics": {
537	                "ImageNet-1K": {
538	                    "acc@1": 79.312,
539	                    "acc@5": 94.526,
540	                }
541	            },
542	            "_ops": 16.414,
543	            "_file_size": 339.586,
544	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
545	        },
546	    )
547	    IMAGENET1K_V2 = Weights(
548	        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:548
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
547	    IMAGENET1K_V2 = Weights(
548	        url="https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth",
549	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:553
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
552	            "num_params": 88791336,
553	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
554	            "_metrics": {
555	                "ImageNet-1K": {
556	                    "acc@1": 82.834,
557	                    "acc@5": 96.228,
558	                }
559	            },
560	            "_ops": 16.414,
561	            "_file_size": 339.673,
562	            "_docs": """
563	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
564	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
565	            """,
566	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:562
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
561	            "_file_size": 339.673,
562	            "_docs": """
563	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
564	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
565	            """,
566	        },
567	    )
568	    DEFAULT = IMAGENET1K_V2
569	
570	
571	class ResNeXt101_64X4D_Weights(WeightsEnum):
572	    IMAGENET1K_V1 = Weights(
573	        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
574	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
575	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:573
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
572	    IMAGENET1K_V1 = Weights(
573	        url="https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth",
574	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:578
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
577	            "num_params": 83455272,
578	            "recipe": "https://github.com/pytorch/vision/pull/5935",
579	            "_metrics": {
580	                "ImageNet-1K": {
581	                    "acc@1": 83.246,
582	                    "acc@5": 96.454,
583	                }
584	            },
585	            "_ops": 15.46,
586	            "_file_size": 319.318,
587	            "_docs": """
588	                These weights were trained from scratch by using TorchVision's `new training recipe
589	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
590	            """,
591	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:587
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
586	            "_file_size": 319.318,
587	            "_docs": """
588	                These weights were trained from scratch by using TorchVision's `new training recipe
589	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
590	            """,
591	        },
592	    )
593	    DEFAULT = IMAGENET1K_V1
594	
595	
596	class Wide_ResNet50_2_Weights(WeightsEnum):
597	    IMAGENET1K_V1 = Weights(
598	        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
599	        transforms=partial(ImageClassification, crop_size=224),
600	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:598
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
597	    IMAGENET1K_V1 = Weights(
598	        url="https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth",
599	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:603
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
602	            "num_params": 68883240,
603	            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
604	            "_metrics": {
605	                "ImageNet-1K": {
606	                    "acc@1": 78.468,
607	                    "acc@5": 94.086,
608	                }
609	            },
610	            "_ops": 11.398,
611	            "_file_size": 131.82,
612	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
613	        },
614	    )
615	    IMAGENET1K_V2 = Weights(
616	        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:616
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
615	    IMAGENET1K_V2 = Weights(
616	        url="https://download.pytorch.org/models/wide_resnet50_2-9ba9bcbe.pth",
617	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:621
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
620	            "num_params": 68883240,
621	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-fixres",
622	            "_metrics": {
623	                "ImageNet-1K": {
624	                    "acc@1": 81.602,
625	                    "acc@5": 95.758,
626	                }
627	            },
628	            "_ops": 11.398,
629	            "_file_size": 263.124,
630	            "_docs": """
631	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
632	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
633	            """,
634	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:630
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
629	            "_file_size": 263.124,
630	            "_docs": """
631	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
632	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
633	            """,
634	        },
635	    )
636	    DEFAULT = IMAGENET1K_V2
637	
638	
639	class Wide_ResNet101_2_Weights(WeightsEnum):
640	    IMAGENET1K_V1 = Weights(
641	        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
642	        transforms=partial(ImageClassification, crop_size=224),
643	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:641
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
640	    IMAGENET1K_V1 = Weights(
641	        url="https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth",
642	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:646
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
645	            "num_params": 126886696,
646	            "recipe": "https://github.com/pytorch/vision/pull/912#issue-445437439",
647	            "_metrics": {
648	                "ImageNet-1K": {
649	                    "acc@1": 78.848,
650	                    "acc@5": 94.284,
651	                }
652	            },
653	            "_ops": 22.753,
654	            "_file_size": 242.896,
655	            "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
656	        },
657	    )
658	    IMAGENET1K_V2 = Weights(
659	        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:659
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
658	    IMAGENET1K_V2 = Weights(
659	        url="https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth",
660	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:664
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
663	            "num_params": 126886696,
664	            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe",
665	            "_metrics": {
666	                "ImageNet-1K": {
667	                    "acc@1": 82.510,
668	                    "acc@5": 96.020,
669	                }
670	            },
671	            "_ops": 22.753,
672	            "_file_size": 484.747,
673	            "_docs": """
674	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
675	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
676	            """,
677	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/resnet.py:673
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
672	            "_file_size": 484.747,
673	            "_docs": """
674	                These weights improve upon the results of the original paper by using TorchVision's `new training recipe
675	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
676	            """,
677	        },
678	    )
679	    DEFAULT = IMAGENET1K_V2
680	
681	
682	@register_model()
683	@handle_legacy_interface(weights=("pretrained", ResNet18_Weights.IMAGENET1K_V1))
684	def resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:
685	    """ResNet-18 from `Deep Residual Learning for Image Recognition <https://arxiv.org/abs/1512.03385>`__.
686	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/deeplabv3.py:143
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
142	    COCO_WITH_VOC_LABELS_V1 = Weights(
143	        url="https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth",
144	        transforms=partial(SemanticSegmentation, resize_size=520),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/deeplabv3.py:148
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
147	            "num_params": 42004074,
148	            "recipe": "https://github.com/pytorch/vision/tree/main/references/segmentation#deeplabv3_resnet50",
149	            "_metrics": {
150	                "COCO-val2017-VOC-labels": {
151	                    "miou": 66.4,
152	                    "pixel_acc": 92.4,
153	                }
154	            },
155	            "_ops": 178.722,
156	            "_file_size": 160.515,
157	        },
158	    )
159	    DEFAULT = COCO_WITH_VOC_LABELS_V1
160	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/deeplabv3.py:164
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
163	    COCO_WITH_VOC_LABELS_V1 = Weights(
164	        url="https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth",
165	        transforms=partial(SemanticSegmentation, resize_size=520),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/deeplabv3.py:169
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
168	            "num_params": 60996202,
169	            "recipe": "https://github.com/pytorch/vision/tree/main/references/segmentation#fcn_resnet101",
170	            "_metrics": {
171	                "COCO-val2017-VOC-labels": {
172	                    "miou": 67.4,
173	                    "pixel_acc": 92.4,
174	                }
175	            },
176	            "_ops": 258.743,
177	            "_file_size": 233.217,
178	        },
179	    )
180	    DEFAULT = COCO_WITH_VOC_LABELS_V1
181	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/deeplabv3.py:185
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
184	    COCO_WITH_VOC_LABELS_V1 = Weights(
185	        url="https://download.pytorch.org/models/deeplabv3_mobilenet_v3_large-fc3c493d.pth",
186	        transforms=partial(SemanticSegmentation, resize_size=520),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/deeplabv3.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
189	            "num_params": 11029328,
190	            "recipe": "https://github.com/pytorch/vision/tree/main/references/segmentation#deeplabv3_mobilenet_v3_large",
191	            "_metrics": {
192	                "COCO-val2017-VOC-labels": {
193	                    "miou": 60.3,
194	                    "pixel_acc": 91.2,
195	                }
196	            },
197	            "_ops": 10.452,
198	            "_file_size": 42.301,
199	        },
200	    )
201	    DEFAULT = COCO_WITH_VOC_LABELS_V1
202	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/fcn.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
61	    COCO_WITH_VOC_LABELS_V1 = Weights(
62	        url="https://download.pytorch.org/models/fcn_resnet50_coco-1167a1af.pth",
63	        transforms=partial(SemanticSegmentation, resize_size=520),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/fcn.py:67
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
66	            "num_params": 35322218,
67	            "recipe": "https://github.com/pytorch/vision/tree/main/references/segmentation#fcn_resnet50",
68	            "_metrics": {
69	                "COCO-val2017-VOC-labels": {
70	                    "miou": 60.5,
71	                    "pixel_acc": 91.4,
72	                }
73	            },
74	            "_ops": 152.717,
75	            "_file_size": 135.009,
76	        },
77	    )
78	    DEFAULT = COCO_WITH_VOC_LABELS_V1
79	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/fcn.py:83
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
82	    COCO_WITH_VOC_LABELS_V1 = Weights(
83	        url="https://download.pytorch.org/models/fcn_resnet101_coco-7ecb50ca.pth",
84	        transforms=partial(SemanticSegmentation, resize_size=520),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/fcn.py:88
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
87	            "num_params": 54314346,
88	            "recipe": "https://github.com/pytorch/vision/tree/main/references/segmentation#deeplabv3_resnet101",
89	            "_metrics": {
90	                "COCO-val2017-VOC-labels": {
91	                    "miou": 63.7,
92	                    "pixel_acc": 91.9,
93	                }
94	            },
95	            "_ops": 232.738,
96	            "_file_size": 207.711,
97	        },
98	    )
99	    DEFAULT = COCO_WITH_VOC_LABELS_V1
100	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/lraspp.py:98
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
97	    COCO_WITH_VOC_LABELS_V1 = Weights(
98	        url="https://download.pytorch.org/models/lraspp_mobilenet_v3_large-d234d4ea.pth",
99	        transforms=partial(SemanticSegmentation, resize_size=520),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/segmentation/lraspp.py:104
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
103	            "min_size": (1, 1),
104	            "recipe": "https://github.com/pytorch/vision/tree/main/references/segmentation#lraspp_mobilenet_v3_large",
105	            "_metrics": {
106	                "COCO-val2017-VOC-labels": {
107	                    "miou": 57.9,
108	                    "pixel_acc": 91.2,
109	                }
110	            },
111	            "_ops": 2.086,
112	            "_file_size": 12.49,
113	            "_docs": """
114	                These weights were trained on a subset of COCO, using only the 20 categories that are present in the
115	                Pascal VOC dataset.
116	            """,
117	        },
118	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/shufflenetv2.py:189
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
188	    "categories": _IMAGENET_CATEGORIES,
189	    "recipe": "https://github.com/ericsun99/Shufflenet-v2-Pytorch",
190	}
191	
192	
193	class ShuffleNet_V2_X0_5_Weights(WeightsEnum):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/shufflenetv2.py:196
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
195	        # Weights ported from https://github.com/ericsun99/Shufflenet-v2-Pytorch
196	        url="https://download.pytorch.org/models/shufflenetv2_x0.5-f707e7126e.pth",
197	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/shufflenetv2.py:218
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
217	        # Weights ported from https://github.com/ericsun99/Shufflenet-v2-Pytorch
218	        url="https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth",
219	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/shufflenetv2.py:239
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
238	    IMAGENET1K_V1 = Weights(
239	        url="https://download.pytorch.org/models/shufflenetv2_x1_5-3c479a10.pth",
240	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/shufflenetv2.py:243
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
242	            **_COMMON_META,
243	            "recipe": "https://github.com/pytorch/vision/pull/5906",
244	            "num_params": 3503624,
245	            "_metrics": {
246	                "ImageNet-1K": {
247	                    "acc@1": 72.996,
248	                    "acc@5": 91.086,
249	                }
250	            },
251	            "_ops": 0.296,
252	            "_file_size": 13.557,
253	            "_docs": """
254	                These weights were trained from scratch by using TorchVision's `new training recipe
255	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
256	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/shufflenetv2.py:253
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
252	            "_file_size": 13.557,
253	            "_docs": """
254	                These weights were trained from scratch by using TorchVision's `new training recipe
255	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
256	            """,
257	        },
258	    )
259	    DEFAULT = IMAGENET1K_V1
260	
261	
262	class ShuffleNet_V2_X2_0_Weights(WeightsEnum):
263	    IMAGENET1K_V1 = Weights(
264	        url="https://download.pytorch.org/models/shufflenetv2_x2_0-8be3c8ee.pth",
265	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
266	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/shufflenetv2.py:264
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
263	    IMAGENET1K_V1 = Weights(
264	        url="https://download.pytorch.org/models/shufflenetv2_x2_0-8be3c8ee.pth",
265	        transforms=partial(ImageClassification, crop_size=224, resize_size=232),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/shufflenetv2.py:268
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
267	            **_COMMON_META,
268	            "recipe": "https://github.com/pytorch/vision/pull/5906",
269	            "num_params": 7393996,
270	            "_metrics": {
271	                "ImageNet-1K": {
272	                    "acc@1": 76.230,
273	                    "acc@5": 93.006,
274	                }
275	            },
276	            "_ops": 0.583,
277	            "_file_size": 28.433,
278	            "_docs": """
279	                These weights were trained from scratch by using TorchVision's `new training recipe
280	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
281	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/shufflenetv2.py:278
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
277	            "_file_size": 28.433,
278	            "_docs": """
279	                These weights were trained from scratch by using TorchVision's `new training recipe
280	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
281	            """,
282	        },
283	    )
284	    DEFAULT = IMAGENET1K_V1
285	
286	
287	@register_model()
288	@handle_legacy_interface(weights=("pretrained", ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1))
289	def shufflenet_v2_x0_5(
290	    *, weights: Optional[ShuffleNet_V2_X0_5_Weights] = None, progress: bool = True, **kwargs: Any
291	) -> ShuffleNetV2:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/squeezenet.py:119
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
118	    "categories": _IMAGENET_CATEGORIES,
119	    "recipe": "https://github.com/pytorch/vision/pull/49#issuecomment-277560717",
120	    "_docs": """These weights reproduce closely the results of the paper using a simple training recipe.""",
121	}
122	
123	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/squeezenet.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
125	    IMAGENET1K_V1 = Weights(
126	        url="https://download.pytorch.org/models/squeezenet1_0-b66bff10.pth",
127	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/squeezenet.py:147
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
146	    IMAGENET1K_V1 = Weights(
147	        url="https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth",
148	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:654
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
653	    IMAGENET1K_V1 = Weights(
654	        url="https://download.pytorch.org/models/swin_t-704ceda3.pth",
655	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:662
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
661	            "min_size": (224, 224),
662	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#swintransformer",
663	            "_metrics": {
664	                "ImageNet-1K": {
665	                    "acc@1": 81.474,
666	                    "acc@5": 95.776,
667	                }
668	            },
669	            "_ops": 4.491,
670	            "_file_size": 108.19,
671	            "_docs": """These weights reproduce closely the results of the paper using a similar training recipe.""",
672	        },
673	    )
674	    DEFAULT = IMAGENET1K_V1
675	
676	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:679
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
678	    IMAGENET1K_V1 = Weights(
679	        url="https://download.pytorch.org/models/swin_s-5e29d889.pth",
680	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:687
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
686	            "min_size": (224, 224),
687	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#swintransformer",
688	            "_metrics": {
689	                "ImageNet-1K": {
690	                    "acc@1": 83.196,
691	                    "acc@5": 96.360,
692	                }
693	            },
694	            "_ops": 8.741,
695	            "_file_size": 189.786,
696	            "_docs": """These weights reproduce closely the results of the paper using a similar training recipe.""",
697	        },
698	    )
699	    DEFAULT = IMAGENET1K_V1
700	
701	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:704
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
703	    IMAGENET1K_V1 = Weights(
704	        url="https://download.pytorch.org/models/swin_b-68c6b09e.pth",
705	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:712
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
711	            "min_size": (224, 224),
712	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#swintransformer",
713	            "_metrics": {
714	                "ImageNet-1K": {
715	                    "acc@1": 83.582,
716	                    "acc@5": 96.640,
717	                }
718	            },
719	            "_ops": 15.431,
720	            "_file_size": 335.364,
721	            "_docs": """These weights reproduce closely the results of the paper using a similar training recipe.""",
722	        },
723	    )
724	    DEFAULT = IMAGENET1K_V1
725	
726	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:729
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
728	    IMAGENET1K_V1 = Weights(
729	        url="https://download.pytorch.org/models/swin_v2_t-b137f0e2.pth",
730	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:737
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
736	            "min_size": (256, 256),
737	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#swintransformer-v2",
738	            "_metrics": {
739	                "ImageNet-1K": {
740	                    "acc@1": 82.072,
741	                    "acc@5": 96.132,
742	                }
743	            },
744	            "_ops": 5.94,
745	            "_file_size": 108.626,
746	            "_docs": """These weights reproduce closely the results of the paper using a similar training recipe.""",
747	        },
748	    )
749	    DEFAULT = IMAGENET1K_V1
750	
751	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:754
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
753	    IMAGENET1K_V1 = Weights(
754	        url="https://download.pytorch.org/models/swin_v2_s-637d8ceb.pth",
755	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:762
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
761	            "min_size": (256, 256),
762	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#swintransformer-v2",
763	            "_metrics": {
764	                "ImageNet-1K": {
765	                    "acc@1": 83.712,
766	                    "acc@5": 96.816,
767	                }
768	            },
769	            "_ops": 11.546,
770	            "_file_size": 190.675,
771	            "_docs": """These weights reproduce closely the results of the paper using a similar training recipe.""",
772	        },
773	    )
774	    DEFAULT = IMAGENET1K_V1
775	
776	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:779
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
778	    IMAGENET1K_V1 = Weights(
779	        url="https://download.pytorch.org/models/swin_v2_b-781e5279.pth",
780	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/swin_transformer.py:787
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
786	            "min_size": (256, 256),
787	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#swintransformer-v2",
788	            "_metrics": {
789	                "ImageNet-1K": {
790	                    "acc@1": 84.112,
791	                    "acc@5": 96.864,
792	                }
793	            },
794	            "_ops": 20.325,
795	            "_file_size": 336.372,
796	            "_docs": """These weights reproduce closely the results of the paper using a similar training recipe.""",
797	        },
798	    )
799	    DEFAULT = IMAGENET1K_V1
800	
801	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
111	    "categories": _IMAGENET_CATEGORIES,
112	    "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg",
113	    "_docs": """These weights were trained from scratch by using a simplified training recipe.""",
114	}
115	
116	
117	class VGG11_Weights(WeightsEnum):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:119
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
118	    IMAGENET1K_V1 = Weights(
119	        url="https://download.pytorch.org/models/vgg11-8a719046.pth",
120	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:139
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
138	    IMAGENET1K_V1 = Weights(
139	        url="https://download.pytorch.org/models/vgg11_bn-6002323d.pth",
140	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:159
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
158	    IMAGENET1K_V1 = Weights(
159	        url="https://download.pytorch.org/models/vgg13-19584684.pth",
160	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:179
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
178	    IMAGENET1K_V1 = Weights(
179	        url="https://download.pytorch.org/models/vgg13_bn-abd245e5.pth",
180	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
198	    IMAGENET1K_V1 = Weights(
199	        url="https://download.pytorch.org/models/vgg16-397923af.pth",
200	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:216
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
215	        # Weights ported from https://github.com/amdegroot/ssd.pytorch/
216	        url="https://download.pytorch.org/models/vgg16_features-amdegroot-88682ab5.pth",
217	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:227
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
226	            "categories": None,
227	            "recipe": "https://github.com/amdegroot/ssd.pytorch#training-ssd",
228	            "_metrics": {
229	                "ImageNet-1K": {
230	                    "acc@1": float("nan"),
231	                    "acc@5": float("nan"),
232	                }
233	            },
234	            "_ops": 15.47,
235	            "_file_size": 527.802,
236	            "_docs": """
237	                These weights can't be used for classification because they are missing values in the `classifier`
238	                module. Only the `features` module has valid values and can be used for feature extraction. The weights
239	                were trained using the original input standardization method as described in the paper.
240	            """,
241	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:248
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
247	    IMAGENET1K_V1 = Weights(
248	        url="https://download.pytorch.org/models/vgg16_bn-6c64b313.pth",
249	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:268
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
267	    IMAGENET1K_V1 = Weights(
268	        url="https://download.pytorch.org/models/vgg19-dcbb9e9d.pth",
269	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vgg.py:288
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
287	    IMAGENET1K_V1 = Weights(
288	        url="https://download.pytorch.org/models/vgg19_bn-c79401a0.pth",
289	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/mvit.py:603
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
602	    KINETICS400_V1 = Weights(
603	        url="https://download.pytorch.org/models/mvit_v1_b-dbeb1030.pth",
604	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/mvit.py:615
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
614	            "categories": _KINETICS400_CATEGORIES,
615	            "recipe": "https://github.com/facebookresearch/pytorchvideo/blob/main/docs/source/model_zoo.md",
616	            "_docs": (
617	                "The weights were ported from the paper. The accuracies are estimated on video-level "
618	                "with parameters `frame_rate=7.5`, `clips_per_video=5`, and `clip_len=16`"
619	            ),
620	            "num_params": 36610672,
621	            "_metrics": {
622	                "Kinetics-400": {
623	                    "acc@1": 78.477,
624	                    "acc@5": 93.582,
625	                }
626	            },
627	            "_ops": 70.599,
628	            "_file_size": 139.764,
629	        },
630	    )
631	    DEFAULT = KINETICS400_V1
632	
633	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/mvit.py:636
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
635	    KINETICS400_V1 = Weights(
636	        url="https://download.pytorch.org/models/mvit_v2_s-ae3be167.pth",
637	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/mvit.py:648
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
647	            "categories": _KINETICS400_CATEGORIES,
648	            "recipe": "https://github.com/facebookresearch/SlowFast/blob/main/MODEL_ZOO.md",
649	            "_docs": (
650	                "The weights were ported from the paper. The accuracies are estimated on video-level "
651	                "with parameters `frame_rate=7.5`, `clips_per_video=5`, and `clip_len=16`"
652	            ),
653	            "num_params": 34537744,
654	            "_metrics": {
655	                "Kinetics-400": {
656	                    "acc@1": 80.757,
657	                    "acc@5": 94.665,
658	                }
659	            },
660	            "_ops": 64.224,
661	            "_file_size": 131.884,
662	        },
663	    )
664	    DEFAULT = KINETICS400_V1
665	
666	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/resnet.py:314
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
313	    "categories": _KINETICS400_CATEGORIES,
314	    "recipe": "https://github.com/pytorch/vision/tree/main/references/video_classification",
315	    "_docs": (
316	        "The weights reproduce closely the accuracy of the paper. The accuracies are estimated on video-level "
317	        "with parameters `frame_rate=15`, `clips_per_video=5`, and `clip_len=16`."
318	    ),
319	}
320	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/resnet.py:324
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
323	    KINETICS400_V1 = Weights(
324	        url="https://download.pytorch.org/models/r3d_18-b3b3357e.pth",
325	        transforms=partial(VideoClassification, crop_size=(112, 112), resize_size=(128, 171)),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/resnet.py:344
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
343	    KINETICS400_V1 = Weights(
344	        url="https://download.pytorch.org/models/mc3_18-a90a0ba3.pth",
345	        transforms=partial(VideoClassification, crop_size=(112, 112), resize_size=(128, 171)),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/resnet.py:364
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
363	    KINETICS400_V1 = Weights(
364	        url="https://download.pytorch.org/models/r2plus1d_18-91a641e6.pth",
365	        transforms=partial(VideoClassification, crop_size=(112, 112), resize_size=(128, 171)),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/s3d.py:156
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
155	    KINETICS400_V1 = Weights(
156	        url="https://download.pytorch.org/models/s3d-d76dad2f.pth",
157	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/s3d.py:166
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
165	            "categories": _KINETICS400_CATEGORIES,
166	            "recipe": "https://github.com/pytorch/vision/tree/main/references/video_classification#s3d",
167	            "_docs": (
168	                "The weights aim to approximate the accuracy of the paper. The accuracies are estimated on clip-level "
169	                "with parameters `frame_rate=15`, `clips_per_video=1`, and `clip_len=128`."
170	            ),
171	            "num_params": 8320048,
172	            "_metrics": {
173	                "Kinetics-400": {
174	                    "acc@1": 68.368,
175	                    "acc@5": 88.050,
176	                }
177	            },
178	            "_ops": 17.979,
179	            "_file_size": 31.972,
180	        },
181	    )
182	    DEFAULT = KINETICS400_V1
183	
184	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/swin_transformer.py:514
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
513	    KINETICS400_V1 = Weights(
514	        url="https://download.pytorch.org/models/swin3d_t-7615ae03.pth",
515	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/swin_transformer.py:524
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
523	            **_COMMON_META,
524	            "recipe": "https://github.com/SwinTransformer/Video-Swin-Transformer#kinetics-400",
525	            "_docs": (
526	                "The weights were ported from the paper. The accuracies are estimated on video-level "
527	                "with parameters `frame_rate=15`, `clips_per_video=12`, and `clip_len=32`"
528	            ),
529	            "num_params": 28158070,
530	            "_metrics": {
531	                "Kinetics-400": {
532	                    "acc@1": 77.715,
533	                    "acc@5": 93.519,
534	                }
535	            },
536	            "_ops": 43.882,
537	            "_file_size": 121.543,
538	        },
539	    )
540	    DEFAULT = KINETICS400_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/swin_transformer.py:545
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
544	    KINETICS400_V1 = Weights(
545	        url="https://download.pytorch.org/models/swin3d_s-da41c237.pth",
546	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/swin_transformer.py:555
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
554	            **_COMMON_META,
555	            "recipe": "https://github.com/SwinTransformer/Video-Swin-Transformer#kinetics-400",
556	            "_docs": (
557	                "The weights were ported from the paper. The accuracies are estimated on video-level "
558	                "with parameters `frame_rate=15`, `clips_per_video=12`, and `clip_len=32`"
559	            ),
560	            "num_params": 49816678,
561	            "_metrics": {
562	                "Kinetics-400": {
563	                    "acc@1": 79.521,
564	                    "acc@5": 94.158,
565	                }
566	            },
567	            "_ops": 82.841,
568	            "_file_size": 218.288,
569	        },
570	    )
571	    DEFAULT = KINETICS400_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/swin_transformer.py:576
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
575	    KINETICS400_V1 = Weights(
576	        url="https://download.pytorch.org/models/swin3d_b_1k-24f7c7c6.pth",
577	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/swin_transformer.py:586
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
585	            **_COMMON_META,
586	            "recipe": "https://github.com/SwinTransformer/Video-Swin-Transformer#kinetics-400",
587	            "_docs": (
588	                "The weights were ported from the paper. The accuracies are estimated on video-level "
589	                "with parameters `frame_rate=15`, `clips_per_video=12`, and `clip_len=32`"
590	            ),
591	            "num_params": 88048984,
592	            "_metrics": {
593	                "Kinetics-400": {
594	                    "acc@1": 79.427,
595	                    "acc@5": 94.386,
596	                }
597	            },
598	            "_ops": 140.667,
599	            "_file_size": 364.134,
600	        },
601	    )
602	    KINETICS400_IMAGENET22K_V1 = Weights(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/swin_transformer.py:603
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
602	    KINETICS400_IMAGENET22K_V1 = Weights(
603	        url="https://download.pytorch.org/models/swin3d_b_22k-7c6ae6fa.pth",
604	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/video/swin_transformer.py:613
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
612	            **_COMMON_META,
613	            "recipe": "https://github.com/SwinTransformer/Video-Swin-Transformer#kinetics-400",
614	            "_docs": (
615	                "The weights were ported from the paper. The accuracies are estimated on video-level "
616	                "with parameters `frame_rate=15`, `clips_per_video=12`, and `clip_len=32`"
617	            ),
618	            "num_params": 88048984,
619	            "_metrics": {
620	                "Kinetics-400": {
621	                    "acc@1": 81.643,
622	                    "acc@5": 95.574,
623	                }
624	            },
625	            "_ops": 140.667,
626	            "_file_size": 364.134,
627	        },
628	    )
629	    DEFAULT = KINETICS400_V1

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:346
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
345	    **_COMMON_META,
346	    "recipe": "https://github.com/facebookresearch/SWAG",
347	    "license": "https://github.com/facebookresearch/SWAG/blob/main/LICENSE",
348	}
349	
350	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:347
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
346	    "recipe": "https://github.com/facebookresearch/SWAG",
347	    "license": "https://github.com/facebookresearch/SWAG/blob/main/LICENSE",
348	}
349	
350	
351	class ViT_B_16_Weights(WeightsEnum):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:353
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
352	    IMAGENET1K_V1 = Weights(
353	        url="https://download.pytorch.org/models/vit_b_16-c867db91.pth",
354	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:359
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
358	            "min_size": (224, 224),
359	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#vit_b_16",
360	            "_metrics": {
361	                "ImageNet-1K": {
362	                    "acc@1": 81.072,
363	                    "acc@5": 95.318,
364	                }
365	            },
366	            "_ops": 17.564,
367	            "_file_size": 330.285,
368	            "_docs": """
369	                These weights were trained from scratch by using a modified version of `DeIT
370	                <https://arxiv.org/abs/2012.12877>`_'s training recipe.
371	            """,
372	        },
373	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:368
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
367	            "_file_size": 330.285,
368	            "_docs": """
369	                These weights were trained from scratch by using a modified version of `DeIT
370	                <https://arxiv.org/abs/2012.12877>`_'s training recipe.
371	            """,
372	        },
373	    )
374	    IMAGENET1K_SWAG_E2E_V1 = Weights(
375	        url="https://download.pytorch.org/models/vit_b_16_swag-9ac1b537.pth",
376	        transforms=partial(
377	            ImageClassification,
378	            crop_size=384,
379	            resize_size=384,
380	            interpolation=InterpolationMode.BICUBIC,
381	        ),
382	        meta={

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:375
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
374	    IMAGENET1K_SWAG_E2E_V1 = Weights(
375	        url="https://download.pytorch.org/models/vit_b_16_swag-9ac1b537.pth",
376	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:394
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
393	            "_file_size": 331.398,
394	            "_docs": """
395	                These weights are learnt via transfer learning by end-to-end fine-tuning the original
396	                `SWAG <https://arxiv.org/abs/2201.08371>`_ weights on ImageNet-1K data.
397	            """,
398	        },
399	    )
400	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
401	        url="https://download.pytorch.org/models/vit_b_16_lc_swag-4e70ced5.pth",
402	        transforms=partial(
403	            ImageClassification,
404	            crop_size=224,
405	            resize_size=224,
406	            interpolation=InterpolationMode.BICUBIC,
407	        ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:401
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
400	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
401	        url="https://download.pytorch.org/models/vit_b_16_lc_swag-4e70ced5.pth",
402	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:410
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
409	            **_COMMON_SWAG_META,
410	            "recipe": "https://github.com/pytorch/vision/pull/5793",
411	            "num_params": 86567656,
412	            "min_size": (224, 224),
413	            "_metrics": {
414	                "ImageNet-1K": {
415	                    "acc@1": 81.886,
416	                    "acc@5": 96.180,
417	                }
418	            },
419	            "_ops": 17.564,
420	            "_file_size": 330.285,
421	            "_docs": """
422	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
423	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
424	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:421
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
420	            "_file_size": 330.285,
421	            "_docs": """
422	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
423	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
424	            """,
425	        },
426	    )
427	    DEFAULT = IMAGENET1K_V1
428	
429	
430	class ViT_B_32_Weights(WeightsEnum):
431	    IMAGENET1K_V1 = Weights(
432	        url="https://download.pytorch.org/models/vit_b_32-d86f8d99.pth",
433	        transforms=partial(ImageClassification, crop_size=224),
434	        meta={
435	            **_COMMON_META,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:432
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
431	    IMAGENET1K_V1 = Weights(
432	        url="https://download.pytorch.org/models/vit_b_32-d86f8d99.pth",
433	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:438
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
437	            "min_size": (224, 224),
438	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#vit_b_32",
439	            "_metrics": {
440	                "ImageNet-1K": {
441	                    "acc@1": 75.912,
442	                    "acc@5": 92.466,
443	                }
444	            },
445	            "_ops": 4.409,
446	            "_file_size": 336.604,
447	            "_docs": """
448	                These weights were trained from scratch by using a modified version of `DeIT
449	                <https://arxiv.org/abs/2012.12877>`_'s training recipe.
450	            """,
451	        },
452	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:447
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
446	            "_file_size": 336.604,
447	            "_docs": """
448	                These weights were trained from scratch by using a modified version of `DeIT
449	                <https://arxiv.org/abs/2012.12877>`_'s training recipe.
450	            """,
451	        },
452	    )
453	    DEFAULT = IMAGENET1K_V1
454	
455	
456	class ViT_L_16_Weights(WeightsEnum):
457	    IMAGENET1K_V1 = Weights(
458	        url="https://download.pytorch.org/models/vit_l_16-852ce7e3.pth",
459	        transforms=partial(ImageClassification, crop_size=224, resize_size=242),
460	        meta={
461	            **_COMMON_META,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:458
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
457	    IMAGENET1K_V1 = Weights(
458	        url="https://download.pytorch.org/models/vit_l_16-852ce7e3.pth",
459	        transforms=partial(ImageClassification, crop_size=224, resize_size=242),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:464
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
463	            "min_size": (224, 224),
464	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#vit_l_16",
465	            "_metrics": {
466	                "ImageNet-1K": {
467	                    "acc@1": 79.662,
468	                    "acc@5": 94.638,
469	                }
470	            },
471	            "_ops": 61.555,
472	            "_file_size": 1161.023,
473	            "_docs": """
474	                These weights were trained from scratch by using a modified version of TorchVision's
475	                `new training recipe
476	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
477	            """,
478	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:473
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
472	            "_file_size": 1161.023,
473	            "_docs": """
474	                These weights were trained from scratch by using a modified version of TorchVision's
475	                `new training recipe
476	                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
477	            """,
478	        },
479	    )
480	    IMAGENET1K_SWAG_E2E_V1 = Weights(
481	        url="https://download.pytorch.org/models/vit_l_16_swag-4f3808c9.pth",
482	        transforms=partial(
483	            ImageClassification,
484	            crop_size=512,
485	            resize_size=512,
486	            interpolation=InterpolationMode.BICUBIC,
487	        ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:481
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
480	    IMAGENET1K_SWAG_E2E_V1 = Weights(
481	        url="https://download.pytorch.org/models/vit_l_16_swag-4f3808c9.pth",
482	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:500
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
499	            "_file_size": 1164.258,
500	            "_docs": """
501	                These weights are learnt via transfer learning by end-to-end fine-tuning the original
502	                `SWAG <https://arxiv.org/abs/2201.08371>`_ weights on ImageNet-1K data.
503	            """,
504	        },
505	    )
506	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
507	        url="https://download.pytorch.org/models/vit_l_16_lc_swag-4d563306.pth",
508	        transforms=partial(
509	            ImageClassification,
510	            crop_size=224,
511	            resize_size=224,
512	            interpolation=InterpolationMode.BICUBIC,
513	        ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:507
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
506	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
507	        url="https://download.pytorch.org/models/vit_l_16_lc_swag-4d563306.pth",
508	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:516
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
515	            **_COMMON_SWAG_META,
516	            "recipe": "https://github.com/pytorch/vision/pull/5793",
517	            "num_params": 304326632,
518	            "min_size": (224, 224),
519	            "_metrics": {
520	                "ImageNet-1K": {
521	                    "acc@1": 85.146,
522	                    "acc@5": 97.422,
523	                }
524	            },
525	            "_ops": 61.555,
526	            "_file_size": 1161.023,
527	            "_docs": """
528	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
529	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
530	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:527
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
526	            "_file_size": 1161.023,
527	            "_docs": """
528	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
529	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
530	            """,
531	        },
532	    )
533	    DEFAULT = IMAGENET1K_V1
534	
535	
536	class ViT_L_32_Weights(WeightsEnum):
537	    IMAGENET1K_V1 = Weights(
538	        url="https://download.pytorch.org/models/vit_l_32-c7638314.pth",
539	        transforms=partial(ImageClassification, crop_size=224),
540	        meta={
541	            **_COMMON_META,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:538
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
537	    IMAGENET1K_V1 = Weights(
538	        url="https://download.pytorch.org/models/vit_l_32-c7638314.pth",
539	        transforms=partial(ImageClassification, crop_size=224),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:544
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
543	            "min_size": (224, 224),
544	            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#vit_l_32",
545	            "_metrics": {
546	                "ImageNet-1K": {
547	                    "acc@1": 76.972,
548	                    "acc@5": 93.07,
549	                }
550	            },
551	            "_ops": 15.378,
552	            "_file_size": 1169.449,
553	            "_docs": """
554	                These weights were trained from scratch by using a modified version of `DeIT
555	                <https://arxiv.org/abs/2012.12877>`_'s training recipe.
556	            """,
557	        },
558	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:553
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
552	            "_file_size": 1169.449,
553	            "_docs": """
554	                These weights were trained from scratch by using a modified version of `DeIT
555	                <https://arxiv.org/abs/2012.12877>`_'s training recipe.
556	            """,
557	        },
558	    )
559	    DEFAULT = IMAGENET1K_V1
560	
561	
562	class ViT_H_14_Weights(WeightsEnum):
563	    IMAGENET1K_SWAG_E2E_V1 = Weights(
564	        url="https://download.pytorch.org/models/vit_h_14_swag-80465313.pth",
565	        transforms=partial(
566	            ImageClassification,
567	            crop_size=518,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:564
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
563	    IMAGENET1K_SWAG_E2E_V1 = Weights(
564	        url="https://download.pytorch.org/models/vit_h_14_swag-80465313.pth",
565	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:583
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
582	            "_file_size": 2416.643,
583	            "_docs": """
584	                These weights are learnt via transfer learning by end-to-end fine-tuning the original
585	                `SWAG <https://arxiv.org/abs/2201.08371>`_ weights on ImageNet-1K data.
586	            """,
587	        },
588	    )
589	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
590	        url="https://download.pytorch.org/models/vit_h_14_lc_swag-c1eb923e.pth",
591	        transforms=partial(
592	            ImageClassification,
593	            crop_size=224,
594	            resize_size=224,
595	            interpolation=InterpolationMode.BICUBIC,
596	        ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:590
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
589	    IMAGENET1K_SWAG_LINEAR_V1 = Weights(
590	        url="https://download.pytorch.org/models/vit_h_14_lc_swag-c1eb923e.pth",
591	        transforms=partial(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:599
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
598	            **_COMMON_SWAG_META,
599	            "recipe": "https://github.com/pytorch/vision/pull/5793",
600	            "num_params": 632045800,
601	            "min_size": (224, 224),
602	            "_metrics": {
603	                "ImageNet-1K": {
604	                    "acc@1": 85.708,
605	                    "acc@5": 97.730,
606	                }
607	            },
608	            "_ops": 167.295,
609	            "_file_size": 2411.209,
610	            "_docs": """
611	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
612	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
613	            """,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/models/vision_transformer.py:610
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
609	            "_file_size": 2411.209,
610	            "_docs": """
611	                These weights are composed of the original frozen `SWAG <https://arxiv.org/abs/2201.08371>`_ trunk
612	                weights and a linear classifier learnt on top of them trained on ImageNet-1K data.
613	            """,
614	        },
615	    )
616	    DEFAULT = IMAGENET1K_SWAG_E2E_V1
617	
618	
619	@register_model()
620	@handle_legacy_interface(weights=("pretrained", ViT_B_16_Weights.IMAGENET1K_V1))
621	def vit_b_16(*, weights: Optional[ViT_B_16_Weights] = None, progress: bool = True, **kwargs: Any) -> VisionTransformer:
622	    """
623	    Constructs a vit_b_16 architecture from
624	    `An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale <https://arxiv.org/abs/2010.11929>`_.

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/tv_tensors/_dataset_wrapper.py:133
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
132	            raise TypeError(
133	                f"This wrapper is meant for subclasses of `torchvision.datasets.VisionDataset`, "
134	                f"but got a '{dataset_cls.__name__}' instead.\n"
135	                f"For an example of how to perform the wrapping for custom datasets, see\n\n"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/tv_tensors/_dataset_wrapper.py:158
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
157	                    msg = (
158	                        f"{msg} If an automated wrapper for this dataset would be useful for you, "
159	                        f"please open an issue at https://github.com/pytorch/vision/issues."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/torchvision-0.21.0-cp39-cp39-win_amd64/torchvision/tv_tensors/_dataset_wrapper.py:217
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
216	    raise RuntimeError(
217	        f"{description} is currently not supported by this wrapper. "
218	        f"If this would be helpful for you, please open an issue at https://github.com/pytorch/vision/issues."

--------------------------------------------------

Code scanned:
	Total lines of code: 46716
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 436.0
		High: 26.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 461.0
		High: 1.0
Files skipped (0):
