Run started:2025-04-12 14:33:53.950091

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/setup.py:54
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
53	    license="MIT",
54	    url="https://github.com/martin-majlis/Wikipedia-API",
55	    download_url="https://github.com/martin-majlis/Wikipedia-API/archive/master.tar.gz",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/setup.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
54	    url="https://github.com/martin-majlis/Wikipedia-API",
55	    download_url="https://github.com/martin-majlis/Wikipedia-API/archive/master.tar.gz",
56	    keywords="Wikipedia API wrapper",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
22	    + ".".join(str(s) for s in __version__)
23	    + "; https://github.com/martin-majlis/Wikipedia-API/"
24	)
25	
26	MIN_USER_AGENT_LEN = 5

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:177
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
176	            variant,
177	            default_headers.get("User-Agent"),
178	        )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:539
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
538	
539	        r = self._session.get(base_url, params=used_params, **self._request_kwargs)
540	        return r.json()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:628
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
627	
628	        for langlink in extract.get("langlinks", []):
629	            p = WikipediaPage(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:646
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
645	
646	        for link in extract.get("links", []):
647	            page._links[link["title"]] = WikipediaPage(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:663
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
662	
663	        for backlink in extract.get("backlinks", []):
664	            page._backlinks[backlink["title"]] = WikipediaPage(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:680
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
679	
680	        for category in extract.get("categories", []):
681	            page._categories[category["title"]] = WikipediaPage(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:697
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
696	
697	        for member in extract.get("categorymembers", []):
698	            p = WikipediaPage(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:735
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
734	                "Please, be nice to Wikipedia and specify user agent - "
735	                + "https://meta.wikimedia.org/wiki/User-Agent_policy. Current user_agent: '"
736	                + str(user_agent)
737	                + "' is not sufficient. "

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:1035
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1034	            self._fetch("extracts")
1035	        sections = self._section_mapping.get(title)
1036	        if sections:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/wikipedia_api-0.8.1/wikipedia_api-0.8.1/wikipediaapi/__init__.py:1052
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1051	            self._fetch("extracts")
1052	        sections = self._section_mapping.get(title)
1053	        if sections is None:

--------------------------------------------------

Code scanned:
	Total lines of code: 985
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 4.0
		High: 9.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 13.0
		High: 0.0
Files skipped (0):
