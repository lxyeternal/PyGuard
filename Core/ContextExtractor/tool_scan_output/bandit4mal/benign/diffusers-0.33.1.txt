Run started:2025-04-12 12:39:17.809354

Test results:
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/setup.py:213
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
212	        with open(target, "w", encoding="utf-8", newline="\n") as f:
213	            f.write("\n".join(content))
214	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/setup.py:274
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
273	    description="State-of-the-art diffusion in PyTorch and JAX.",
274	    long_description=open("README.md", "r", encoding="utf-8").read(),
275	    long_description_content_type="text/markdown",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/setup.py:278
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
277	    license="Apache 2.0 License",
278	    author="The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/diffusers/graphs/contributors)",
279	    author_email="diffusers@huggingface.co",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/setup.py:280
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
279	    author_email="diffusers@huggingface.co",
280	    url="https://github.com/huggingface/diffusers",
281	    package_dir={"": "src"},

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/commands/env.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
111	        accelerator = "NA"
112	        if platform.system() in {"Linux", "Windows"}:
113	            try:

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/commands/env.py:112
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
111	        accelerator = "NA"
112	        if platform.system() in {"Linux", "Windows"}:
113	            try:

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/commands/env.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
125	                pass
126	        elif platform.system() == "Darwin":  # Mac OS
127	            try:

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/commands/env.py:126
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
125	                pass
126	        elif platform.system() == "Darwin":  # Mac OS
127	            try:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/commands/fp16_safetensors.py:121
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
120	        commit_description = (
121	            "Variables converted by the [`diffusers`' `fp16_safetensors`"
122	            " CLI](https://github.com/huggingface/diffusers/blob/main/src/diffusers/commands/fp16_safetensors.py)."
123	        )
124	        hub_pr_url = create_commit(
125	            repo_id=self.ckpt_id,

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/configuration_utils.py:390
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
389	                # Load from URL or cache if already cached
390	                config_file = hf_hub_download(
391	                    pretrained_model_name_or_path,
392	                    filename=cls.config_name,
393	                    cache_dir=cache_dir,
394	                    force_download=force_download,
395	                    proxies=proxies,
396	                    local_files_only=local_files_only,
397	                    token=token,
398	                    user_agent=user_agent,
399	                    subfolder=subfolder,
400	                    revision=revision,
401	                    local_dir=local_dir,
402	                    local_dir_use_symlinks=local_dir_use_symlinks,
403	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/configuration_utils.py:406
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
405	                raise EnvironmentError(
406	                    f"{pretrained_model_name_or_path} is not a local folder and is not a valid model identifier"
407	                    " listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/configuration_utils.py:412
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
411	                raise EnvironmentError(
412	                    f"{revision} is not a valid git identifier (branch name, tag name or commit id) that exists for"
413	                    " this model name. Check the model page at"
414	                    f" 'https://huggingface.co/{pretrained_model_name_or_path}' for available revisions."
415	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/configuration_utils.py:427
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
426	                raise EnvironmentError(
427	                    f"We couldn't connect to '{HUGGINGFACE_CO_RESOLVE_ENDPOINT}' to load this model, couldn't find it"
428	                    f" in the cached files and it looks like {pretrained_model_name_or_path} is not the path to a"
429	                    f" directory containing a {cls.config_name} file.\nCheckout your internet connection or see how to"
430	                    " run the library in offline mode at"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/configuration_utils.py:435
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
434	                raise EnvironmentError(
435	                    f"Can't load config for '{pretrained_model_name_or_path}'. If you were trying to load it from "
436	                    "'https://huggingface.co/models', make sure you don't have a local directory with the same name. "
437	                    f"Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory "
438	                    f"containing a {cls.config_name} file"
439	                )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/configuration_utils.py:467
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
466	        # Skip keys that were not present in the original config, so default __init__ values were used
467	        used_defaults = config_dict.get("_use_default_values", [])
468	        config_dict = {k: v for k, v in config_dict.items() if k not in used_defaults and k != "_use_default_values"}

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/configuration_utils.py:571
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
570	            with open(json_file, "r", encoding="utf-8") as reader:
571	                text = reader.read()
572	        return json.loads(text)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/configuration_utils.py:631
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
630	        with open(json_file_path, "w", encoding="utf-8") as writer:
631	            writer.write(self.to_json_string())
632	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/configuration_utils.py:681
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
680	            {
681	                k: init_kwargs.get(k, default)
682	                for k, default in parameters.items()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/hooks/faster_cache.py:518
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
517	    logger.warning(
518	        "FasterCache is a purely experimental feature and may not work as expected. Not all models support FasterCache. "
519	        "The API is subject to change in future releases, with no guarantee of backward compatibility. Please report any issues at "
520	        "https://github.com/huggingface/diffusers/issues."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/__init__.py:11
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
10	        "0.27.0",
11	        "`text_encoder_lora_state_dict` is deprecated and will be removed in 0.27.0. Make sure to retrieve the weights using `get_peft_model`. See https://huggingface.co/docs/peft/v0.6.2/en/quicktour#peftmodel for more information.",
12	    )
13	    state_dict = {}
14	
15	    for name, module in text_encoder_attn_modules(text_encoder):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/__init__.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	            "0.27.0",
37	            "`text_encoder_lora_state_dict` is deprecated and will be removed in 0.27.0. Make sure to retrieve the weights using `get_peft_model`. See https://huggingface.co/docs/peft/v0.6.2/en/quicktour#peftmodel for more information.",
38	        )
39	        from transformers import CLIPTextModel, CLIPTextModelWithProjection
40	
41	        attn_modules = []

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_base.py:432
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
431	        logger.warning(
432	            f"No LoRA keys associated to {text_encoder.__class__.__name__} found with the {prefix=}. "
433	            "This is safe to ignore if LoRA state dict didn't originally have any "
434	            f"{text_encoder.__class__.__name__} related params. You can also try specifying `prefix=None` "
435	            "to resolve the warning. Otherwise, open an issue if you think it's unexpected: "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_conversion_utils.py:809
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
808	                logger.info(
809	                    "The state_dict has position_embedding LoRA params and we currently do not support them. "
810	                    "Open an issue if you need this supported - https://github.com/huggingface/diffusers/issues/new."
811	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_conversion_utils.py:824
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
823	                logger.info(
824	                    "T5-xxl keys found in the state dict, which are currently unsupported. We will filter them out."
825	                    "Open an issue if this is a problem - https://github.com/huggingface/diffusers/issues/new."
826	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_conversion_utils.py:839
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
838	                logger.info(
839	                    "`diff_b` keys found in the state dict which are currently unsupported. "
840	                    "So, we will filter out those keys. Open an issue if this is a problem - "
841	                    "https://github.com/huggingface/diffusers/issues/new."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_conversion_utils.py:855
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
854	                logger.info(
855	                    "Normalization diff keys found in the state dict which are currently unsupported. "
856	                    "So, we will filter out those keys. Open an issue if this is a problem - "
857	                    "https://github.com/huggingface/diffusers/issues/new."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_conversion_utils.py:873
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
872	            logger.info(
873	                "`text_projection` keys found in the `state_dict` which are unexpected. "
874	                "So, we will filter out those keys. Open an issue if this is a problem - "
875	                "https://github.com/huggingface/diffusers/issues/new."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:316
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
315	        if is_dora_scale_present:
316	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
317	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:806
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
805	        if is_dora_scale_present:
806	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
807	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:1216
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1215	        if is_dora_scale_present:
1216	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
1217	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:1699
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1698	        if is_dora_scale_present:
1699	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
1700	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:1988
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1987	        logger.info(
1988	            "The provided state dict contains normalization layers in addition to LoRA layers. The normalization layers will directly update the state_dict of the transformer "
1989	            'as opposed to the LoRA layers that will co-exist separately until the "fuse_lora()" method is called. That is to say, the normalization layers will always be directly '
1990	            "fused into the transformer and can only be unfused if `discard_original_layers=True` is passed. This might also have implications when dealing with multiple LoRAs. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:2450
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2449	                raise NotImplementedError(
2450	                    f"This LoRA param ({k}.lora_A.weight) has an incompatible shape {lora_A_param.shape}. Please open an issue to file for a feature request - https://github.com/huggingface/diffusers/issues/new."
2451	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:2455
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2454	            logger.info(
2455	                f"The following LoRA modules were zero padded to match the state dict of {cls.transformer_name}: {expanded_module_names}. Please open an issue if you think this was unexpected - https://github.com/huggingface/diffusers/issues/new."
2456	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:2797
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2796	        if is_dora_scale_present:
2797	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
2798	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:3127
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
3126	        if is_dora_scale_present:
3127	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
3128	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:3460
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
3459	        if is_dora_scale_present:
3460	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
3461	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:3793
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
3792	        if is_dora_scale_present:
3793	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
3794	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:4125
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4124	        if is_dora_scale_present:
4125	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
4126	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:4461
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4460	        if is_dora_scale_present:
4461	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
4462	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:4800
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4799	        if is_dora_scale_present:
4800	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
4801	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/lora_pipeline.py:5163
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
5162	        if is_dora_scale_present:
5163	            warn_msg = "It seems like you are using a DoRA checkpoint that is not compatible in Diffusers at the moment. So, we are going to filter out the keys associated to 'dora_scale` from the state dict. If you think this is a mistake please open an issue https://github.com/huggingface/diffusers/issues/new."
5164	            logger.warning(warn_msg)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/peft.py:417
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
416	            logger.warning(
417	                f"No LoRA keys associated to {self.__class__.__name__} found with the {prefix=}. "
418	                "This is safe to ignore if LoRA state dict didn't originally have any "
419	                f"{self.__class__.__name__} related params. You can also try specifying `prefix=None` "
420	                "to resolve the warning. Otherwise, open an issue if you think it's unexpected: "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/peft.py:618
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
617	                    raise ValueError(
618	                        "You are trying to set multiple adapters and you have a PEFT version that does not support multi-adapter inference. Please upgrade to the latest version of PEFT."
619	                        " `pip install -U peft` or `pip install -U git+https://github.com/huggingface/peft.git`"
620	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:346
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
345	
346	VALID_URL_PREFIXES = ["https://huggingface.co/", "huggingface.co/", "hf.co/", "https://hf.co/"]
347	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:346
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
345	
346	VALID_URL_PREFIXES = ["https://huggingface.co/", "huggingface.co/", "hf.co/", "https://hf.co/"]
347	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:438
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
437	        with open(original_config_file, "r") as fp:
438	            original_config_file = fp.read()
439	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:447
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
446	
447	        original_config_file = BytesIO(requests.get(original_config_file, timeout=DIFFUSERS_REQUEST_TIMEOUT).content)
448	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:961
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
960	            diffusers_key = diffusers_key.replace(mapping["old"], mapping["new"])
961	        new_checkpoint[diffusers_key] = checkpoint.get(ldm_key)
962	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:967
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
966	        diffusers_key = ldm_key.replace(mapping["old"], mapping["new"])
967	        new_checkpoint[diffusers_key] = checkpoint.get(ldm_key)
968	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:973
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
972	        diffusers_key = ldm_key.replace(mapping["old"], mapping["new"]).replace("nin_shortcut", "conv_shortcut")
973	        new_checkpoint[diffusers_key] = checkpoint.get(ldm_key)
974	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:991
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
990	        )
991	        new_checkpoint[diffusers_key] = checkpoint.get(ldm_key)
992	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1077
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1076	                flat_ema_key = "model_ema." + "".join(key.split(".")[1:])
1077	                unet_state_dict[key.replace(unet_key, "")] = checkpoint.get(flat_ema_key)
1078	    else:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1086
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1085	            if key.startswith(unet_key):
1086	                unet_state_dict[key.replace(unet_key, "")] = checkpoint.get(key)
1087	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1147
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1146	        if f"input_blocks.{i}.0.op.weight" in unet_state_dict:
1147	            new_checkpoint[f"down_blocks.{block_id}.downsamplers.0.conv.weight"] = unet_state_dict.get(
1148	                f"input_blocks.{i}.0.op.weight"
1149	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1150
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1149	            )
1150	            new_checkpoint[f"down_blocks.{block_id}.downsamplers.0.conv.bias"] = unet_state_dict.get(
1151	                f"input_blocks.{i}.0.op.bias"
1152	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1244
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1243	            if key.startswith(controlnet_key):
1244	                controlnet_state_dict[key.replace(controlnet_key, "")] = checkpoint.get(key)
1245	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1278
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1277	        if f"input_blocks.{i}.0.op.weight" in controlnet_state_dict:
1278	            new_checkpoint[f"down_blocks.{block_id}.downsamplers.0.conv.weight"] = controlnet_state_dict.get(
1279	                f"input_blocks.{i}.0.op.weight"
1280	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1281
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1280	            )
1281	            new_checkpoint[f"down_blocks.{block_id}.downsamplers.0.conv.bias"] = controlnet_state_dict.get(
1282	                f"input_blocks.{i}.0.op.bias"
1283	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1296
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1295	    for i in range(num_input_blocks):
1296	        new_checkpoint[f"controlnet_down_blocks.{i}.weight"] = controlnet_state_dict.get(f"zero_convs.{i}.0.weight")
1297	        new_checkpoint[f"controlnet_down_blocks.{i}.bias"] = controlnet_state_dict.get(f"zero_convs.{i}.0.bias")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1297
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1296	        new_checkpoint[f"controlnet_down_blocks.{i}.weight"] = controlnet_state_dict.get(f"zero_convs.{i}.0.weight")
1297	        new_checkpoint[f"controlnet_down_blocks.{i}.bias"] = controlnet_state_dict.get(f"zero_convs.{i}.0.bias")
1298	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1327
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1326	    # mid block
1327	    new_checkpoint["controlnet_mid_block.weight"] = controlnet_state_dict.get("middle_block_out.0.weight")
1328	    new_checkpoint["controlnet_mid_block.bias"] = controlnet_state_dict.get("middle_block_out.0.bias")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1328
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1327	    new_checkpoint["controlnet_mid_block.weight"] = controlnet_state_dict.get("middle_block_out.0.weight")
1328	    new_checkpoint["controlnet_mid_block.bias"] = controlnet_state_dict.get("middle_block_out.0.bias")
1329	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1342
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1341	
1342	        new_checkpoint[f"controlnet_cond_embedding.blocks.{diffusers_idx}.weight"] = controlnet_state_dict.get(
1343	            f"input_hint_block.{cond_block_id}.weight"
1344	        )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1345
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1344	        )
1345	        new_checkpoint[f"controlnet_cond_embedding.blocks.{diffusers_idx}.bias"] = controlnet_state_dict.get(
1346	            f"input_hint_block.{cond_block_id}.bias"
1347	        )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1364
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1363	        if key.startswith(vae_key):
1364	            vae_state_dict[key.replace(vae_key, "")] = checkpoint.get(key)
1365	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1388
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1387	        if f"encoder.down.{i}.downsample.conv.weight" in vae_state_dict:
1388	            new_checkpoint[f"encoder.down_blocks.{i}.downsamplers.0.conv.weight"] = vae_state_dict.get(
1389	                f"encoder.down.{i}.downsample.conv.weight"
1390	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1391
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1390	            )
1391	            new_checkpoint[f"encoder.down_blocks.{i}.downsamplers.0.conv.bias"] = vae_state_dict.get(
1392	                f"encoder.down.{i}.downsample.conv.bias"
1393	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1469
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1468	                diffusers_key = key.replace(prefix, "")
1469	                text_model_dict[diffusers_key] = checkpoint.get(key)
1470	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1519
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1518	        if key.endswith(".in_proj_weight"):
1519	            weight_value = checkpoint.get(key)
1520	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1528
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1527	        elif key.endswith(".in_proj_bias"):
1528	            weight_value = checkpoint.get(key)
1529	            text_model_dict[diffusers_key + ".q_proj.bias"] = weight_value[:text_proj_dim].clone().detach()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1535
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1534	        else:
1535	            text_model_dict[diffusers_key] = checkpoint.get(key)
1536	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1648
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1647	):
1648	    scheduler_type = kwargs.get("scheduler_type", None)
1649	    prediction_type = kwargs.get("prediction_type", None)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1649
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1648	    scheduler_type = kwargs.get("scheduler_type", None)
1649	    prediction_type = kwargs.get("prediction_type", None)
1650	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1700
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1699	        if original_config:
1700	            beta_start = original_config["model"]["params"].get("linear_start")
1701	            beta_end = original_config["model"]["params"].get("linear_end")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:1701
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1700	            beta_start = original_config["model"]["params"].get("linear_start")
1701	            beta_end = original_config["model"]["params"].get("linear_end")
1702	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/loaders/single_file_utils.py:2062
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
2061	                diffusers_key = key.replace(prefix, "")
2062	                text_model_dict[diffusers_key] = checkpoint.get(key)
2063	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/attention_processor.py:405
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
404	                    (
405	                        "Refer to https://github.com/facebookresearch/xformers for more information on how to install"
406	                        " xformers"
407	                    ),
408	                    name="xformers",
409	                )
410	            elif not torch.cuda.is_available():
411	                raise ValueError(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/embeddings.py:739
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
738	                raise ValueError(
739	                    "It is currently not possible to generate videos at a different resolution that the defaults. This should only be the case with 'THUDM/CogVideoX-5b-I2V'."
740	                    "If you think this is incorrect, please open an issue at https://github.com/huggingface/diffusers/issues."
741	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/model_loading_utils.py:174
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
173	            if disable_mmap:
174	                return safetensors.torch.load(open(checkpoint_file, "rb").read())
175	            else:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/model_loading_utils.py:195
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
194	            with open(checkpoint_file) as f:
195	                if f.read().startswith("version"):
196	                    raise OSError(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/model_loading_utils.py:289
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
288	                raise ValueError(
289	                    f"Cannot load {model_name_or_path_str} because {param_name} expected shape {empty_state_dict[param_name].shape}, but got {param.shape}. If you want to instead overwrite randomly initialized weights, please make sure to pass both `low_cpu_mem_usage=False` and `ignore_mismatched_sizes=True`. For more information, see also: https://github.com/huggingface/diffusers/issues/1619#issuecomment-1345604389 as an example."
290	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/model_loading_utils.py:494
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
493	        logger.error(
494	            "Loading a GGUF checkpoint in PyTorch, requires both PyTorch and GGUF>=0.10.0 to be installed. Please see "
495	            "https://pytorch.org/ and https://github.com/ggerganov/llama.cpp/tree/master/gguf-py for installation instructions."
496	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/model_loading_utils.py:512
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
511	                (
512	                    f"{name} has a quantization type: {str(quant_type)} which is unsupported."
513	                    "\n\nCurrently the following quantization types are supported: \n\n"
514	                    f"{_supported_quants_str}"
515	                    "\n\nTo request support for this quantization type please open an issue here: https://github.com/huggingface/diffusers"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_flax_utils.py:370
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
369	                raise EnvironmentError(
370	                    f"{pretrained_model_name_or_path} is not a local folder and is not a valid model identifier "
371	                    "listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_flax_utils.py:377
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
376	                raise EnvironmentError(
377	                    f"{revision} is not a valid git identifier (branch name, tag name or commit id) that exists for "
378	                    "this model name. Check the model page at "
379	                    f"'https://huggingface.co/{pretrained_model_name_or_path}' for available revisions."
380	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_flax_utils.py:392
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
391	                raise EnvironmentError(
392	                    f"We couldn't connect to '{HUGGINGFACE_CO_RESOLVE_ENDPOINT}' to load this model, couldn't find it"
393	                    f" in the cached files and it looks like {pretrained_model_name_or_path} is not the path to a"
394	                    f" directory containing a file named {FLAX_WEIGHTS_NAME} or {WEIGHTS_NAME}.\nCheckout your"
395	                    " internet connection or see how to run the library in offline mode at"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_flax_utils.py:400
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
399	                raise EnvironmentError(
400	                    f"Can't load the model for '{pretrained_model_name_or_path}'. If you were trying to load it from "
401	                    "'https://huggingface.co/models', make sure you don't have a local directory with the same name. "
402	                    f"Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory "
403	                    f"containing a file named {FLAX_WEIGHTS_NAME} or {WEIGHTS_NAME}."
404	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_flax_utils.py:423
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
422	                with open(model_file, "rb") as state_f:
423	                    state = from_bytes(cls, state_f.read())
424	            except (UnpicklingError, msgpack.exceptions.ExtraData) as e:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_flax_utils.py:427
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
426	                    with open(model_file) as f:
427	                        if f.read().startswith("version"):
428	                            raise OSError(

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_flax_utils.py:550
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
549	            model_bytes = to_bytes(params)
550	            f.write(model_bytes)
551	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_pytorch_flax_utils.py:65
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
64	        logger.error(
65	            "Loading Flax weights in PyTorch requires both PyTorch and Flax to be installed. Please see"
66	            " https://pytorch.org/ and https://flax.readthedocs.io/en/latest/installation.html for installation"
67	            " instructions."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_utils.py:586
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
585	            raise ValueError(
586	                f"{self.__class__.__name__} does not support group offloading. Please make sure to set the boolean attribute "
587	                f"`_supports_group_offloading` to `True` in the class definition. If you believe this is a mistake, please "

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_utils.py:733
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
732	                content = json.dumps(index, indent=2, sort_keys=True) + "\n"
733	                f.write(content)
734	            logger.info(

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_utils.py:733
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
732	                content = json.dumps(index, indent=2, sort_keys=True) + "\n"
733	                f.write(content)
734	            logger.info(

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/modeling_utils.py:1502
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
1501	                load_offloaded_weights(model, state_dict_index, state_dict_folder)
1502	                shutil.rmtree(state_dict_folder)
1503	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/transformers/cogvideox_transformer_3d.py:257
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
256	            raise ValueError(
257	                "There are no CogVideoX checkpoints available with disable rotary embeddings and learned positional "
258	                "embeddings. If you're using a custom model and/or believe this should be supported, please open an "
259	                "issue at https://github.com/huggingface/diffusers/issues."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/transformers/consisid_transformer_3d.py:512
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
511	            raise ValueError(
512	                "There are no ConsisID checkpoints available with disable rotary embeddings and learned positional "
513	                "embeddings. If you're using a custom model and/or believe this should be supported, please open an "
514	                "issue at https://github.com/huggingface/diffusers/issues."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/unets/unet_2d_condition.py:234
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
233	            raise ValueError(
234	                "At the moment it is not possible to define the number of attention heads via `num_attention_heads` because of a naming issue as described in https://github.com/huggingface/diffusers/issues/2011#issuecomment-1547958131. Passing `num_attention_heads` will only be supported in diffusers v0.19."
235	            )
236	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/unets/unet_2d_condition_flax.py:171
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
170	            raise ValueError(
171	                "At the moment it is not possible to define the number of attention heads via `num_attention_heads` because of a naming issue as described in https://github.com/huggingface/diffusers/issues/2011#issuecomment-1547958131. Passing `num_attention_heads` will only be supported in diffusers v0.19."
172	            )
173	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/models/unets/unet_3d_condition.py:134
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
133	            raise NotImplementedError(
134	                "At the moment it is not possible to define the number of attention heads via `num_attention_heads` because of a naming issue as described in https://github.com/huggingface/diffusers/issues/2011#issuecomment-1547958131. Passing `num_attention_heads` will only be supported in diffusers v0.19."
135	            )
136	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/amused/pipeline_amused_img2img.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
34	
35	EXAMPLE_DOC_STRING = """
36	    Examples:
37	        ```py
38	        >>> import torch
39	        >>> from diffusers import AmusedImg2ImgPipeline
40	        >>> from diffusers.utils import load_image
41	
42	        >>> pipe = AmusedImg2ImgPipeline.from_pretrained(
43	        ...     "amused/amused-512", variant="fp16", torch_dtype=torch.float16
44	        ... )
45	        >>> pipe = pipe.to("cuda")
46	
47	        >>> prompt = "winter mountains"
48	        >>> input_image = (
49	        ...     load_image(
50	        ...         "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/open_muse/mountains.jpg"
51	        ...     )
52	        ...     .resize((512, 512))
53	        ...     .convert("RGB")
54	        ... )
55	        >>> image = pipe(prompt, input_image).images[0]
56	        ```
57	"""
58	
59	
60	class AmusedImg2ImgPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/amused/pipeline_amused_inpaint.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	
36	EXAMPLE_DOC_STRING = """
37	    Examples:
38	        ```py
39	        >>> import torch
40	        >>> from diffusers import AmusedInpaintPipeline
41	        >>> from diffusers.utils import load_image
42	
43	        >>> pipe = AmusedInpaintPipeline.from_pretrained(
44	        ...     "amused/amused-512", variant="fp16", torch_dtype=torch.float16
45	        ... )
46	        >>> pipe = pipe.to("cuda")
47	
48	        >>> prompt = "fall mountains"
49	        >>> input_image = (
50	        ...     load_image(
51	        ...         "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/open_muse/mountains_1.jpg"
52	        ...     )
53	        ...     .resize((512, 512))
54	        ...     .convert("RGB")
55	        ... )
56	        >>> mask = (
57	        ...     load_image(
58	        ...         "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/open_muse/mountains_1_mask.png"
59	        ...     )
60	        ...     .resize((512, 512))
61	        ...     .convert("L")
62	        ... )
63	        >>> pipe(prompt, input_image, mask).images[0].save("out.png")
64	        ```
65	"""
66	
67	
68	class AmusedInpaintPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/animatediff/pipeline_animatediff_controlnet.py:54
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
53	
54	EXAMPLE_DOC_STRING = """
55	    Examples:
56	        ```py
57	        >>> import torch
58	        >>> from diffusers import (
59	        ...     AnimateDiffControlNetPipeline,
60	        ...     AutoencoderKL,
61	        ...     ControlNetModel,
62	        ...     MotionAdapter,
63	        ...     LCMScheduler,
64	        ... )
65	        >>> from diffusers.utils import export_to_gif, load_video
66	
67	        >>> # Additionally, you will need a preprocess videos before they can be used with the ControlNet
68	        >>> # HF maintains just the right package for it: `pip install controlnet_aux`
69	        >>> from controlnet_aux.processor import ZoeDetector
70	
71	        >>> # Download controlnets from https://huggingface.co/lllyasviel/ControlNet-v1-1 to use .from_single_file
72	        >>> # Download Diffusers-format controlnets, such as https://huggingface.co/lllyasviel/sd-controlnet-depth, to use .from_pretrained()
73	        >>> controlnet = ControlNetModel.from_single_file("control_v11f1p_sd15_depth.pth", torch_dtype=torch.float16)
74	
75	        >>> # We use AnimateLCM for this example but one can use the original motion adapters as well (for example, https://huggingface.co/guoyww/animatediff-motion-adapter-v1-5-3)
76	        >>> motion_adapter = MotionAdapter.from_pretrained("wangfuyun/AnimateLCM")
77	
78	        >>> vae = AutoencoderKL.from_pretrained("stabilityai/sd-vae-ft-mse", torch_dtype=torch.float16)
79	        >>> pipe: AnimateDiffControlNetPipeline = AnimateDiffControlNetPipeline.from_pretrained(
80	        ...     "SG161222/Realistic_Vision_V5.1_noVAE",
81	        ...     motion_adapter=motion_adapter,
82	        ...     controlnet=controlnet,
83	        ...     vae=vae,
84	        ... ).to(device="cuda", dtype=torch.float16)
85	        >>> pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config, beta_schedule="linear")
86	        >>> pipe.load_lora_weights(
87	        ...     "wangfuyun/AnimateLCM", weight_name="AnimateLCM_sd15_t2v_lora.safetensors", adapter_name="lcm-lora"
88	        ... )
89	        >>> pipe.set_adapters(["lcm-lora"], [0.8])
90	
91	        >>> depth_detector = ZoeDetector.from_pretrained("lllyasviel/Annotators").to("cuda")
92	        >>> video = load_video(
93	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-vid2vid-input-1.gif"
94	        ... )
95	        >>> conditioning_frames = []
96	
97	        >>> with pipe.progress_bar(total=len(video)) as progress_bar:
98	        ...     for frame in video:
99	        ...         conditioning_frames.append(depth_detector(frame))
100	        ...         progress_bar.update()
101	
102	        >>> prompt = "a panda, playing a guitar, sitting in a pink boat, in the ocean, mountains in background, realistic, high quality"
103	        >>> negative_prompt = "bad quality, worst quality"
104	
105	        >>> video = pipe(
106	        ...     prompt=prompt,
107	        ...     negative_prompt=negative_prompt,
108	        ...     num_frames=len(video),
109	        ...     num_inference_steps=10,
110	        ...     guidance_scale=2.0,
111	        ...     conditioning_frames=conditioning_frames,
112	        ...     generator=torch.Generator().manual_seed(42),
113	        ... ).frames[0]
114	
115	        >>> export_to_gif(video, "animatediff_controlnet.gif", fps=8)
116	        ```
117	"""
118	
119	
120	class AnimateDiffControlNetPipeline(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/animatediff/pipeline_animatediff_sparsectrl.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
55	
56	EXAMPLE_DOC_STRING = """
57	    Examples:
58	        ```python
59	        >>> import torch
60	        >>> from diffusers import AnimateDiffSparseControlNetPipeline
61	        >>> from diffusers.models import AutoencoderKL, MotionAdapter, SparseControlNetModel
62	        >>> from diffusers.schedulers import DPMSolverMultistepScheduler
63	        >>> from diffusers.utils import export_to_gif, load_image
64	
65	        >>> model_id = "SG161222/Realistic_Vision_V5.1_noVAE"
66	        >>> motion_adapter_id = "guoyww/animatediff-motion-adapter-v1-5-3"
67	        >>> controlnet_id = "guoyww/animatediff-sparsectrl-scribble"
68	        >>> lora_adapter_id = "guoyww/animatediff-motion-lora-v1-5-3"
69	        >>> vae_id = "stabilityai/sd-vae-ft-mse"
70	        >>> device = "cuda"
71	
72	        >>> motion_adapter = MotionAdapter.from_pretrained(motion_adapter_id, torch_dtype=torch.float16).to(device)
73	        >>> controlnet = SparseControlNetModel.from_pretrained(controlnet_id, torch_dtype=torch.float16).to(device)
74	        >>> vae = AutoencoderKL.from_pretrained(vae_id, torch_dtype=torch.float16).to(device)
75	        >>> scheduler = DPMSolverMultistepScheduler.from_pretrained(
76	        ...     model_id,
77	        ...     subfolder="scheduler",
78	        ...     beta_schedule="linear",
79	        ...     algorithm_type="dpmsolver++",
80	        ...     use_karras_sigmas=True,
81	        ... )
82	        >>> pipe = AnimateDiffSparseControlNetPipeline.from_pretrained(
83	        ...     model_id,
84	        ...     motion_adapter=motion_adapter,
85	        ...     controlnet=controlnet,
86	        ...     vae=vae,
87	        ...     scheduler=scheduler,
88	        ...     torch_dtype=torch.float16,
89	        ... ).to(device)
90	        >>> pipe.load_lora_weights(lora_adapter_id, adapter_name="motion_lora")
91	        >>> pipe.fuse_lora(lora_scale=1.0)
92	
93	        >>> prompt = "an aerial view of a cyberpunk city, night time, neon lights, masterpiece, high quality"
94	        >>> negative_prompt = "low quality, worst quality, letterboxed"
95	
96	        >>> image_files = [
97	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-scribble-1.png",
98	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-scribble-2.png",
99	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-scribble-3.png",
100	        ... ]
101	        >>> condition_frame_indices = [0, 8, 15]
102	        >>> conditioning_frames = [load_image(img_file) for img_file in image_files]
103	
104	        >>> video = pipe(
105	        ...     prompt=prompt,
106	        ...     negative_prompt=negative_prompt,
107	        ...     num_inference_steps=25,
108	        ...     conditioning_frames=conditioning_frames,
109	        ...     controlnet_conditioning_scale=1.0,
110	        ...     controlnet_frame_indices=condition_frame_indices,
111	        ...     generator=torch.Generator().manual_seed(1337),
112	        ... ).frames[0]
113	        >>> export_to_gif(video, "output.gif")
114	        ```
115	"""
116	
117	
118	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
119	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/animatediff/pipeline_animatediff_video2video.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
52	
53	EXAMPLE_DOC_STRING = """
54	    Examples:
55	        ```py
56	        >>> import imageio
57	        >>> import requests
58	        >>> import torch
59	        >>> from diffusers import AnimateDiffVideoToVideoPipeline, DDIMScheduler, MotionAdapter
60	        >>> from diffusers.utils import export_to_gif
61	        >>> from io import BytesIO
62	        >>> from PIL import Image
63	
64	        >>> adapter = MotionAdapter.from_pretrained(
65	        ...     "guoyww/animatediff-motion-adapter-v1-5-2", torch_dtype=torch.float16
66	        ... )
67	        >>> pipe = AnimateDiffVideoToVideoPipeline.from_pretrained(
68	        ...     "SG161222/Realistic_Vision_V5.1_noVAE", motion_adapter=adapter
69	        ... ).to("cuda")
70	        >>> pipe.scheduler = DDIMScheduler(
71	        ...     beta_schedule="linear", steps_offset=1, clip_sample=False, timespace_spacing="linspace"
72	        ... )
73	
74	
75	        >>> def load_video(file_path: str):
76	        ...     images = []
77	
78	        ...     if file_path.startswith(("http://", "https://")):
79	        ...         # If the file_path is a URL
80	        ...         response = requests.get(file_path)
81	        ...         response.raise_for_status()
82	        ...         content = BytesIO(response.content)
83	        ...         vid = imageio.get_reader(content)
84	        ...     else:
85	        ...         # Assuming it's a local file path
86	        ...         vid = imageio.get_reader(file_path)
87	
88	        ...     for frame in vid:
89	        ...         pil_image = Image.fromarray(frame)
90	        ...         images.append(pil_image)
91	
92	        ...     return images
93	
94	
95	        >>> video = load_video(
96	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/animatediff-vid2vid-input-1.gif"
97	        ... )
98	        >>> output = pipe(
99	        ...     video=video, prompt="panda playing a guitar, on a boat, in the ocean, high quality", strength=0.5
100	        ... )
101	        >>> frames = output.frames[0]
102	        >>> export_to_gif(frames, "animation.gif")
103	        ```
104	"""
105	
106	
107	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
108	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/animatediff/pipeline_animatediff_video2video_controlnet.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
60	
61	EXAMPLE_DOC_STRING = """
62	    Examples:
63	        ```py
64	        >>> import torch
65	        >>> from PIL import Image
66	        >>> from tqdm.auto import tqdm
67	
68	        >>> from diffusers import AnimateDiffVideoToVideoControlNetPipeline
69	        >>> from diffusers.utils import export_to_gif, load_video
70	        >>> from diffusers import AutoencoderKL, ControlNetModel, MotionAdapter, LCMScheduler
71	
72	        >>> controlnet = ControlNetModel.from_pretrained(
73	        ...     "lllyasviel/sd-controlnet-openpose", torch_dtype=torch.float16
74	        ... )
75	        >>> motion_adapter = MotionAdapter.from_pretrained("wangfuyun/AnimateLCM")
76	        >>> vae = AutoencoderKL.from_pretrained("stabilityai/sd-vae-ft-mse", torch_dtype=torch.float16)
77	
78	        >>> pipe = AnimateDiffVideoToVideoControlNetPipeline.from_pretrained(
79	        ...     "SG161222/Realistic_Vision_V5.1_noVAE",
80	        ...     motion_adapter=motion_adapter,
81	        ...     controlnet=controlnet,
82	        ...     vae=vae,
83	        ... ).to(device="cuda", dtype=torch.float16)
84	
85	        >>> pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config, beta_schedule="linear")
86	        >>> pipe.load_lora_weights(
87	        ...     "wangfuyun/AnimateLCM", weight_name="AnimateLCM_sd15_t2v_lora.safetensors", adapter_name="lcm-lora"
88	        ... )
89	        >>> pipe.set_adapters(["lcm-lora"], [0.8])
90	
91	        >>> video = load_video(
92	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/dance.gif"
93	        ... )
94	        >>> video = [frame.convert("RGB") for frame in video]
95	
96	        >>> from controlnet_aux.processor import OpenposeDetector
97	
98	        >>> open_pose = OpenposeDetector.from_pretrained("lllyasviel/Annotators").to("cuda")
99	        >>> for frame in tqdm(video):
100	        ...     conditioning_frames.append(open_pose(frame))
101	
102	        >>> prompt = "astronaut in space, dancing"
103	        >>> negative_prompt = "bad quality, worst quality, jpeg artifacts, ugly"
104	
105	        >>> strength = 0.8
106	        >>> with torch.inference_mode():
107	        ...     video = pipe(
108	        ...         video=video,
109	        ...         prompt=prompt,
110	        ...         negative_prompt=negative_prompt,
111	        ...         num_inference_steps=10,
112	        ...         guidance_scale=2.0,
113	        ...         controlnet_conditioning_scale=0.75,
114	        ...         conditioning_frames=conditioning_frames,
115	        ...         strength=strength,
116	        ...         generator=torch.Generator().manual_seed(42),
117	        ...     ).frames[0]
118	
119	        >>> video = [frame.resize(conditioning_frames[0].size) for frame in video]
120	        >>> export_to_gif(video, f"animatediff_vid2vid_controlnet.gif", fps=8)
121	        ```
122	"""
123	
124	
125	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
126	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/audioldm2/modeling_audioldm2.py:290
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
289	            raise ValueError(
290	                "At the moment it is not possible to define the number of attention heads via `num_attention_heads` because of a naming issue as described in https://github.com/huggingface/diffusers/issues/2011#issuecomment-1547958131. Passing `num_attention_heads` will only be supported in diffusers v0.19."
291	            )
292	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/blip_diffusion/pipeline_blip_diffusion.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
43	
44	EXAMPLE_DOC_STRING = """
45	    Examples:
46	        ```py
47	        >>> from diffusers.pipelines import BlipDiffusionPipeline
48	        >>> from diffusers.utils import load_image
49	        >>> import torch
50	
51	        >>> blip_diffusion_pipe = BlipDiffusionPipeline.from_pretrained(
52	        ...     "Salesforce/blipdiffusion", torch_dtype=torch.float16
53	        ... ).to("cuda")
54	
55	
56	        >>> cond_subject = "dog"
57	        >>> tgt_subject = "dog"
58	        >>> text_prompt_input = "swimming underwater"
59	
60	        >>> cond_image = load_image(
61	        ...     "https://huggingface.co/datasets/ayushtues/blipdiffusion_images/resolve/main/dog.jpg"
62	        ... )
63	        >>> guidance_scale = 7.5
64	        >>> num_inference_steps = 25
65	        >>> negative_prompt = "over-exposure, under-exposure, saturated, duplicate, out of frame, lowres, cropped, worst quality, low quality, jpeg artifacts, morbid, mutilated, out of frame, ugly, bad anatomy, bad proportions, deformed, blurry, duplicate"
66	
67	
68	        >>> output = blip_diffusion_pipe(
69	        ...     text_prompt_input,
70	        ...     cond_image,
71	        ...     cond_subject,
72	        ...     tgt_subject,
73	        ...     guidance_scale=guidance_scale,
74	        ...     num_inference_steps=num_inference_steps,
75	        ...     neg_prompt=negative_prompt,
76	        ...     height=512,
77	        ...     width=512,
78	        ... ).images
79	        >>> output[0].save("image.png")
80	        ```
81	"""
82	
83	
84	class BlipDiffusionPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/cogvideo/pipeline_cogvideox_fun_control.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	
46	EXAMPLE_DOC_STRING = """
47	    Examples:
48	        ```python
49	        >>> import torch
50	        >>> from diffusers import CogVideoXFunControlPipeline, DDIMScheduler
51	        >>> from diffusers.utils import export_to_video, load_video
52	
53	        >>> pipe = CogVideoXFunControlPipeline.from_pretrained(
54	        ...     "alibaba-pai/CogVideoX-Fun-V1.1-5b-Pose", torch_dtype=torch.bfloat16
55	        ... )
56	        >>> pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
57	        >>> pipe.to("cuda")
58	
59	        >>> control_video = load_video(
60	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/hiker.mp4"
61	        ... )
62	        >>> prompt = (
63	        ...     "An astronaut stands triumphantly at the peak of a towering mountain. Panorama of rugged peaks and "
64	        ...     "valleys. Very futuristic vibe and animated aesthetic. Highlights of purple and golden colors in "
65	        ...     "the scene. The sky is looks like an animated/cartoonish dream of galaxies, nebulae, stars, planets, "
66	        ...     "moons, but the remainder of the scene is mostly realistic."
67	        ... )
68	
69	        >>> video = pipe(prompt=prompt, control_video=control_video).frames[0]
70	        >>> export_to_video(video, "output.mp4", fps=8)
71	        ```
72	"""
73	
74	
75	# Copied from diffusers.pipelines.cogvideo.pipeline_cogvideox.get_resize_crop_region_for_grid
76	def get_resize_crop_region_for_grid(src, tgt_width, tgt_height):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/cogvideo/pipeline_cogvideox_image2video.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
50	
51	EXAMPLE_DOC_STRING = """
52	    Examples:
53	        ```py
54	        >>> import torch
55	        >>> from diffusers import CogVideoXImageToVideoPipeline
56	        >>> from diffusers.utils import export_to_video, load_image
57	
58	        >>> pipe = CogVideoXImageToVideoPipeline.from_pretrained("THUDM/CogVideoX-5b-I2V", torch_dtype=torch.bfloat16)
59	        >>> pipe.to("cuda")
60	
61	        >>> prompt = "An astronaut hatching from an egg, on the surface of the moon, the darkness and depth of space realised in the background. High quality, ultrarealistic detail and breath-taking movie-like camera shot."
62	        >>> image = load_image(
63	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/astronaut.jpg"
64	        ... )
65	        >>> video = pipe(image, prompt, use_dynamic_cfg=True)
66	        >>> export_to_video(video.frames[0], "output.mp4", fps=8)
67	        ```
68	"""
69	
70	
71	# Similar to diffusers.pipelines.hunyuandit.pipeline_hunyuandit.get_resize_crop_region_for_grid
72	def get_resize_crop_region_for_grid(src, tgt_width, tgt_height):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/cogvideo/pipeline_cogvideox_video2video.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	
46	EXAMPLE_DOC_STRING = """
47	    Examples:
48	        ```python
49	        >>> import torch
50	        >>> from diffusers import CogVideoXDPMScheduler, CogVideoXVideoToVideoPipeline
51	        >>> from diffusers.utils import export_to_video, load_video
52	
53	        >>> # Models: "THUDM/CogVideoX-2b" or "THUDM/CogVideoX-5b"
54	        >>> pipe = CogVideoXVideoToVideoPipeline.from_pretrained("THUDM/CogVideoX-5b", torch_dtype=torch.bfloat16)
55	        >>> pipe.to("cuda")
56	        >>> pipe.scheduler = CogVideoXDPMScheduler.from_config(pipe.scheduler.config)
57	
58	        >>> input_video = load_video(
59	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/hiker.mp4"
60	        ... )
61	        >>> prompt = (
62	        ...     "An astronaut stands triumphantly at the peak of a towering mountain. Panorama of rugged peaks and "
63	        ...     "valleys. Very futuristic vibe and animated aesthetic. Highlights of purple and golden colors in "
64	        ...     "the scene. The sky is looks like an animated/cartoonish dream of galaxies, nebulae, stars, planets, "
65	        ...     "moons, but the remainder of the scene is mostly realistic."
66	        ... )
67	
68	        >>> video = pipe(
69	        ...     video=input_video, prompt=prompt, strength=0.8, guidance_scale=6, num_inference_steps=50
70	        ... ).frames[0]
71	        >>> export_to_video(video, "output.mp4", fps=8)
72	        ```
73	"""
74	
75	
76	# Similar to diffusers.pipelines.hunyuandit.pipeline_hunyuandit.get_resize_crop_region_for_grid
77	def get_resize_crop_region_for_grid(src, tgt_width, tgt_height):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/cogview4/pipeline_cogview4_control.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
41	
42	EXAMPLE_DOC_STRING = """
43	    Examples:
44	        ```python
45	        >>> import torch
46	        >>> from diffusers import CogView4ControlPipeline
47	
48	        >>> pipe = CogView4ControlPipeline.from_pretrained("THUDM/CogView4-6B-Control", torch_dtype=torch.bfloat16)
49	        >>> control_image = load_image(
50	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/bird_canny.png"
51	        ... )
52	        >>> prompt = "A bird in space"
53	        >>> image = pipe(prompt, control_image=control_image, height=1024, width=1024, guidance_scale=3.5).images[0]
54	        >>> image.save("cogview4-control.png")
55	        ```
56	"""
57	
58	
59	# Copied from diffusers.pipelines.cogview4.pipeline_cogview4.calculate_shift
60	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/consisid/pipeline_consisid.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
43	
44	EXAMPLE_DOC_STRING = """
45	    Examples:
46	        ```python
47	        >>> import torch
48	        >>> from diffusers import ConsisIDPipeline
49	        >>> from diffusers.pipelines.consisid.consisid_utils import prepare_face_models, process_face_embeddings_infer
50	        >>> from diffusers.utils import export_to_video
51	        >>> from huggingface_hub import snapshot_download
52	
53	        >>> snapshot_download(repo_id="BestWishYsh/ConsisID-preview", local_dir="BestWishYsh/ConsisID-preview")
54	        >>> (
55	        ...     face_helper_1,
56	        ...     face_helper_2,
57	        ...     face_clip_model,
58	        ...     face_main_model,
59	        ...     eva_transform_mean,
60	        ...     eva_transform_std,
61	        ... ) = prepare_face_models("BestWishYsh/ConsisID-preview", device="cuda", dtype=torch.bfloat16)
62	        >>> pipe = ConsisIDPipeline.from_pretrained("BestWishYsh/ConsisID-preview", torch_dtype=torch.bfloat16)
63	        >>> pipe.to("cuda")
64	
65	        >>> # ConsisID works well with long and well-described prompts. Make sure the face in the image is clearly visible (e.g., preferably half-body or full-body).
66	        >>> prompt = "The video captures a boy walking along a city street, filmed in black and white on a classic 35mm camera. His expression is thoughtful, his brow slightly furrowed as if he's lost in contemplation. The film grain adds a textured, timeless quality to the image, evoking a sense of nostalgia. Around him, the cityscape is filled with vintage buildings, cobblestone sidewalks, and softly blurred figures passing by, their outlines faint and indistinct. Streetlights cast a gentle glow, while shadows play across the boy's path, adding depth to the scene. The lighting highlights the boy's subtle smile, hinting at a fleeting moment of curiosity. The overall cinematic atmosphere, complete with classic film still aesthetics and dramatic contrasts, gives the scene an evocative and introspective feel."
67	        >>> image = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/consisid/consisid_input.png?download=true"
68	
69	        >>> id_cond, id_vit_hidden, image, face_kps = process_face_embeddings_infer(
70	        ...     face_helper_1,
71	        ...     face_clip_model,
72	        ...     face_helper_2,
73	        ...     eva_transform_mean,
74	        ...     eva_transform_std,
75	        ...     face_main_model,
76	        ...     "cuda",
77	        ...     torch.bfloat16,
78	        ...     image,
79	        ...     is_align_face=True,
80	        ... )
81	
82	        >>> video = pipe(
83	        ...     image=image,
84	        ...     prompt=prompt,
85	        ...     num_inference_steps=50,
86	        ...     guidance_scale=6.0,
87	        ...     use_dynamic_cfg=False,
88	        ...     id_vit_hidden=id_vit_hidden,
89	        ...     id_cond=id_cond,
90	        ...     kps_cond=face_kps,
91	        ...     generator=torch.Generator("cuda").manual_seed(42),
92	        ... )
93	        >>> export_to_video(video.frames[0], "output.mp4", fps=8)
94	        ```
95	"""
96	
97	
98	def draw_kps(image_pil, kps, color_list=[(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/consistency_models/pipeline_consistency_models.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	
40	EXAMPLE_DOC_STRING = """
41	    Examples:
42	        ```py
43	        >>> import torch
44	
45	        >>> from diffusers import ConsistencyModelPipeline
46	
47	        >>> device = "cuda"
48	        >>> # Load the cd_imagenet64_l2 checkpoint.
49	        >>> model_id_or_path = "openai/diffusers-cd_imagenet64_l2"
50	        >>> pipe = ConsistencyModelPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)
51	        >>> pipe.to(device)
52	
53	        >>> # Onestep Sampling
54	        >>> image = pipe(num_inference_steps=1).images[0]
55	        >>> image.save("cd_imagenet64_l2_onestep_sample.png")
56	
57	        >>> # Onestep sampling, class-conditional image generation
58	        >>> # ImageNet-64 class label 145 corresponds to king penguins
59	        >>> image = pipe(num_inference_steps=1, class_labels=145).images[0]
60	        >>> image.save("cd_imagenet64_l2_onestep_sample_penguin.png")
61	
62	        >>> # Multistep sampling, class-conditional image generation
63	        >>> # Timesteps can be explicitly specified; the particular timesteps below are from the original GitHub repo:
64	        >>> # https://github.com/openai/consistency_models/blob/main/scripts/launch.sh#L77
65	        >>> image = pipe(num_inference_steps=None, timesteps=[22, 0], class_labels=145).images[0]
66	        >>> image.save("cd_imagenet64_l2_multistep_sample_penguin.png")
67	        ```
68	"""
69	
70	
71	class ConsistencyModelPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
55	
56	EXAMPLE_DOC_STRING = """
57	    Examples:
58	        ```py
59	        >>> # !pip install opencv-python transformers accelerate
60	        >>> from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
61	        >>> from diffusers.utils import load_image
62	        >>> import numpy as np
63	        >>> import torch
64	
65	        >>> import cv2
66	        >>> from PIL import Image
67	
68	        >>> # download an image
69	        >>> image = load_image(
70	        ...     "https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/input_image_vermeer.png"
71	        ... )
72	        >>> image = np.array(image)
73	
74	        >>> # get canny image
75	        >>> image = cv2.Canny(image, 100, 200)
76	        >>> image = image[:, :, None]
77	        >>> image = np.concatenate([image, image, image], axis=2)
78	        >>> canny_image = Image.fromarray(image)
79	
80	        >>> # load control net and stable diffusion v1-5
81	        >>> controlnet = ControlNetModel.from_pretrained("lllyasviel/sd-controlnet-canny", torch_dtype=torch.float16)
82	        >>> pipe = StableDiffusionControlNetPipeline.from_pretrained(
83	        ...     "stable-diffusion-v1-5/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16
84	        ... )
85	
86	        >>> # speed up diffusion process with faster scheduler and memory optimization
87	        >>> pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
88	        >>> # remove following line if xformers is not installed
89	        >>> pipe.enable_xformers_memory_efficient_attention()
90	
91	        >>> pipe.enable_model_cpu_offload()
92	
93	        >>> # generate image
94	        >>> generator = torch.manual_seed(0)
95	        >>> image = pipe(
96	        ...     "futuristic-looking woman", num_inference_steps=20, generator=generator, image=canny_image
97	        ... ).images[0]
98	        ```
99	"""
100	
101	
102	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.retrieve_timesteps
103	def retrieve_timesteps(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet.py:229
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
228	            logger.warning(
229	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
230	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_blip_diffusion.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	
45	EXAMPLE_DOC_STRING = """
46	    Examples:
47	        ```py
48	        >>> from diffusers.pipelines import BlipDiffusionControlNetPipeline
49	        >>> from diffusers.utils import load_image
50	        >>> from controlnet_aux import CannyDetector
51	        >>> import torch
52	
53	        >>> blip_diffusion_pipe = BlipDiffusionControlNetPipeline.from_pretrained(
54	        ...     "Salesforce/blipdiffusion-controlnet", torch_dtype=torch.float16
55	        ... ).to("cuda")
56	
57	        >>> style_subject = "flower"
58	        >>> tgt_subject = "teapot"
59	        >>> text_prompt = "on a marble table"
60	
61	        >>> cldm_cond_image = load_image(
62	        ...     "https://huggingface.co/datasets/ayushtues/blipdiffusion_images/resolve/main/kettle.jpg"
63	        ... ).resize((512, 512))
64	        >>> canny = CannyDetector()
65	        >>> cldm_cond_image = canny(cldm_cond_image, 30, 70, output_type="pil")
66	        >>> style_image = load_image(
67	        ...     "https://huggingface.co/datasets/ayushtues/blipdiffusion_images/resolve/main/flower.jpg"
68	        ... )
69	        >>> guidance_scale = 7.5
70	        >>> num_inference_steps = 50
71	        >>> negative_prompt = "over-exposure, under-exposure, saturated, duplicate, out of frame, lowres, cropped, worst quality, low quality, jpeg artifacts, morbid, mutilated, out of frame, ugly, bad anatomy, bad proportions, deformed, blurry, duplicate"
72	
73	
74	        >>> output = blip_diffusion_pipe(
75	        ...     text_prompt,
76	        ...     style_image,
77	        ...     cldm_cond_image,
78	        ...     style_subject,
79	        ...     tgt_subject,
80	        ...     guidance_scale=guidance_scale,
81	        ...     num_inference_steps=num_inference_steps,
82	        ...     neg_prompt=negative_prompt,
83	        ...     height=512,
84	        ...     width=512,
85	        ... ).images
86	        >>> output[0].save("image.png")
87	        ```
88	"""
89	
90	
91	class BlipDiffusionControlNetPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_img2img.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
54	
55	EXAMPLE_DOC_STRING = """
56	    Examples:
57	        ```py
58	        >>> # !pip install opencv-python transformers accelerate
59	        >>> from diffusers import StableDiffusionControlNetImg2ImgPipeline, ControlNetModel, UniPCMultistepScheduler
60	        >>> from diffusers.utils import load_image
61	        >>> import numpy as np
62	        >>> import torch
63	
64	        >>> import cv2
65	        >>> from PIL import Image
66	
67	        >>> # download an image
68	        >>> image = load_image(
69	        ...     "https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/input_image_vermeer.png"
70	        ... )
71	        >>> np_image = np.array(image)
72	
73	        >>> # get canny image
74	        >>> np_image = cv2.Canny(np_image, 100, 200)
75	        >>> np_image = np_image[:, :, None]
76	        >>> np_image = np.concatenate([np_image, np_image, np_image], axis=2)
77	        >>> canny_image = Image.fromarray(np_image)
78	
79	        >>> # load control net and stable diffusion v1-5
80	        >>> controlnet = ControlNetModel.from_pretrained("lllyasviel/sd-controlnet-canny", torch_dtype=torch.float16)
81	        >>> pipe = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(
82	        ...     "stable-diffusion-v1-5/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16
83	        ... )
84	
85	        >>> # speed up diffusion process with faster scheduler and memory optimization
86	        >>> pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
87	        >>> pipe.enable_model_cpu_offload()
88	
89	        >>> # generate image
90	        >>> generator = torch.manual_seed(0)
91	        >>> image = pipe(
92	        ...     "futuristic-looking woman",
93	        ...     num_inference_steps=20,
94	        ...     generator=generator,
95	        ...     image=image,
96	        ...     control_image=canny_image,
97	        ... ).images[0]
98	        ```
99	"""
100	
101	
102	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
103	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_img2img.py:207
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
206	            logger.warning(
207	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
208	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_inpaint.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	EXAMPLE_DOC_STRING = """
58	    Examples:
59	        ```py
60	        >>> # !pip install transformers accelerate
61	        >>> from diffusers import StableDiffusionControlNetInpaintPipeline, ControlNetModel, DDIMScheduler
62	        >>> from diffusers.utils import load_image
63	        >>> import numpy as np
64	        >>> import torch
65	
66	        >>> init_image = load_image(
67	        ...     "https://huggingface.co/datasets/diffusers/test-arrays/resolve/main/stable_diffusion_inpaint/boy.png"
68	        ... )
69	        >>> init_image = init_image.resize((512, 512))
70	
71	        >>> generator = torch.Generator(device="cpu").manual_seed(1)
72	
73	        >>> mask_image = load_image(
74	        ...     "https://huggingface.co/datasets/diffusers/test-arrays/resolve/main/stable_diffusion_inpaint/boy_mask.png"
75	        ... )
76	        >>> mask_image = mask_image.resize((512, 512))
77	
78	
79	        >>> def make_canny_condition(image):
80	        ...     image = np.array(image)
81	        ...     image = cv2.Canny(image, 100, 200)
82	        ...     image = image[:, :, None]
83	        ...     image = np.concatenate([image, image, image], axis=2)
84	        ...     image = Image.fromarray(image)
85	        ...     return image
86	
87	
88	        >>> control_image = make_canny_condition(init_image)
89	
90	        >>> controlnet = ControlNetModel.from_pretrained(
91	        ...     "lllyasviel/control_v11p_sd15_inpaint", torch_dtype=torch.float16
92	        ... )
93	        >>> pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(
94	        ...     "stable-diffusion-v1-5/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16
95	        ... )
96	
97	        >>> pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
98	        >>> pipe.enable_model_cpu_offload()
99	
100	        >>> # generate image
101	        >>> image = pipe(
102	        ...     "a handsome man with ray-ban sunglasses",
103	        ...     num_inference_steps=20,
104	        ...     generator=generator,
105	        ...     eta=1.0,
106	        ...     image=init_image,
107	        ...     mask_image=mask_image,
108	        ...     control_image=control_image,
109	        ... ).images[0]
110	        ```
111	"""
112	
113	
114	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
115	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_inpaint.py:213
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
212	            logger.warning(
213	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
214	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_inpaint_sd_xl.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
89	
90	EXAMPLE_DOC_STRING = """
91	    Examples:
92	        ```py
93	        >>> # !pip install transformers accelerate
94	        >>> from diffusers import StableDiffusionXLControlNetInpaintPipeline, ControlNetModel, DDIMScheduler
95	        >>> from diffusers.utils import load_image
96	        >>> from PIL import Image
97	        >>> import numpy as np
98	        >>> import torch
99	
100	        >>> init_image = load_image(
101	        ...     "https://huggingface.co/datasets/diffusers/test-arrays/resolve/main/stable_diffusion_inpaint/boy.png"
102	        ... )
103	        >>> init_image = init_image.resize((1024, 1024))
104	
105	        >>> generator = torch.Generator(device="cpu").manual_seed(1)
106	
107	        >>> mask_image = load_image(
108	        ...     "https://huggingface.co/datasets/diffusers/test-arrays/resolve/main/stable_diffusion_inpaint/boy_mask.png"
109	        ... )
110	        >>> mask_image = mask_image.resize((1024, 1024))
111	
112	
113	        >>> def make_canny_condition(image):
114	        ...     image = np.array(image)
115	        ...     image = cv2.Canny(image, 100, 200)
116	        ...     image = image[:, :, None]
117	        ...     image = np.concatenate([image, image, image], axis=2)
118	        ...     image = Image.fromarray(image)
119	        ...     return image
120	
121	
122	        >>> control_image = make_canny_condition(init_image)
123	
124	        >>> controlnet = ControlNetModel.from_pretrained(
125	        ...     "diffusers/controlnet-canny-sdxl-1.0", torch_dtype=torch.float16
126	        ... )
127	        >>> pipe = StableDiffusionXLControlNetInpaintPipeline.from_pretrained(
128	        ...     "stabilityai/stable-diffusion-xl-base-1.0", controlnet=controlnet, torch_dtype=torch.float16
129	        ... )
130	
131	        >>> pipe.enable_model_cpu_offload()
132	
133	        >>> # generate image
134	        >>> image = pipe(
135	        ...     "a handsome man with ray-ban sunglasses",
136	        ...     num_inference_steps=20,
137	        ...     generator=generator,
138	        ...     eta=1.0,
139	        ...     image=init_image,
140	        ...     mask_image=mask_image,
141	        ...     control_image=control_image,
142	        ... ).images[0]
143	        ```
144	"""
145	
146	
147	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.rescale_noise_cfg
148	def rescale_noise_cfg(noise_cfg, noise_pred_text, guidance_rescale=0.0):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	
78	EXAMPLE_DOC_STRING = """
79	    Examples:
80	        ```py
81	        >>> # !pip install opencv-python transformers accelerate
82	        >>> from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel, AutoencoderKL
83	        >>> from diffusers.utils import load_image
84	        >>> import numpy as np
85	        >>> import torch
86	
87	        >>> import cv2
88	        >>> from PIL import Image
89	
90	        >>> prompt = "aerial view, a futuristic research complex in a bright foggy jungle, hard lighting"
91	        >>> negative_prompt = "low quality, bad quality, sketches"
92	
93	        >>> # download an image
94	        >>> image = load_image(
95	        ...     "https://hf.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/hf-logo.png"
96	        ... )
97	
98	        >>> # initialize the models and pipeline
99	        >>> controlnet_conditioning_scale = 0.5  # recommended for good generalization
100	        >>> controlnet = ControlNetModel.from_pretrained(
101	        ...     "diffusers/controlnet-canny-sdxl-1.0", torch_dtype=torch.float16
102	        ... )
103	        >>> vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
104	        >>> pipe = StableDiffusionXLControlNetPipeline.from_pretrained(
105	        ...     "stabilityai/stable-diffusion-xl-base-1.0", controlnet=controlnet, vae=vae, torch_dtype=torch.float16
106	        ... )
107	        >>> pipe.enable_model_cpu_offload()
108	
109	        >>> # get canny image
110	        >>> image = np.array(image)
111	        >>> image = cv2.Canny(image, 100, 200)
112	        >>> image = image[:, :, None]
113	        >>> image = np.concatenate([image, image, image], axis=2)
114	        >>> canny_image = Image.fromarray(image)
115	
116	        >>> # generate image
117	        >>> image = pipe(
118	        ...     prompt, controlnet_conditioning_scale=controlnet_conditioning_scale, image=canny_image
119	        ... ).images[0]
120	        ```
121	"""
122	
123	
124	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.retrieve_timesteps
125	def retrieve_timesteps(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl_img2img.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	
78	EXAMPLE_DOC_STRING = """
79	    Examples:
80	        ```py
81	        >>> # pip install accelerate transformers safetensors diffusers
82	
83	        >>> import torch
84	        >>> import numpy as np
85	        >>> from PIL import Image
86	
87	        >>> from transformers import DPTImageProcessor, DPTForDepthEstimation
88	        >>> from diffusers import ControlNetModel, StableDiffusionXLControlNetImg2ImgPipeline, AutoencoderKL
89	        >>> from diffusers.utils import load_image
90	
91	
92	        >>> depth_estimator = DPTForDepthEstimation.from_pretrained("Intel/dpt-hybrid-midas").to("cuda")
93	        >>> feature_extractor = DPTImageProcessor.from_pretrained("Intel/dpt-hybrid-midas")
94	        >>> controlnet = ControlNetModel.from_pretrained(
95	        ...     "diffusers/controlnet-depth-sdxl-1.0-small",
96	        ...     variant="fp16",
97	        ...     use_safetensors=True,
98	        ...     torch_dtype=torch.float16,
99	        ... )
100	        >>> vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
101	        >>> pipe = StableDiffusionXLControlNetImg2ImgPipeline.from_pretrained(
102	        ...     "stabilityai/stable-diffusion-xl-base-1.0",
103	        ...     controlnet=controlnet,
104	        ...     vae=vae,
105	        ...     variant="fp16",
106	        ...     use_safetensors=True,
107	        ...     torch_dtype=torch.float16,
108	        ... )
109	        >>> pipe.enable_model_cpu_offload()
110	
111	
112	        >>> def get_depth_map(image):
113	        ...     image = feature_extractor(images=image, return_tensors="pt").pixel_values.to("cuda")
114	        ...     with torch.no_grad(), torch.autocast("cuda"):
115	        ...         depth_map = depth_estimator(image).predicted_depth
116	
117	        ...     depth_map = torch.nn.functional.interpolate(
118	        ...         depth_map.unsqueeze(1),
119	        ...         size=(1024, 1024),
120	        ...         mode="bicubic",
121	        ...         align_corners=False,
122	        ...     )
123	        ...     depth_min = torch.amin(depth_map, dim=[1, 2, 3], keepdim=True)
124	        ...     depth_max = torch.amax(depth_map, dim=[1, 2, 3], keepdim=True)
125	        ...     depth_map = (depth_map - depth_min) / (depth_max - depth_min)
126	        ...     image = torch.cat([depth_map] * 3, dim=1)
127	        ...     image = image.permute(0, 2, 3, 1).cpu().numpy()[0]
128	        ...     image = Image.fromarray((image * 255.0).clip(0, 255).astype(np.uint8))
129	        ...     return image
130	
131	
132	        >>> prompt = "A robot, 4k photo"
133	        >>> image = load_image(
134	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
135	        ...     "/kandinsky/cat.png"
136	        ... ).resize((1024, 1024))
137	        >>> controlnet_conditioning_scale = 0.5  # recommended for good generalization
138	        >>> depth_image = get_depth_map(image)
139	
140	        >>> images = pipe(
141	        ...     prompt,
142	        ...     image=image,
143	        ...     control_image=depth_image,
144	        ...     strength=0.99,
145	        ...     num_inference_steps=50,
146	        ...     controlnet_conditioning_scale=controlnet_conditioning_scale,
147	        ... ).images
148	        >>> images[0].save(f"robot_cat.png")
149	        ```
150	"""
151	
152	
153	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
154	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_union_inpaint_sd_xl.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
89	
90	EXAMPLE_DOC_STRING = """
91	    Examples:
92	        ```py
93	        from diffusers import StableDiffusionXLControlNetUnionInpaintPipeline, ControlNetUnionModel, AutoencoderKL
94	        from diffusers.utils import load_image
95	        import torch
96	        import numpy as np
97	        from PIL import Image
98	
99	        prompt = "A cat"
100	        # download an image
101	        image = load_image(
102	            "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/in_paint/overture-creations-5sI6fQgYIuo.png"
103	        ).resize((1024, 1024))
104	        mask = load_image(
105	            "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/in_paint/overture-creations-5sI6fQgYIuo_mask.png"
106	        ).resize((1024, 1024))
107	        # initialize the models and pipeline
108	        controlnet = ControlNetUnionModel.from_pretrained(
109	            "brad-twinkl/controlnet-union-sdxl-1.0-promax", torch_dtype=torch.float16
110	        )
111	        vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
112	        pipe = StableDiffusionXLControlNetUnionInpaintPipeline.from_pretrained(
113	            "stabilityai/stable-diffusion-xl-base-1.0",
114	            controlnet=controlnet,
115	            vae=vae,
116	            torch_dtype=torch.float16,
117	            variant="fp16",
118	        )
119	        pipe.enable_model_cpu_offload()
120	        controlnet_img = image.copy()
121	        controlnet_img_np = np.array(controlnet_img)
122	        mask_np = np.array(mask)
123	        controlnet_img_np[mask_np > 0] = 0
124	        controlnet_img = Image.fromarray(controlnet_img_np)
125	        # generate image
126	        image = pipe(prompt, image=image, mask_image=mask, control_image=[controlnet_img], control_mode=[7]).images[0]
127	        image.save("inpaint.png")
128	        ```
129	"""
130	
131	
132	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.rescale_noise_cfg
133	def rescale_noise_cfg(noise_cfg, noise_pred_text, guidance_rescale=0.0):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_union_sd_xl.py:82
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
81	
82	EXAMPLE_DOC_STRING = """
83	    Examples:
84	        ```py
85	        >>> # !pip install controlnet_aux
86	        >>> from controlnet_aux import LineartAnimeDetector
87	        >>> from diffusers import StableDiffusionXLControlNetUnionPipeline, ControlNetUnionModel, AutoencoderKL
88	        >>> from diffusers.utils import load_image
89	        >>> import torch
90	
91	        >>> prompt = "A cat"
92	        >>> # download an image
93	        >>> image = load_image(
94	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/cat.png"
95	        ... ).resize((1024, 1024))
96	        >>> # initialize the models and pipeline
97	        >>> controlnet = ControlNetUnionModel.from_pretrained(
98	        ...     "xinsir/controlnet-union-sdxl-1.0", torch_dtype=torch.float16
99	        ... )
100	        >>> vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
101	        >>> pipe = StableDiffusionXLControlNetUnionPipeline.from_pretrained(
102	        ...     "stabilityai/stable-diffusion-xl-base-1.0",
103	        ...     controlnet=controlnet,
104	        ...     vae=vae,
105	        ...     torch_dtype=torch.float16,
106	        ...     variant="fp16",
107	        ... )
108	        >>> pipe.enable_model_cpu_offload()
109	        >>> # prepare image
110	        >>> processor = LineartAnimeDetector.from_pretrained("lllyasviel/Annotators")
111	        >>> controlnet_img = processor(image, output_type="pil")
112	        >>> # generate image
113	        >>> image = pipe(prompt, control_image=[controlnet_img], control_mode=[3], height=1024, width=1024).images[0]
114	        ```
115	"""
116	
117	
118	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.retrieve_timesteps
119	def retrieve_timesteps(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_controlnet_union_sd_xl_img2img.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	
78	EXAMPLE_DOC_STRING = """
79	    Examples:
80	        ```py
81	        # !pip install controlnet_aux
82	        from diffusers import (
83	            StableDiffusionXLControlNetUnionImg2ImgPipeline,
84	            ControlNetUnionModel,
85	            AutoencoderKL,
86	        )
87	        from diffusers.utils import load_image
88	        import torch
89	        from PIL import Image
90	        import numpy as np
91	
92	        prompt = "A cat"
93	        # download an image
94	        image = load_image(
95	            "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/cat.png"
96	        )
97	        # initialize the models and pipeline
98	        controlnet = ControlNetUnionModel.from_pretrained(
99	            "brad-twinkl/controlnet-union-sdxl-1.0-promax", torch_dtype=torch.float16
100	        )
101	        vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
102	        pipe = StableDiffusionXLControlNetUnionImg2ImgPipeline.from_pretrained(
103	            "stabilityai/stable-diffusion-xl-base-1.0",
104	            controlnet=controlnet,
105	            vae=vae,
106	            torch_dtype=torch.float16,
107	            variant="fp16",
108	        ).to("cuda")
109	        # `enable_model_cpu_offload` is not recommended due to multiple generations
110	        height = image.height
111	        width = image.width
112	        ratio = np.sqrt(1024.0 * 1024.0 / (width * height))
113	        # 3 * 3 upscale correspond to 16 * 3 multiply, 2 * 2 correspond to 16 * 2 multiply and so on.
114	        scale_image_factor = 3
115	        base_factor = 16
116	        factor = scale_image_factor * base_factor
117	        W, H = int(width * ratio) // factor * factor, int(height * ratio) // factor * factor
118	        image = image.resize((W, H))
119	        target_width = W // scale_image_factor
120	        target_height = H // scale_image_factor
121	        images = []
122	        crops_coords_list = [
123	            (0, 0),
124	            (0, width // 2),
125	            (height // 2, 0),
126	            (width // 2, height // 2),
127	            0,
128	            0,
129	            0,
130	            0,
131	            0,
132	        ]
133	        for i in range(scale_image_factor):
134	            for j in range(scale_image_factor):
135	                left = j * target_width
136	                top = i * target_height
137	                right = left + target_width
138	                bottom = top + target_height
139	                cropped_image = image.crop((left, top, right, bottom))
140	                cropped_image = cropped_image.resize((W, H))
141	                images.append(cropped_image)
142	        # set ControlNetUnion input
143	        result_images = []
144	        for sub_img, crops_coords in zip(images, crops_coords_list):
145	            new_width, new_height = W, H
146	            out = pipe(
147	                prompt=[prompt] * 1,
148	                image=sub_img,
149	                control_image=[sub_img],
150	                control_mode=[6],
151	                width=new_width,
152	                height=new_height,
153	                num_inference_steps=30,
154	                crops_coords_top_left=(W, H),
155	                target_size=(W, H),
156	                original_size=(W * 2, H * 2),
157	            )
158	            result_images.append(out.images[0])
159	        new_im = Image.new("RGB", (new_width * scale_image_factor, new_height * scale_image_factor))
160	        new_im.paste(result_images[0], (0, 0))
161	        new_im.paste(result_images[1], (new_width, 0))
162	        new_im.paste(result_images[2], (new_width * 2, 0))
163	        new_im.paste(result_images[3], (0, new_height))
164	        new_im.paste(result_images[4], (new_width, new_height))
165	        new_im.paste(result_images[5], (new_width * 2, new_height))
166	        new_im.paste(result_images[6], (0, new_height * 2))
167	        new_im.paste(result_images[7], (new_width, new_height * 2))
168	        new_im.paste(result_images[8], (new_width * 2, new_height * 2))
169	        ```
170	"""
171	
172	
173	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
174	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_flax_controlnet.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	
46	EXAMPLE_DOC_STRING = """
47	    Examples:
48	        ```py
49	        >>> import jax
50	        >>> import numpy as np
51	        >>> import jax.numpy as jnp
52	        >>> from flax.jax_utils import replicate
53	        >>> from flax.training.common_utils import shard
54	        >>> from diffusers.utils import load_image, make_image_grid
55	        >>> from PIL import Image
56	        >>> from diffusers import FlaxStableDiffusionControlNetPipeline, FlaxControlNetModel
57	
58	
59	        >>> def create_key(seed=0):
60	        ...     return jax.random.PRNGKey(seed)
61	
62	
63	        >>> rng = create_key(0)
64	
65	        >>> # get canny image
66	        >>> canny_image = load_image(
67	        ...     "https://huggingface.co/datasets/YiYiXu/test-doc-assets/resolve/main/blog_post_cell_10_output_0.jpeg"
68	        ... )
69	
70	        >>> prompts = "best quality, extremely detailed"
71	        >>> negative_prompts = "monochrome, lowres, bad anatomy, worst quality, low quality"
72	
73	        >>> # load control net and stable diffusion v1-5
74	        >>> controlnet, controlnet_params = FlaxControlNetModel.from_pretrained(
75	        ...     "lllyasviel/sd-controlnet-canny", from_pt=True, dtype=jnp.float32
76	        ... )
77	        >>> pipe, params = FlaxStableDiffusionControlNetPipeline.from_pretrained(
78	        ...     "stable-diffusion-v1-5/stable-diffusion-v1-5",
79	        ...     controlnet=controlnet,
80	        ...     revision="flax",
81	        ...     dtype=jnp.float32,
82	        ... )
83	        >>> params["controlnet"] = controlnet_params
84	
85	        >>> num_samples = jax.device_count()
86	        >>> rng = jax.random.split(rng, jax.device_count())
87	
88	        >>> prompt_ids = pipe.prepare_text_inputs([prompts] * num_samples)
89	        >>> negative_prompt_ids = pipe.prepare_text_inputs([negative_prompts] * num_samples)
90	        >>> processed_image = pipe.prepare_image_inputs([canny_image] * num_samples)
91	
92	        >>> p_params = replicate(params)
93	        >>> prompt_ids = shard(prompt_ids)
94	        >>> negative_prompt_ids = shard(negative_prompt_ids)
95	        >>> processed_image = shard(processed_image)
96	
97	        >>> output = pipe(
98	        ...     prompt_ids=prompt_ids,
99	        ...     image=processed_image,
100	        ...     params=p_params,
101	        ...     prng_seed=rng,
102	        ...     num_inference_steps=50,
103	        ...     neg_prompt_ids=negative_prompt_ids,
104	        ...     jit=True,
105	        ... ).images
106	
107	        >>> output_images = pipe.numpy_to_pil(np.asarray(output.reshape((num_samples,) + output.shape[-3:])))
108	        >>> output_images = make_image_grid(output_images, num_samples // 4, 4)
109	        >>> output_images.save("generated_image.png")
110	        ```
111	"""
112	
113	
114	class FlaxStableDiffusionControlNetPipeline(FlaxDiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet/pipeline_flax_controlnet.py:163
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
162	            logger.warning(
163	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
164	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet_hunyuandit/pipeline_hunyuandit_controlnet.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
48	
49	EXAMPLE_DOC_STRING = """
50	    Examples:
51	        ```py
52	        from diffusers import HunyuanDiT2DControlNetModel, HunyuanDiTControlNetPipeline
53	        import torch
54	
55	        controlnet = HunyuanDiT2DControlNetModel.from_pretrained(
56	            "Tencent-Hunyuan/HunyuanDiT-v1.1-ControlNet-Diffusers-Canny", torch_dtype=torch.float16
57	        )
58	
59	        pipe = HunyuanDiTControlNetPipeline.from_pretrained(
60	            "Tencent-Hunyuan/HunyuanDiT-v1.1-Diffusers", controlnet=controlnet, torch_dtype=torch.float16
61	        )
62	        pipe.to("cuda")
63	
64	        from diffusers.utils import load_image
65	
66	        cond_image = load_image(
67	            "https://huggingface.co/Tencent-Hunyuan/HunyuanDiT-v1.1-ControlNet-Diffusers-Canny/resolve/main/canny.jpg?download=true"
68	        )
69	
70	        ## You may also use English prompt as HunyuanDiT supports both English and Chinese
71	        prompt = ""
72	        # prompt="At night, an ancient Chinese-style lion statue stands in front of the hotel, its eyes gleaming as if guarding the building. The background is the hotel entrance at night, with a close-up, eye-level, and centered composition. This photo presents a realistic photographic style, embodies Chinese sculpture culture, and reveals a mysterious atmosphere."
73	        image = pipe(
74	            prompt,
75	            height=1024,
76	            width=1024,
77	            control_image=cond_image,
78	            num_inference_steps=50,
79	        ).images[0]
80	        ```
81	"""
82	
83	STANDARD_RATIO = np.array(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet_hunyuandit/pipeline_hunyuandit_controlnet.py:258
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
257	            logger.warning(
258	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
259	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet_sd3/pipeline_stable_diffusion_3_controlnet.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	EXAMPLE_DOC_STRING = """
58	    Examples:
59	        ```py
60	        >>> import torch
61	        >>> from diffusers import StableDiffusion3ControlNetPipeline
62	        >>> from diffusers.models import SD3ControlNetModel, SD3MultiControlNetModel
63	        >>> from diffusers.utils import load_image
64	
65	        >>> controlnet = SD3ControlNetModel.from_pretrained("InstantX/SD3-Controlnet-Canny", torch_dtype=torch.float16)
66	
67	        >>> pipe = StableDiffusion3ControlNetPipeline.from_pretrained(
68	        ...     "stabilityai/stable-diffusion-3-medium-diffusers", controlnet=controlnet, torch_dtype=torch.float16
69	        ... )
70	        >>> pipe.to("cuda")
71	        >>> control_image = load_image(
72	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/bird_canny.png"
73	        ... )
74	        >>> prompt = "A bird in space"
75	        >>> image = pipe(
76	        ...     prompt, control_image=control_image, height=1024, width=768, controlnet_conditioning_scale=0.7
77	        ... ).images[0]
78	        >>> image.save("sd3.png")
79	        ```
80	"""
81	
82	
83	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.retrieve_timesteps
84	def retrieve_timesteps(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet_sd3/pipeline_stable_diffusion_3_controlnet_inpainting.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	EXAMPLE_DOC_STRING = """
58	    Examples:
59	        ```py
60	        >>> import torch
61	        >>> from diffusers.utils import load_image, check_min_version
62	        >>> from diffusers.pipelines import StableDiffusion3ControlNetInpaintingPipeline
63	        >>> from diffusers.models.controlnet_sd3 import SD3ControlNetModel
64	
65	        >>> controlnet = SD3ControlNetModel.from_pretrained(
66	        ...     "alimama-creative/SD3-Controlnet-Inpainting", use_safetensors=True, extra_conditioning_channels=1
67	        ... )
68	        >>> pipe = StableDiffusion3ControlNetInpaintingPipeline.from_pretrained(
69	        ...     "stabilityai/stable-diffusion-3-medium-diffusers",
70	        ...     controlnet=controlnet,
71	        ...     torch_dtype=torch.float16,
72	        ... )
73	        >>> pipe.text_encoder.to(torch.float16)
74	        >>> pipe.controlnet.to(torch.float16)
75	        >>> pipe.to("cuda")
76	
77	        >>> image = load_image(
78	        ...     "https://huggingface.co/alimama-creative/SD3-Controlnet-Inpainting/resolve/main/images/dog.png"
79	        ... )
80	        >>> mask = load_image(
81	        ...     "https://huggingface.co/alimama-creative/SD3-Controlnet-Inpainting/resolve/main/images/dog_mask.png"
82	        ... )
83	        >>> width = 1024
84	        >>> height = 1024
85	        >>> prompt = "A cat is sitting next to a puppy."
86	        >>> generator = torch.Generator(device="cuda").manual_seed(24)
87	        >>> res_image = pipe(
88	        ...     negative_prompt="deformed, distorted, disfigured, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, mutated hands and fingers, disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation, NSFW",
89	        ...     prompt=prompt,
90	        ...     height=height,
91	        ...     width=width,
92	        ...     control_image=image,
93	        ...     control_mask=mask,
94	        ...     num_inference_steps=28,
95	        ...     generator=generator,
96	        ...     controlnet_conditioning_scale=0.95,
97	        ...     guidance_scale=7,
98	        ... ).images[0]
99	        >>> res_image.save(f"sd3.png")
100	        ```
101	"""
102	
103	
104	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.retrieve_timesteps
105	def retrieve_timesteps(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet_xs/pipeline_controlnet_xs.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
54	
55	EXAMPLE_DOC_STRING = """
56	    Examples:
57	        ```py
58	        >>> # !pip install opencv-python transformers accelerate
59	        >>> from diffusers import StableDiffusionControlNetXSPipeline, ControlNetXSAdapter
60	        >>> from diffusers.utils import load_image
61	        >>> import numpy as np
62	        >>> import torch
63	
64	        >>> import cv2
65	        >>> from PIL import Image
66	
67	        >>> prompt = "aerial view, a futuristic research complex in a bright foggy jungle, hard lighting"
68	        >>> negative_prompt = "low quality, bad quality, sketches"
69	
70	        >>> # download an image
71	        >>> image = load_image(
72	        ...     "https://hf.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/hf-logo.png"
73	        ... )
74	
75	        >>> # initialize the models and pipeline
76	        >>> controlnet_conditioning_scale = 0.5
77	
78	        >>> controlnet = ControlNetXSAdapter.from_pretrained(
79	        ...     "UmerHA/Testing-ConrolNetXS-SD2.1-canny", torch_dtype=torch.float16
80	        ... )
81	        >>> pipe = StableDiffusionControlNetXSPipeline.from_pretrained(
82	        ...     "stabilityai/stable-diffusion-2-1-base", controlnet=controlnet, torch_dtype=torch.float16
83	        ... )
84	        >>> pipe.enable_model_cpu_offload()
85	
86	        >>> # get canny image
87	        >>> image = np.array(image)
88	        >>> image = cv2.Canny(image, 100, 200)
89	        >>> image = image[:, :, None]
90	        >>> image = np.concatenate([image, image, image], axis=2)
91	        >>> canny_image = Image.fromarray(image)
92	        >>> # generate image
93	        >>> image = pipe(
94	        ...     prompt, controlnet_conditioning_scale=controlnet_conditioning_scale, image=canny_image
95	        ... ).images[0]
96	        ```
97	"""
98	
99	
100	class StableDiffusionControlNetXSPipeline(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet_xs/pipeline_controlnet_xs.py:165
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
164	            logger.warning(
165	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
166	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/controlnet_xs/pipeline_controlnet_xs_sd_xl.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
69	
70	EXAMPLE_DOC_STRING = """
71	    Examples:
72	        ```py
73	        >>> # !pip install opencv-python transformers accelerate
74	        >>> from diffusers import StableDiffusionXLControlNetXSPipeline, ControlNetXSAdapter, AutoencoderKL
75	        >>> from diffusers.utils import load_image
76	        >>> import numpy as np
77	        >>> import torch
78	
79	        >>> import cv2
80	        >>> from PIL import Image
81	
82	        >>> prompt = "aerial view, a futuristic research complex in a bright foggy jungle, hard lighting"
83	        >>> negative_prompt = "low quality, bad quality, sketches"
84	
85	        >>> # download an image
86	        >>> image = load_image(
87	        ...     "https://hf.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/hf-logo.png"
88	        ... )
89	
90	        >>> # initialize the models and pipeline
91	        >>> controlnet_conditioning_scale = 0.5
92	        >>> vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
93	        >>> controlnet = ControlNetXSAdapter.from_pretrained(
94	        ...     "UmerHA/Testing-ConrolNetXS-SDXL-canny", torch_dtype=torch.float16
95	        ... )
96	        >>> pipe = StableDiffusionXLControlNetXSPipeline.from_pretrained(
97	        ...     "stabilityai/stable-diffusion-xl-base-1.0", controlnet=controlnet, torch_dtype=torch.float16
98	        ... )
99	        >>> pipe.enable_model_cpu_offload()
100	
101	        >>> # get canny image
102	        >>> image = np.array(image)
103	        >>> image = cv2.Canny(image, 100, 200)
104	        >>> image = image[:, :, None]
105	        >>> image = np.concatenate([image, image, image], axis=2)
106	        >>> canny_image = Image.fromarray(image)
107	
108	        >>> # generate image
109	        >>> image = pipe(
110	        ...     prompt, controlnet_conditioning_scale=controlnet_conditioning_scale, image=canny_image
111	        ... ).images[0]
112	        ```
113	"""
114	
115	
116	class StableDiffusionXLControlNetXSPipeline(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if.py:143
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
142	            logger.warning(
143	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
144	                " that you abide to the conditions of the IF license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img.py:65
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
64	
65	EXAMPLE_DOC_STRING = """
66	    Examples:
67	        ```py
68	        >>> from diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline, DiffusionPipeline
69	        >>> from diffusers.utils import pt_to_pil
70	        >>> import torch
71	        >>> from PIL import Image
72	        >>> import requests
73	        >>> from io import BytesIO
74	
75	        >>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
76	        >>> response = requests.get(url)
77	        >>> original_image = Image.open(BytesIO(response.content)).convert("RGB")
78	        >>> original_image = original_image.resize((768, 512))
79	
80	        >>> pipe = IFImg2ImgPipeline.from_pretrained(
81	        ...     "DeepFloyd/IF-I-XL-v1.0",
82	        ...     variant="fp16",
83	        ...     torch_dtype=torch.float16,
84	        ... )
85	        >>> pipe.enable_model_cpu_offload()
86	
87	        >>> prompt = "A fantasy landscape in style minecraft"
88	        >>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)
89	
90	        >>> image = pipe(
91	        ...     image=original_image,
92	        ...     prompt_embeds=prompt_embeds,
93	        ...     negative_prompt_embeds=negative_embeds,
94	        ...     output_type="pt",
95	        ... ).images
96	
97	        >>> # save intermediate image
98	        >>> pil_image = pt_to_pil(image)
99	        >>> pil_image[0].save("./if_stage_I.png")
100	
101	        >>> super_res_1_pipe = IFImg2ImgSuperResolutionPipeline.from_pretrained(
102	        ...     "DeepFloyd/IF-II-L-v1.0",
103	        ...     text_encoder=None,
104	        ...     variant="fp16",
105	        ...     torch_dtype=torch.float16,
106	        ... )
107	        >>> super_res_1_pipe.enable_model_cpu_offload()
108	
109	        >>> image = super_res_1_pipe(
110	        ...     image=image,
111	        ...     original_image=original_image,
112	        ...     prompt_embeds=prompt_embeds,
113	        ...     negative_prompt_embeds=negative_embeds,
114	        ... ).images
115	        >>> image[0].save("./if_stage_II.png")
116	        ```
117	"""
118	
119	
120	class IFImg2ImgPipeline(DiffusionPipeline, StableDiffusionLoraLoaderMixin):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img.py:167
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
166	            logger.warning(
167	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
168	                " that you abide to the conditions of the IF license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img_superresolution.py:69
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
68	
69	EXAMPLE_DOC_STRING = """
70	    Examples:
71	        ```py
72	        >>> from diffusers import IFImg2ImgPipeline, IFImg2ImgSuperResolutionPipeline, DiffusionPipeline
73	        >>> from diffusers.utils import pt_to_pil
74	        >>> import torch
75	        >>> from PIL import Image
76	        >>> import requests
77	        >>> from io import BytesIO
78	
79	        >>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
80	        >>> response = requests.get(url)
81	        >>> original_image = Image.open(BytesIO(response.content)).convert("RGB")
82	        >>> original_image = original_image.resize((768, 512))
83	
84	        >>> pipe = IFImg2ImgPipeline.from_pretrained(
85	        ...     "DeepFloyd/IF-I-XL-v1.0",
86	        ...     variant="fp16",
87	        ...     torch_dtype=torch.float16,
88	        ... )
89	        >>> pipe.enable_model_cpu_offload()
90	
91	        >>> prompt = "A fantasy landscape in style minecraft"
92	        >>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)
93	
94	        >>> image = pipe(
95	        ...     image=original_image,
96	        ...     prompt_embeds=prompt_embeds,
97	        ...     negative_prompt_embeds=negative_embeds,
98	        ...     output_type="pt",
99	        ... ).images
100	
101	        >>> # save intermediate image
102	        >>> pil_image = pt_to_pil(image)
103	        >>> pil_image[0].save("./if_stage_I.png")
104	
105	        >>> super_res_1_pipe = IFImg2ImgSuperResolutionPipeline.from_pretrained(
106	        ...     "DeepFloyd/IF-II-L-v1.0",
107	        ...     text_encoder=None,
108	        ...     variant="fp16",
109	        ...     torch_dtype=torch.float16,
110	        ... )
111	        >>> super_res_1_pipe.enable_model_cpu_offload()
112	
113	        >>> image = super_res_1_pipe(
114	        ...     image=image,
115	        ...     original_image=original_image,
116	        ...     prompt_embeds=prompt_embeds,
117	        ...     negative_prompt_embeds=negative_embeds,
118	        ... ).images
119	        >>> image[0].save("./if_stage_II.png")
120	        ```
121	"""
122	
123	
124	class IFImg2ImgSuperResolutionPipeline(DiffusionPipeline, StableDiffusionLoraLoaderMixin):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if_img2img_superresolution.py:173
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
172	            logger.warning(
173	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
174	                " that you abide to the conditions of the IF license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
65	
66	EXAMPLE_DOC_STRING = """
67	    Examples:
68	        ```py
69	        >>> from diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline, DiffusionPipeline
70	        >>> from diffusers.utils import pt_to_pil
71	        >>> import torch
72	        >>> from PIL import Image
73	        >>> import requests
74	        >>> from io import BytesIO
75	
76	        >>> url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/person.png"
77	        >>> response = requests.get(url)
78	        >>> original_image = Image.open(BytesIO(response.content)).convert("RGB")
79	        >>> original_image = original_image
80	
81	        >>> url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/glasses_mask.png"
82	        >>> response = requests.get(url)
83	        >>> mask_image = Image.open(BytesIO(response.content))
84	        >>> mask_image = mask_image
85	
86	        >>> pipe = IFInpaintingPipeline.from_pretrained(
87	        ...     "DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16
88	        ... )
89	        >>> pipe.enable_model_cpu_offload()
90	
91	        >>> prompt = "blue sunglasses"
92	        >>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)
93	
94	        >>> image = pipe(
95	        ...     image=original_image,
96	        ...     mask_image=mask_image,
97	        ...     prompt_embeds=prompt_embeds,
98	        ...     negative_prompt_embeds=negative_embeds,
99	        ...     output_type="pt",
100	        ... ).images
101	
102	        >>> # save intermediate image
103	        >>> pil_image = pt_to_pil(image)
104	        >>> pil_image[0].save("./if_stage_I.png")
105	
106	        >>> super_res_1_pipe = IFInpaintingSuperResolutionPipeline.from_pretrained(
107	        ...     "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16
108	        ... )
109	        >>> super_res_1_pipe.enable_model_cpu_offload()
110	
111	        >>> image = super_res_1_pipe(
112	        ...     image=image,
113	        ...     mask_image=mask_image,
114	        ...     original_image=original_image,
115	        ...     prompt_embeds=prompt_embeds,
116	        ...     negative_prompt_embeds=negative_embeds,
117	        ... ).images
118	        >>> image[0].save("./if_stage_II.png")
119	        ```
120	"""
121	
122	
123	class IFInpaintingPipeline(DiffusionPipeline, StableDiffusionLoraLoaderMixin):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting.py:170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
169	            logger.warning(
170	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
171	                " that you abide to the conditions of the IF license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting_superresolution.py:69
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
68	
69	EXAMPLE_DOC_STRING = """
70	    Examples:
71	        ```py
72	        >>> from diffusers import IFInpaintingPipeline, IFInpaintingSuperResolutionPipeline, DiffusionPipeline
73	        >>> from diffusers.utils import pt_to_pil
74	        >>> import torch
75	        >>> from PIL import Image
76	        >>> import requests
77	        >>> from io import BytesIO
78	
79	        >>> url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/person.png"
80	        >>> response = requests.get(url)
81	        >>> original_image = Image.open(BytesIO(response.content)).convert("RGB")
82	        >>> original_image = original_image
83	
84	        >>> url = "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/if/glasses_mask.png"
85	        >>> response = requests.get(url)
86	        >>> mask_image = Image.open(BytesIO(response.content))
87	        >>> mask_image = mask_image
88	
89	        >>> pipe = IFInpaintingPipeline.from_pretrained(
90	        ...     "DeepFloyd/IF-I-XL-v1.0", variant="fp16", torch_dtype=torch.float16
91	        ... )
92	        >>> pipe.enable_model_cpu_offload()
93	
94	        >>> prompt = "blue sunglasses"
95	
96	        >>> prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)
97	        >>> image = pipe(
98	        ...     image=original_image,
99	        ...     mask_image=mask_image,
100	        ...     prompt_embeds=prompt_embeds,
101	        ...     negative_prompt_embeds=negative_embeds,
102	        ...     output_type="pt",
103	        ... ).images
104	
105	        >>> # save intermediate image
106	        >>> pil_image = pt_to_pil(image)
107	        >>> pil_image[0].save("./if_stage_I.png")
108	
109	        >>> super_res_1_pipe = IFInpaintingSuperResolutionPipeline.from_pretrained(
110	        ...     "DeepFloyd/IF-II-L-v1.0", text_encoder=None, variant="fp16", torch_dtype=torch.float16
111	        ... )
112	        >>> super_res_1_pipe.enable_model_cpu_offload()
113	
114	        >>> image = super_res_1_pipe(
115	        ...     image=image,
116	        ...     mask_image=mask_image,
117	        ...     original_image=original_image,
118	        ...     prompt_embeds=prompt_embeds,
119	        ...     negative_prompt_embeds=negative_embeds,
120	        ... ).images
121	        >>> image[0].save("./if_stage_II.png")
122	        ```
123	    """
124	
125	
126	class IFInpaintingSuperResolutionPipeline(DiffusionPipeline, StableDiffusionLoraLoaderMixin):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if_inpainting_superresolution.py:175
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
174	            logger.warning(
175	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
176	                " that you abide to the conditions of the IF license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deepfloyd_if/pipeline_if_superresolution.py:131
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
130	            logger.warning(
131	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
132	                " that you abide to the conditions of the IF license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/alt_diffusion/pipeline_alt_diffusion.py:242
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
241	            logger.warning(
242	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
243	                " that you abide to the conditions of the Alt Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/alt_diffusion/pipeline_alt_diffusion_img2img.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
52	
53	EXAMPLE_DOC_STRING = """
54	    Examples:
55	        ```py
56	        >>> import requests
57	        >>> import torch
58	        >>> from PIL import Image
59	        >>> from io import BytesIO
60	
61	        >>> from diffusers import AltDiffusionImg2ImgPipeline
62	
63	        >>> device = "cuda"
64	        >>> model_id_or_path = "BAAI/AltDiffusion-m9"
65	        >>> pipe = AltDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)
66	        >>> pipe = pipe.to(device)
67	
68	        >>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
69	
70	        >>> response = requests.get(url)
71	        >>> init_image = Image.open(BytesIO(response.content)).convert("RGB")
72	        >>> init_image = init_image.resize((768, 512))
73	
74	        >>> # "A fantasy landscape, trending on artstation"
75	        >>> prompt = ", artstation"
76	
77	        >>> images = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images
78	        >>> images[0].save(".png")
79	        ```
80	"""
81	
82	
83	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
84	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/alt_diffusion/pipeline_alt_diffusion_img2img.py:270
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
269	            logger.warning(
270	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
271	                " that you abide to the conditions of the Alt Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/spectrogram_diffusion/midi_utils.py:638
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
637	            with open(midi, "rb") as f:
638	                midi = f.read()
639	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/stable_diffusion_variants/pipeline_cycle_diffusion.py:203
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
202	            logger.warning(
203	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
204	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/stable_diffusion_variants/pipeline_onnx_stable_diffusion_inpaint_legacy.py:125
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
124	            logger.warning(
125	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
126	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/stable_diffusion_variants/pipeline_stable_diffusion_inpaint_legacy.py:137
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
136	        deprecation_message = (
137	            f"The class {self.__class__} is deprecated and will be removed in v1.0.0. You can achieve exactly the same functionality"
138	            "by loading your model into `StableDiffusionInpaintPipeline` instead. See https://github.com/huggingface/diffusers/pull/3533"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/stable_diffusion_variants/pipeline_stable_diffusion_inpaint_legacy.py:172
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
171	            logger.warning(
172	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
173	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/stable_diffusion_variants/pipeline_stable_diffusion_model_editing.py:101
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
100	            logger.warning(
101	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
102	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/stable_diffusion_variants/pipeline_stable_diffusion_paradigms.py:123
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
122	            logger.warning(
123	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
124	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/stable_diffusion_variants/pipeline_stable_diffusion_pix2pix_zero.py:74
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
73	
74	EXAMPLE_DOC_STRING = """
75	    Examples:
76	        ```py
77	        >>> import requests
78	        >>> import torch
79	
80	        >>> from diffusers import DDIMScheduler, StableDiffusionPix2PixZeroPipeline
81	
82	
83	        >>> def download(embedding_url, local_filepath):
84	        ...     r = requests.get(embedding_url)
85	        ...     with open(local_filepath, "wb") as f:
86	        ...         f.write(r.content)
87	
88	
89	        >>> model_ckpt = "CompVis/stable-diffusion-v1-4"
90	        >>> pipeline = StableDiffusionPix2PixZeroPipeline.from_pretrained(model_ckpt, torch_dtype=torch.float16)
91	        >>> pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)
92	        >>> pipeline.to("cuda")
93	
94	        >>> prompt = "a high resolution painting of a cat in the style of van gough"
95	        >>> source_emb_url = "https://hf.co/datasets/sayakpaul/sample-datasets/resolve/main/cat.pt"
96	        >>> target_emb_url = "https://hf.co/datasets/sayakpaul/sample-datasets/resolve/main/dog.pt"
97	
98	        >>> for url in [source_emb_url, target_emb_url]:
99	        ...     download(url, url.split("/")[-1])
100	
101	        >>> src_embeds = torch.load(source_emb_url.split("/")[-1])
102	        >>> target_embeds = torch.load(target_emb_url.split("/")[-1])
103	        >>> images = pipeline(
104	        ...     prompt,
105	        ...     source_embeds=src_embeds,
106	        ...     target_embeds=target_embeds,
107	        ...     num_inference_steps=50,
108	        ...     cross_attention_guidance_amount=0.15,
109	        ... ).images
110	
111	        >>> images[0].save("edited_image_dog.png")
112	        ```
113	"""
114	
115	EXAMPLE_INVERT_DOC_STRING = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/stable_diffusion_variants/pipeline_stable_diffusion_pix2pix_zero.py:115
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
114	
115	EXAMPLE_INVERT_DOC_STRING = """
116	    Examples:
117	        ```py
118	        >>> import torch
119	        >>> from transformers import BlipForConditionalGeneration, BlipProcessor
120	        >>> from diffusers import DDIMScheduler, DDIMInverseScheduler, StableDiffusionPix2PixZeroPipeline
121	
122	        >>> import requests
123	        >>> from PIL import Image
124	
125	        >>> captioner_id = "Salesforce/blip-image-captioning-base"
126	        >>> processor = BlipProcessor.from_pretrained(captioner_id)
127	        >>> model = BlipForConditionalGeneration.from_pretrained(
128	        ...     captioner_id, torch_dtype=torch.float16, low_cpu_mem_usage=True
129	        ... )
130	
131	        >>> sd_model_ckpt = "CompVis/stable-diffusion-v1-4"
132	        >>> pipeline = StableDiffusionPix2PixZeroPipeline.from_pretrained(
133	        ...     sd_model_ckpt,
134	        ...     caption_generator=model,
135	        ...     caption_processor=processor,
136	        ...     torch_dtype=torch.float16,
137	        ...     safety_checker=None,
138	        ... )
139	
140	        >>> pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)
141	        >>> pipeline.inverse_scheduler = DDIMInverseScheduler.from_config(pipeline.scheduler.config)
142	        >>> pipeline.enable_model_cpu_offload()
143	
144	        >>> img_url = "https://github.com/pix2pixzero/pix2pix-zero/raw/main/assets/test_images/cats/cat_6.png"
145	
146	        >>> raw_image = Image.open(requests.get(img_url, stream=True).raw).convert("RGB").resize((512, 512))
147	        >>> # generate caption
148	        >>> caption = pipeline.generate_caption(raw_image)
149	
150	        >>> # "a photography of a cat with flowers and dai dai daie - daie - daie kasaii"
151	        >>> inv_latents = pipeline.invert(caption, image=raw_image).latents
152	        >>> # we need to generate source and target embeds
153	
154	        >>> source_prompts = ["a cat sitting on the street", "a cat playing in the field", "a face of a cat"]
155	
156	        >>> target_prompts = ["a dog sitting on the street", "a dog playing in the field", "a face of a dog"]
157	
158	        >>> source_embeds = pipeline.get_embeds(source_prompts)
159	        >>> target_embeds = pipeline.get_embeds(target_prompts)
160	        >>> # the latents can then be used to edit a real image
161	        >>> # when using Stable Diffusion 2 or other models that use v-prediction
162	        >>> # set `cross_attention_guidance_amount` to 0.01 or less to avoid input latent gradient explosion
163	
164	        >>> image = pipeline(
165	        ...     caption,
166	        ...     source_embeds=source_embeds,
167	        ...     target_embeds=target_embeds,
168	        ...     num_inference_steps=50,
169	        ...     cross_attention_guidance_amount=0.15,
170	        ...     generator=generator,
171	        ...     latents=inv_latents,
172	        ...     negative_prompt=caption,
173	        ... ).images[0]
174	        >>> image.save("edited_image.png")
175	        ```
176	"""
177	
178	
179	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.preprocess
180	def preprocess(image):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/stable_diffusion_variants/pipeline_stable_diffusion_pix2pix_zero.py:342
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
341	            logger.warning(
342	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
343	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/deprecated/versatile_diffusion/modeling_text_unet.py:436
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
435	            raise ValueError(
436	                "At the moment it is not possible to define the number of attention heads via `num_attention_heads` because of a naming issue as described in https://github.com/huggingface/diffusers/issues/2011#issuecomment-1547958131. Passing `num_attention_heads` will only be supported in diffusers v0.19."
437	            )
438	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/easyanimate/pipeline_easyanimate_control.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
50	
51	EXAMPLE_DOC_STRING = """
52	    Examples:
53	        ```python
54	        >>> import torch
55	        >>> from diffusers import EasyAnimateControlPipeline
56	        >>> from diffusers.pipelines.easyanimate.pipeline_easyanimate_control import get_video_to_video_latent
57	        >>> from diffusers.utils import export_to_video, load_video
58	
59	        >>> pipe = EasyAnimateControlPipeline.from_pretrained(
60	        ...     "alibaba-pai/EasyAnimateV5.1-12b-zh-Control-diffusers", torch_dtype=torch.bfloat16
61	        ... )
62	        >>> pipe.to("cuda")
63	
64	        >>> control_video = load_video(
65	        ...     "https://huggingface.co/alibaba-pai/EasyAnimateV5.1-12b-zh-Control/blob/main/asset/pose.mp4"
66	        ... )
67	        >>> prompt = (
68	        ...     "In this sunlit outdoor garden, a beautiful woman is dressed in a knee-length, sleeveless white dress. "
69	        ...     "The hem of her dress gently sways with her graceful dance, much like a butterfly fluttering in the breeze. "
70	        ...     "Sunlight filters through the leaves, casting dappled shadows that highlight her soft features and clear eyes, "
71	        ...     "making her appear exceptionally elegant. It seems as if every movement she makes speaks of youth and vitality. "
72	        ...     "As she twirls on the grass, her dress flutters, as if the entire garden is rejoicing in her dance. "
73	        ...     "The colorful flowers around her sway in the gentle breeze, with roses, chrysanthemums, and lilies each "
74	        ...     "releasing their fragrances, creating a relaxed and joyful atmosphere."
75	        ... )
76	        >>> sample_size = (672, 384)
77	        >>> num_frames = 49
78	
79	        >>> input_video, _, _ = get_video_to_video_latent(control_video, num_frames, sample_size)
80	        >>> video = pipe(
81	        ...     prompt,
82	        ...     num_frames=num_frames,
83	        ...     negative_prompt="Twisted body, limb deformities, text subtitles, comics, stillness, ugliness, errors, garbled text.",
84	        ...     height=sample_size[0],
85	        ...     width=sample_size[1],
86	        ...     control_video=input_video,
87	        ... ).frames[0]
88	        >>> export_to_video(video, "output.mp4", fps=8)
89	        ```
90	"""
91	
92	
93	def preprocess_image(image, sample_size):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/easyanimate/pipeline_easyanimate_inpaint.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
50	
51	EXAMPLE_DOC_STRING = """
52	    Examples:
53	        ```py
54	        >>> import torch
55	        >>> from diffusers import EasyAnimateInpaintPipeline
56	        >>> from diffusers.pipelines.easyanimate.pipeline_easyanimate_inpaint import get_image_to_video_latent
57	        >>> from diffusers.utils import export_to_video, load_image
58	
59	        >>> pipe = EasyAnimateInpaintPipeline.from_pretrained(
60	        ...     "alibaba-pai/EasyAnimateV5.1-12b-zh-InP-diffusers", torch_dtype=torch.bfloat16
61	        ... )
62	        >>> pipe.to("cuda")
63	
64	        >>> prompt = "An astronaut hatching from an egg, on the surface of the moon, the darkness and depth of space realised in the background. High quality, ultrarealistic detail and breath-taking movie-like camera shot."
65	        >>> validation_image_start = load_image(
66	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/astronaut.jpg"
67	        ... )
68	
69	        >>> validation_image_end = None
70	        >>> sample_size = (448, 576)
71	        >>> num_frames = 49
72	        >>> input_video, input_video_mask = get_image_to_video_latent(
73	        ...     [validation_image_start], validation_image_end, num_frames, sample_size
74	        ... )
75	
76	        >>> video = pipe(
77	        ...     prompt,
78	        ...     num_frames=num_frames,
79	        ...     negative_prompt="Twisted body, limb deformities, text subtitles, comics, stillness, ugliness, errors, garbled text.",
80	        ...     height=sample_size[0],
81	        ...     width=sample_size[1],
82	        ...     video=input_video,
83	        ...     mask_video=input_video_mask,
84	        ... )
85	        >>> export_to_video(video.frames[0], "output.mp4", fps=8)
86	        ```
87	"""
88	
89	
90	def preprocess_image(image, sample_size):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_control.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	
50	EXAMPLE_DOC_STRING = """
51	    Examples:
52	        ```py
53	        >>> import torch
54	        >>> from controlnet_aux import CannyDetector
55	        >>> from diffusers import FluxControlPipeline
56	        >>> from diffusers.utils import load_image
57	
58	        >>> pipe = FluxControlPipeline.from_pretrained(
59	        ...     "black-forest-labs/FLUX.1-Canny-dev", torch_dtype=torch.bfloat16
60	        ... ).to("cuda")
61	
62	        >>> prompt = "A robot made of exotic candies and chocolates of different kinds. The background is filled with confetti and celebratory gifts."
63	        >>> control_image = load_image(
64	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/robot.png"
65	        ... )
66	
67	        >>> processor = CannyDetector()
68	        >>> control_image = processor(
69	        ...     control_image, low_threshold=50, high_threshold=200, detect_resolution=1024, image_resolution=1024
70	        ... )
71	
72	        >>> image = pipe(
73	        ...     prompt=prompt,
74	        ...     control_image=control_image,
75	        ...     height=1024,
76	        ...     width=1024,
77	        ...     num_inference_steps=50,
78	        ...     guidance_scale=30.0,
79	        ... ).images[0]
80	        >>> image.save("output.png")
81	        ```
82	"""
83	
84	
85	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
86	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_control_img2img.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	
50	EXAMPLE_DOC_STRING = """
51	    Examples:
52	        ```py
53	        >>> import torch
54	        >>> from controlnet_aux import CannyDetector
55	        >>> from diffusers import FluxControlImg2ImgPipeline
56	        >>> from diffusers.utils import load_image
57	
58	        >>> pipe = FluxControlImg2ImgPipeline.from_pretrained(
59	        ...     "black-forest-labs/FLUX.1-Canny-dev", torch_dtype=torch.bfloat16
60	        ... ).to("cuda")
61	
62	        >>> prompt = "A robot made of exotic candies and chocolates of different kinds. Abstract background"
63	        >>> image = load_image(
64	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/watercolor-painting.jpg"
65	        ... )
66	        >>> control_image = load_image(
67	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/robot.png"
68	        ... )
69	
70	        >>> processor = CannyDetector()
71	        >>> control_image = processor(
72	        ...     control_image, low_threshold=50, high_threshold=200, detect_resolution=1024, image_resolution=1024
73	        ... )
74	
75	        >>> image = pipe(
76	        ...     prompt=prompt,
77	        ...     image=image,
78	        ...     control_image=control_image,
79	        ...     strength=0.8,
80	        ...     height=1024,
81	        ...     width=1024,
82	        ...     num_inference_steps=50,
83	        ...     guidance_scale=30.0,
84	        ... ).images[0]
85	        >>> image.save("output.png")
86	        ```
87	"""
88	
89	
90	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
91	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_control_inpaint.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
58	
59	EXAMPLE_DOC_STRING = """
60	    Examples:
61	        ```py
62	        import torch
63	        from diffusers import FluxControlInpaintPipeline
64	        from diffusers.models.transformers import FluxTransformer2DModel
65	        from transformers import T5EncoderModel
66	        from diffusers.utils import load_image, make_image_grid
67	        from image_gen_aux import DepthPreprocessor  # https://github.com/huggingface/image_gen_aux
68	        from PIL import Image
69	        import numpy as np
70	
71	        pipe = FluxControlInpaintPipeline.from_pretrained(
72	            "black-forest-labs/FLUX.1-Depth-dev",
73	            torch_dtype=torch.bfloat16,
74	        )
75	        # use following lines if you have GPU constraints
76	        # ---------------------------------------------------------------
77	        transformer = FluxTransformer2DModel.from_pretrained(
78	            "sayakpaul/FLUX.1-Depth-dev-nf4", subfolder="transformer", torch_dtype=torch.bfloat16
79	        )
80	        text_encoder_2 = T5EncoderModel.from_pretrained(
81	            "sayakpaul/FLUX.1-Depth-dev-nf4", subfolder="text_encoder_2", torch_dtype=torch.bfloat16
82	        )
83	        pipe.transformer = transformer
84	        pipe.text_encoder_2 = text_encoder_2
85	        pipe.enable_model_cpu_offload()
86	        # ---------------------------------------------------------------
87	        pipe.to("cuda")
88	
89	        prompt = "a blue robot singing opera with human-like expressions"
90	        image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/robot.png")
91	
92	        head_mask = np.zeros_like(image)
93	        head_mask[65:580, 300:642] = 255
94	        mask_image = Image.fromarray(head_mask)
95	
96	        processor = DepthPreprocessor.from_pretrained("LiheYoung/depth-anything-large-hf")
97	        control_image = processor(image)[0].convert("RGB")
98	
99	        output = pipe(
100	            prompt=prompt,
101	            image=image,
102	            control_image=control_image,
103	            mask_image=mask_image,
104	            num_inference_steps=30,
105	            strength=0.9,
106	            guidance_scale=10.0,
107	            generator=torch.Generator().manual_seed(42),
108	        ).images[0]
109	        make_image_grid([image, control_image, mask_image, output.resize(image.size)], rows=1, cols=4).save(
110	            "output.png"
111	        )
112	        ```
113	"""
114	
115	
116	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
117	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_controlnet.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
57	
58	EXAMPLE_DOC_STRING = """
59	    Examples:
60	        ```py
61	        >>> import torch
62	        >>> from diffusers.utils import load_image
63	        >>> from diffusers import FluxControlNetPipeline
64	        >>> from diffusers import FluxControlNetModel
65	
66	        >>> base_model = "black-forest-labs/FLUX.1-dev"
67	        >>> controlnet_model = "InstantX/FLUX.1-dev-controlnet-canny"
68	        >>> controlnet = FluxControlNetModel.from_pretrained(controlnet_model, torch_dtype=torch.bfloat16)
69	        >>> pipe = FluxControlNetPipeline.from_pretrained(
70	        ...     base_model, controlnet=controlnet, torch_dtype=torch.bfloat16
71	        ... )
72	        >>> pipe.to("cuda")
73	        >>> control_image = load_image("https://huggingface.co/InstantX/SD3-Controlnet-Canny/resolve/main/canny.jpg")
74	        >>> prompt = "A girl in city, 25 years old, cool, futuristic"
75	        >>> image = pipe(
76	        ...     prompt,
77	        ...     control_image=control_image,
78	        ...     control_guidance_start=0.2,
79	        ...     control_guidance_end=0.8,
80	        ...     controlnet_conditioning_scale=1.0,
81	        ...     num_inference_steps=28,
82	        ...     guidance_scale=3.5,
83	        ... ).images[0]
84	        >>> image.save("flux.png")
85	        ```
86	"""
87	
88	
89	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
90	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_controlnet_image_to_image.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	
41	EXAMPLE_DOC_STRING = """
42	    Examples:
43	        ```py
44	        >>> import torch
45	        >>> from diffusers import FluxControlNetImg2ImgPipeline, FluxControlNetModel
46	        >>> from diffusers.utils import load_image
47	
48	        >>> device = "cuda" if torch.cuda.is_available() else "cpu"
49	
50	        >>> controlnet = FluxControlNetModel.from_pretrained(
51	        ...     "InstantX/FLUX.1-dev-Controlnet-Canny-alpha", torch_dtype=torch.bfloat16
52	        ... )
53	
54	        >>> pipe = FluxControlNetImg2ImgPipeline.from_pretrained(
55	        ...     "black-forest-labs/FLUX.1-schnell", controlnet=controlnet, torch_dtype=torch.float16
56	        ... )
57	
58	        >>> pipe.text_encoder.to(torch.float16)
59	        >>> pipe.controlnet.to(torch.float16)
60	        >>> pipe.to("cuda")
61	
62	        >>> control_image = load_image("https://huggingface.co/InstantX/SD3-Controlnet-Canny/resolve/main/canny.jpg")
63	        >>> init_image = load_image(
64	        ...     "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
65	        ... )
66	
67	        >>> prompt = "A girl in city, 25 years old, cool, futuristic"
68	        >>> image = pipe(
69	        ...     prompt,
70	        ...     image=init_image,
71	        ...     control_image=control_image,
72	        ...     control_guidance_start=0.2,
73	        ...     control_guidance_end=0.8,
74	        ...     controlnet_conditioning_scale=1.0,
75	        ...     strength=0.7,
76	        ...     num_inference_steps=2,
77	        ...     guidance_scale=3.5,
78	        ... ).images[0]
79	        >>> image.save("flux_controlnet_img2img.png")
80	        ```
81	"""
82	
83	
84	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
85	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_controlnet_inpainting.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
41	
42	EXAMPLE_DOC_STRING = """
43	    Examples:
44	        ```py
45	        >>> import torch
46	        >>> from diffusers import FluxControlNetInpaintPipeline
47	        >>> from diffusers.models import FluxControlNetModel
48	        >>> from diffusers.utils import load_image
49	
50	        >>> controlnet = FluxControlNetModel.from_pretrained(
51	        ...     "InstantX/FLUX.1-dev-controlnet-canny", torch_dtype=torch.float16
52	        ... )
53	        >>> pipe = FluxControlNetInpaintPipeline.from_pretrained(
54	        ...     "black-forest-labs/FLUX.1-schnell", controlnet=controlnet, torch_dtype=torch.float16
55	        ... )
56	        >>> pipe.to("cuda")
57	
58	        >>> control_image = load_image(
59	        ...     "https://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Canny-alpha/resolve/main/canny.jpg"
60	        ... )
61	        >>> init_image = load_image(
62	        ...     "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
63	        ... )
64	        >>> mask_image = load_image(
65	        ...     "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
66	        ... )
67	
68	        >>> prompt = "A girl holding a sign that says InstantX"
69	        >>> image = pipe(
70	        ...     prompt,
71	        ...     image=init_image,
72	        ...     mask_image=mask_image,
73	        ...     control_image=control_image,
74	        ...     control_guidance_start=0.2,
75	        ...     control_guidance_end=0.8,
76	        ...     controlnet_conditioning_scale=0.7,
77	        ...     strength=0.7,
78	        ...     num_inference_steps=28,
79	        ...     guidance_scale=3.5,
80	        ... ).images[0]
81	        >>> image.save("flux_controlnet_inpaint.png")
82	        ```
83	"""
84	
85	
86	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
87	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_fill.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	
50	EXAMPLE_DOC_STRING = """
51	    Examples:
52	        ```py
53	        >>> import torch
54	        >>> from diffusers import FluxFillPipeline
55	        >>> from diffusers.utils import load_image
56	
57	        >>> image = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/cup.png")
58	        >>> mask = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/cup_mask.png")
59	
60	        >>> pipe = FluxFillPipeline.from_pretrained("black-forest-labs/FLUX.1-Fill-dev", torch_dtype=torch.bfloat16)
61	        >>> pipe.enable_model_cpu_offload()  # save some VRAM by offloading the model to CPU
62	
63	        >>> image = pipe(
64	        ...     prompt="a white paper cup",
65	        ...     image=image,
66	        ...     mask_image=mask,
67	        ...     height=1632,
68	        ...     width=1232,
69	        ...     guidance_scale=30,
70	        ...     num_inference_steps=50,
71	        ...     max_sequence_length=512,
72	        ...     generator=torch.Generator("cpu").manual_seed(0),
73	        ... ).images[0]
74	        >>> image.save("flux_fill.png")
75	        ```
76	"""
77	
78	
79	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
80	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_img2img.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	EXAMPLE_DOC_STRING = """
58	    Examples:
59	        ```py
60	        >>> import torch
61	
62	        >>> from diffusers import FluxImg2ImgPipeline
63	        >>> from diffusers.utils import load_image
64	
65	        >>> device = "cuda"
66	        >>> pipe = FluxImg2ImgPipeline.from_pretrained("black-forest-labs/FLUX.1-schnell", torch_dtype=torch.bfloat16)
67	        >>> pipe = pipe.to(device)
68	
69	        >>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
70	        >>> init_image = load_image(url).resize((1024, 1024))
71	
72	        >>> prompt = "cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k"
73	
74	        >>> images = pipe(
75	        ...     prompt=prompt, image=init_image, num_inference_steps=4, strength=0.95, guidance_scale=0.0
76	        ... ).images[0]
77	        ```
78	"""
79	
80	
81	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
82	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_inpaint.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
57	
58	EXAMPLE_DOC_STRING = """
59	    Examples:
60	        ```py
61	        >>> import torch
62	        >>> from diffusers import FluxInpaintPipeline
63	        >>> from diffusers.utils import load_image
64	
65	        >>> pipe = FluxInpaintPipeline.from_pretrained("black-forest-labs/FLUX.1-schnell", torch_dtype=torch.bfloat16)
66	        >>> pipe.to("cuda")
67	        >>> prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
68	        >>> img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
69	        >>> mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
70	        >>> source = load_image(img_url)
71	        >>> mask = load_image(mask_url)
72	        >>> image = pipe(prompt=prompt, image=source, mask_image=mask).images[0]
73	        >>> image.save("flux_inpainting.png")
74	        ```
75	"""
76	
77	
78	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
79	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/flux/pipeline_flux_prior_redux.py:52
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
51	
52	EXAMPLE_DOC_STRING = """
53	    Examples:
54	        ```py
55	        >>> import torch
56	        >>> from diffusers import FluxPriorReduxPipeline, FluxPipeline
57	        >>> from diffusers.utils import load_image
58	
59	        >>> device = "cuda"
60	        >>> dtype = torch.bfloat16
61	
62	        >>> repo_redux = "black-forest-labs/FLUX.1-Redux-dev"
63	        >>> repo_base = "black-forest-labs/FLUX.1-dev"
64	        >>> pipe_prior_redux = FluxPriorReduxPipeline.from_pretrained(repo_redux, torch_dtype=dtype).to(device)
65	        >>> pipe = FluxPipeline.from_pretrained(
66	        ...     repo_base, text_encoder=None, text_encoder_2=None, torch_dtype=torch.bfloat16
67	        ... ).to(device)
68	
69	        >>> image = load_image(
70	        ...     "https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/style_ziggy/img5.png"
71	        ... )
72	        >>> pipe_prior_output = pipe_prior_redux(image)
73	        >>> images = pipe(
74	        ...     guidance_scale=2.5,
75	        ...     num_inference_steps=50,
76	        ...     generator=torch.Generator("cpu").manual_seed(0),
77	        ...     **pipe_prior_output,
78	        ... ).images
79	        >>> images[0].save("flux-redux.png")
80	        ```
81	"""
82	
83	
84	class FluxPriorReduxPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/hunyuan_video/pipeline_hunyuan_skyreels_image2video.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
43	
44	EXAMPLE_DOC_STRING = """
45	    Examples:
46	        ```python
47	        >>> import torch
48	        >>> from diffusers import HunyuanSkyreelsImageToVideoPipeline, HunyuanVideoTransformer3DModel
49	        >>> from diffusers.utils import load_image, export_to_video
50	
51	        >>> model_id = "hunyuanvideo-community/HunyuanVideo"
52	        >>> transformer_model_id = "Skywork/SkyReels-V1-Hunyuan-I2V"
53	        >>> transformer = HunyuanVideoTransformer3DModel.from_pretrained(
54	        ...     transformer_model_id, torch_dtype=torch.bfloat16
55	        ... )
56	        >>> pipe = HunyuanSkyreelsImageToVideoPipeline.from_pretrained(
57	        ...     model_id, transformer=transformer, torch_dtype=torch.float16
58	        ... )
59	        >>> pipe.vae.enable_tiling()
60	        >>> pipe.to("cuda")
61	
62	        >>> prompt = "An astronaut hatching from an egg, on the surface of the moon, the darkness and depth of space realised in the background. High quality, ultrarealistic detail and breath-taking movie-like camera shot."
63	        >>> negative_prompt = "Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion"
64	        >>> image = load_image(
65	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/astronaut.jpg"
66	        ... )
67	
68	        >>> output = pipe(
69	        ...     image=image,
70	        ...     prompt=prompt,
71	        ...     negative_prompt=negative_prompt,
72	        ...     num_inference_steps=30,
73	        ...     true_cfg_scale=6.0,
74	        ...     guidance_scale=1.0,
75	        ... ).frames[0]
76	        >>> export_to_video(output, "output.mp4", fps=15)
77	        ```
78	"""
79	
80	
81	DEFAULT_PROMPT_TEMPLATE = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/hunyuan_video/pipeline_hunyuan_video_image2video.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	
50	EXAMPLE_DOC_STRING = """
51	    Examples:
52	        ```python
53	        >>> import torch
54	        >>> from diffusers import HunyuanVideoImageToVideoPipeline, HunyuanVideoTransformer3DModel
55	        >>> from diffusers.utils import load_image, export_to_video
56	
57	        >>> # Available checkpoints: hunyuanvideo-community/HunyuanVideo-I2V, hunyuanvideo-community/HunyuanVideo-I2V-33ch
58	        >>> model_id = "hunyuanvideo-community/HunyuanVideo-I2V"
59	        >>> transformer = HunyuanVideoTransformer3DModel.from_pretrained(
60	        ...     model_id, subfolder="transformer", torch_dtype=torch.bfloat16
61	        ... )
62	        >>> pipe = HunyuanVideoImageToVideoPipeline.from_pretrained(
63	        ...     model_id, transformer=transformer, torch_dtype=torch.float16
64	        ... )
65	        >>> pipe.vae.enable_tiling()
66	        >>> pipe.to("cuda")
67	
68	        >>> prompt = "A man with short gray hair plays a red electric guitar."
69	        >>> image = load_image(
70	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/guitar-man.png"
71	        ... )
72	
73	        >>> # If using hunyuanvideo-community/HunyuanVideo-I2V
74	        >>> output = pipe(image=image, prompt=prompt, guidance_scale=6.0).frames[0]
75	
76	        >>> # If using hunyuanvideo-community/HunyuanVideo-I2V-33ch
77	        >>> output = pipe(image=image, prompt=prompt, guidance_scale=1.0, true_cfg_scale=1.0).frames[0]
78	
79	        >>> export_to_video(output, "output.mp4", fps=15)
80	        ```
81	"""
82	
83	
84	DEFAULT_PROMPT_TEMPLATE = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/hunyuandit/pipeline_hunyuandit.py:229
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
228	            logger.warning(
229	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
230	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/i2vgen_xl/pipeline_i2vgen_xl.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
48	
49	EXAMPLE_DOC_STRING = """
50	    Examples:
51	        ```py
52	        >>> import torch
53	        >>> from diffusers import I2VGenXLPipeline
54	        >>> from diffusers.utils import export_to_gif, load_image
55	
56	        >>> pipeline = I2VGenXLPipeline.from_pretrained(
57	        ...     "ali-vilab/i2vgen-xl", torch_dtype=torch.float16, variant="fp16"
58	        ... )
59	        >>> pipeline.enable_model_cpu_offload()
60	
61	        >>> image_url = (
62	        ...     "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/i2vgen_xl_images/img_0009.png"
63	        ... )
64	        >>> image = load_image(image_url).convert("RGB")
65	
66	        >>> prompt = "Papers were floating in the air on a table in the library"
67	        >>> negative_prompt = "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms"
68	        >>> generator = torch.manual_seed(8888)
69	
70	        >>> frames = pipeline(
71	        ...     prompt=prompt,
72	        ...     image=image,
73	        ...     num_inference_steps=50,
74	        ...     negative_prompt=negative_prompt,
75	        ...     guidance_scale=9.0,
76	        ...     generator=generator,
77	        ... ).frames[0]
78	        >>> video_path = export_to_gif(frames, "i2v.gif")
79	        ```
80	"""
81	
82	
83	@dataclass
84	class I2VGenXLPipelineOutput(BaseOutput):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
55	
56	IMAGE2IMAGE_EXAMPLE_DOC_STRING = """
57	    Examples:
58	        ```py
59	        from diffusers import AutoPipelineForImage2Image
60	        import torch
61	        import requests
62	        from io import BytesIO
63	        from PIL import Image
64	        import os
65	
66	        pipe = AutoPipelineForImage2Image.from_pretrained(
67	            "kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16
68	        )
69	        pipe.enable_model_cpu_offload()
70	
71	        prompt = "A fantasy landscape, Cinematic lighting"
72	        negative_prompt = "low quality, bad quality"
73	
74	        url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
75	
76	        response = requests.get(url)
77	        image = Image.open(BytesIO(response.content)).convert("RGB")
78	        image.thumbnail((768, 768))
79	
80	        image = pipe(prompt=prompt, image=original_image, num_inference_steps=25).images[0]
81	        ```
82	"""
83	
84	INPAINT_EXAMPLE_DOC_STRING = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_combined.py:84
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
83	
84	INPAINT_EXAMPLE_DOC_STRING = """
85	    Examples:
86	        ```py
87	        from diffusers import AutoPipelineForInpainting
88	        from diffusers.utils import load_image
89	        import torch
90	        import numpy as np
91	
92	        pipe = AutoPipelineForInpainting.from_pretrained(
93	            "kandinsky-community/kandinsky-2-1-inpaint", torch_dtype=torch.float16
94	        )
95	        pipe.enable_model_cpu_offload()
96	
97	        prompt = "A fantasy landscape, Cinematic lighting"
98	        negative_prompt = "low quality, bad quality"
99	
100	        original_image = load_image(
101	            "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main" "/kandinsky/cat.png"
102	        )
103	
104	        mask = np.zeros((768, 768), dtype=np.float32)
105	        # Let's mask out an area above the cat's head
106	        mask[:250, 250:-250] = 1
107	
108	        image = pipe(prompt=prompt, image=original_image, mask_image=mask, num_inference_steps=25).images[0]
109	        ```
110	"""
111	
112	
113	class KandinskyCombinedPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_img2img.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	
47	EXAMPLE_DOC_STRING = """
48	    Examples:
49	        ```py
50	        >>> from diffusers import KandinskyImg2ImgPipeline, KandinskyPriorPipeline
51	        >>> from diffusers.utils import load_image
52	        >>> import torch
53	
54	        >>> pipe_prior = KandinskyPriorPipeline.from_pretrained(
55	        ...     "kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16
56	        ... )
57	        >>> pipe_prior.to("cuda")
58	
59	        >>> prompt = "A red cartoon frog, 4k"
60	        >>> image_emb, zero_image_emb = pipe_prior(prompt, return_dict=False)
61	
62	        >>> pipe = KandinskyImg2ImgPipeline.from_pretrained(
63	        ...     "kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16
64	        ... )
65	        >>> pipe.to("cuda")
66	
67	        >>> init_image = load_image(
68	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
69	        ...     "/kandinsky/frog.png"
70	        ... )
71	
72	        >>> image = pipe(
73	        ...     prompt,
74	        ...     image=init_image,
75	        ...     image_embeds=image_emb,
76	        ...     negative_image_embeds=zero_image_emb,
77	        ...     height=768,
78	        ...     width=768,
79	        ...     num_inference_steps=100,
80	        ...     strength=0.2,
81	        ... ).images
82	
83	        >>> image[0].save("red_frog.png")
84	        ```
85	"""
86	
87	
88	def get_new_h_w(h, w, scale_factor=8):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_inpaint.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
50	
51	EXAMPLE_DOC_STRING = """
52	    Examples:
53	        ```py
54	        >>> from diffusers import KandinskyInpaintPipeline, KandinskyPriorPipeline
55	        >>> from diffusers.utils import load_image
56	        >>> import torch
57	        >>> import numpy as np
58	
59	        >>> pipe_prior = KandinskyPriorPipeline.from_pretrained(
60	        ...     "kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16
61	        ... )
62	        >>> pipe_prior.to("cuda")
63	
64	        >>> prompt = "a hat"
65	        >>> image_emb, zero_image_emb = pipe_prior(prompt, return_dict=False)
66	
67	        >>> pipe = KandinskyInpaintPipeline.from_pretrained(
68	        ...     "kandinsky-community/kandinsky-2-1-inpaint", torch_dtype=torch.float16
69	        ... )
70	        >>> pipe.to("cuda")
71	
72	        >>> init_image = load_image(
73	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
74	        ...     "/kandinsky/cat.png"
75	        ... )
76	
77	        >>> mask = np.zeros((768, 768), dtype=np.float32)
78	        >>> mask[:250, 250:-250] = 1
79	
80	        >>> out = pipe(
81	        ...     prompt,
82	        ...     image=init_image,
83	        ...     mask_image=mask,
84	        ...     image_embeds=image_emb,
85	        ...     negative_image_embeds=zero_image_emb,
86	        ...     height=768,
87	        ...     width=768,
88	        ...     num_inference_steps=50,
89	        ... )
90	
91	        >>> image = out.images[0]
92	        >>> image.save("cat_with_hat.png")
93	        ```
94	"""
95	
96	
97	def get_new_h_w(h, w, scale_factor=8):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_inpaint.py:494
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
493	            logger.warning(
494	                "Please note that the expected format of `mask_image` has recently been changed. "
495	                "Before diffusers == 0.19.0, Kandinsky Inpainting pipelines repainted black pixels and preserved black pixels. "
496	                "As of diffusers==0.19.0 this behavior has been inverted. Now white pixels are repainted and black pixels are preserved. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky/pipeline_kandinsky_prior.py:75
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
74	
75	EXAMPLE_INTERPOLATE_DOC_STRING = """
76	    Examples:
77	        ```py
78	        >>> from diffusers import KandinskyPriorPipeline, KandinskyPipeline
79	        >>> from diffusers.utils import load_image
80	        >>> import PIL
81	
82	        >>> import torch
83	        >>> from torchvision import transforms
84	
85	        >>> pipe_prior = KandinskyPriorPipeline.from_pretrained(
86	        ...     "kandinsky-community/kandinsky-2-1-prior", torch_dtype=torch.float16
87	        ... )
88	        >>> pipe_prior.to("cuda")
89	
90	        >>> img1 = load_image(
91	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
92	        ...     "/kandinsky/cat.png"
93	        ... )
94	
95	        >>> img2 = load_image(
96	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
97	        ...     "/kandinsky/starry_night.jpeg"
98	        ... )
99	
100	        >>> images_texts = ["a cat", img1, img2]
101	        >>> weights = [0.3, 0.3, 0.4]
102	        >>> image_emb, zero_image_emb = pipe_prior.interpolate(images_texts, weights)
103	
104	        >>> pipe = KandinskyPipeline.from_pretrained("kandinsky-community/kandinsky-2-1", torch_dtype=torch.float16)
105	        >>> pipe.to("cuda")
106	
107	        >>> image = pipe(
108	        ...     "",
109	        ...     image_embeds=image_emb,
110	        ...     negative_image_embeds=zero_image_emb,
111	        ...     height=768,
112	        ...     width=768,
113	        ...     num_inference_steps=150,
114	        ... ).images[0]
115	
116	        >>> image.save("starry_cat.png")
117	        ```
118	"""
119	
120	
121	@dataclass
122	class KandinskyPriorPipelineOutput(BaseOutput):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	
50	IMAGE2IMAGE_EXAMPLE_DOC_STRING = """
51	    Examples:
52	        ```py
53	        from diffusers import AutoPipelineForImage2Image
54	        import torch
55	        import requests
56	        from io import BytesIO
57	        from PIL import Image
58	        import os
59	
60	        pipe = AutoPipelineForImage2Image.from_pretrained(
61	            "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16
62	        )
63	        pipe.enable_model_cpu_offload()
64	
65	        prompt = "A fantasy landscape, Cinematic lighting"
66	        negative_prompt = "low quality, bad quality"
67	
68	        url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
69	
70	        response = requests.get(url)
71	        image = Image.open(BytesIO(response.content)).convert("RGB")
72	        image.thumbnail((768, 768))
73	
74	        image = pipe(prompt=prompt, image=original_image, num_inference_steps=25).images[0]
75	        ```
76	"""
77	
78	INPAINT_EXAMPLE_DOC_STRING = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_combined.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	
78	INPAINT_EXAMPLE_DOC_STRING = """
79	    Examples:
80	        ```py
81	        from diffusers import AutoPipelineForInpainting
82	        from diffusers.utils import load_image
83	        import torch
84	        import numpy as np
85	
86	        pipe = AutoPipelineForInpainting.from_pretrained(
87	            "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
88	        )
89	        pipe.enable_model_cpu_offload()
90	
91	        prompt = "A fantasy landscape, Cinematic lighting"
92	        negative_prompt = "low quality, bad quality"
93	
94	        original_image = load_image(
95	            "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main" "/kandinsky/cat.png"
96	        )
97	
98	        mask = np.zeros((768, 768), dtype=np.float32)
99	        # Let's mask out an area above the cat's head
100	        mask[:250, 250:-250] = 1
101	
102	        image = pipe(prompt=prompt, image=original_image, mask_image=mask, num_inference_steps=25).images[0]
103	        ```
104	"""
105	
106	
107	class KandinskyV22CombinedPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	
39	EXAMPLE_DOC_STRING = """
40	    Examples:
41	        ```py
42	        >>> import torch
43	        >>> import numpy as np
44	
45	        >>> from diffusers import KandinskyV22PriorPipeline, KandinskyV22ControlnetPipeline
46	        >>> from transformers import pipeline
47	        >>> from diffusers.utils import load_image
48	
49	
50	        >>> def make_hint(image, depth_estimator):
51	        ...     image = depth_estimator(image)["depth"]
52	        ...     image = np.array(image)
53	        ...     image = image[:, :, None]
54	        ...     image = np.concatenate([image, image, image], axis=2)
55	        ...     detected_map = torch.from_numpy(image).float() / 255.0
56	        ...     hint = detected_map.permute(2, 0, 1)
57	        ...     return hint
58	
59	
60	        >>> depth_estimator = pipeline("depth-estimation")
61	
62	        >>> pipe_prior = KandinskyV22PriorPipeline.from_pretrained(
63	        ...     "kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16
64	        ... )
65	        >>> pipe_prior = pipe_prior.to("cuda")
66	
67	        >>> pipe = KandinskyV22ControlnetPipeline.from_pretrained(
68	        ...     "kandinsky-community/kandinsky-2-2-controlnet-depth", torch_dtype=torch.float16
69	        ... )
70	        >>> pipe = pipe.to("cuda")
71	
72	
73	        >>> img = load_image(
74	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
75	        ...     "/kandinsky/cat.png"
76	        ... ).resize((768, 768))
77	
78	        >>> hint = make_hint(img, depth_estimator).unsqueeze(0).half().to("cuda")
79	
80	        >>> prompt = "A robot, 4k photo"
81	        >>> negative_prior_prompt = "lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature"
82	
83	        >>> generator = torch.Generator(device="cuda").manual_seed(43)
84	
85	        >>> image_emb, zero_image_emb = pipe_prior(
86	        ...     prompt=prompt, negative_prompt=negative_prior_prompt, generator=generator
87	        ... ).to_tuple()
88	
89	        >>> images = pipe(
90	        ...     image_embeds=image_emb,
91	        ...     negative_image_embeds=zero_image_emb,
92	        ...     hint=hint,
93	        ...     num_inference_steps=50,
94	        ...     generator=generator,
95	        ...     height=768,
96	        ...     width=768,
97	        ... ).images
98	
99	        >>> images[0].save("robot_cat.png")
100	        ```
101	"""
102	
103	
104	# Copied from diffusers.pipelines.kandinsky2_2.pipeline_kandinsky2_2.downscale_height_and_width
105	def downscale_height_and_width(height, width, scale_factor=8):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_controlnet_img2img.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
41	
42	EXAMPLE_DOC_STRING = """
43	    Examples:
44	        ```py
45	        >>> import torch
46	        >>> import numpy as np
47	
48	        >>> from diffusers import KandinskyV22PriorEmb2EmbPipeline, KandinskyV22ControlnetImg2ImgPipeline
49	        >>> from transformers import pipeline
50	        >>> from diffusers.utils import load_image
51	
52	
53	        >>> def make_hint(image, depth_estimator):
54	        ...     image = depth_estimator(image)["depth"]
55	        ...     image = np.array(image)
56	        ...     image = image[:, :, None]
57	        ...     image = np.concatenate([image, image, image], axis=2)
58	        ...     detected_map = torch.from_numpy(image).float() / 255.0
59	        ...     hint = detected_map.permute(2, 0, 1)
60	        ...     return hint
61	
62	
63	        >>> depth_estimator = pipeline("depth-estimation")
64	
65	        >>> pipe_prior = KandinskyV22PriorEmb2EmbPipeline.from_pretrained(
66	        ...     "kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16
67	        ... )
68	        >>> pipe_prior = pipe_prior.to("cuda")
69	
70	        >>> pipe = KandinskyV22ControlnetImg2ImgPipeline.from_pretrained(
71	        ...     "kandinsky-community/kandinsky-2-2-controlnet-depth", torch_dtype=torch.float16
72	        ... )
73	        >>> pipe = pipe.to("cuda")
74	
75	        >>> img = load_image(
76	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
77	        ...     "/kandinsky/cat.png"
78	        ... ).resize((768, 768))
79	
80	
81	        >>> hint = make_hint(img, depth_estimator).unsqueeze(0).half().to("cuda")
82	
83	        >>> prompt = "A robot, 4k photo"
84	        >>> negative_prior_prompt = "lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature"
85	
86	        >>> generator = torch.Generator(device="cuda").manual_seed(43)
87	
88	        >>> img_emb = pipe_prior(prompt=prompt, image=img, strength=0.85, generator=generator)
89	        >>> negative_emb = pipe_prior(prompt=negative_prior_prompt, image=img, strength=1, generator=generator)
90	
91	        >>> images = pipe(
92	        ...     image=img,
93	        ...     strength=0.5,
94	        ...     image_embeds=img_emb.image_embeds,
95	        ...     negative_image_embeds=negative_emb.image_embeds,
96	        ...     hint=hint,
97	        ...     num_inference_steps=50,
98	        ...     generator=generator,
99	        ...     height=768,
100	        ...     width=768,
101	        ... ).images
102	
103	        >>> images[0].save("robot_cat.png")
104	        ```
105	"""
106	
107	
108	# Copied from diffusers.pipelines.kandinsky2_2.pipeline_kandinsky2_2.downscale_height_and_width
109	def downscale_height_and_width(height, width, scale_factor=8):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_img2img.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	
39	EXAMPLE_DOC_STRING = """
40	    Examples:
41	        ```py
42	        >>> from diffusers import KandinskyV22Img2ImgPipeline, KandinskyV22PriorPipeline
43	        >>> from diffusers.utils import load_image
44	        >>> import torch
45	
46	        >>> pipe_prior = KandinskyV22PriorPipeline.from_pretrained(
47	        ...     "kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16
48	        ... )
49	        >>> pipe_prior.to("cuda")
50	
51	        >>> prompt = "A red cartoon frog, 4k"
52	        >>> image_emb, zero_image_emb = pipe_prior(prompt, return_dict=False)
53	
54	        >>> pipe = KandinskyV22Img2ImgPipeline.from_pretrained(
55	        ...     "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16
56	        ... )
57	        >>> pipe.to("cuda")
58	
59	        >>> init_image = load_image(
60	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
61	        ...     "/kandinsky/frog.png"
62	        ... )
63	
64	        >>> image = pipe(
65	        ...     image=init_image,
66	        ...     image_embeds=image_emb,
67	        ...     negative_image_embeds=zero_image_emb,
68	        ...     height=768,
69	        ...     width=768,
70	        ...     num_inference_steps=100,
71	        ...     strength=0.2,
72	        ... ).images
73	
74	        >>> image[0].save("red_frog.png")
75	        ```
76	"""
77	
78	
79	# Copied from diffusers.pipelines.kandinsky2_2.pipeline_kandinsky2_2.downscale_height_and_width
80	def downscale_height_and_width(height, width, scale_factor=8):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_inpainting.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	
43	EXAMPLE_DOC_STRING = """
44	    Examples:
45	        ```py
46	        >>> from diffusers import KandinskyV22InpaintPipeline, KandinskyV22PriorPipeline
47	        >>> from diffusers.utils import load_image
48	        >>> import torch
49	        >>> import numpy as np
50	
51	        >>> pipe_prior = KandinskyV22PriorPipeline.from_pretrained(
52	        ...     "kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16
53	        ... )
54	        >>> pipe_prior.to("cuda")
55	
56	        >>> prompt = "a hat"
57	        >>> image_emb, zero_image_emb = pipe_prior(prompt, return_dict=False)
58	
59	        >>> pipe = KandinskyV22InpaintPipeline.from_pretrained(
60	        ...     "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
61	        ... )
62	        >>> pipe.to("cuda")
63	
64	        >>> init_image = load_image(
65	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
66	        ...     "/kandinsky/cat.png"
67	        ... )
68	
69	        >>> mask = np.zeros((768, 768), dtype=np.float32)
70	        >>> mask[:250, 250:-250] = 1
71	
72	        >>> out = pipe(
73	        ...     image=init_image,
74	        ...     mask_image=mask,
75	        ...     image_embeds=image_emb,
76	        ...     negative_image_embeds=zero_image_emb,
77	        ...     height=768,
78	        ...     width=768,
79	        ...     num_inference_steps=50,
80	        ... )
81	
82	        >>> image = out.images[0]
83	        >>> image.save("cat_with_hat.png")
84	        ```
85	"""
86	
87	
88	# Copied from diffusers.pipelines.kandinsky2_2.pipeline_kandinsky2_2.downscale_height_and_width
89	def downscale_height_and_width(height, width, scale_factor=8):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_inpainting.py:384
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
383	            logger.warning(
384	                "Please note that the expected format of `mask_image` has recently been changed. "
385	                "Before diffusers == 0.19.0, Kandinsky Inpainting pipelines repainted black pixels and preserved black pixels. "
386	                "As of diffusers==0.19.0 this behavior has been inverted. Now white pixels are repainted and black pixels are preserved. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
52	
53	EXAMPLE_INTERPOLATE_DOC_STRING = """
54	    Examples:
55	        ```py
56	        >>> from diffusers import KandinskyV22PriorPipeline, KandinskyV22Pipeline
57	        >>> from diffusers.utils import load_image
58	        >>> import PIL
59	        >>> import torch
60	        >>> from torchvision import transforms
61	
62	        >>> pipe_prior = KandinskyV22PriorPipeline.from_pretrained(
63	        ...     "kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16
64	        ... )
65	        >>> pipe_prior.to("cuda")
66	        >>> img1 = load_image(
67	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
68	        ...     "/kandinsky/cat.png"
69	        ... )
70	        >>> img2 = load_image(
71	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
72	        ...     "/kandinsky/starry_night.jpeg"
73	        ... )
74	        >>> images_texts = ["a cat", img1, img2]
75	        >>> weights = [0.3, 0.3, 0.4]
76	        >>> out = pipe_prior.interpolate(images_texts, weights)
77	        >>> pipe = KandinskyV22Pipeline.from_pretrained(
78	        ...     "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16
79	        ... )
80	        >>> pipe.to("cuda")
81	        >>> image = pipe(
82	        ...     image_embeds=out.image_embeds,
83	        ...     negative_image_embeds=out.negative_image_embeds,
84	        ...     height=768,
85	        ...     width=768,
86	        ...     num_inference_steps=50,
87	        ... ).images[0]
88	        >>> image.save("starry_cat.png")
89	        ```
90	"""
91	
92	
93	class KandinskyV22PriorPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior_emb2emb.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	
29	EXAMPLE_DOC_STRING = """
30	    Examples:
31	        ```py
32	        >>> from diffusers import KandinskyV22Pipeline, KandinskyV22PriorEmb2EmbPipeline
33	        >>> import torch
34	
35	        >>> pipe_prior = KandinskyPriorPipeline.from_pretrained(
36	        ...     "kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16
37	        ... )
38	        >>> pipe_prior.to("cuda")
39	
40	        >>> prompt = "red cat, 4k photo"
41	        >>> img = load_image(
42	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
43	        ...     "/kandinsky/cat.png"
44	        ... )
45	        >>> image_emb, nagative_image_emb = pipe_prior(prompt, image=img, strength=0.2).to_tuple()
46	
47	        >>> pipe = KandinskyPipeline.from_pretrained(
48	        ...     "kandinsky-community/kandinsky-2-2-decoder, torch_dtype=torch.float16"
49	        ... )
50	        >>> pipe.to("cuda")
51	
52	        >>> image = pipe(
53	        ...     image_embeds=image_emb,
54	        ...     negative_image_embeds=negative_image_emb,
55	        ...     height=768,
56	        ...     width=768,
57	        ...     num_inference_steps=100,
58	        ... ).images
59	
60	        >>> image[0].save("cat.png")
61	        ```
62	"""
63	
64	EXAMPLE_INTERPOLATE_DOC_STRING = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky2_2/pipeline_kandinsky2_2_prior_emb2emb.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
63	
64	EXAMPLE_INTERPOLATE_DOC_STRING = """
65	    Examples:
66	        ```py
67	        >>> from diffusers import KandinskyV22PriorEmb2EmbPipeline, KandinskyV22Pipeline
68	        >>> from diffusers.utils import load_image
69	        >>> import PIL
70	
71	        >>> import torch
72	        >>> from torchvision import transforms
73	
74	        >>> pipe_prior = KandinskyV22PriorPipeline.from_pretrained(
75	        ...     "kandinsky-community/kandinsky-2-2-prior", torch_dtype=torch.float16
76	        ... )
77	        >>> pipe_prior.to("cuda")
78	
79	        >>> img1 = load_image(
80	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
81	        ...     "/kandinsky/cat.png"
82	        ... )
83	
84	        >>> img2 = load_image(
85	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
86	        ...     "/kandinsky/starry_night.jpeg"
87	        ... )
88	
89	        >>> images_texts = ["a cat", img1, img2]
90	        >>> weights = [0.3, 0.3, 0.4]
91	        >>> image_emb, zero_image_emb = pipe_prior.interpolate(images_texts, weights)
92	
93	        >>> pipe = KandinskyV22Pipeline.from_pretrained(
94	        ...     "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16
95	        ... )
96	        >>> pipe.to("cuda")
97	
98	        >>> image = pipe(
99	        ...     image_embeds=image_emb,
100	        ...     negative_image_embeds=zero_image_emb,
101	        ...     height=768,
102	        ...     width=768,
103	        ...     num_inference_steps=150,
104	        ... ).images[0]
105	
106	        >>> image.save("starry_cat.png")
107	        ```
108	"""
109	
110	
111	class KandinskyV22PriorEmb2EmbPipeline(DiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kandinsky3/pipeline_kandinsky3_img2img.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
32	
33	EXAMPLE_DOC_STRING = """
34	    Examples:
35	        ```py
36	        >>> from diffusers import AutoPipelineForImage2Image
37	        >>> from diffusers.utils import load_image
38	        >>> import torch
39	
40	        >>> pipe = AutoPipelineForImage2Image.from_pretrained(
41	        ...     "kandinsky-community/kandinsky-3", variant="fp16", torch_dtype=torch.float16
42	        ... )
43	        >>> pipe.enable_model_cpu_offload()
44	
45	        >>> prompt = "A painting of the inside of a subway train with tiny raccoons."
46	        >>> image = load_image(
47	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky3/t2i.png"
48	        ... )
49	
50	        >>> generator = torch.Generator(device="cpu").manual_seed(0)
51	        >>> image = pipe(prompt, image=image, strength=0.75, num_inference_steps=25, generator=generator).images[0]
52	        ```
53	"""
54	
55	
56	def downscale_height_and_width(height, width, scale_factor=8):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kolors/pipeline_kolors_img2img.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	
46	EXAMPLE_DOC_STRING = """
47	    Examples:
48	        ```py
49	        >>> import torch
50	        >>> from diffusers import KolorsImg2ImgPipeline
51	        >>> from diffusers.utils import load_image
52	
53	        >>> pipe = KolorsImg2ImgPipeline.from_pretrained(
54	        ...     "Kwai-Kolors/Kolors-diffusers", variant="fp16", torch_dtype=torch.float16
55	        ... )
56	        >>> pipe = pipe.to("cuda")
57	        >>> url = (
58	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/kolors/bunny_source.png"
59	        ... )
60	
61	
62	        >>> init_image = load_image(url)
63	        >>> prompt = "high quality image of a capybara wearing sunglasses. In the background of the image there are trees, poles, grass and other objects. At the bottom of the object there is the road., 8k, highly detailed."
64	        >>> image = pipe(prompt, image=init_image).images[0]
65	        ```
66	"""
67	
68	
69	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
70	def retrieve_latents(

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kolors/tokenizer.py:217
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
216	        with open(self.vocab_file, "rb") as fin:
217	            proto_str = fin.read()
218	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/kolors/tokenizer.py:220
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
219	        with open(vocab_file, "wb") as writer:
220	            writer.write(proto_str)
221	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py:229
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
228	            logger.warning(
229	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
230	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py:197
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
196	            logger.warning(
197	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
198	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/latent_diffusion/pipeline_latent_diffusion.py:247
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
246	LDMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP = {
247	    "ldm-bert": "https://huggingface.co/valhalla/ldm-bert/blob/main/config.json",
248	}
249	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/ledits_pp/pipeline_leditspp_stable_diffusion.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	
43	EXAMPLE_DOC_STRING = """
44	    Examples:
45	        ```py
46	        >>> import torch
47	
48	        >>> from diffusers import LEditsPPPipelineStableDiffusion
49	        >>> from diffusers.utils import load_image
50	
51	        >>> pipe = LEditsPPPipelineStableDiffusion.from_pretrained(
52	        ...     "runwayml/stable-diffusion-v1-5", variant="fp16", torch_dtype=torch.float16
53	        ... )
54	        >>> pipe.enable_vae_tiling()
55	        >>> pipe = pipe.to("cuda")
56	
57	        >>> img_url = "https://www.aiml.informatik.tu-darmstadt.de/people/mbrack/cherry_blossom.png"
58	        >>> image = load_image(img_url).resize((512, 512))
59	
60	        >>> _ = pipe.invert(image=image, num_inversion_steps=50, skip=0.1)
61	
62	        >>> edited_image = pipe(
63	        ...     editing_prompt=["cherry blossom"], edit_guidance_scale=10.0, edit_threshold=0.75
64	        ... ).images[0]
65	        ```
66	"""
67	
68	
69	# Modified from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionAttendAndExcitePipeline.AttentionStore
70	class LeditsAttentionStore:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/ledits_pp/pipeline_leditspp_stable_diffusion.py:357
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
356	            logger.warning(
357	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
358	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/ledits_pp/pipeline_leditspp_stable_diffusion_xl.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
70	
71	EXAMPLE_DOC_STRING = """
72	    Examples:
73	        ```py
74	        >>> import torch
75	
76	        >>> from diffusers import LEditsPPPipelineStableDiffusionXL
77	        >>> from diffusers.utils import load_image
78	
79	        >>> pipe = LEditsPPPipelineStableDiffusionXL.from_pretrained(
80	        ...     "stabilityai/stable-diffusion-xl-base-1.0", variant="fp16", torch_dtype=torch.float16
81	        ... )
82	        >>> pipe.enable_vae_tiling()
83	        >>> pipe = pipe.to("cuda")
84	
85	        >>> img_url = "https://www.aiml.informatik.tu-darmstadt.de/people/mbrack/tennis.jpg"
86	        >>> image = load_image(img_url).resize((1024, 1024))
87	
88	        >>> _ = pipe.invert(image=image, num_inversion_steps=50, skip=0.2)
89	
90	        >>> edited_image = pipe(
91	        ...     editing_prompt=["tennis ball", "tomato"],
92	        ...     reverse_editing_direction=[True, False],
93	        ...     edit_guidance_scale=[5.0, 10.0],
94	        ...     edit_threshold=[0.9, 0.85],
95	        ... ).images[0]
96	        ```
97	"""
98	
99	
100	# Copied from diffusers.pipelines.ledits_pp.pipeline_leditspp_stable_diffusion.LeditsAttentionStore
101	class LeditsAttentionStore:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/ltx/pipeline_ltx_condition.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	
45	EXAMPLE_DOC_STRING = """
46	    Examples:
47	        ```py
48	        >>> import torch
49	        >>> from diffusers.pipelines.ltx.pipeline_ltx_condition import LTXConditionPipeline, LTXVideoCondition
50	        >>> from diffusers.utils import export_to_video, load_video, load_image
51	
52	        >>> pipe = LTXConditionPipeline.from_pretrained("Lightricks/LTX-Video-0.9.5", torch_dtype=torch.bfloat16)
53	        >>> pipe.to("cuda")
54	
55	        >>> # Load input image and video
56	        >>> video = load_video(
57	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cosmos/cosmos-video2world-input-vid.mp4"
58	        ... )
59	        >>> image = load_image(
60	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cosmos/cosmos-video2world-input.jpg"
61	        ... )
62	
63	        >>> # Create conditioning objects
64	        >>> condition1 = LTXVideoCondition(
65	        ...     image=image,
66	        ...     frame_index=0,
67	        ... )
68	        >>> condition2 = LTXVideoCondition(
69	        ...     video=video,
70	        ...     frame_index=80,
71	        ... )
72	
73	        >>> prompt = "The video depicts a long, straight highway stretching into the distance, flanked by metal guardrails. The road is divided into multiple lanes, with a few vehicles visible in the far distance. The surrounding landscape features dry, grassy fields on one side and rolling hills on the other. The sky is mostly clear with a few scattered clouds, suggesting a bright, sunny day. And then the camera switch to a winding mountain road covered in snow, with a single vehicle traveling along it. The road is flanked by steep, rocky cliffs and sparse vegetation. The landscape is characterized by rugged terrain and a river visible in the distance. The scene captures the solitude and beauty of a winter drive through a mountainous region."
74	        >>> negative_prompt = "worst quality, inconsistent motion, blurry, jittery, distorted"
75	
76	        >>> # Generate video
77	        >>> generator = torch.Generator("cuda").manual_seed(0)
78	        >>> # Text-only conditioning is also supported without the need to pass `conditions`
79	        >>> video = pipe(
80	        ...     conditions=[condition1, condition2],
81	        ...     prompt=prompt,
82	        ...     negative_prompt=negative_prompt,
83	        ...     width=768,
84	        ...     height=512,
85	        ...     num_frames=161,
86	        ...     num_inference_steps=40,
87	        ...     generator=generator,
88	        ... ).frames[0]
89	
90	        >>> export_to_video(video, "output.mp4", fps=24)
91	        ```
92	"""
93	
94	
95	@dataclass
96	class LTXVideoCondition:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/ltx/pipeline_ltx_image2video.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
43	
44	EXAMPLE_DOC_STRING = """
45	    Examples:
46	        ```py
47	        >>> import torch
48	        >>> from diffusers import LTXImageToVideoPipeline
49	        >>> from diffusers.utils import export_to_video, load_image
50	
51	        >>> pipe = LTXImageToVideoPipeline.from_pretrained("Lightricks/LTX-Video", torch_dtype=torch.bfloat16)
52	        >>> pipe.to("cuda")
53	
54	        >>> image = load_image(
55	        ...     "https://huggingface.co/datasets/a-r-r-o-w/tiny-meme-dataset-captioned/resolve/main/images/8.png"
56	        ... )
57	        >>> prompt = "A young girl stands calmly in the foreground, looking directly at the camera, as a house fire rages in the background. Flames engulf the structure, with smoke billowing into the air. Firefighters in protective gear rush to the scene, a fire truck labeled '38' visible behind them. The girl's neutral expression contrasts sharply with the chaos of the fire, creating a poignant and emotionally charged scene."
58	        >>> negative_prompt = "worst quality, inconsistent motion, blurry, jittery, distorted"
59	
60	        >>> video = pipe(
61	        ...     image=image,
62	        ...     prompt=prompt,
63	        ...     negative_prompt=negative_prompt,
64	        ...     width=704,
65	        ...     height=480,
66	        ...     num_frames=161,
67	        ...     num_inference_steps=50,
68	        ... ).frames[0]
69	        >>> export_to_video(video, "output.mp4", fps=24)
70	        ```
71	"""
72	
73	
74	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
75	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/marigold/pipeline_marigold_depth.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
59	
60	EXAMPLE_DOC_STRING = """
61	Examples:
62	```py
63	>>> import diffusers
64	>>> import torch
65	
66	>>> pipe = diffusers.MarigoldDepthPipeline.from_pretrained(
67	...     "prs-eth/marigold-depth-v1-1", variant="fp16", torch_dtype=torch.float16
68	... ).to("cuda")
69	
70	>>> image = diffusers.utils.load_image("https://marigoldmonodepth.github.io/images/einstein.jpg")
71	>>> depth = pipe(image)
72	
73	>>> vis = pipe.image_processor.visualize_depth(depth.prediction)
74	>>> vis[0].save("einstein_depth.png")
75	
76	>>> depth_16bit = pipe.image_processor.export_depth_to_16bit_png(depth.prediction)
77	>>> depth_16bit[0].save("einstein_depth_16bit.png")
78	```
79	"""
80	
81	
82	@dataclass
83	class MarigoldDepthOutput(BaseOutput):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/marigold/pipeline_marigold_intrinsics.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
57	
58	EXAMPLE_DOC_STRING = """
59	Examples:
60	```py
61	>>> import diffusers
62	>>> import torch
63	
64	>>> pipe = diffusers.MarigoldIntrinsicsPipeline.from_pretrained(
65	...     "prs-eth/marigold-iid-appearance-v1-1", variant="fp16", torch_dtype=torch.float16
66	... ).to("cuda")
67	
68	>>> image = diffusers.utils.load_image("https://marigoldmonodepth.github.io/images/einstein.jpg")
69	>>> intrinsics = pipe(image)
70	
71	>>> vis = pipe.image_processor.visualize_intrinsics(intrinsics.prediction, pipe.target_properties)
72	>>> vis[0]["albedo"].save("einstein_albedo.png")
73	>>> vis[0]["roughness"].save("einstein_roughness.png")
74	>>> vis[0]["metallicity"].save("einstein_metallicity.png")
75	```
76	```py
77	>>> import diffusers
78	>>> import torch
79	
80	>>> pipe = diffusers.MarigoldIntrinsicsPipeline.from_pretrained(
81	...     "prs-eth/marigold-iid-lighting-v1-1", variant="fp16", torch_dtype=torch.float16
82	... ).to("cuda")
83	
84	>>> image = diffusers.utils.load_image("https://marigoldmonodepth.github.io/images/einstein.jpg")
85	>>> intrinsics = pipe(image)
86	
87	>>> vis = pipe.image_processor.visualize_intrinsics(intrinsics.prediction, pipe.target_properties)
88	>>> vis[0]["albedo"].save("einstein_albedo.png")
89	>>> vis[0]["shading"].save("einstein_shading.png")
90	>>> vis[0]["residual"].save("einstein_residual.png")
91	```
92	"""
93	
94	
95	@dataclass
96	class MarigoldIntrinsicsOutput(BaseOutput):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/marigold/pipeline_marigold_normals.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
57	
58	EXAMPLE_DOC_STRING = """
59	Examples:
60	```py
61	>>> import diffusers
62	>>> import torch
63	
64	>>> pipe = diffusers.MarigoldNormalsPipeline.from_pretrained(
65	...     "prs-eth/marigold-normals-v1-1", variant="fp16", torch_dtype=torch.float16
66	... ).to("cuda")
67	
68	>>> image = diffusers.utils.load_image("https://marigoldmonodepth.github.io/images/einstein.jpg")
69	>>> normals = pipe(image)
70	
71	>>> vis = pipe.image_processor.visualize_normals(normals.prediction)
72	>>> vis[0].save("einstein_normals.png")
73	```
74	"""
75	
76	
77	@dataclass
78	class MarigoldNormalsOutput(BaseOutput):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_controlnet_sd.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
55	
56	EXAMPLE_DOC_STRING = """
57	    Examples:
58	        ```py
59	        >>> # !pip install opencv-python transformers accelerate
60	        >>> from diffusers import AutoPipelineForText2Image, ControlNetModel, UniPCMultistepScheduler
61	        >>> from diffusers.utils import load_image
62	        >>> import numpy as np
63	        >>> import torch
64	
65	        >>> import cv2
66	        >>> from PIL import Image
67	
68	        >>> # download an image
69	        >>> image = load_image(
70	        ...     "https://hf.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/hf-logo.png"
71	        ... )
72	        >>> image = np.array(image)
73	
74	        >>> # get canny image
75	        >>> image = cv2.Canny(image, 100, 200)
76	        >>> image = image[:, :, None]
77	        >>> image = np.concatenate([image, image, image], axis=2)
78	        >>> canny_image = Image.fromarray(image)
79	
80	        >>> # load control net and stable diffusion v1-5
81	        >>> controlnet = ControlNetModel.from_pretrained("lllyasviel/sd-controlnet-canny", torch_dtype=torch.float16)
82	        >>> pipe = AutoPipelineForText2Image.from_pretrained(
83	        ...     "runwayml/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16, enable_pag=True
84	        ... )
85	
86	        >>> # speed up diffusion process with faster scheduler and memory optimization
87	        >>> # remove following line if xformers is not installed
88	        >>> pipe.enable_xformers_memory_efficient_attention()
89	
90	        >>> pipe.enable_model_cpu_offload()
91	
92	        >>> # generate image
93	        >>> generator = torch.manual_seed(0)
94	        >>> image = pipe(
95	        ...     "aerial view, a futuristic research complex in a bright foggy jungle, hard lighting",
96	        ...     guidance_scale=7.5,
97	        ...     generator=generator,
98	        ...     image=canny_image,
99	        ...     pag_scale=10,
100	        ... ).images[0]
101	        ```
102	"""
103	
104	
105	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.retrieve_timesteps
106	def retrieve_timesteps(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_controlnet_sd.py:234
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
233	            logger.warning(
234	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
235	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_controlnet_sd_inpaint.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	EXAMPLE_DOC_STRING = """
58	    Examples:
59	        ```py
60	        >>> # !pip install transformers accelerate
61	        >>> import cv2
62	        >>> from diffusers import AutoPipelineForInpainting, ControlNetModel, DDIMScheduler
63	        >>> from diffusers.utils import load_image
64	        >>> import numpy as np
65	        >>> from PIL import Image
66	        >>> import torch
67	
68	        >>> init_image = load_image(
69	        ...     "https://huggingface.co/datasets/diffusers/test-arrays/resolve/main/stable_diffusion_inpaint/boy.png"
70	        ... )
71	        >>> init_image = init_image.resize((512, 512))
72	
73	        >>> generator = torch.Generator(device="cpu").manual_seed(1)
74	
75	        >>> mask_image = load_image(
76	        ...     "https://huggingface.co/datasets/diffusers/test-arrays/resolve/main/stable_diffusion_inpaint/boy_mask.png"
77	        ... )
78	        >>> mask_image = mask_image.resize((512, 512))
79	
80	
81	        >>> def make_canny_condition(image):
82	        ...     image = np.array(image)
83	        ...     image = cv2.Canny(image, 100, 200)
84	        ...     image = image[:, :, None]
85	        ...     image = np.concatenate([image, image, image], axis=2)
86	        ...     image = Image.fromarray(image)
87	        ...     return image
88	
89	
90	        >>> control_image = make_canny_condition(init_image)
91	
92	        >>> controlnet = ControlNetModel.from_pretrained(
93	        ...     "lllyasviel/control_v11p_sd15_inpaint", torch_dtype=torch.float16
94	        ... )
95	        >>> pipe = AutoPipelineForInpainting.from_pretrained(
96	        ...     "runwayml/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16, enable_pag=True
97	        ... )
98	
99	        >>> pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
100	        >>> pipe.enable_model_cpu_offload()
101	
102	        >>> # generate image
103	        >>> image = pipe(
104	        ...     "a handsome man with ray-ban sunglasses",
105	        ...     num_inference_steps=20,
106	        ...     generator=generator,
107	        ...     eta=1.0,
108	        ...     image=init_image,
109	        ...     mask_image=mask_image,
110	        ...     control_image=control_image,
111	        ...     pag_scale=0.3,
112	        ... ).images[0]
113	        ```
114	"""
115	
116	
117	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
118	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_controlnet_sd_inpaint.py:211
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
210	            logger.warning(
211	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
212	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_controlnet_sd_xl.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	
78	EXAMPLE_DOC_STRING = """
79	    Examples:
80	        ```py
81	        >>> # !pip install opencv-python transformers accelerate
82	        >>> from diffusers import AutoPipelineForText2Image, ControlNetModel, AutoencoderKL
83	        >>> from diffusers.utils import load_image
84	        >>> import numpy as np
85	        >>> import torch
86	
87	        >>> import cv2
88	        >>> from PIL import Image
89	
90	        >>> prompt = "aerial view, a futuristic research complex in a bright foggy jungle, hard lighting"
91	        >>> negative_prompt = "low quality, bad quality, sketches"
92	
93	        >>> # download an image
94	        >>> image = load_image(
95	        ...     "https://hf.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/hf-logo.png"
96	        ... )
97	
98	        >>> # initialize the models and pipeline
99	        >>> controlnet_conditioning_scale = 0.5  # recommended for good generalization
100	        >>> controlnet = ControlNetModel.from_pretrained(
101	        ...     "diffusers/controlnet-canny-sdxl-1.0", torch_dtype=torch.float16
102	        ... )
103	        >>> vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
104	        >>> pipe = AutoPipelineForText2Image.from_pretrained(
105	        ...     "stabilityai/stable-diffusion-xl-base-1.0",
106	        ...     controlnet=controlnet,
107	        ...     vae=vae,
108	        ...     torch_dtype=torch.float16,
109	        ...     enable_pag=True,
110	        ... )
111	        >>> pipe.enable_model_cpu_offload()
112	
113	        >>> # get canny image
114	        >>> image = np.array(image)
115	        >>> image = cv2.Canny(image, 100, 200)
116	        >>> image = image[:, :, None]
117	        >>> image = np.concatenate([image, image, image], axis=2)
118	        >>> canny_image = Image.fromarray(image)
119	
120	        >>> # generate image
121	        >>> image = pipe(
122	        ...     prompt, controlnet_conditioning_scale=controlnet_conditioning_scale, image=canny_image, pag_scale=0.3
123	        ... ).images[0]
124	        ```
125	"""
126	
127	
128	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.retrieve_timesteps
129	def retrieve_timesteps(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_controlnet_sd_xl_img2img.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	
78	EXAMPLE_DOC_STRING = """
79	    Examples:
80	        ```py
81	        >>> # pip install accelerate transformers safetensors diffusers
82	
83	        >>> import torch
84	        >>> import numpy as np
85	        >>> from PIL import Image
86	
87	        >>> from transformers import DPTFeatureExtractor, DPTForDepthEstimation
88	        >>> from diffusers import ControlNetModel, StableDiffusionXLControlNetPAGImg2ImgPipeline, AutoencoderKL
89	        >>> from diffusers.utils import load_image
90	
91	
92	        >>> depth_estimator = DPTForDepthEstimation.from_pretrained("Intel/dpt-hybrid-midas").to("cuda")
93	        >>> feature_extractor = DPTFeatureExtractor.from_pretrained("Intel/dpt-hybrid-midas")
94	        >>> controlnet = ControlNetModel.from_pretrained(
95	        ...     "diffusers/controlnet-depth-sdxl-1.0-small",
96	        ...     variant="fp16",
97	        ...     use_safetensors="True",
98	        ...     torch_dtype=torch.float16,
99	        ... )
100	        >>> vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
101	        >>> pipe = StableDiffusionXLControlNetPAGImg2ImgPipeline.from_pretrained(
102	        ...     "stabilityai/stable-diffusion-xl-base-1.0",
103	        ...     controlnet=controlnet,
104	        ...     vae=vae,
105	        ...     variant="fp16",
106	        ...     use_safetensors=True,
107	        ...     torch_dtype=torch.float16,
108	        ...     enable_pag=True,
109	        ... )
110	        >>> pipe.enable_model_cpu_offload()
111	
112	
113	        >>> def get_depth_map(image):
114	        ...     image = feature_extractor(images=image, return_tensors="pt").pixel_values.to("cuda")
115	        ...     with torch.no_grad(), torch.autocast("cuda"):
116	        ...         depth_map = depth_estimator(image).predicted_depth
117	
118	        ...     depth_map = torch.nn.fuctional.interpolate(
119	        ...         depth_map.unsqueeze(1),
120	        ...         size=(1024, 1024),
121	        ...         mode="bicubic",
122	        ...         align_corners=False,
123	        ...     )
124	        ...     depth_min = torch.amin(depth_map, dim=[1, 2, 3], keepdim=True)
125	        ...     depth_max = torch.amax(depth_map, dim=[1, 2, 3], keepdim=True)
126	        ...     depth_map = (depth_map - depth_min) / (depth_max - depth_min)
127	        ...     image = torch.cat([depth_map] * 3, dim=1)
128	        ...     image = image.permute(0, 2, 3, 1).cpu().numpy()[0]
129	        ...     image = Image.fromarray((image * 255.0).clip(0, 255).astype(np.uint8))
130	        ...     return image
131	
132	
133	        >>> prompt = "A robot, 4k photo"
134	        >>> image = load_image(
135	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
136	        ...     "/kandinsky/cat.png"
137	        ... ).resize((1024, 1024))
138	        >>> controlnet_conditioning_scale = 0.5  # recommended for good generalization
139	        >>> depth_image = get_depth_map(image)
140	
141	        >>> images = pipe(
142	        ...     prompt,
143	        ...     image=image,
144	        ...     control_image=depth_image,
145	        ...     strength=0.99,
146	        ...     num_inference_steps=50,
147	        ...     controlnet_conditioning_scale=controlnet_conditioning_scale,
148	        ... ).images
149	        >>> images[0].save(f"robot_cat.png")
150	        ```
151	"""
152	
153	
154	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
155	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_hunyuandit.py:234
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
233	            logger.warning(
234	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
235	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_sd.py:248
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
247	            logger.warning(
248	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
249	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_sd_3_img2img.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	EXAMPLE_DOC_STRING = """
58	    Examples:
59	        ```py
60	        >>> import torch
61	        >>> from diffusers import StableDiffusion3PAGImg2ImgPipeline
62	        >>> from diffusers.utils import load_image
63	
64	        >>> pipe = StableDiffusion3PAGImg2ImgPipeline.from_pretrained(
65	        ...     "stabilityai/stable-diffusion-3-medium-diffusers",
66	        ...     torch_dtype=torch.float16,
67	        ...     pag_applied_layers=["blocks.13"],
68	        ... )
69	        >>> pipe.to("cuda")
70	        >>> prompt = "a photo of an astronaut riding a horse on mars"
71	        >>> url = "https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png"
72	        >>> init_image = load_image(url).convert("RGB")
73	        >>> image = pipe(prompt, image=init_image, guidance_scale=5.0, pag_scale=0.7).images[0]
74	        ```
75	"""
76	
77	
78	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
79	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_sd_img2img.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
55	
56	EXAMPLE_DOC_STRING = """
57	    Examples:
58	        ```py
59	        >>> import torch
60	        >>> from diffusers import AutoPipelineForImage2Image
61	        >>> from diffusers.utils import load_image
62	
63	        >>> pipe = AutoPipelineForImage2Image.from_pretrained(
64	        ...     "runwayml/stable-diffusion-v1-5",
65	        ...     torch_dtype=torch.float16,
66	        ...     enable_pag=True,
67	        ... )
68	        >>> pipe = pipe.to("cuda")
69	        >>> url = "https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png"
70	
71	        >>> init_image = load_image(url).convert("RGB")
72	        >>> prompt = "a photo of an astronaut riding a horse on mars"
73	        >>> image = pipe(prompt, image=init_image, pag_scale=0.3).images[0]
74	        ```
75	"""
76	
77	
78	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
79	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_sd_img2img.py:243
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
242	            logger.warning(
243	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
244	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_sd_inpaint.py:54
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
53	
54	EXAMPLE_DOC_STRING = """
55	    Examples:
56	        ```py
57	        >>> import torch
58	        >>> from diffusers import AutoPipelineForInpainting
59	
60	        >>> pipe = AutoPipelineForInpainting.from_pretrained(
61	        ...     "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, enable_pag=True
62	        ... )
63	        >>> pipe = pipe.to("cuda")
64	        >>> img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
65	        >>> mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
66	        >>> init_image = load_image(img_url).convert("RGB")
67	        >>> mask_image = load_image(mask_url).convert("RGB")
68	        >>> prompt = "A majestic tiger sitting on a bench"
69	        >>> image = pipe(
70	        ...     prompt=prompt,
71	        ...     image=init_image,
72	        ...     mask_image=mask_image,
73	        ...     strength=0.8,
74	        ...     num_inference_steps=50,
75	        ...     guidance_scale=guidance_scale,
76	        ...     generator=generator,
77	        ...     pag_scale=pag_scale,
78	        ... ).images[0]
79	        ```
80	"""
81	
82	
83	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
84	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_sd_inpaint.py:275
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
274	            logger.warning(
275	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
276	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_sd_xl_img2img.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
70	
71	EXAMPLE_DOC_STRING = """
72	    Examples:
73	        ```py
74	        >>> import torch
75	        >>> from diffusers import AutoPipelineForImage2Image
76	        >>> from diffusers.utils import load_image
77	
78	        >>> pipe = AutoPipelineForImage2Image.from_pretrained(
79	        ...     "stabilityai/stable-diffusion-xl-refiner-1.0",
80	        ...     torch_dtype=torch.float16,
81	        ...     enable_pag=True,
82	        ... )
83	        >>> pipe = pipe.to("cuda")
84	        >>> url = "https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png"
85	
86	        >>> init_image = load_image(url).convert("RGB")
87	        >>> prompt = "a photo of an astronaut riding a horse on mars"
88	        >>> image = pipe(prompt, image=init_image, pag_scale=0.3).images[0]
89	        ```
90	"""
91	
92	
93	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.rescale_noise_cfg
94	def rescale_noise_cfg(noise_cfg, noise_pred_text, guidance_rescale=0.0):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pag/pipeline_pag_sd_xl_inpaint.py:72
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
71	
72	EXAMPLE_DOC_STRING = """
73	    Examples:
74	        ```py
75	        >>> import torch
76	        >>> from diffusers import AutoPipelineForInpainting
77	        >>> from diffusers.utils import load_image
78	
79	        >>> pipe = AutoPipelineForInpainting.from_pretrained(
80	        ...     "stabilityai/stable-diffusion-xl-base-1.0",
81	        ...     torch_dtype=torch.float16,
82	        ...     variant="fp16",
83	        ...     enable_pag=True,
84	        ... )
85	        >>> pipe.to("cuda")
86	
87	        >>> img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
88	        >>> mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
89	
90	        >>> init_image = load_image(img_url).convert("RGB")
91	        >>> mask_image = load_image(mask_url).convert("RGB")
92	
93	        >>> prompt = "A majestic tiger sitting on a bench"
94	        >>> image = pipe(
95	        ...     prompt=prompt,
96	        ...     image=init_image,
97	        ...     mask_image=mask_image,
98	        ...     num_inference_steps=50,
99	        ...     strength=0.80,
100	        ...     pag_scale=0.3,
101	        ... ).images[0]
102	        ```
103	"""
104	
105	
106	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.rescale_noise_cfg
107	def rescale_noise_cfg(noise_cfg, noise_pred_text, guidance_rescale=0.0):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pia/pipeline_pia.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
61	
62	EXAMPLE_DOC_STRING = """
63	    Examples:
64	        ```py
65	        >>> import torch
66	        >>> from diffusers import EulerDiscreteScheduler, MotionAdapter, PIAPipeline
67	        >>> from diffusers.utils import export_to_gif, load_image
68	
69	        >>> adapter = MotionAdapter.from_pretrained("openmmlab/PIA-condition-adapter")
70	        >>> pipe = PIAPipeline.from_pretrained(
71	        ...     "SG161222/Realistic_Vision_V6.0_B1_noVAE", motion_adapter=adapter, torch_dtype=torch.float16
72	        ... )
73	
74	        >>> pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)
75	        >>> image = load_image(
76	        ...     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/pix2pix/cat_6.png?download=true"
77	        ... )
78	        >>> image = image.resize((512, 512))
79	        >>> prompt = "cat in a hat"
80	        >>> negative_prompt = "wrong white balance, dark, sketches, worst quality, low quality, deformed, distorted"
81	        >>> generator = torch.Generator("cpu").manual_seed(0)
82	        >>> output = pipe(image=image, prompt=prompt, negative_prompt=negative_prompt, generator=generator)
83	        >>> frames = output.frames[0]
84	        >>> export_to_gif(frames, "pia-animation.gif")
85	        ```
86	"""
87	
88	RANGE_LIST = [

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_flax_utils.py:359
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
358	            # download all allow_patterns
359	            cached_folder = snapshot_download(
360	                pretrained_model_name_or_path,
361	                cache_dir=cache_dir,
362	                proxies=proxies,
363	                local_files_only=local_files_only,
364	                token=token,
365	                revision=revision,
366	                allow_patterns=allow_patterns,
367	                ignore_patterns=ignore_patterns,
368	                user_agent=user_agent,
369	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:286
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
285	        warnings.warn(
286	            f"You are loading the variant {revision} from {pretrained_model_name_or_path} via `revision='{revision}'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='{revision}'` instead. However, it appears that {pretrained_model_name_or_path} currently does not have the required variant filenames in the 'main' branch. \n The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title '{pretrained_model_name_or_path} is missing {revision} files' so that the correct variant file can be added.",
287	            FutureWarning,

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:563
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
562	
563	    torch_dtype = kwargs.get("torch_dtype", torch.float32)
564	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:594
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
593	            sub_model_dtype = (
594	                torch_dtype.get(name, torch_dtype.get("default", torch.float32))
595	                if isinstance(torch_dtype, dict)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:594
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
593	            sub_model_dtype = (
594	                torch_dtype.get(name, torch_dtype.get("default", torch.float32))
595	                if isinstance(torch_dtype, dict)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:607
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
606	                torch_dtype=sub_model_dtype,
607	                cached_folder=kwargs.get("cached_folder", None),
608	                force_download=kwargs.get("force_download", None),

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:608
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
607	                cached_folder=kwargs.get("cached_folder", None),
608	                force_download=kwargs.get("force_download", None),
609	                proxies=kwargs.get("proxies", None),

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:609
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
608	                force_download=kwargs.get("force_download", None),
609	                proxies=kwargs.get("proxies", None),
610	                local_files_only=kwargs.get("local_files_only", None),

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:610
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
609	                proxies=kwargs.get("proxies", None),
610	                local_files_only=kwargs.get("local_files_only", None),
611	                token=kwargs.get("token", None),

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:611
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
610	                local_files_only=kwargs.get("local_files_only", None),
611	                token=kwargs.get("token", None),
612	                revision=kwargs.get("revision", None),

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:612
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
611	                token=kwargs.get("token", None),
612	                revision=kwargs.get("revision", None),
613	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:624
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
623	            module,
624	            dtype=torch_dtype.get(module_name, torch_dtype.get("default", torch.float32))
625	            if isinstance(torch_dtype, dict)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:624
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
623	            module,
624	            dtype=torch_dtype.get(module_name, torch_dtype.get("default", torch.float32))
625	            if isinstance(torch_dtype, dict)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:881
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
880	        deprecation_message = (
881	            "You are using a legacy checkpoint for inpainting with Stable Diffusion, therefore we are loading the"
882	            f" {StableDiffusionInpaintPipelineLegacy} class instead of {StableDiffusionInpaintPipeline}. For"
883	            " better inpainting results, we strongly suggest using Stable Diffusion's official inpainting"
884	            " checkpoint: https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-inpainting instead or adapting your"
885	            f" checkpoint {pretrained_model_name_or_path} to the format of"
886	            " https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-inpainting. Note that we do not actively maintain"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_loading_utils.py:881
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
880	        deprecation_message = (
881	            "You are using a legacy checkpoint for inpainting with Stable Diffusion, therefore we are loading the"
882	            f" {StableDiffusionInpaintPipelineLegacy} class instead of {StableDiffusionInpaintPipeline}. For"
883	            " better inpainting results, we strongly suggest using Stable Diffusion's official inpainting"
884	            " checkpoint: https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-inpainting instead or adapting your"
885	            f" checkpoint {pretrained_model_name_or_path} to the format of"
886	            " https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-inpainting. Note that we do not actively maintain"

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_utils.py:931
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
930	            if final_device_map is not None and len(final_device_map) > 0:
931	                component_device = final_device_map.get(name, None)
932	                if component_device is not None:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_utils.py:957
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
956	                sub_model_dtype = (
957	                    torch_dtype.get(name, torch_dtype.get("default", torch.float32))
958	                    if isinstance(torch_dtype, dict)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_utils.py:957
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
956	                sub_model_dtype = (
957	                    torch_dtype.get(name, torch_dtype.get("default", torch.float32))
958	                    if isinstance(torch_dtype, dict)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_utils.py:1007
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1006	            for module in missing_modules:
1007	                init_kwargs[module] = passed_class_obj.get(module, None)
1008	        elif len(missing_modules) > 0:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_utils.py:1460
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1459	                raise ValueError(
1460	                    f"The repository for {pretrained_model_name} contains custom code in {custom_pipeline}.py which must be executed to correctly "
1461	                    f"load the model. You can inspect the repository content at https://hf.co/{pretrained_model_name}/blob/main/{custom_pipeline}.py.\n"
1462	                    f"Please pass the argument `trust_remote_code=True` to allow custom code to be run."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_utils.py:1468
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1467	                    f"The repository for {pretrained_model_name} contains custom code in {'.py, '.join([os.path.join(k, v) for k, v in custom_components.items()])} which must be executed to correctly "
1468	                    f"load the model. You can inspect the repository content at {', '.join([f'https://hf.co/{pretrained_model_name}/{k}/{v}.py' for k, v in custom_components.items()])}.\n"
1469	                    f"Please pass the argument `trust_remote_code=True` to allow custom code to be run."

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/pipeline_utils.py:1569
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1568	
1569	            cls_name = cls.load_config(os.path.join(cached_folder, "model_index.json")).get("_class_name", None)
1570	            cls_name = cls_name[4:] if isinstance(cls_name, str) and cls_name.startswith("Flax") else cls_name

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/semantic_stable_diffusion/pipeline_semantic_stable_diffusion.py:74
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
73	            logger.warning(
74	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
75	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/shap_e/pipeline_shap_e_img2img.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	
46	EXAMPLE_DOC_STRING = """
47	    Examples:
48	        ```py
49	        >>> from PIL import Image
50	        >>> import torch
51	        >>> from diffusers import DiffusionPipeline
52	        >>> from diffusers.utils import export_to_gif, load_image
53	
54	        >>> device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
55	
56	        >>> repo = "openai/shap-e-img2img"
57	        >>> pipe = DiffusionPipeline.from_pretrained(repo, torch_dtype=torch.float16)
58	        >>> pipe = pipe.to(device)
59	
60	        >>> guidance_scale = 3.0
61	        >>> image_url = "https://hf.co/datasets/diffusers/docs-images/resolve/main/shap-e/corgi.png"
62	        >>> image = load_image(image_url).convert("RGB")
63	
64	        >>> images = pipe(
65	        ...     image,
66	        ...     guidance_scale=guidance_scale,
67	        ...     num_inference_steps=64,
68	        ...     frame_size=256,
69	        ... ).images
70	
71	        >>> gif_path = export_to_gif(images[0], "corgi_3d.gif")
72	        ```
73	"""
74	
75	
76	@dataclass
77	class ShapEPipelineOutput(BaseOutput):

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py:644
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
643	        if key.startswith(vae_key):
644	            vae_state_dict[key.replace(vae_key, "")] = checkpoint.get(key)
645	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py:1300
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1299	        else:
1300	            config_url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml"
1301	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py:1307
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1306	            else:
1307	                config_url = "https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml"
1308	            if global_step == 110000:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py:1316
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1315	            else:
1316	                config_url = "https://raw.githubusercontent.com/Stability-AI/generative-models/main/configs/inference/sd_xl_base.yaml"
1317	        elif key_name_sd_xl_refiner in checkpoint:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py:1322
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1321	            else:
1322	                config_url = "https://raw.githubusercontent.com/Stability-AI/generative-models/main/configs/inference/sd_xl_refiner.yaml"
1323	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py:1325
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1324	        if is_upscale:
1325	            config_url = "https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/x4-upscaling.yaml"
1326	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py:1328
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1327	        if config_url is not None:
1328	            original_config_file = BytesIO(requests.get(config_url, timeout=DIFFUSERS_REQUEST_TIMEOUT).content)
1329	        else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion.py:127
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
126	            logger.warning(
127	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
128	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion_img2img.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	
46	EXAMPLE_DOC_STRING = """
47	    Examples:
48	        ```py
49	        >>> import jax
50	        >>> import numpy as np
51	        >>> import jax.numpy as jnp
52	        >>> from flax.jax_utils import replicate
53	        >>> from flax.training.common_utils import shard
54	        >>> import requests
55	        >>> from io import BytesIO
56	        >>> from PIL import Image
57	        >>> from diffusers import FlaxStableDiffusionImg2ImgPipeline
58	
59	
60	        >>> def create_key(seed=0):
61	        ...     return jax.random.PRNGKey(seed)
62	
63	
64	        >>> rng = create_key(0)
65	
66	        >>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
67	        >>> response = requests.get(url)
68	        >>> init_img = Image.open(BytesIO(response.content)).convert("RGB")
69	        >>> init_img = init_img.resize((768, 512))
70	
71	        >>> prompts = "A fantasy landscape, trending on artstation"
72	
73	        >>> pipeline, params = FlaxStableDiffusionImg2ImgPipeline.from_pretrained(
74	        ...     "CompVis/stable-diffusion-v1-4",
75	        ...     revision="flax",
76	        ...     dtype=jnp.bfloat16,
77	        ... )
78	
79	        >>> num_samples = jax.device_count()
80	        >>> rng = jax.random.split(rng, jax.device_count())
81	        >>> prompt_ids, processed_image = pipeline.prepare_inputs(
82	        ...     prompt=[prompts] * num_samples, image=[init_img] * num_samples
83	        ... )
84	        >>> p_params = replicate(params)
85	        >>> prompt_ids = shard(prompt_ids)
86	        >>> processed_image = shard(processed_image)
87	
88	        >>> output = pipeline(
89	        ...     prompt_ids=prompt_ids,
90	        ...     image=processed_image,
91	        ...     params=p_params,
92	        ...     prng_seed=rng,
93	        ...     strength=0.75,
94	        ...     num_inference_steps=50,
95	        ...     jit=True,
96	        ...     height=512,
97	        ...     width=768,
98	        ... ).images
99	
100	        >>> output_images = pipeline.numpy_to_pil(np.asarray(output.reshape((num_samples,) + output.shape[-3:])))
101	        ```
102	"""
103	
104	
105	class FlaxStableDiffusionImg2ImgPipeline(FlaxDiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion_img2img.py:151
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
150	            logger.warning(
151	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
152	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion_inpaint.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	
47	EXAMPLE_DOC_STRING = """
48	    Examples:
49	        ```py
50	        >>> import jax
51	        >>> import numpy as np
52	        >>> from flax.jax_utils import replicate
53	        >>> from flax.training.common_utils import shard
54	        >>> import PIL
55	        >>> import requests
56	        >>> from io import BytesIO
57	        >>> from diffusers import FlaxStableDiffusionInpaintPipeline
58	
59	
60	        >>> def download_image(url):
61	        ...     response = requests.get(url)
62	        ...     return PIL.Image.open(BytesIO(response.content)).convert("RGB")
63	
64	
65	        >>> img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
66	        >>> mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
67	
68	        >>> init_image = download_image(img_url).resize((512, 512))
69	        >>> mask_image = download_image(mask_url).resize((512, 512))
70	
71	        >>> pipeline, params = FlaxStableDiffusionInpaintPipeline.from_pretrained(
72	        ...     "xvjiarui/stable-diffusion-2-inpainting"
73	        ... )
74	
75	        >>> prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
76	        >>> prng_seed = jax.random.PRNGKey(0)
77	        >>> num_inference_steps = 50
78	
79	        >>> num_samples = jax.device_count()
80	        >>> prompt = num_samples * [prompt]
81	        >>> init_image = num_samples * [init_image]
82	        >>> mask_image = num_samples * [mask_image]
83	        >>> prompt_ids, processed_masked_images, processed_masks = pipeline.prepare_inputs(
84	        ...     prompt, init_image, mask_image
85	        ... )
86	        # shard inputs and rng
87	
88	        >>> params = replicate(params)
89	        >>> prng_seed = jax.random.split(prng_seed, jax.device_count())
90	        >>> prompt_ids = shard(prompt_ids)
91	        >>> processed_masked_images = shard(processed_masked_images)
92	        >>> processed_masks = shard(processed_masks)
93	
94	        >>> images = pipeline(
95	        ...     prompt_ids, processed_masks, processed_masked_images, params, prng_seed, num_inference_steps, jit=True
96	        ... ).images
97	        >>> images = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))
98	        ```
99	"""
100	
101	
102	class FlaxStableDiffusionInpaintPipeline(FlaxDiffusionPipeline):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_flax_stable_diffusion_inpaint.py:154
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
153	            logger.warning(
154	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
155	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_onnx_stable_diffusion.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
88	            logger.warning(
89	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
90	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_onnx_stable_diffusion_img2img.py:142
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
141	            logger.warning(
142	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
143	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_onnx_stable_diffusion_inpaint.py:141
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
140	            logger.warning(
141	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
142	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_onnx_stable_diffusion_upscale.py:115
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
114	            logger.warning(
115	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
116	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:243
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
242	            logger.warning(
243	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
244	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_image_variation.py:93
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
92	            logger.warning(
93	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
94	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	EXAMPLE_DOC_STRING = """
58	    Examples:
59	        ```py
60	        >>> import requests
61	        >>> import torch
62	        >>> from PIL import Image
63	        >>> from io import BytesIO
64	
65	        >>> from diffusers import StableDiffusionImg2ImgPipeline
66	
67	        >>> device = "cuda"
68	        >>> model_id_or_path = "stable-diffusion-v1-5/stable-diffusion-v1-5"
69	        >>> pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)
70	        >>> pipe = pipe.to(device)
71	
72	        >>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
73	
74	        >>> response = requests.get(url)
75	        >>> init_image = Image.open(BytesIO(response.content)).convert("RGB")
76	        >>> init_image = init_image.resize((768, 512))
77	
78	        >>> prompt = "A fantasy landscape, trending on artstation"
79	
80	        >>> images = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images
81	        >>> images[0].save("fantasy_landscape.png")
82	        ```
83	"""
84	
85	
86	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py:271
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
270	            logger.warning(
271	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
272	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py:218
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
217	            logger.warning(
218	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
219	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py:144
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
143	            logger.warning(
144	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
145	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion/pipeline_stable_unclip_img2img.py:52
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
51	
52	EXAMPLE_DOC_STRING = """
53	    Examples:
54	        ```py
55	        >>> import requests
56	        >>> import torch
57	        >>> from PIL import Image
58	        >>> from io import BytesIO
59	
60	        >>> from diffusers import StableUnCLIPImg2ImgPipeline
61	
62	        >>> pipe = StableUnCLIPImg2ImgPipeline.from_pretrained(
63	        ...     "stabilityai/stable-diffusion-2-1-unclip-small", torch_dtype=torch.float16
64	        ... )
65	        >>> pipe = pipe.to("cuda")
66	
67	        >>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
68	
69	        >>> response = requests.get(url)
70	        >>> init_image = Image.open(BytesIO(response.content)).convert("RGB")
71	        >>> init_image = init_image.resize((768, 512))
72	
73	        >>> prompt = "A fantasy landscape, trending on artstation"
74	
75	        >>> images = pipe(init_image, prompt).images
76	        >>> images[0].save("fantasy_landscape.png")
77	        ```
78	"""
79	
80	
81	class StableUnCLIPImg2ImgPipeline(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_3/pipeline_stable_diffusion_3_img2img.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	EXAMPLE_DOC_STRING = """
58	    Examples:
59	        ```py
60	        >>> import torch
61	
62	        >>> from diffusers import AutoPipelineForImage2Image
63	        >>> from diffusers.utils import load_image
64	
65	        >>> device = "cuda"
66	        >>> model_id_or_path = "stabilityai/stable-diffusion-3-medium-diffusers"
67	        >>> pipe = AutoPipelineForImage2Image.from_pretrained(model_id_or_path, torch_dtype=torch.float16)
68	        >>> pipe = pipe.to(device)
69	
70	        >>> url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"
71	        >>> init_image = load_image(url).resize((1024, 1024))
72	
73	        >>> prompt = "cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k"
74	
75	        >>> images = pipe(prompt=prompt, image=init_image, strength=0.95, guidance_scale=7.5).images[0]
76	        ```
77	"""
78	
79	
80	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
81	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_3/pipeline_stable_diffusion_3_inpaint.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
56	
57	EXAMPLE_DOC_STRING = """
58	    Examples:
59	        ```py
60	        >>> import torch
61	        >>> from diffusers import StableDiffusion3InpaintPipeline
62	        >>> from diffusers.utils import load_image
63	
64	        >>> pipe = StableDiffusion3InpaintPipeline.from_pretrained(
65	        ...     "stabilityai/stable-diffusion-3-medium-diffusers", torch_dtype=torch.float16
66	        ... )
67	        >>> pipe.to("cuda")
68	        >>> prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
69	        >>> img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
70	        >>> mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
71	        >>> source = load_image(img_url)
72	        >>> mask = load_image(mask_url)
73	        >>> image = pipe(prompt=prompt, image=source, mask_image=mask).images[0]
74	        >>> image.save("sd3_inpainting.png")
75	        ```
76	"""
77	
78	
79	# Copied from diffusers.pipelines.flux.pipeline_flux.calculate_shift
80	def calculate_shift(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_attend_and_excite/pipeline_stable_diffusion_attend_and_excite.py:231
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
230	            logger.warning(
231	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
232	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
75	
76	EXAMPLE_DOC_STRING = """
77	
78	        ```py
79	        >>> import PIL
80	        >>> import requests
81	        >>> import torch
82	        >>> from io import BytesIO
83	
84	        >>> from diffusers import StableDiffusionDiffEditPipeline
85	
86	
87	        >>> def download_image(url):
88	        ...     response = requests.get(url)
89	        ...     return PIL.Image.open(BytesIO(response.content)).convert("RGB")
90	
91	
92	        >>> img_url = "https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png"
93	
94	        >>> init_image = download_image(img_url).resize((768, 768))
95	
96	        >>> pipeline = StableDiffusionDiffEditPipeline.from_pretrained(
97	        ...     "stabilityai/stable-diffusion-2-1", torch_dtype=torch.float16
98	        ... )
99	
100	        >>> pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)
101	        >>> pipeline.inverse_scheduler = DDIMInverseScheduler.from_config(pipeline.scheduler.config)
102	        >>> pipeline.enable_model_cpu_offload()
103	
104	        >>> mask_prompt = "A bowl of fruits"
105	        >>> prompt = "A bowl of pears"
106	
107	        >>> mask_image = pipeline.generate_mask(image=init_image, source_prompt=prompt, target_prompt=mask_prompt)
108	        >>> image_latents = pipeline.invert(image=init_image, prompt=mask_prompt).latents
109	        >>> image = pipeline(prompt=prompt, mask_image=mask_image, image_latents=image_latents).images[0]
110	        ```
111	"""
112	
113	EXAMPLE_INVERT_DOC_STRING = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py:113
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
112	
113	EXAMPLE_INVERT_DOC_STRING = """
114	        ```py
115	        >>> import PIL
116	        >>> import requests
117	        >>> import torch
118	        >>> from io import BytesIO
119	
120	        >>> from diffusers import StableDiffusionDiffEditPipeline
121	
122	
123	        >>> def download_image(url):
124	        ...     response = requests.get(url)
125	        ...     return PIL.Image.open(BytesIO(response.content)).convert("RGB")
126	
127	
128	        >>> img_url = "https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png"
129	
130	        >>> init_image = download_image(img_url).resize((768, 768))
131	
132	        >>> pipeline = StableDiffusionDiffEditPipeline.from_pretrained(
133	        ...     "stabilityai/stable-diffusion-2-1", torch_dtype=torch.float16
134	        ... )
135	
136	        >>> pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)
137	        >>> pipeline.inverse_scheduler = DDIMInverseScheduler.from_config(pipeline.scheduler.config)
138	        >>> pipeline.enable_model_cpu_offload()
139	
140	        >>> prompt = "A bowl of fruits"
141	
142	        >>> inverted_latents = pipeline.invert(image=init_image, prompt=prompt).latents
143	        ```
144	"""
145	
146	
147	def auto_corr_loss(hidden_states, generator=None):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_diffedit/pipeline_stable_diffusion_diffedit.py:333
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
332	            logger.warning(
333	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
334	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py:54
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
53	
54	EXAMPLE_DOC_STRING = """
55	    Examples:
56	        ```py
57	        >>> import torch
58	        >>> from diffusers import StableDiffusionGLIGENPipeline
59	        >>> from diffusers.utils import load_image
60	
61	        >>> # Insert objects described by text at the region defined by bounding boxes
62	        >>> pipe = StableDiffusionGLIGENPipeline.from_pretrained(
63	        ...     "masterful/gligen-1-4-inpainting-text-box", variant="fp16", torch_dtype=torch.float16
64	        ... )
65	        >>> pipe = pipe.to("cuda")
66	
67	        >>> input_image = load_image(
68	        ...     "https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/livingroom_modern.png"
69	        ... )
70	        >>> prompt = "a birthday cake"
71	        >>> boxes = [[0.2676, 0.6088, 0.4773, 0.7183]]
72	        >>> phrases = ["a birthday cake"]
73	
74	        >>> images = pipe(
75	        ...     prompt=prompt,
76	        ...     gligen_phrases=phrases,
77	        ...     gligen_inpaint_image=input_image,
78	        ...     gligen_boxes=boxes,
79	        ...     gligen_scheduled_sampling_beta=1,
80	        ...     output_type="pil",
81	        ...     num_inference_steps=50,
82	        ... ).images
83	
84	        >>> images[0].save("./gligen-1-4-inpainting-text-box.jpg")
85	
86	        >>> # Generate an image described by the prompt and
87	        >>> # insert objects described by text at the region defined by bounding boxes
88	        >>> pipe = StableDiffusionGLIGENPipeline.from_pretrained(
89	        ...     "masterful/gligen-1-4-generation-text-box", variant="fp16", torch_dtype=torch.float16
90	        ... )
91	        >>> pipe = pipe.to("cuda")
92	
93	        >>> prompt = "a waterfall and a modern high speed train running through the tunnel in a beautiful forest with fall foliage"
94	        >>> boxes = [[0.1387, 0.2051, 0.4277, 0.7090], [0.4980, 0.4355, 0.8516, 0.7266]]
95	        >>> phrases = ["a waterfall", "a modern high speed train running through the tunnel"]
96	
97	        >>> images = pipe(
98	        ...     prompt=prompt,
99	        ...     gligen_phrases=phrases,
100	        ...     gligen_boxes=boxes,
101	        ...     gligen_scheduled_sampling_beta=1,
102	        ...     output_type="pil",
103	        ...     num_inference_steps=50,
104	        ... ).images
105	
106	        >>> images[0].save("./gligen-1-4-generation-text-box.jpg")
107	        ```
108	"""
109	
110	
111	class StableDiffusionGLIGENPipeline(DiffusionPipeline, StableDiffusionMixin):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen.py:157
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
156	            logger.warning(
157	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
158	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
59	
60	EXAMPLE_DOC_STRING = """
61	    Examples:
62	        ```py
63	        >>> import torch
64	        >>> from diffusers import StableDiffusionGLIGENTextImagePipeline
65	        >>> from diffusers.utils import load_image
66	
67	        >>> # Insert objects described by image at the region defined by bounding boxes
68	        >>> pipe = StableDiffusionGLIGENTextImagePipeline.from_pretrained(
69	        ...     "anhnct/Gligen_Inpainting_Text_Image", torch_dtype=torch.float16
70	        ... )
71	        >>> pipe = pipe.to("cuda")
72	
73	        >>> input_image = load_image(
74	        ...     "https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/livingroom_modern.png"
75	        ... )
76	        >>> prompt = "a backpack"
77	        >>> boxes = [[0.2676, 0.4088, 0.4773, 0.7183]]
78	        >>> phrases = None
79	        >>> gligen_image = load_image(
80	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/backpack.jpeg"
81	        ... )
82	
83	        >>> images = pipe(
84	        ...     prompt=prompt,
85	        ...     gligen_phrases=phrases,
86	        ...     gligen_inpaint_image=input_image,
87	        ...     gligen_boxes=boxes,
88	        ...     gligen_images=[gligen_image],
89	        ...     gligen_scheduled_sampling_beta=1,
90	        ...     output_type="pil",
91	        ...     num_inference_steps=50,
92	        ... ).images
93	
94	        >>> images[0].save("./gligen-inpainting-text-image-box.jpg")
95	
96	        >>> # Generate an image described by the prompt and
97	        >>> # insert objects described by text and image at the region defined by bounding boxes
98	        >>> pipe = StableDiffusionGLIGENTextImagePipeline.from_pretrained(
99	        ...     "anhnct/Gligen_Text_Image", torch_dtype=torch.float16
100	        ... )
101	        >>> pipe = pipe.to("cuda")
102	
103	        >>> prompt = "a flower sitting on the beach"
104	        >>> boxes = [[0.0, 0.09, 0.53, 0.76]]
105	        >>> phrases = ["flower"]
106	        >>> gligen_image = load_image(
107	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/pexels-pixabay-60597.jpg"
108	        ... )
109	
110	        >>> images = pipe(
111	        ...     prompt=prompt,
112	        ...     gligen_phrases=phrases,
113	        ...     gligen_images=[gligen_image],
114	        ...     gligen_boxes=boxes,
115	        ...     gligen_scheduled_sampling_beta=1,
116	        ...     output_type="pil",
117	        ...     num_inference_steps=50,
118	        ... ).images
119	
120	        >>> images[0].save("./gligen-generation-text-image-box.jpg")
121	
122	        >>> # Generate an image described by the prompt and
123	        >>> # transfer style described by image at the region defined by bounding boxes
124	        >>> pipe = StableDiffusionGLIGENTextImagePipeline.from_pretrained(
125	        ...     "anhnct/Gligen_Text_Image", torch_dtype=torch.float16
126	        ... )
127	        >>> pipe = pipe.to("cuda")
128	
129	        >>> prompt = "a dragon flying on the sky"
130	        >>> boxes = [[0.4, 0.2, 1.0, 0.8], [0.0, 1.0, 0.0, 1.0]]  # Set `[0.0, 1.0, 0.0, 1.0]` for the style
131	
132	        >>> gligen_image = load_image(
133	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/landscape.png"
134	        ... )
135	
136	        >>> gligen_placeholder = load_image(
137	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/landscape.png"
138	        ... )
139	
140	        >>> images = pipe(
141	        ...     prompt=prompt,
142	        ...     gligen_phrases=[
143	        ...         "dragon",
144	        ...         "placeholder",
145	        ...     ],  # Can use any text instead of `placeholder` token, because we will use mask here
146	        ...     gligen_images=[
147	        ...         gligen_placeholder,
148	        ...         gligen_image,
149	        ...     ],  # Can use any image in gligen_placeholder, because we will use mask here
150	        ...     input_phrases_mask=[1, 0],  # Set 0 for the placeholder token
151	        ...     input_images_mask=[0, 1],  # Set 0 for the placeholder image
152	        ...     gligen_boxes=boxes,
153	        ...     gligen_scheduled_sampling_beta=1,
154	        ...     output_type="pil",
155	        ...     num_inference_steps=50,
156	        ... ).images
157	
158	        >>> images[0].save("./gligen-generation-text-image-box-style-transfer.jpg")
159	        ```
160	"""
161	
162	
163	class StableDiffusionGLIGENTextImagePipeline(DiffusionPipeline, StableDiffusionMixin):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_gligen/pipeline_stable_diffusion_gligen_text_image.py:218
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
217	            logger.warning(
218	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
219	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_k_diffusion/pipeline_stable_diffusion_k_diffusion.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
125	        logger.info(
126	            f"{self.__class__} is an experimntal pipeline and is likely to change in the future. We recommend to use"
127	            " this pipeline for fast experimentation / iteration if needed, but advice to rely on existing pipelines"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_ldm3d/pipeline_stable_diffusion_ldm3d.py:242
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
241	            logger.warning(
242	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
243	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_panorama/pipeline_stable_diffusion_panorama.py:218
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
217	            logger.warning(
218	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
219	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_safe/pipeline_stable_diffusion_safe.py:113
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
112	            logger.warning(
113	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
114	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
70	
71	EXAMPLE_DOC_STRING = """
72	    Examples:
73	        ```py
74	        >>> import torch
75	        >>> from diffusers import StableDiffusionXLImg2ImgPipeline
76	        >>> from diffusers.utils import load_image
77	
78	        >>> pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(
79	        ...     "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16
80	        ... )
81	        >>> pipe = pipe.to("cuda")
82	        >>> url = "https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png"
83	
84	        >>> init_image = load_image(url).convert("RGB")
85	        >>> prompt = "a photo of an astronaut riding a horse on mars"
86	        >>> image = pipe(prompt, image=init_image).images[0]
87	        ```
88	"""
89	
90	
91	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.rescale_noise_cfg
92	def rescale_noise_cfg(noise_cfg, noise_pred_text, guidance_rescale=0.0):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
72	
73	EXAMPLE_DOC_STRING = """
74	    Examples:
75	        ```py
76	        >>> import torch
77	        >>> from diffusers import StableDiffusionXLInpaintPipeline
78	        >>> from diffusers.utils import load_image
79	
80	        >>> pipe = StableDiffusionXLInpaintPipeline.from_pretrained(
81	        ...     "stabilityai/stable-diffusion-xl-base-1.0",
82	        ...     torch_dtype=torch.float16,
83	        ...     variant="fp16",
84	        ...     use_safetensors=True,
85	        ... )
86	        >>> pipe.to("cuda")
87	
88	        >>> img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
89	        >>> mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
90	
91	        >>> init_image = load_image(img_url).convert("RGB")
92	        >>> mask_image = load_image(mask_url).convert("RGB")
93	
94	        >>> prompt = "A majestic tiger sitting on a bench"
95	        >>> image = pipe(
96	        ...     prompt=prompt, image=init_image, mask_image=mask_image, num_inference_steps=50, strength=0.80
97	        ... ).images[0]
98	        ```
99	"""
100	
101	
102	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.rescale_noise_cfg
103	def rescale_noise_cfg(noise_cfg, noise_pred_text, guidance_rescale=0.0):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_instruct_pix2pix.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
58	
59	EXAMPLE_DOC_STRING = """
60	    Examples:
61	        ```py
62	        >>> import torch
63	        >>> from diffusers import StableDiffusionXLInstructPix2PixPipeline
64	        >>> from diffusers.utils import load_image
65	
66	        >>> resolution = 768
67	        >>> image = load_image(
68	        ...     "https://hf.co/datasets/diffusers/diffusers-images-docs/resolve/main/mountain.png"
69	        ... ).resize((resolution, resolution))
70	        >>> edit_instruction = "Turn sky into a cloudy one"
71	
72	        >>> pipe = StableDiffusionXLInstructPix2PixPipeline.from_pretrained(
73	        ...     "diffusers/sdxl-instructpix2pix-768", torch_dtype=torch.float16
74	        ... ).to("cuda")
75	
76	        >>> edited_image = pipe(
77	        ...     prompt=edit_instruction,
78	        ...     image=image,
79	        ...     height=resolution,
80	        ...     width=resolution,
81	        ...     guidance_scale=3.0,
82	        ...     image_guidance_scale=1.5,
83	        ...     num_inference_steps=30,
84	        ... ).images[0]
85	        >>> edited_image
86	        ```
87	"""
88	
89	
90	# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.retrieve_latents
91	def retrieve_latents(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/stable_video_diffusion/pipeline_stable_video_diffusion.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	
43	EXAMPLE_DOC_STRING = """
44	    Examples:
45	        ```py
46	        >>> from diffusers import StableVideoDiffusionPipeline
47	        >>> from diffusers.utils import load_image, export_to_video
48	
49	        >>> pipe = StableVideoDiffusionPipeline.from_pretrained(
50	        ...     "stabilityai/stable-video-diffusion-img2vid-xt", torch_dtype=torch.float16, variant="fp16"
51	        ... )
52	        >>> pipe.to("cuda")
53	
54	        >>> image = load_image(
55	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/svd-docstring-example.jpeg"
56	        ... )
57	        >>> image = image.resize((1024, 576))
58	
59	        >>> frames = pipe(image, num_frames=25, decode_chunk_size=8).frames[0]
60	        >>> export_to_video(frames, "generated.mp4", fps=7)
61	        ```
62	"""
63	
64	
65	def _append_dims(x, target_dims):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/t2i_adapter/pipeline_stable_diffusion_adapter.py:72
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
71	
72	EXAMPLE_DOC_STRING = """
73	    Examples:
74	        ```py
75	        >>> from PIL import Image
76	        >>> from diffusers.utils import load_image
77	        >>> import torch
78	        >>> from diffusers import StableDiffusionAdapterPipeline, T2IAdapter
79	
80	        >>> image = load_image(
81	        ...     "https://huggingface.co/datasets/diffusers/docs-images/resolve/main/t2i-adapter/color_ref.png"
82	        ... )
83	
84	        >>> color_palette = image.resize((8, 8))
85	        >>> color_palette = color_palette.resize((512, 512), resample=Image.Resampling.NEAREST)
86	
87	        >>> adapter = T2IAdapter.from_pretrained("TencentARC/t2iadapter_color_sd14v1", torch_dtype=torch.float16)
88	        >>> pipe = StableDiffusionAdapterPipeline.from_pretrained(
89	        ...     "CompVis/stable-diffusion-v1-4",
90	        ...     adapter=adapter,
91	        ...     torch_dtype=torch.float16,
92	        ... )
93	
94	        >>> pipe.to("cuda")
95	
96	        >>> out_image = pipe(
97	        ...     "At night, glowing cubes in front of the beach",
98	        ...     image=color_palette,
99	        ... ).images[0]
100	        ```
101	"""
102	
103	
104	def _preprocess_adapter_image(image, height, width):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/t2i_adapter/pipeline_stable_diffusion_adapter.py:246
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
245	            logger.warning(
246	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
247	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/t2i_adapter/pipeline_stable_diffusion_xl_adapter.py:67
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
66	
67	EXAMPLE_DOC_STRING = """
68	    Examples:
69	        ```py
70	        >>> import torch
71	        >>> from diffusers import T2IAdapter, StableDiffusionXLAdapterPipeline, DDPMScheduler
72	        >>> from diffusers.utils import load_image
73	
74	        >>> sketch_image = load_image("https://huggingface.co/Adapter/t2iadapter/resolve/main/sketch.png").convert("L")
75	
76	        >>> model_id = "stabilityai/stable-diffusion-xl-base-1.0"
77	
78	        >>> adapter = T2IAdapter.from_pretrained(
79	        ...     "Adapter/t2iadapter",
80	        ...     subfolder="sketch_sdxl_1.0",
81	        ...     torch_dtype=torch.float16,
82	        ...     adapter_type="full_adapter_xl",
83	        ... )
84	        >>> scheduler = DDPMScheduler.from_pretrained(model_id, subfolder="scheduler")
85	
86	        >>> pipe = StableDiffusionXLAdapterPipeline.from_pretrained(
87	        ...     model_id, adapter=adapter, torch_dtype=torch.float16, variant="fp16", scheduler=scheduler
88	        ... ).to("cuda")
89	
90	        >>> generator = torch.manual_seed(42)
91	        >>> sketch_image_out = pipe(
92	        ...     prompt="a photo of a dog in real world, high quality",
93	        ...     negative_prompt="extra digit, fewer digits, cropped, worst quality, low quality",
94	        ...     image=sketch_image,
95	        ...     generator=generator,
96	        ...     guidance_scale=7.5,
97	        ... ).images[0]
98	        ```
99	"""
100	
101	
102	def _preprocess_adapter_image(image, height, width):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/text_to_video_synthesis/pipeline_text_to_video_zero.py:354
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
353	            logger.warning(
354	                f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
355	                " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/transformers_loading_utils.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
54	                    with entry.as_mmap() as mm:
55	                        f.write(mm)
56	        return cls.from_pretrained(os.path.dirname(tmp_entry_path), **kwargs)

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/transformers_loading_utils.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
54	                    with entry.as_mmap() as mm:
55	                        f.write(mm)
56	        return cls.from_pretrained(os.path.dirname(tmp_entry_path), **kwargs)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/transformers_loading_utils.py:99
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
98	        with open(tmp_config_file, "w") as f:
99	            f.write(config_file.read_text())
100	        config = AutoConfig.from_pretrained(tmp_config_file)

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/transformers_loading_utils.py:99
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
98	        with open(tmp_config_file, "w") as f:
99	            f.write(config_file.read_text())
100	        config = AutoConfig.from_pretrained(tmp_config_file)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/transformers_loading_utils.py:104
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
103	            with open(tmp_generation_config_file, "w") as f:
104	                f.write(generation_config.read_text())
105	            generation_config = GenerationConfig.from_pretrained(tmp_generation_config_file)

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/transformers_loading_utils.py:104
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
103	            with open(tmp_generation_config_file, "w") as f:
104	                f.write(generation_config.read_text())
105	            generation_config = GenerationConfig.from_pretrained(tmp_generation_config_file)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/wan/pipeline_wan_i2v.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
46	
47	EXAMPLE_DOC_STRING = """
48	    Examples:
49	        ```python
50	        >>> import torch
51	        >>> import numpy as np
52	        >>> from diffusers import AutoencoderKLWan, WanImageToVideoPipeline
53	        >>> from diffusers.utils import export_to_video, load_image
54	        >>> from transformers import CLIPVisionModel
55	
56	        >>> # Available models: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers, Wan-AI/Wan2.1-I2V-14B-720P-Diffusers
57	        >>> model_id = "Wan-AI/Wan2.1-I2V-14B-480P-Diffusers"
58	        >>> image_encoder = CLIPVisionModel.from_pretrained(
59	        ...     model_id, subfolder="image_encoder", torch_dtype=torch.float32
60	        ... )
61	        >>> vae = AutoencoderKLWan.from_pretrained(model_id, subfolder="vae", torch_dtype=torch.float32)
62	        >>> pipe = WanImageToVideoPipeline.from_pretrained(
63	        ...     model_id, vae=vae, image_encoder=image_encoder, torch_dtype=torch.bfloat16
64	        ... )
65	        >>> pipe.to("cuda")
66	
67	        >>> image = load_image(
68	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/astronaut.jpg"
69	        ... )
70	        >>> max_area = 480 * 832
71	        >>> aspect_ratio = image.height / image.width
72	        >>> mod_value = pipe.vae_scale_factor_spatial * pipe.transformer.config.patch_size[1]
73	        >>> height = round(np.sqrt(max_area * aspect_ratio)) // mod_value * mod_value
74	        >>> width = round(np.sqrt(max_area / aspect_ratio)) // mod_value * mod_value
75	        >>> image = image.resize((width, height))
76	        >>> prompt = (
77	        ...     "An astronaut hatching from an egg, on the surface of the moon, the darkness and depth of space realised in "
78	        ...     "the background. High quality, ultrarealistic detail and breath-taking movie-like camera shot."
79	        ... )
80	        >>> negative_prompt = "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
81	
82	        >>> output = pipe(
83	        ...     image=image,
84	        ...     prompt=prompt,
85	        ...     negative_prompt=negative_prompt,
86	        ...     height=height,
87	        ...     width=width,
88	        ...     num_frames=81,
89	        ...     guidance_scale=5.0,
90	        ... ).frames[0]
91	        >>> export_to_video(output, "output.mp4", fps=16)
92	        ```
93	"""
94	
95	
96	def basic_clean(text):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/pipelines/wan/pipeline_wan_video2video.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
47	
48	EXAMPLE_DOC_STRING = """
49	    Examples:
50	        ```python
51	        >>> import torch
52	        >>> from diffusers.utils import export_to_video
53	        >>> from diffusers import AutoencoderKLWan, WanVideoToVideoPipeline
54	        >>> from diffusers.schedulers.scheduling_unipc_multistep import UniPCMultistepScheduler
55	
56	        >>> # Available models: Wan-AI/Wan2.1-T2V-14B-Diffusers, Wan-AI/Wan2.1-T2V-1.3B-Diffusers
57	        >>> model_id = "Wan-AI/Wan2.1-T2V-1.3B-Diffusers"
58	        >>> vae = AutoencoderKLWan.from_pretrained(model_id, subfolder="vae", torch_dtype=torch.float32)
59	        >>> pipe = WanVideoToVideoPipeline.from_pretrained(model_id, vae=vae, torch_dtype=torch.bfloat16)
60	        >>> flow_shift = 3.0  # 5.0 for 720P, 3.0 for 480P
61	        >>> pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config, flow_shift=flow_shift)
62	        >>> pipe.to("cuda")
63	
64	        >>> prompt = "A robot standing on a mountain top. The sun is setting in the background"
65	        >>> negative_prompt = "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
66	        >>> video = load_video(
67	        ...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/hiker.mp4"
68	        ... )
69	        >>> output = pipe(
70	        ...     video=video,
71	        ...     prompt=prompt,
72	        ...     negative_prompt=negative_prompt,
73	        ...     height=480,
74	        ...     width=720,
75	        ...     guidance_scale=5.0,
76	        ...     strength=0.7,
77	        ... ).frames[0]
78	        >>> export_to_video(output, "output.mp4", fps=16)
79	        ```
80	"""
81	
82	
83	def basic_clean(text):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/quantizers/bitsandbytes/bnb_quantizer.py:92
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
91	                raise ValueError(
92	                    "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the "
93	                    "quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules "
94	                    "in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/quantizers/bitsandbytes/bnb_quantizer.py:381
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
380	                raise ValueError(
381	                    "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the "
382	                    "quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules "
383	                    "in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to "

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/quantizers/quantization_config.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
117	
118	            writer.write(json_string)
119	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/quantizers/quantization_config.py:503
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
502	            raise ValueError(
503	                f"Requested quantization type: {self.quant_type} is not supported or is an incorrect `quant_type` name. If you think the "
504	                f"provided quantization type should be supported, please open an issue at https://github.com/huggingface/diffusers/issues."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/quantizers/quanto/utils.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	        logger.warning(
50	            f"{model.__class__.__name__} does not appear to have any `nn.Linear` modules. Quantization will not be applied."
51	            " Please check your model architecture, or submit an issue on Github if you think this is a bug."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/quantizers/torchao/torchao_quantizer.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
224	        raise ValueError(
225	            f"You have set `device_map` as one of {possible_device_maps} on a TorchAO quantized model but a suitable target dtype "
226	            f"could not be inferred. The supported target_dtypes are: {SUPPORTED_TORCH_DTYPES_FOR_QUANTIZATION}. If you think the "
227	            f"dtype you are using should be supported, please open an issue at https://github.com/huggingface/diffusers/issues."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/schedulers/scheduling_pndm.py:353
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
352	            raise ValueError(
353	                f"{self.__class__} can only be run AFTER scheduler has been run "
354	                "in 'prk' mode for at least 12 iterations "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/__init__.py:142
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
141	            error_message = (
142	                "This example requires a source install from HuggingFace diffusers (see "
143	                "`https://huggingface.co/docs/diffusers/installation#install-from-source`),"
144	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/constants.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	ONNX_EXTERNAL_WEIGHTS_NAME = "weights.pb"
39	HUGGINGFACE_CO_RESOLVE_ENDPOINT = os.environ.get("HF_ENDPOINT", "https://huggingface.co")
40	DIFFUSERS_DYNAMIC_MODULE_NAME = "diffusers_modules"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/constants.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
61	
62	DECODE_ENDPOINT_SD_V1 = "https://q1bj3bpq6kzilnsu.us-east-1.aws.endpoints.huggingface.cloud/"
63	DECODE_ENDPOINT_SD_XL = "https://x2dmsqunjd6k9prw.us-east-1.aws.endpoints.huggingface.cloud/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/constants.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
62	DECODE_ENDPOINT_SD_V1 = "https://q1bj3bpq6kzilnsu.us-east-1.aws.endpoints.huggingface.cloud/"
63	DECODE_ENDPOINT_SD_XL = "https://x2dmsqunjd6k9prw.us-east-1.aws.endpoints.huggingface.cloud/"
64	DECODE_ENDPOINT_FLUX = "https://whhx50ex1aryqvw6.us-east-1.aws.endpoints.huggingface.cloud/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/constants.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
63	DECODE_ENDPOINT_SD_XL = "https://x2dmsqunjd6k9prw.us-east-1.aws.endpoints.huggingface.cloud/"
64	DECODE_ENDPOINT_FLUX = "https://whhx50ex1aryqvw6.us-east-1.aws.endpoints.huggingface.cloud/"
65	DECODE_ENDPOINT_HUNYUAN_VIDEO = "https://o7ywnmrahorts457.us-east-1.aws.endpoints.huggingface.cloud/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/constants.py:65
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
64	DECODE_ENDPOINT_FLUX = "https://whhx50ex1aryqvw6.us-east-1.aws.endpoints.huggingface.cloud/"
65	DECODE_ENDPOINT_HUNYUAN_VIDEO = "https://o7ywnmrahorts457.us-east-1.aws.endpoints.huggingface.cloud/"
66	
67	
68	ENCODE_ENDPOINT_SD_V1 = "https://qc6479g0aac6qwy9.us-east-1.aws.endpoints.huggingface.cloud/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/constants.py:68
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
67	
68	ENCODE_ENDPOINT_SD_V1 = "https://qc6479g0aac6qwy9.us-east-1.aws.endpoints.huggingface.cloud/"
69	ENCODE_ENDPOINT_SD_XL = "https://xjqqhmyn62rog84g.us-east-1.aws.endpoints.huggingface.cloud/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/constants.py:69
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
68	ENCODE_ENDPOINT_SD_V1 = "https://qc6479g0aac6qwy9.us-east-1.aws.endpoints.huggingface.cloud/"
69	ENCODE_ENDPOINT_SD_XL = "https://xjqqhmyn62rog84g.us-east-1.aws.endpoints.huggingface.cloud/"
70	ENCODE_ENDPOINT_FLUX = "https://ptccx55jz97f9zgo.us-east-1.aws.endpoints.huggingface.cloud/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/constants.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
69	ENCODE_ENDPOINT_SD_XL = "https://xjqqhmyn62rog84g.us-east-1.aws.endpoints.huggingface.cloud/"
70	ENCODE_ENDPOINT_FLUX = "https://ptccx55jz97f9zgo.us-east-1.aws.endpoints.huggingface.cloud/"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/dynamic_modules_utils.py:43
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
42	def get_diffusers_versions():
43	    url = "https://pypi.org/pypi/diffusers/json"
44	    releases = json.loads(request.urlopen(url).read())["releases"].keys()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/dynamic_modules_utils.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
43	    url = "https://pypi.org/pypi/diffusers/json"
44	    releases = json.loads(request.urlopen(url).read())["releases"].keys()
45	    return sorted(releases, key=lambda x: version.Version(x))

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/dynamic_modules_utils.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
43	    url = "https://pypi.org/pypi/diffusers/json"
44	    releases = json.loads(request.urlopen(url).read())["releases"].keys()
45	    return sorted(releases, key=lambda x: version.Version(x))

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/dynamic_modules_utils.py:86
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
85	    with open(module_file, "r", encoding="utf-8") as f:
86	        content = f.read()
87	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/dynamic_modules_utils.py:130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
129	    with open(filename, "r", encoding="utf-8") as f:
130	        content = f.read()
131	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/dynamic_modules_utils.py:293
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
292	            raise EnvironmentError(
293	                f"Revision '{revision}' not found in the community pipelines mirror. Check available revisions on"
294	                " https://huggingface.co/datasets/diffusers/community-pipelines-mirror/tree/main."

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
54	    with buffered_writer(open(output_ply_path, "wb")) as f:
55	        f.write(b"ply\n")
56	        f.write(b"format binary_little_endian 1.0\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
55	        f.write(b"ply\n")
56	        f.write(b"format binary_little_endian 1.0\n")
57	        f.write(bytes(f"element vertex {len(coords)}\n", "ascii"))

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
56	        f.write(b"format binary_little_endian 1.0\n")
57	        f.write(bytes(f"element vertex {len(coords)}\n", "ascii"))
58	        f.write(b"property float x\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
57	        f.write(bytes(f"element vertex {len(coords)}\n", "ascii"))
58	        f.write(b"property float x\n")
59	        f.write(b"property float y\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
58	        f.write(b"property float x\n")
59	        f.write(b"property float y\n")
60	        f.write(b"property float z\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
59	        f.write(b"property float y\n")
60	        f.write(b"property float z\n")
61	        if rgb is not None:

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
61	        if rgb is not None:
62	            f.write(b"property uchar red\n")
63	            f.write(b"property uchar green\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
62	            f.write(b"property uchar red\n")
63	            f.write(b"property uchar green\n")
64	            f.write(b"property uchar blue\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
63	            f.write(b"property uchar green\n")
64	            f.write(b"property uchar blue\n")
65	        if faces is not None:

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
65	        if faces is not None:
66	            f.write(bytes(f"element face {len(faces)}\n", "ascii"))
67	            f.write(b"property list uchar int vertex_index\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:67
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
66	            f.write(bytes(f"element face {len(faces)}\n", "ascii"))
67	            f.write(b"property list uchar int vertex_index\n")
68	        f.write(b"end_header\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:68
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
67	            f.write(b"property list uchar int vertex_index\n")
68	        f.write(b"end_header\n")
69	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:81
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
80	            for item in vertices:
81	                f.write(format.pack(*item))
82	        else:

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
84	            for vertex in coords.tolist():
85	                f.write(format.pack(*vertex))
86	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
89	            for tri in faces.tolist():
90	                f.write(format.pack(len(tri), *tri))
91	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/export_utils.py:136
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
135	        img = cv2.cvtColor(video_frames[i], cv2.COLOR_RGB2BGR)
136	        video_writer.write(img)
137	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/hub_utils.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
89	    # CI will set this value to True
90	    if os.environ.get("DIFFUSERS_IS_CI", "").upper() in ENV_VARS_TRUE_VALUES:
91	        ua += "; is_ci/true"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/hub_utils.py:284
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
283	                warnings.warn(
284	                    f"You are loading the variant {revision} from {pretrained_model_name_or_path} via `revision='{revision}'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='{revision}'` instead. However, it appears that {pretrained_model_name_or_path} currently does not have a {_add_variant(weights_name, revision)} file in the 'main' branch of {pretrained_model_name_or_path}. \n The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title '{pretrained_model_name_or_path} is missing {_add_variant(weights_name, revision)}' so that the correct variant file can be added.",
285	                    FutureWarning,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/hub_utils.py:305
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
304	            raise EnvironmentError(
305	                f"{pretrained_model_name_or_path} is not a local folder and is not a valid model identifier "
306	                "listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/hub_utils.py:312
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
311	            raise EnvironmentError(
312	                f"{revision} is not a valid git identifier (branch name, tag name or commit id) that exists for "
313	                "this model name. Check the model page at "
314	                f"'https://huggingface.co/{pretrained_model_name_or_path}' for available revisions."
315	            ) from e

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/hub_utils.py:326
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
325	            raise EnvironmentError(
326	                f"We couldn't connect to '{HUGGINGFACE_CO_RESOLVE_ENDPOINT}' to load this model, couldn't find it"
327	                f" in the cached files and it looks like {pretrained_model_name_or_path} is not the path to a"
328	                f" directory containing a file named {weights_name} or"
329	                " \nCheckout your internet connection or see how to run the library in"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/hub_utils.py:334
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
333	            raise EnvironmentError(
334	                f"Can't load the model for '{pretrained_model_name_or_path}'. If you were trying to load it from "
335	                "'https://huggingface.co/models', make sure you don't have a local directory with the same name. "
336	                f"Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory "
337	                f"containing a file named {weights_name}"
338	            ) from e

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/hub_utils.py:374
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
373	        with open(index_filename, "r") as f:
374	            index = json.loads(f.read())
375	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/import_utils.py:338
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
337	# docstyle-ignore
338	FLAX_IMPORT_ERROR = """
339	{0} requires the FLAX library but it was not found in your environment. Checkout the instructions on the
340	installation page: https://github.com/google/flax and follow the ones that match your environment.
341	"""
342	
343	# docstyle-ignore
344	INFLECT_IMPORT_ERROR = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/import_utils.py:350
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
349	# docstyle-ignore
350	PYTORCH_IMPORT_ERROR = """
351	{0} requires the PyTorch library but it was not found in your environment. Checkout the instructions on the
352	installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
353	"""
354	
355	# docstyle-ignore
356	ONNX_IMPORT_ERROR = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/import_utils.py:374
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
373	# docstyle-ignore
374	LIBROSA_IMPORT_ERROR = """
375	{0} requires the librosa library but it was not found in your environment.  Checkout the instructions on the
376	installation page: https://librosa.org/doc/latest/install.html and follow the ones that match your environment.
377	"""
378	
379	# docstyle-ignore
380	TRANSFORMERS_IMPORT_ERROR = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/import_utils.py:428
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
427	# docstyle-ignore
428	FTFY_IMPORT_ERROR = """
429	{0} requires the ftfy library but it was not found in your environment. Checkout the instructions on the
430	installation section: https://github.com/rspeer/python-ftfy/tree/master#installing and follow the ones
431	that match your environment. Please note that you may need to restart your runtime after installation.
432	"""
433	
434	# docstyle-ignore
435	TORCHSDE_IMPORT_ERROR = """

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/loading_utils.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
32	        if image.startswith("http://") or image.startswith("https://"):
33	            image = PIL.Image.open(requests.get(image, stream=True, timeout=DIFFUSERS_REQUEST_TIMEOUT).raw)
34	        elif os.path.isfile(image):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/loading_utils.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
37	            raise ValueError(
38	                f"Incorrect path or URL. URLs must start with `http://` or `https://`, and {image} is not a valid path."
39	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/loading_utils.py:81
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
80	        raise ValueError(
81	            f"Incorrect path or URL. URLs must start with `http://` or `https://`, and {video} is not a valid path."
82	        )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/loading_utils.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
84	    if is_url:
85	        response = requests.get(video, stream=True)
86	        if response.status_code != 200:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/loading_utils.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
99	            for chunk in video_data:
100	                f.write(chunk)
101	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/loading_utils.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
99	            for chunk in video_data:
100	                f.write(chunk)
101	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/remote_utils.py:324
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
323	    )
324	    response = requests.post(endpoint, **kwargs)
325	    if not response.ok:

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/remote_utils.py:419
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
418	    )
419	    response = requests.post(endpoint, **kwargs)
420	    if not response.ok:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:145
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
144	
145	    test_name = os.environ.get("PYTEST_CURRENT_TEST")
146	    if not torch.is_tensor(tensor):

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:610
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
609	        elif arry.startswith("http://") or arry.startswith("https://"):
610	            response = requests.get(arry, timeout=DIFFUSERS_REQUEST_TIMEOUT)
611	            response.raise_for_status()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:617
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
616	            raise ValueError(
617	                f"Incorrect path or url, URLs must start with `http://` or `https://`, and {arry} is not a valid path"
618	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:631
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
630	def load_pt(url: str, map_location: str):
631	    response = requests.get(url, timeout=DIFFUSERS_REQUEST_TIMEOUT)
632	    response.raise_for_status()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:650
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
649	        if image.startswith("http://") or image.startswith("https://"):
650	            image = PIL.Image.open(requests.get(image, stream=True, timeout=DIFFUSERS_REQUEST_TIMEOUT).raw)
651	        elif os.path.isfile(image):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:655
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
654	            raise ValueError(
655	                f"Incorrect path or url, URLs must start with `http://` or `https://`, and {image} is not a valid path"
656	            )

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:712
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
711	    with buffered_writer(open(output_ply_path, "wb")) as f:
712	        f.write(b"ply\n")
713	        f.write(b"format binary_little_endian 1.0\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:712
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
711	    with buffered_writer(open(output_ply_path, "wb")) as f:
712	        f.write(b"ply\n")
713	        f.write(b"format binary_little_endian 1.0\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:713
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
712	        f.write(b"ply\n")
713	        f.write(b"format binary_little_endian 1.0\n")
714	        f.write(bytes(f"element vertex {len(coords)}\n", "ascii"))

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:713
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
712	        f.write(b"ply\n")
713	        f.write(b"format binary_little_endian 1.0\n")
714	        f.write(bytes(f"element vertex {len(coords)}\n", "ascii"))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:714
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
713	        f.write(b"format binary_little_endian 1.0\n")
714	        f.write(bytes(f"element vertex {len(coords)}\n", "ascii"))
715	        f.write(b"property float x\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:714
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
713	        f.write(b"format binary_little_endian 1.0\n")
714	        f.write(bytes(f"element vertex {len(coords)}\n", "ascii"))
715	        f.write(b"property float x\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:715
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
714	        f.write(bytes(f"element vertex {len(coords)}\n", "ascii"))
715	        f.write(b"property float x\n")
716	        f.write(b"property float y\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:715
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
714	        f.write(bytes(f"element vertex {len(coords)}\n", "ascii"))
715	        f.write(b"property float x\n")
716	        f.write(b"property float y\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:716
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
715	        f.write(b"property float x\n")
716	        f.write(b"property float y\n")
717	        f.write(b"property float z\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:716
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
715	        f.write(b"property float x\n")
716	        f.write(b"property float y\n")
717	        f.write(b"property float z\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:717
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
716	        f.write(b"property float y\n")
717	        f.write(b"property float z\n")
718	        if rgb is not None:

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:717
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
716	        f.write(b"property float y\n")
717	        f.write(b"property float z\n")
718	        if rgb is not None:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:719
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
718	        if rgb is not None:
719	            f.write(b"property uchar red\n")
720	            f.write(b"property uchar green\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:719
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
718	        if rgb is not None:
719	            f.write(b"property uchar red\n")
720	            f.write(b"property uchar green\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:720
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
719	            f.write(b"property uchar red\n")
720	            f.write(b"property uchar green\n")
721	            f.write(b"property uchar blue\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:720
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
719	            f.write(b"property uchar red\n")
720	            f.write(b"property uchar green\n")
721	            f.write(b"property uchar blue\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:721
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
720	            f.write(b"property uchar green\n")
721	            f.write(b"property uchar blue\n")
722	        if faces is not None:

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:721
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
720	            f.write(b"property uchar green\n")
721	            f.write(b"property uchar blue\n")
722	        if faces is not None:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:723
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
722	        if faces is not None:
723	            f.write(bytes(f"element face {len(faces)}\n", "ascii"))
724	            f.write(b"property list uchar int vertex_index\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:723
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
722	        if faces is not None:
723	            f.write(bytes(f"element face {len(faces)}\n", "ascii"))
724	            f.write(b"property list uchar int vertex_index\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:724
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
723	            f.write(bytes(f"element face {len(faces)}\n", "ascii"))
724	            f.write(b"property list uchar int vertex_index\n")
725	        f.write(b"end_header\n")

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:724
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
723	            f.write(bytes(f"element face {len(faces)}\n", "ascii"))
724	            f.write(b"property list uchar int vertex_index\n")
725	        f.write(b"end_header\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:725
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
724	            f.write(b"property list uchar int vertex_index\n")
725	        f.write(b"end_header\n")
726	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:725
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
724	            f.write(b"property list uchar int vertex_index\n")
725	        f.write(b"end_header\n")
726	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:738
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
737	            for item in vertices:
738	                f.write(format.pack(*item))
739	        else:

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:738
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
737	            for item in vertices:
738	                f.write(format.pack(*item))
739	        else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:742
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
741	            for vertex in coords.tolist():
742	                f.write(format.pack(*vertex))
743	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:742
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
741	            for vertex in coords.tolist():
742	                f.write(format.pack(*vertex))
743	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:747
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
746	            for tri in faces.tolist():
747	                f.write(format.pack(len(tri), *tri))
748	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:747
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
746	            for tri in faces.tolist():
747	                f.write(format.pack(len(tri), *tri))
748	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:785
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
784	        img = cv2.cvtColor(video_frames[i], cv2.COLOR_RGB2BGR)
785	        video_writer.write(img)
786	    return output_video_path

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:785
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
784	        img = cv2.cvtColor(video_frames[i], cv2.COLOR_RGB2BGR)
785	        video_writer.write(img)
786	    return output_video_path

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:790
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
789	def load_hf_numpy(path) -> np.ndarray:
790	    base_url = "https://huggingface.co/datasets/fusing/diffusers-testing/resolve/main"
791	
792	    if not path.startswith("http://") and not path.startswith("https://"):

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:882
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
881	            durations_min = 0.05  # sec
882	            f.write("slowest durations\n")
883	            for i, rep in enumerate(dlist):

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:882
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
881	            durations_min = 0.05  # sec
882	            f.write("slowest durations\n")
883	            for i, rep in enumerate(dlist):

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:885
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
884	                if rep.duration < durations_min:
885	                    f.write(f"{len(dlist) - i} durations < {durations_min} secs were omitted")
886	                    break

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:885
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
884	                if rep.duration < durations_min:
885	                    f.write(f"{len(dlist) - i} durations < {durations_min} secs were omitted")
886	                    break

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:887
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
886	                    break
887	                f.write(f"{rep.duration:02.2f}s {rep.when:<8} {rep.nodeid}\n")
888	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:887
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
886	                    break
887	                f.write(f"{rep.duration:02.2f}s {rep.when:<8} {rep.nodeid}\n")
888	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:1006
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1005	    if timeout is None:
1006	        timeout = int(os.environ.get("PYTEST_TIMEOUT", 600))
1007	

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:1017
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
1016	
1017	    process = ctx.Process(target=target_func, args=(input_queue, output_queue, timeout))
1018	    process.start()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/diffusers-0.33.1/diffusers-0.33.1/src/diffusers/utils/testing_utils.py:1022
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1021	    try:
1022	        results = output_queue.get(timeout=timeout)
1023	        output_queue.task_done()

--------------------------------------------------

Code scanned:
	Total lines of code: 264926
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 256.0
		High: 150.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 404.0
		High: 2.0
Files skipped (0):
