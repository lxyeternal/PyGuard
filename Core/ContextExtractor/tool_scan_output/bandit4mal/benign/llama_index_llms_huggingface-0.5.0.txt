Run started:2025-04-12 18:15:35.936656

Test results:
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_index_llms_huggingface-0.5.0/llama_index_llms_huggingface-0.5.0/llama_index/llms/huggingface/utils.py:11
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
10	    url = f"{url}/info"
11	    model_info = dict(requests.get(url).json())
12	    tgi_version = model_info.get("version", None)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_index_llms_huggingface-0.5.0/llama_index_llms_huggingface-0.5.0/llama_index/llms/huggingface/utils.py:12
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
11	    model_info = dict(requests.get(url).json())
12	    tgi_version = model_info.get("version", None)
13	    if version.parse(tgi_version) >= version.parse("2.1.0"):

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_index_llms_huggingface-0.5.0/llama_index_llms_huggingface-0.5.0/llama_index/llms/huggingface/utils.py:14
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
13	    if version.parse(tgi_version) >= version.parse("2.1.0"):
14	        return model_info.get("max_input_tokens", None)
15	    else:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_index_llms_huggingface-0.5.0/llama_index_llms_huggingface-0.5.0/llama_index/llms/huggingface/utils.py:16
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
15	    else:
16	        return model_info.get("max_input_length", None)
17	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_index_llms_huggingface-0.5.0/llama_index_llms_huggingface-0.5.0/llama_index/llms/huggingface/utils.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
20	    url = f"{url}/info"
21	    model_info = dict(requests.get(url).json())
22	    return model_info.get("max_total_tokens", None)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_index_llms_huggingface-0.5.0/llama_index_llms_huggingface-0.5.0/llama_index/llms/huggingface/utils.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
21	    model_info = dict(requests.get(url).json())
22	    return model_info.get("max_total_tokens", None)
23	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_index_llms_huggingface-0.5.0/llama_index_llms_huggingface-0.5.0/llama_index/llms/huggingface/utils.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
25	def force_single_tool_call(response: ChatResponse) -> None:
26	    tool_calls = response.message.additional_kwargs.get("tool_calls", [])
27	    if len(tool_calls) > 1:

--------------------------------------------------

Code scanned:
	Total lines of code: 388
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 0.0
		High: 7.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 7.0
		High: 0.0
Files skipped (0):
