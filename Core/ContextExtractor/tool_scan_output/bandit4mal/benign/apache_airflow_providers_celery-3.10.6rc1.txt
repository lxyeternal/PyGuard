Run started:2025-04-12 16:09:44.963935

Test results:
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/cli/celery_command.py:114
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
113	    if skip_serve_logs is False:
114	        sub_proc = Process(target=serve_logs)
115	        sub_proc.start()

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/cli/celery_command.py:150
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
149	    try:
150	        sub_proc = Process(target=bundle_cleanup_main)
151	        sub_proc.start()

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/cli/celery_command.py:303
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
302	    if pid:
303	        worker_process = psutil.Process(pid)
304	        worker_process.terminate()

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/executors/celery_executor.py:336
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
335	
336	        with ProcessPoolExecutor(max_workers=num_processes) as send_pool:
337	            key_and_async_results = list(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/executors/celery_executor.py:497
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
496	                description=(
497	                    "Start celery components. Works only when using CeleryExecutor. For more information, "
498	                    "see https://airflow.apache.org/docs/apache-airflow/stable/executor/celery.html"
499	                ),
500	                subcommands=CELERY_COMMANDS,
501	            ),

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/executors/celery_executor_utils.py:374
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
373	
374	        with ProcessPoolExecutor(max_workers=num_process) as sync_pool:
375	            chunksize = max(1, math.ceil(len(async_results) / self._sync_parallelism))

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/executors/celery_kubernetes_executor.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
75	    def kubernetes_queue(self) -> str:
76	        return conf.get("celery_kubernetes_executor", "kubernetes_queue")
77	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
27	        "name": "Celery",
28	        "description": "`Celery <https://docs.celeryq.dev/en/stable/>`__\n",
29	        "integrations": [
30	            {
31	                "integration-name": "Celery",
32	                "external-doc-url": "https://docs.celeryq.dev/en/stable/",
33	                "logo": "/docs/integration-logos/Celery.png",
34	                "tags": ["software"],
35	            }
36	        ],
37	        "sensors": [
38	            {
39	                "integration-name": "Celery",
40	                "python-modules": ["airflow.providers.celery.sensors.celery_queue"],
41	            }
42	        ],
43	        "executors": [
44	            "airflow.providers.celery.executors.celery_executor.CeleryExecutor",
45	            "airflow.providers.celery.executors.celery_kubernetes_executor.CeleryKubernetesExecutor",
46	        ],
47	        "config": {
48	            "celery_kubernetes_executor": {
49	                "description": "This section only applies if you are using the ``CeleryKubernetesExecutor`` in\n``[core]`` section above\n",
50	                "options": {
51	                    "kubernetes_queue": {
52	                        "description": "Define when to send a task to ``KubernetesExecutor`` when using ``CeleryKubernetesExecutor``.\nWhen the queue of a task is the value of ``kubernetes_queue`` (default ``kubernetes``),\nthe task is executed via ``KubernetesExecutor``,\notherwise via ``CeleryExecutor``\n",
53	                        "version_added": None,
54	                        "type": "string",
55	                        "example": None,
56	                        "default": "kubernetes",
57	                    }
58	                },
59	            },
60	            "celery": {
61	                "description": "This section only applies if you are using the CeleryExecutor in\n``[core]`` section above\n",
62	                "options": {
63	                    "celery_app_name": {
64	                        "description": "The app name that will be used by celery\n",
65	                        "version_added": None,
66	                        "type": "string",
67	                        "example": None,
68	                        "default": "airflow.providers.celery.executors.celery_executor",
69	                    },
70	                    "worker_concurrency": {
71	                        "description": "The concurrency that will be used when starting workers with the\n``airflow celery worker`` command. This defines the number of task instances that\na worker will take, so size up your workers based on the resources on\nyour worker box and the nature of your tasks\n",
72	                        "version_added": None,
73	                        "type": "string",
74	                        "example": None,
75	                        "default": "16",
76	                    },
77	                    "worker_autoscale": {
78	                        "description": "The maximum and minimum number of pool processes that will be used to dynamically resize\nthe pool based on load.Enable autoscaling by providing max_concurrency,min_concurrency\nwith the ``airflow celery worker`` command (always keep minimum processes,\nbut grow to maximum if necessary).\nPick these numbers based on resources on worker box and the nature of the task.\nIf autoscale option is available, worker_concurrency will be ignored.\nhttps://docs.celeryq.dev/en/latest/reference/celery.bin.worker.html#cmdoption-celery-worker-autoscale\n",
79	                        "version_added": None,
80	                        "type": "string",
81	                        "example": "16,12",
82	                        "default": None,
83	                    },
84	                    "worker_prefetch_multiplier": {
85	                        "description": "Used to increase the number of tasks that a worker prefetches which can improve performance.\nThe number of processes multiplied by worker_prefetch_multiplier is the number of tasks\nthat are prefetched by a worker. A value greater than 1 can result in tasks being unnecessarily\nblocked if there are multiple workers and one worker prefetches tasks that sit behind long\nrunning tasks while another worker has unutilized processes that are unable to process the already\nclaimed blocked tasks.\nhttps://docs.celeryq.dev/en/stable/userguide/optimizing.html#prefetch-limits\n",
86	                        "version_added": None,
87	                        "type": "integer",
88	                        "example": None,
89	                        "default": "1",
90	                    },
91	                    "worker_enable_remote_control": {
92	                        "description": "Specify if remote control of the workers is enabled.\nIn some cases when the broker does not support remote control, Celery creates lots of\n``.*reply-celery-pidbox`` queues. You can prevent this by setting this to false.\nHowever, with this disabled Flower won't work.\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/index.html#broker-overview\n",
93	                        "version_added": None,
94	                        "type": "boolean",
95	                        "example": None,
96	                        "default": "true",
97	                    },
98	                    "broker_url": {
99	                        "description": "The Celery broker URL. Celery supports RabbitMQ, Redis and experimentally\na sqlalchemy database. Refer to the Celery documentation for more information.\n",
100	                        "version_added": None,
101	                        "type": "string",
102	                        "sensitive": True,
103	                        "example": None,
104	                        "default": "redis://redis:6379/0",
105	                    },
106	                    "result_backend": {
107	                        "description": "The Celery result_backend. When a job finishes, it needs to update the\nmetadata of the job. Therefore it will post a message on a message bus,\nor insert it into a database (depending of the backend)\nThis status is used by the scheduler to update the state of the task\nThe use of a database is highly recommended\nWhen not specified, sql_alchemy_conn with a db+ scheme prefix will be used\nhttps://docs.celeryq.dev/en/latest/userguide/configuration.html#task-result-backend-settings\n",
108	                        "version_added": None,
109	                        "type": "string",
110	                        "sensitive": True,
111	                        "example": "db+postgresql://postgres:airflow@postgres/airflow",
112	                        "default": None,
113	                    },
114	                    "result_backend_sqlalchemy_engine_options": {
115	                        "description": "Optional configuration dictionary to pass to the Celery result backend SQLAlchemy engine.\n",
116	                        "version_added": None,
117	                        "type": "string",
118	                        "example": '{"pool_recycle": 1800}',
119	                        "default": "",
120	                    },
121	                    "flower_host": {
122	                        "description": "Celery Flower is a sweet UI for Celery. Airflow has a shortcut to start\nit ``airflow celery flower``. This defines the IP that Celery Flower runs on\n",
123	                        "version_added": None,
124	                        "type": "string",
125	                        "example": None,
126	                        "default": "0.0.0.0",
127	                    },
128	                    "flower_url_prefix": {
129	                        "description": "The root URL for Flower\n",
130	                        "version_added": None,
131	                        "type": "string",
132	                        "example": "/flower",
133	                        "default": "",
134	                    },
135	                    "flower_port": {
136	                        "description": "This defines the port that Celery Flower runs on\n",
137	                        "version_added": None,
138	                        "type": "string",
139	                        "example": None,
140	                        "default": "5555",
141	                    },
142	                    "flower_basic_auth": {
143	                        "description": "Securing Flower with Basic Authentication\nAccepts user:password pairs separated by a comma\n",
144	                        "version_added": None,
145	                        "type": "string",
146	                        "sensitive": True,
147	                        "example": "user1:password1,user2:password2",
148	                        "default": "",
149	                    },
150	                    "sync_parallelism": {
151	                        "description": "How many processes CeleryExecutor uses to sync task state.\n0 means to use max(1, number of cores - 1) processes.\n",
152	                        "version_added": None,
153	                        "type": "string",
154	                        "example": None,
155	                        "default": "0",
156	                    },
157	                    "celery_config_options": {
158	                        "description": "Import path for celery configuration options\n",
159	                        "version_added": None,
160	                        "type": "string",
161	                        "example": None,
162	                        "default": "airflow.providers.celery.executors.default_celery.DEFAULT_CELERY_CONFIG",
163	                    },
164	                    "ssl_active": {
165	                        "description": None,
166	                        "version_added": None,
167	                        "type": "string",
168	                        "example": None,
169	                        "default": "False",
170	                    },
171	                    "ssl_key": {
172	                        "description": "Path to the client key.\n",
173	                        "version_added": None,
174	                        "type": "string",
175	                        "example": None,
176	                        "default": "",
177	                    },
178	                    "ssl_cert": {
179	                        "description": "Path to the client certificate.\n",
180	                        "version_added": None,
181	                        "type": "string",
182	                        "example": None,
183	                        "default": "",
184	                    },
185	                    "ssl_cacert": {
186	                        "description": "Path to the CA certificate.\n",
187	                        "version_added": None,
188	                        "type": "string",
189	                        "example": None,
190	                        "default": "",
191	                    },
192	                    "pool": {
193	                        "description": "Celery Pool implementation.\nChoices include: ``prefork`` (default), ``eventlet``, ``gevent`` or ``solo``.\nSee:\nhttps://docs.celeryq.dev/en/latest/userguide/workers.html#concurrency\nhttps://docs.celeryq.dev/en/latest/userguide/concurrency/eventlet.html\n",
194	                        "version_added": None,
195	                        "type": "string",
196	                        "example": None,
197	                        "default": "prefork",
198	                    },
199	                    "operation_timeout": {
200	                        "description": "The number of seconds to wait before timing out ``send_task_to_executor`` or\n``fetch_celery_task_state`` operations.\n",
201	                        "version_added": None,
202	                        "type": "float",
203	                        "example": None,
204	                        "default": "1.0",
205	                    },
206	                    "task_acks_late": {
207	                        "description": "If an Airflow task's execution time exceeds the visibility_timeout, Celery will re-assign the\ntask to a Celery worker, even if the original task is still running successfully. The new task\ninstance then runs concurrently with the original task and the Airflow UI and logs only show an\nerror message:\n'Task Instance Not Running' FAILED: Task is in the running state'\nSetting task_acks_late to True will force Celery to wait until a task is finished before a\nnew task instance is assigned. This effectively overrides the visibility timeout.\nSee also:\nhttps://docs.celeryq.dev/en/stable/reference/celery.app.task.html#celery.app.task.Task.acks_late\n",
208	                        "version_added": "3.6.0",
209	                        "type": "boolean",
210	                        "example": "True",
211	                        "default": "True",
212	                    },
213	                    "task_track_started": {
214	                        "description": "Celery task will report its status as 'started' when the task is executed by a worker.\nThis is used in Airflow to keep track of the running tasks and if a Scheduler is restarted\nor run in HA mode, it can adopt the orphan tasks launched by previous SchedulerJob.\n",
215	                        "version_added": None,
216	                        "type": "boolean",
217	                        "example": None,
218	                        "default": "True",
219	                    },
220	                    "task_publish_max_retries": {
221	                        "description": "The Maximum number of retries for publishing task messages to the broker when failing\ndue to ``AirflowTaskTimeout`` error before giving up and marking Task as failed.\n",
222	                        "version_added": None,
223	                        "type": "integer",
224	                        "example": None,
225	                        "default": "3",
226	                    },
227	                    "extra_celery_config": {
228	                        "description": 'Extra celery configs to include in the celery worker.\nAny of the celery config can be added to this config and it\nwill be applied while starting the celery worker. e.g. {"worker_max_tasks_per_child": 10}\nSee also:\nhttps://docs.celeryq.dev/en/stable/userguide/configuration.html#configuration-and-defaults\n',
229	                        "version_added": None,
230	                        "type": "string",
231	                        "example": None,
232	                        "default": "{{}}",
233	                    },
234	                },
235	            },
236	            "celery_broker_transport_options": {
237	                "description": "This section is for specifying options which can be passed to the\nunderlying celery broker transport. See:\nhttps://docs.celeryq.dev/en/latest/userguide/configuration.html#std:setting-broker_transport_options\n",
238	                "options": {
239	                    "visibility_timeout": {
240	                        "description": "The visibility timeout defines the number of seconds to wait for the worker\nto acknowledge the task before the message is redelivered to another worker.\nMake sure to increase the visibility timeout to match the time of the longest\nETA you're planning to use.\nvisibility_timeout is only supported for Redis and SQS celery brokers.\nSee:\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html#visibility-timeout\n",
241	                        "version_added": None,
242	                        "type": "string",
243	                        "example": "21600",
244	                        "default": None,
245	                    },
246	                    "sentinel_kwargs": {
247	                        "description": "The sentinel_kwargs parameter allows passing additional options to the Sentinel client.\nIn a typical scenario where Redis Sentinel is used as the broker and Redis servers are\npassword-protected, the password needs to be passed through this parameter. Although its\ntype is string, it is required to pass a string that conforms to the dictionary format.\nSee:\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html#configuration\n",
248	                        "version_added": None,
249	                        "type": "string",
250	                        "sensitive": True,
251	                        "example": '{"password": "password_for_redis_server"}',
252	                        "default": None,
253	                    },
254	                },
255	            },
256	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	                "integration-name": "Celery",
32	                "external-doc-url": "https://docs.celeryq.dev/en/stable/",
33	                "logo": "/docs/integration-logos/Celery.png",
34	                "tags": ["software"],
35	            }
36	        ],
37	        "sensors": [

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	                    "worker_autoscale": {
78	                        "description": "The maximum and minimum number of pool processes that will be used to dynamically resize\nthe pool based on load.Enable autoscaling by providing max_concurrency,min_concurrency\nwith the ``airflow celery worker`` command (always keep minimum processes,\nbut grow to maximum if necessary).\nPick these numbers based on resources on worker box and the nature of the task.\nIf autoscale option is available, worker_concurrency will be ignored.\nhttps://docs.celeryq.dev/en/latest/reference/celery.bin.worker.html#cmdoption-celery-worker-autoscale\n",
79	                        "version_added": None,
80	                        "type": "string",
81	                        "example": "16,12",
82	                        "default": None,
83	                    },
84	                    "worker_prefetch_multiplier": {
85	                        "description": "Used to increase the number of tasks that a worker prefetches which can improve performance.\nThe number of processes multiplied by worker_prefetch_multiplier is the number of tasks\nthat are prefetched by a worker. A value greater than 1 can result in tasks being unnecessarily\nblocked if there are multiple workers and one worker prefetches tasks that sit behind long\nrunning tasks while another worker has unutilized processes that are unable to process the already\nclaimed blocked tasks.\nhttps://docs.celeryq.dev/en/stable/userguide/optimizing.html#prefetch-limits\n",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
84	                    "worker_prefetch_multiplier": {
85	                        "description": "Used to increase the number of tasks that a worker prefetches which can improve performance.\nThe number of processes multiplied by worker_prefetch_multiplier is the number of tasks\nthat are prefetched by a worker. A value greater than 1 can result in tasks being unnecessarily\nblocked if there are multiple workers and one worker prefetches tasks that sit behind long\nrunning tasks while another worker has unutilized processes that are unable to process the already\nclaimed blocked tasks.\nhttps://docs.celeryq.dev/en/stable/userguide/optimizing.html#prefetch-limits\n",
86	                        "version_added": None,
87	                        "type": "integer",
88	                        "example": None,
89	                        "default": "1",
90	                    },
91	                    "worker_enable_remote_control": {
92	                        "description": "Specify if remote control of the workers is enabled.\nIn some cases when the broker does not support remote control, Celery creates lots of\n``.*reply-celery-pidbox`` queues. You can prevent this by setting this to false.\nHowever, with this disabled Flower won't work.\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/index.html#broker-overview\n",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:92
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
91	                    "worker_enable_remote_control": {
92	                        "description": "Specify if remote control of the workers is enabled.\nIn some cases when the broker does not support remote control, Celery creates lots of\n``.*reply-celery-pidbox`` queues. You can prevent this by setting this to false.\nHowever, with this disabled Flower won't work.\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/index.html#broker-overview\n",
93	                        "version_added": None,
94	                        "type": "boolean",
95	                        "example": None,
96	                        "default": "true",
97	                    },
98	                    "broker_url": {
99	                        "description": "The Celery broker URL. Celery supports RabbitMQ, Redis and experimentally\na sqlalchemy database. Refer to the Celery documentation for more information.\n",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:107
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
106	                    "result_backend": {
107	                        "description": "The Celery result_backend. When a job finishes, it needs to update the\nmetadata of the job. Therefore it will post a message on a message bus,\nor insert it into a database (depending of the backend)\nThis status is used by the scheduler to update the state of the task\nThe use of a database is highly recommended\nWhen not specified, sql_alchemy_conn with a db+ scheme prefix will be used\nhttps://docs.celeryq.dev/en/latest/userguide/configuration.html#task-result-backend-settings\n",
108	                        "version_added": None,
109	                        "type": "string",
110	                        "sensitive": True,
111	                        "example": "db+postgresql://postgres:airflow@postgres/airflow",
112	                        "default": None,
113	                    },
114	                    "result_backend_sqlalchemy_engine_options": {
115	                        "description": "Optional configuration dictionary to pass to the Celery result backend SQLAlchemy engine.\n",

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
125	                        "example": None,
126	                        "default": "0.0.0.0",
127	                    },
128	                    "flower_url_prefix": {
129	                        "description": "The root URL for Flower\n",
130	                        "version_added": None,
131	                        "type": "string",
132	                        "example": "/flower",
133	                        "default": "",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:193
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
192	                    "pool": {
193	                        "description": "Celery Pool implementation.\nChoices include: ``prefork`` (default), ``eventlet``, ``gevent`` or ``solo``.\nSee:\nhttps://docs.celeryq.dev/en/latest/userguide/workers.html#concurrency\nhttps://docs.celeryq.dev/en/latest/userguide/concurrency/eventlet.html\n",
194	                        "version_added": None,
195	                        "type": "string",
196	                        "example": None,
197	                        "default": "prefork",
198	                    },
199	                    "operation_timeout": {
200	                        "description": "The number of seconds to wait before timing out ``send_task_to_executor`` or\n``fetch_celery_task_state`` operations.\n",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:207
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
206	                    "task_acks_late": {
207	                        "description": "If an Airflow task's execution time exceeds the visibility_timeout, Celery will re-assign the\ntask to a Celery worker, even if the original task is still running successfully. The new task\ninstance then runs concurrently with the original task and the Airflow UI and logs only show an\nerror message:\n'Task Instance Not Running' FAILED: Task is in the running state'\nSetting task_acks_late to True will force Celery to wait until a task is finished before a\nnew task instance is assigned. This effectively overrides the visibility timeout.\nSee also:\nhttps://docs.celeryq.dev/en/stable/reference/celery.app.task.html#celery.app.task.Task.acks_late\n",
208	                        "version_added": "3.6.0",
209	                        "type": "boolean",
210	                        "example": "True",
211	                        "default": "True",
212	                    },
213	                    "task_track_started": {
214	                        "description": "Celery task will report its status as 'started' when the task is executed by a worker.\nThis is used in Airflow to keep track of the running tasks and if a Scheduler is restarted\nor run in HA mode, it can adopt the orphan tasks launched by previous SchedulerJob.\n",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:228
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
227	                    "extra_celery_config": {
228	                        "description": 'Extra celery configs to include in the celery worker.\nAny of the celery config can be added to this config and it\nwill be applied while starting the celery worker. e.g. {"worker_max_tasks_per_child": 10}\nSee also:\nhttps://docs.celeryq.dev/en/stable/userguide/configuration.html#configuration-and-defaults\n',
229	                        "version_added": None,
230	                        "type": "string",
231	                        "example": None,
232	                        "default": "{{}}",
233	                    },
234	                },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:237
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
236	            "celery_broker_transport_options": {
237	                "description": "This section is for specifying options which can be passed to the\nunderlying celery broker transport. See:\nhttps://docs.celeryq.dev/en/latest/userguide/configuration.html#std:setting-broker_transport_options\n",
238	                "options": {
239	                    "visibility_timeout": {
240	                        "description": "The visibility timeout defines the number of seconds to wait for the worker\nto acknowledge the task before the message is redelivered to another worker.\nMake sure to increase the visibility timeout to match the time of the longest\nETA you're planning to use.\nvisibility_timeout is only supported for Redis and SQS celery brokers.\nSee:\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html#visibility-timeout\n",
241	                        "version_added": None,
242	                        "type": "string",
243	                        "example": "21600",
244	                        "default": None,
245	                    },
246	                    "sentinel_kwargs": {
247	                        "description": "The sentinel_kwargs parameter allows passing additional options to the Sentinel client.\nIn a typical scenario where Redis Sentinel is used as the broker and Redis servers are\npassword-protected, the password needs to be passed through this parameter. Although its\ntype is string, it is required to pass a string that conforms to the dictionary format.\nSee:\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html#configuration\n",
248	                        "version_added": None,
249	                        "type": "string",
250	                        "sensitive": True,
251	                        "example": '{"password": "password_for_redis_server"}',
252	                        "default": None,
253	                    },
254	                },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:240
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
239	                    "visibility_timeout": {
240	                        "description": "The visibility timeout defines the number of seconds to wait for the worker\nto acknowledge the task before the message is redelivered to another worker.\nMake sure to increase the visibility timeout to match the time of the longest\nETA you're planning to use.\nvisibility_timeout is only supported for Redis and SQS celery brokers.\nSee:\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html#visibility-timeout\n",
241	                        "version_added": None,
242	                        "type": "string",
243	                        "example": "21600",
244	                        "default": None,
245	                    },
246	                    "sentinel_kwargs": {
247	                        "description": "The sentinel_kwargs parameter allows passing additional options to the Sentinel client.\nIn a typical scenario where Redis Sentinel is used as the broker and Redis servers are\npassword-protected, the password needs to be passed through this parameter. Although its\ntype is string, it is required to pass a string that conforms to the dictionary format.\nSee:\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html#configuration\n",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/src/airflow/providers/celery/get_provider_info.py:247
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
246	                    "sentinel_kwargs": {
247	                        "description": "The sentinel_kwargs parameter allows passing additional options to the Sentinel client.\nIn a typical scenario where Redis Sentinel is used as the broker and Redis servers are\npassword-protected, the password needs to be passed through this parameter. Although its\ntype is string, it is required to pass a string that conforms to the dictionary format.\nSee:\nhttps://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html#configuration\n",
248	                        "version_added": None,
249	                        "type": "string",
250	                        "sensitive": True,
251	                        "example": '{"password": "password_for_redis_server"}',
252	                        "default": None,
253	                    },
254	                },

--------------------------------------------------
>> Issue: [B813:popen] os.popen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/cli/test_celery_command.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b813_popen.html
198	        finally:
199	            mock_popen().terminate.assert_called()
200	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/cli/test_celery_command.py:220
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
219	                "--broker-api",
220	                "http://username:password@rabbitmq-server-name:15672/api/",
221	                "--flower-conf",
222	                "flower_config",
223	                "--hostname",
224	                "my-hostname",
225	                "--port",
226	                "3333",
227	                "--url-prefix",
228	                "flower-monitoring",
229	            ]
230	        )
231	
232	        celery_command.flower(args)
233	        mock_celery_app.start.assert_called_once_with(
234	            [
235	                "flower",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/cli/test_celery_command.py:239
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
238	                "--port=3333",
239	                "--broker-api=http://username:password@rabbitmq-server-name:15672/api/",
240	                "--url-prefix=flower-monitoring",
241	                "--basic-auth=admin:admin",
242	                "--conf=flower_config",
243	            ]
244	        )
245	
246	    def _test_run_command_daemon(self, mock_celery_app, mock_daemon, mock_setup_locations, mock_pid_file):
247	        mock_setup_locations.return_value = (
248	            mock.MagicMock(name="pidfile"),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/cli/test_celery_command.py:260
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
259	                "--broker-api",
260	                "http://username:password@rabbitmq-server-name:15672/api/",
261	                "--flower-conf",
262	                "flower_config",
263	                "--hostname",
264	                "my-hostname",
265	                "--log-file",
266	                "/tmp/flower.log",
267	                "--pid",
268	                "/tmp/flower.pid",
269	                "--port",
270	                "3333",
271	                "--stderr",
272	                "/tmp/flower-stderr.log",
273	                "--stdout",
274	                "/tmp/flower-stdout.log",
275	                "--url-prefix",
276	                "flower-monitoring",
277	                "--daemon",
278	            ]
279	        )
280	        mock_open = mock.mock_open()
281	        with mock.patch("airflow.cli.commands.daemon_utils.open", mock_open):
282	            celery_command.flower(args)
283	
284	        mock_celery_app.start.assert_called_once_with(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/cli/test_celery_command.py:290
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
289	                "--port=3333",
290	                "--broker-api=http://username:password@rabbitmq-server-name:15672/api/",
291	                "--url-prefix=flower-monitoring",
292	                "--basic-auth=admin:admin",
293	                "--conf=flower_config",
294	            ]
295	        )
296	        assert mock_daemon.mock_calls[:3] == [
297	            mock.call.DaemonContext(
298	                pidfile=mock_pid_file.return_value,
299	                files_preserve=None,

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:342
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
341	
342	    orig_sigint = signal.signal(signal.SIGINT, _exit_gracefully)
343	    orig_sigterm = signal.signal(signal.SIGTERM, _exit_gracefully)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:342
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
341	
342	    orig_sigint = signal.signal(signal.SIGINT, _exit_gracefully)
343	    orig_sigterm = signal.signal(signal.SIGTERM, _exit_gracefully)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:343
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
342	    orig_sigint = signal.signal(signal.SIGINT, _exit_gracefully)
343	    orig_sigterm = signal.signal(signal.SIGTERM, _exit_gracefully)
344	    orig_sigusr2 = signal.signal(signal.SIGUSR2, _exit_gracefully)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:343
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
342	    orig_sigint = signal.signal(signal.SIGINT, _exit_gracefully)
343	    orig_sigterm = signal.signal(signal.SIGTERM, _exit_gracefully)
344	    orig_sigusr2 = signal.signal(signal.SIGUSR2, _exit_gracefully)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:344
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
343	    orig_sigterm = signal.signal(signal.SIGTERM, _exit_gracefully)
344	    orig_sigusr2 = signal.signal(signal.SIGUSR2, _exit_gracefully)
345	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:344
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
343	    orig_sigterm = signal.signal(signal.SIGTERM, _exit_gracefully)
344	    orig_sigusr2 = signal.signal(signal.SIGUSR2, _exit_gracefully)
345	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:349
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
348	    # Restore original signal handlers after test
349	    signal.signal(signal.SIGINT, orig_sigint)
350	    signal.signal(signal.SIGTERM, orig_sigterm)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:349
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
348	    # Restore original signal handlers after test
349	    signal.signal(signal.SIGINT, orig_sigint)
350	    signal.signal(signal.SIGTERM, orig_sigterm)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:350
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
349	    signal.signal(signal.SIGINT, orig_sigint)
350	    signal.signal(signal.SIGTERM, orig_sigterm)
351	    signal.signal(signal.SIGUSR2, orig_sigusr2)

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:350
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
349	    signal.signal(signal.SIGINT, orig_sigint)
350	    signal.signal(signal.SIGTERM, orig_sigterm)
351	    signal.signal(signal.SIGUSR2, orig_sigusr2)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:351
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
350	    signal.signal(signal.SIGTERM, orig_sigterm)
351	    signal.signal(signal.SIGUSR2, orig_sigusr2)
352	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_executor.py:351
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
350	    signal.signal(signal.SIGTERM, orig_sigterm)
351	    signal.signal(signal.SIGUSR2, orig_sigusr2)
352	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/apache_airflow_providers_celery-3.10.6rc1/apache_airflow_providers_celery-3.10.6rc1/tests/unit/celery/executors/test_celery_kubernetes_executor.py:253
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
252	
253	        assert k8s_executor_mock.kubernetes_queue == conf.get(
254	            "celery_kubernetes_executor", "kubernetes_queue"
255	        )

--------------------------------------------------

Code scanned:
	Total lines of code: 2456
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 24.0
		High: 14.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 32.0
		High: 6.0
Files skipped (0):
