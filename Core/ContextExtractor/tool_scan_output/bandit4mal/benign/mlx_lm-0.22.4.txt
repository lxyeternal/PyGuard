Run started:2025-04-12 12:11:24.107787

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/generate.py:209
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
208	        print(
209	            f"[WARNING] Generating with a model that requires {model_mb} MB "
210	            f"which is close to the maximum recommended size of {max_rec_mb} "
211	            "MB. This can be slow. See the documentation for possible work-arounds: "

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/server.py:163
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
162	        if self.cli_args.model is not None:
163	            self.load("default_model")
164	

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/server.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
189	        if model_path == "default_model" and self.cli_args.model is not None:
190	            model, tokenizer = load(
191	                self.cli_args.model,
192	                adapter_path=(
193	                    adapter_path if adapter_path else self.cli_args.adapter_path
194	                ),  # if the user doesn't change the model but adds an adapter path
195	                tokenizer_config=tokenizer_config,
196	            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/server.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
198	            self._validate_model_path(model_path)
199	            model, tokenizer = load(
200	                model_path, adapter_path=adapter_path, tokenizer_config=tokenizer_config
201	            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/server.py:296
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
295	        try:
296	            self.model, self.tokenizer = self.model_provider.load(
297	                self.requested_model, self.adapter
298	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/server.py:670
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
669	        if self.path == "/v1/models":
670	            self.handle_models_request()
671	        else:

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/server.py:752
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
751	        type=str,
752	        default="127.0.0.1",
753	        help="Host for the HTTP server (default: 127.0.0.1)",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/tuner/datasets.py:182
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
181	        raise ValueError(
182	            "Unsupported data format, check the supported formats here:\n"
183	            "https://github.com/ml-explore/mlx-examples/blob/main/llms/mlx_lm/LORA.md#data."
184	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/utils.py:125
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
124	            raise ModelNotFoundError(
125	                f"Model not found for path or HF repo: {path_or_hf_repo}.\n"
126	                "Please make sure you specified the local path or Hugging Face"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/utils.py:325
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
324	    card.text = dedent(
325	        f"""
326	        # {upload_repo}
327	
328	        This model [{upload_repo}](https://huggingface.co/{upload_repo}) was
329	        converted to MLX format from [{hf_path}](https://huggingface.co/{hf_path})
330	        using mlx-lm version **{__version__}**.
331	
332	        ## Use with mlx
333	
334	        ```bash
335	        pip install mlx-lm
336	        ```
337	
338	        ```python
339	        from mlx_lm import load, generate
340	
341	        model, tokenizer = load("{upload_repo}")
342	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/utils.py:325
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
324	    card.text = dedent(
325	        f"""
326	        # {upload_repo}
327	
328	        This model [{upload_repo}](https://huggingface.co/{upload_repo}) was
329	        converted to MLX format from [{hf_path}](https://huggingface.co/{hf_path})
330	        using mlx-lm version **{__version__}**.
331	
332	        ## Use with mlx
333	
334	        ```bash
335	        pip install mlx-lm
336	        ```
337	
338	        ```python
339	        from mlx_lm import load, generate
340	
341	        model, tokenizer = load("{upload_repo}")
342	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/mlx_lm/utils.py:366
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
365	    )
366	    print(f"Upload successful, go to https://huggingface.co/{upload_repo} for details.")
367	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/setup.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
23	    author="MLX Contributors",
24	    url="https://github.com/ml-explore/mlx-lm",
25	    license="MIT",

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_datsets.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
33	                    json.dump(l, fid)
34	                    fid.write("\n")
35	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_datsets.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
33	                    json.dump(l, fid)
34	                    fid.write("\n")
35	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_gguf.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
18	        with open(cls.tokenizer_file_path, "w") as f:
19	            f.write("{}")
20	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_gguf.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
18	        with open(cls.tokenizer_file_path, "w") as f:
19	            f.write("{}")
20	

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:17
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
16	        HF_MODEL_PATH = "mlx-community/Qwen1.5-0.5B-Chat-4bit"
17	        self.model, self.tokenizer = load(HF_MODEL_PATH)
18	        self.model_key = (HF_MODEL_PATH, None)

--------------------------------------------------
>> Issue: [B827:httpserver] http.server.HTTPServer
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b827_httpserver.html
29	        cls.server_address = ("localhost", 0)
30	        cls.httpd = http.server.HTTPServer(
31	            cls.server_address,
32	            lambda *args, **kwargs: APIHandler(cls.model_provider, *args, **kwargs),
33	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	    def test_handle_completions(self):
46	        url = f"http://localhost:{self.port}/v1/completions"
47	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
58	
59	        response = requests.post(url, json=post_data)
60	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:67
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
66	    def test_handle_chat_completions(self):
67	        url = f"http://localhost:{self.port}/v1/chat/completions"
68	        chat_post_data = {

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:79
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
78	        }
79	        response = requests.post(url, json=chat_post_data)
80	        response_body = response.text

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
84	    def test_handle_chat_completions_with_content_fragments(self):
85	        url = f"http://localhost:{self.port}/v1/chat/completions"
86	        chat_post_data = {

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:102
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
101	        }
102	        response = requests.post(url, json=chat_post_data)
103	        response_body = response.text

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:108
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
107	    def test_handle_models(self):
108	        url = f"http://localhost:{self.port}/v1/models"
109	        response = requests.get(url)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/mlx_lm-0.22.4/mlx_lm-0.22.4/tests/test_server.py:109
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
108	        url = f"http://localhost:{self.port}/v1/models"
109	        response = requests.get(url)
110	        self.assertEqual(response.status_code, 200)

--------------------------------------------------

Code scanned:
	Total lines of code: 16774
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 12.0
		High: 15.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 27.0
		High: 0.0
Files skipped (0):
