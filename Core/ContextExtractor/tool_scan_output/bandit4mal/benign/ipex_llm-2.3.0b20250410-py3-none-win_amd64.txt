Run started:2025-04-12 14:50:37.130236

Test results:
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/ggml/model/bloom/bloom_cpp.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
89	            try:
90	                return ctypes.CDLL(str(_lib_path))
91	            except Exception as e:

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/ggml/model/gptneox/gptneox_cpp.py:91
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
90	            try:
91	                return ctypes.CDLL(str(_lib_path), **cdll_args)
92	            except Exception as e:

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/ggml/model/llama/llama_cpp.py:98
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
97	            try:
98	                return ctypes.CDLL(str(_lib_path), **cdll_args)
99	            except Exception as e:

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/ggml/model/starcoder/starcoder_cpp.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
89	            try:
90	                return ctypes.CDLL(str(_lib_path))
91	            except Exception as e:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/gptq/convert/convert_gptq_to_ggml.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
36	    sname = dst_name.encode('utf-8')
37	    fout.write(struct.pack("iii", len(shape), len(sname), ftype_cur))
38	    fout.write(struct.pack("i" * len(shape), *shape[::-1]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/gptq/convert/convert_gptq_to_ggml.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
37	    fout.write(struct.pack("iii", len(shape), len(sname), ftype_cur))
38	    fout.write(struct.pack("i" * len(shape), *shape[::-1]))
39	    fout.write(sname)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/gptq/convert/convert_gptq_to_ggml.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
38	    fout.write(struct.pack("i" * len(shape), *shape[::-1]))
39	    fout.write(sname)
40	    fout.seek((fout.tell() + 31) & -32)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/gptq/convert/convert_gptq_to_ggml.py:209
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
208	
209	    fout.write(b"ggjt"[::-1])  # magic: ggmf in hex
210	    values = [3,  # file version

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/gptq/convert/convert_gptq_to_ggml.py:218
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
217	              4]
218	    fout.write(struct.pack("i" * len(values), *values))
219	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/gptq/convert/convert_gptq_to_ggml.py:235
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
234	            text = tokenizer.id_to_piece(i).replace("\u2581", " ").encode("utf-8")
235	        fout.write(struct.pack("i", len(text)))
236	        fout.write(text)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/gptq/convert/convert_gptq_to_ggml.py:236
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
235	        fout.write(struct.pack("i", len(text)))
236	        fout.write(text)
237	        fout.write(struct.pack("f", tokenizer.get_score(i)))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/gptq/convert/convert_gptq_to_ggml.py:237
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
236	        fout.write(text)
237	        fout.write(struct.pack("f", tokenizer.get_score(i)))
238	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastapi/api_server.py:416
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
415	        with open(file_path, "wb") as f:
416	            f.write(await file.read())
417	    inputs_request = InputsRequest(

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastapi/api_server.py:416
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
415	        with open(file_path, "wb") as f:
416	            f.write(await file.read())
417	    inputs_request = InputsRequest(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastapi/model_worker.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
88	        else:
89	            response = requests.get(image_path)
90	            if response.status_code == 200:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastapi/model_worker.py:94
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
93	                with open(local_path, 'wb') as file:
94	                    file.write(response.content)
95	        return local_path

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastapi/model_worker.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
99	            return
100	        tmp_result = await self.waiting_requests.get()
101	        request_id, request = tmp_result

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastapi/model_worker.py:120
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
119	            return
120	        tmp_result = await self.waiting_requests.get()
121	        request_id, prompt_request = tmp_result

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastapi/model_worker.py:172
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
171	            if processor is not None and "whisper" in self.model_name.lower():
172	                input_features, decoder_ids, request_id = await self.add_asr_request(processor)
173	                self.streamer[request_id] = TextIteratorStreamer(tokenizer, skip_prompt=True)

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastapi/model_worker.py:181
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
180	                input_ids, parameters, request_id, inputs_embeds, inputs = \
181	                    await self.add_request(tokenizer)
182	                self.streamer[request_id] = TextIteratorStreamer(tokenizer, skip_prompt=True)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastapi/model_worker.py:209
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
208	            from threading import Thread
209	            t1 = Thread(target=model_generate)
210	            t1.start()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/ipex_llm_worker.py:347
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
346	
347	        t1 = Thread(target=model_generate)
348	        t1.start()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/ipex_llm_worker.py:437
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
436	    await acquire_worker_semaphore()
437	    output = await asyncio.to_thread(worker.generate_gate, params)
438	    release_worker_semaphore()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/ipex_llm_worker.py:476
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
475	    parser.add_argument("--port", type=int, default=21002)
476	    parser.add_argument("--worker-address", type=str, default="http://localhost:21002")
477	    parser.add_argument(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/ipex_llm_worker.py:478
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
477	    parser.add_argument(
478	        "--controller-address", type=str, default="http://localhost:21001"
479	    )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:113
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
112	        self.register_to_controller()
113	        self.heart_beat_thread = threading.Thread(
114	            target=heart_beat_worker, args=(self,)
115	        )

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:127
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
126	        }
127	        r = requests.post(url, json=data)
128	        invalidInputError(r.status_code == 200, "Error register to Controller")

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:142
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
141	            try:
142	                ret = requests.post(
143	                    url,
144	                    json={
145	                        "worker_name": self.worker_addr,
146	                        "queue_length": self.get_queue_length(),
147	                    },
148	                    timeout=5,
149	                )

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:394
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
393	
394	@app.post("/worker_generate_stream")
395	async def api_generate_stream(request: Request):

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:403
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
402	
403	@app.post("/worker_generate")
404	async def api_generate(request: Request):

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:412
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
411	
412	@app.post("/worker_get_embeddings")
413	async def api_get_embeddings(request: Request):

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:421
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
420	
421	@app.post("/worker_get_status")
422	async def api_get_status(request: Request):

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:426
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
425	
426	@app.post("/count_token")
427	async def api_count_token(request: Request):

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:432
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
431	
432	@app.post("/worker_get_conv_template")
433	async def api_get_conv(request: Request):

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:437
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
436	
437	@app.post("/model_details")
438	async def api_model_details(request: Request):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:447
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
446	    parser.add_argument("--port", type=int, default=21002)
447	    parser.add_argument("--worker-address", type=str, default="http://localhost:21002")
448	    parser.add_argument(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/model_worker.py:449
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
448	    parser.add_argument(
449	        "--controller-address", type=str, default="http://localhost:21001"
450	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/tgi_api_server.py:125
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
124	    # The address of the model controller.
125	    controller_address: str = "http://localhost:21001"
126	    api_keys: Optional[List[str]] = None

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/tgi_api_server.py:645
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
644	    parser.add_argument(
645	        "--controller-address", type=str, default="http://localhost:21001"
646	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/vllm_worker.py:271
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
270	    parser.add_argument("--port", type=int, default=21002)
271	    parser.add_argument("--worker-address", type=str, default="http://localhost:21002")
272	    parser.add_argument(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/serving/fastchat/vllm_worker.py:273
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
272	    parser.add_argument(
273	        "--controller-address", type=str, default="http://localhost:21001"
274	    )

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/baichuan.py:94
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
93	    with NamedTemporaryFile(delete=False) as f:
94	        f.write(proto)
95	        f.close()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/baichuan.py:94
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
93	    with NamedTemporaryFile(delete=False) as f:
94	        f.write(proto)
95	        f.close()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/llama.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
95	    with NamedTemporaryFile(delete=False) as f:
96	        f.write(proto)
97	        f.close()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/llama.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
95	    with NamedTemporaryFile(delete=False) as f:
96	        f.write(proto)
97	        f.close()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/mistral.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
96	    with NamedTemporaryFile(delete=False) as f:
97	        f.write(proto)
98	        f.close()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/mistral.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
96	    with NamedTemporaryFile(delete=False) as f:
97	        f.write(proto)
98	        f.close()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/mixtral.py:104
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
103	    with NamedTemporaryFile(delete=False) as f:
104	        f.write(proto)
105	        f.close()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/mixtral.py:104
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
103	    with NamedTemporaryFile(delete=False) as f:
104	        f.write(proto)
105	        f.close()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/model_implement/baichuan/tokenization_baichuan.py:173
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
172	                content_spiece_model = self.sp_model.serialized_model_proto()
173	                fi.write(content_spiece_model)
174	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/model_implement/yuan2/yuan_hf_model.py:455
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
454	
455	YUAN_START_DOCSTRING = r"""
456	    This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the
457	    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
458	    etc.)
459	    This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.
460	    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
461	    and behavior.
462	    Parameters:
463	        config ([`YuanConfig`]):
464	            Model configuration class with all the parameters of the model. Initializing with a config file does not
465	            load the weights associated with the model, only the configuration. Check out the
466	            [`~PreTrainedModel.from_pretrained`] method to load the model weights.
467	"""
468	
469	
470	@add_start_docstrings(
471	    "The bare Yuan Model outputting raw hidden-states without any specific head on top.",
472	   YUAN_START_DOCSTRING,
473	)
474	class YuanPreTrainedModel(PreTrainedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/model_implement/yuan2/yuan_hf_model.py:498
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
497	
498	YUAN_INPUTS_DOCSTRING = r"""
499	    Args:
500	        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):
501	            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide
502	            it.
503	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
504	            [`PreTrainedTokenizer.__call__`] for details.
505	            [What are input IDs?](../glossary#input-ids)
506	        attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):
507	            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:
508	            - 1 for tokens that are **not masked**,
509	            - 0 for tokens that are **masked**.
510	            [What are attention masks?](../glossary#attention-mask)
511	            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and
512	            [`PreTrainedTokenizer.__call__`] for details.
513	            If `past_key_values` is used, optionally only the last `decoder_input_ids` have to be input (see
514	            `past_key_values`).
515	            If you want to change padding behavior, you should read [`modeling_opt._prepare_decoder_attention_mask`]
516	            and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more
517	            information on the default strategy.
518	            - 1 indicates the head is **not masked**,
519	            - 0 indicates the head is **masked**.
520	        position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):
521	            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,
522	            config.n_positions - 1]`.
523	            [What are position IDs?](../glossary#position-ids)
524	        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):
525	            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape
526	            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape
527	            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.
528	            Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
529	            blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.
530	            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that
531	            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all
532	            `decoder_input_ids` of shape `(batch_size, sequence_length)`.
533	        inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):
534	            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This
535	            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the
536	            model's internal embedding lookup matrix.
537	        use_cache (`bool`, *optional*):
538	            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see
539	            `past_key_values`).
540	        output_attentions (`bool`, *optional*):
541	            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned
542	            tensors for more detail.
543	        output_hidden_states (`bool`, *optional*):
544	            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for
545	            more detail.
546	        return_dict (`bool`, *optional*):
547	            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.
548	"""
549	
550	
551	@add_start_docstrings(
552	    "The bare Yuan Model outputting raw hidden-states without any specific head on top.",
553	    YUAN_START_DOCSTRING,
554	)
555	class YuanModel(YuanPreTrainedModel):

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/yuan2.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
117	    with NamedTemporaryFile(delete=False) as f:
118	        f.write(proto)
119	        f.close()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/gguf/models/yuan2.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
117	    with NamedTemporaryFile(delete=False) as f:
118	        f.write(proto)
119	        f.close()

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/baichuan_mp.py:610
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
609	
610	    os.environ["MASTER_ADDR"] = "127.0.0.1"
611	    os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/baichuan_mp.py:749
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
748	        port = "54791"
749	        os.environ["MASTER_ADDR"] = "127.0.0.1"
750	        os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/baichuan_mp.py:766
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
765	                end_layer = num_layers
766	            p = mp.Process(
767	                target=run_decode,
768	                args=(
769	                    self.model,
770	                    rank,
771	                    world_size,
772	                    port,
773	                    start_layer,
774	                    end_layer,
775	                    intra_stages,
776	                    self.max_seq_len,
777	                    self.transpose_value_cache,
778	                    input_q,
779	                    output_q,
780	                ),

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/baichuan_mp.py:943
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
942	
943	        self.p = mp.Process(
944	            target=run_prefill,
945	            args=(
946	                model,
947	                max_output_len,
948	                max_prompt_len,
949	                transpose_value_cache,
950	                self.prefill_input_queue,
951	                self.prefill_result_queue,
952	            ),

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/llama_mp.py:542
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
541	
542	    os.environ["MASTER_ADDR"] = "127.0.0.1"
543	    os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/llama_mp.py:704
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
703	        port = "54791"
704	        os.environ["MASTER_ADDR"] = "127.0.0.1"
705	        os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/llama_mp.py:726
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
725	                end_layer = num_layers
726	            p = mp.Process(
727	                target=run_decode,
728	                args=(
729	                    self.model,
730	                    rank,
731	                    world_size,
732	                    port,
733	                    start_layer,
734	                    end_layer,
735	                    intra_stages,
736	                    self.max_seq_len,
737	                    self.transpose_value_cache,
738	                    input_q,
739	                    output_q,
740	                ),

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/llama_mp.py:930
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
929	
930	        self.p = mp.Process(
931	            target=run_prefill,
932	            args=(
933	                model,
934	                max_output_len,
935	                max_prompt_len,
936	                transpose_value_cache,
937	                self.prefill_input_queue,
938	                self.prefill_result_queue,
939	            ),

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/minicpm_mp.py:520
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
519	
520	    os.environ["MASTER_ADDR"] = "127.0.0.1"
521	    os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/minicpm_mp.py:668
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
667	        port = "54791"
668	        os.environ["MASTER_ADDR"] = "127.0.0.1"
669	        os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/minicpm_mp.py:685
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
684	                end_layer = num_layers
685	            p = mp.Process(
686	                target=run_decode,
687	                args=(
688	                    self.model,
689	                    rank,
690	                    world_size,
691	                    port,
692	                    start_layer,
693	                    end_layer,
694	                    intra_stages,
695	                    scale_depth,
696	                    self.max_seq_len,
697	                    self.transpose_value_cache,
698	                    input_q,
699	                    output_q,
700	                ),

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/minicpm_mp.py:868
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
867	
868	        self.p = mp.Process(
869	            target=run_prefill,
870	            args=(
871	                model,
872	                max_output_len,
873	                max_prompt_len,
874	                transpose_value_cache,
875	                self.prefill_input_queue,
876	                self.prefill_result_queue,
877	            ),

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/paraformer_mp.py:408
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
407	
408	        self.p = mp.Process(
409	            target=run_prefill,
410	            args=(
411	                model,
412	                max_output_len,
413	                max_prompt_len,
414	                transpose_value_cache,
415	                self.prefill_input_queue,
416	                self.prefill_result_queue,
417	            ),

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/paraformer_mp.py:748
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
747	
748	    os.environ["MASTER_ADDR"] = "127.0.0.1"
749	    os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/paraformer_mp.py:884
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
883	        port = "54791"
884	        os.environ["MASTER_ADDR"] = "127.0.0.1"
885	        os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/paraformer_mp.py:902
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
901	                end_layer = num_layers
902	            p = mp.Process(
903	                target=run_decode,
904	                args=(
905	                    self.model,
906	                    rank,
907	                    world_size,
908	                    port,
909	                    start_layer,
910	                    end_layer,
911	                    intra_stages,
912	                    self.max_seq_len,
913	                    self.transpose_value_cache,
914	                    input_q,
915	                    output_q,
916	                ),

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/qwen2_mp.py:576
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
575	
576	    os.environ["MASTER_ADDR"] = "127.0.0.1"
577	    os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/qwen2_mp.py:734
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
733	        port = "54791"
734	        os.environ["MASTER_ADDR"] = "127.0.0.1"
735	        os.environ["MASTER_PORT"] = port

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/qwen2_mp.py:756
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
755	                end_layer = num_layers
756	            p = mp.Process(
757	                target=run_decode,
758	                args=(
759	                    self.model,
760	                    rank,
761	                    world_size,
762	                    port,
763	                    start_layer,
764	                    end_layer,
765	                    intra_stages,
766	                    self.max_seq_len,
767	                    self.transpose_value_cache,
768	                    input_q,
769	                    output_q,
770	                ),

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/qwen2_mp.py:936
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
935	
936	        self.p = mp.Process(
937	            target=run_prefill,
938	            args=(
939	                model,
940	                max_output_len,
941	                max_prompt_len,
942	                transpose_value_cache,
943	                self.prefill_input_queue,
944	                self.prefill_result_queue,
945	            ),

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_models/xlm_mp.py:510
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
509	
510	        self.p = mp.Process(
511	            target=run_prefill,
512	            args=(
513	                model,
514	                max_output_len,
515	                max_prompt_len,
516	                transpose_value_cache,
517	                self.prefill_input_queue,
518	                self.prefill_result_queue,
519	            ),

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/common.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
62	        with open(blob_path, 'wb') as f:
63	            f.write(model_stream)
64	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
116	        # start generate_serve by Thread
117	        thread = threading.Thread(target=generate_serve,
118	                                  args=(self.kv_len, self.num_head,
119	                                        self.head_dim, self.num_layers,
120	                                        self.vocab_size,
121	                                        self.transpose_value_cache,
122	                                        new_tokens))
123	        thread.start()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:150
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
149	                          "which may cause read error.")
150	        input_pipe.write(bdata)
151	        input_pipe.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:150
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
149	                          "which may cause read error.")
150	        input_pipe.write(bdata)
151	        input_pipe.flush()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:155
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
154	        while True:
155	            data = output_pipe.read(buffersize)
156	            if len(data) == 0:

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:244
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
243	                                   const_parameter))
244	            with Pool() as pool:
245	                result = pool.starmap(convert_llama_layer, param_list)

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:244
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
243	                                   const_parameter))
244	            with Pool() as pool:
245	                result = pool.starmap(convert_llama_layer, param_list)

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:288
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
287	                                  const_parameter))
288	            with Pool() as pool:
289	                result = pool.starmap(convert_baichuan_layer, param_list)

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:288
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
287	                                  const_parameter))
288	            with Pool() as pool:
289	                result = pool.starmap(convert_baichuan_layer, param_list)

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:329
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
328	                                   const_parameter))
329	            with Pool() as pool:
330	                result = pool.starmap(convert_minicpm_layer, param_list)

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:329
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
328	                                   const_parameter))
329	            with Pool() as pool:
330	                result = pool.starmap(convert_minicpm_layer, param_list)

--------------------------------------------------
>> Issue: [B839:pool] multiprocessing.Pool
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:375
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b839_pool.html
374	                                  const_parameter))
375	            with Pool() as pool:
376	                result = pool.starmap(convert_qwen_layer, param_list)

--------------------------------------------------
>> Issue: [B323:blacklist] multiprocessing_Pool
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py:375
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b323-multiprocessing-pool
374	                                  const_parameter))
375	            with Pool() as pool:
376	                result = pool.starmap(convert_qwen_layer, param_list)

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/pipeline_parallel.py:110
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
109	    import oneccl_bindings_for_pytorch
110	    os.environ["MASTER_ADDR"] = os.environ.get("MASTER_ADDR", "127.0.0.1")
111	    os.environ["MASTER_PORT"] = os.environ.get("MASTER_PORT", "29500")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/utils.py:121
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
120	    with open(index_filename, "r") as f:
121	        index = json.loads(f.read())
122	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/utils.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
189	    imatrix = open(imatrix_file, 'rb')
190	    n_entries = imatrix.read(4)
191	    n_entries = int.from_bytes(n_entries, 'little')

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/utils.py:196
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
195	    for i in range(n_entries):
196	        cur_len = imatrix.read(4)
197	        cur_len = int.from_bytes(cur_len, 'little')

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/utils.py:198
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
197	        cur_len = int.from_bytes(cur_len, 'little')
198	        cur_name = str(imatrix.read(cur_len), encoding='utf-8')
199	        # cur_name looks like blk.14.attn_output.weight for llama / mistral,

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/utils.py:217
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
216	            module_name += '_' + exp_id
217	        ncall = imatrix.read(4)
218	        ncall = int.from_bytes(ncall, 'little')

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/utils.py:219
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
218	        ncall = int.from_bytes(ncall, 'little')
219	        nval = imatrix.read(4)
220	        nval = int.from_bytes(nval, 'little')

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/transformers/utils.py:223
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
222	                          f"failed reading number of values for entry {i}")
223	        byte_data = imatrix.read(4 * nval)
224	        idata = np.frombuffer(byte_data, dtype=np.float32)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_29.py:581
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
580	                    raise ValueError(
581	                        f"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} "
582	                        "doesn't have its forwarding implemented. See the GPT2 implementation for an example "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_29.py:1296
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1295	                    warnings.warn(
1296	                        "You have modified the pretrained model configuration to control generation. This is a"
1297	                        " deprecated strategy to control generation and will be removed soon, in a future version."
1298	                        " Please use a generation configuration file (see"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_29.py:1403
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1402	                logger.warning(
1403	                    f"Both `max_new_tokens` (={generation_config.max_new_tokens}) and `max_length`(="
1404	                    f"{generation_config.max_length}) seem to have been set. `max_new_tokens` will take precedence. "
1405	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_42.py:454
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
453	                    raise ValueError(
454	                        f"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} "
455	                        "doesn't have its forwarding implemented. See the GPT2 implementation for an example "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_42.py:1339
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1338	                logger.warning(
1339	                    f"Both `max_new_tokens` (={generation_config.max_new_tokens}) and `max_length`(="
1340	                    f"{generation_config.max_length}) seem to have been set. `max_new_tokens` will take precedence. "
1341	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_42.py:1359
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1358	                logger.warning(
1359	                    f"Both `min_new_tokens` (={generation_config.min_new_tokens}) and `min_length`(="
1360	                    f"{generation_config.min_length}) seem to have been set. `min_new_tokens` will take precedence. "
1361	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_42.py:1402
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1401	                    warnings.warn(
1402	                        "You have modified the pretrained model configuration to control generation. This is a"
1403	                        " deprecated strategy to control generation and will be removed soon, in a future version."
1404	                        " Please use and modify the model generation configuration (see"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_42.py:1783
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1782	                    raise ValueError(
1783	                        "This model does not support `cache_implementation='static'`. Please check the following "
1784	                        "issue: https://github.com/huggingface/transformers/issues/28981"
1785	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_43.py:462
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
461	                    raise ValueError(
462	                        f"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} "
463	                        "doesn't have its forwarding implemented. See the GPT2 implementation for an example "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_43.py:1356
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1355	                logger.warning(
1356	                    f"Both `max_new_tokens` (={generation_config.max_new_tokens}) and `max_length`(="
1357	                    f"{generation_config.max_length}) seem to have been set. `max_new_tokens` will take precedence. "
1358	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_43.py:1376
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1375	                logger.warning(
1376	                    f"Both `min_new_tokens` (={generation_config.min_new_tokens}) and `min_length`(="
1377	                    f"{generation_config.min_length}) seem to have been set. `min_new_tokens` will take precedence. "
1378	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_43.py:1421
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1420	                    warnings.warn(
1421	                        "You have modified the pretrained model configuration to control generation. This is a"
1422	                        " deprecated strategy to control generation and will be removed soon, in a future version."
1423	                        " Please use and modify the model generation configuration (see"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_43.py:1831
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1830	                    raise ValueError(
1831	                        "This model does not support `cache_implementation='static'`. Please check the following "
1832	                        "issue: https://github.com/huggingface/transformers/issues/28981"
1833	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_44.py:464
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
463	                    raise ValueError(
464	                        f"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} "
465	                        "doesn't have its forwarding implemented. See the GPT2 implementation for an example "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_44.py:1349
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1348	                logger.warning(
1349	                    f"Both `max_new_tokens` (={generation_config.max_new_tokens}) and `max_length`(="
1350	                    f"{generation_config.max_length}) seem to have been set. `max_new_tokens` will take precedence. "
1351	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_44.py:1369
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1368	                logger.warning(
1369	                    f"Both `min_new_tokens` (={generation_config.min_new_tokens}) and `min_length`(="
1370	                    f"{generation_config.min_length}) seem to have been set. `min_new_tokens` will take precedence. "
1371	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_44.py:1414
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1413	                    warnings.warn(
1414	                        "You have modified the pretrained model configuration to control generation. This is a"
1415	                        " deprecated strategy to control generation and will be removed soon, in a future version."
1416	                        " Please use and modify the model generation configuration (see"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_44.py:1857
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1856	                    raise ValueError(
1857	                        "This model does not support `cache_implementation='static'`. Please check the following "
1858	                        "issue: https://github.com/huggingface/transformers/issues/28981"
1859	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_45.py:434
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
433	                    raise ValueError(
434	                        f"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} "
435	                        "doesn't have its forwarding implemented. See the GPT2 implementation for an example "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_45.py:1316
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1315	                logger.warning(
1316	                    f"Both `max_new_tokens` (={generation_config.max_new_tokens}) and `max_length`(="
1317	                    f"{generation_config.max_length}) seem to have been set. `max_new_tokens` will take precedence. "
1318	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_45.py:1336
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1335	                logger.warning(
1336	                    f"Both `min_new_tokens` (={generation_config.min_new_tokens}) and `min_length`(="
1337	                    f"{generation_config.min_length}) seem to have been set. `min_new_tokens` will take precedence. "
1338	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_45.py:1382
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1381	                    warnings.warn(
1382	                        "You have modified the pretrained model configuration to control generation. This is a"
1383	                        " deprecated strategy to control generation and will be removed in v5."
1384	                        " Please use and modify the model generation configuration (see"
1385	                        " https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )",
1386	                        UserWarning,
1387	                    )
1388	                    self.generation_config = new_generation_config

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_45.py:1606
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1605	                    raise ValueError(
1606	                        "This model does not support `cache_implementation='static'`. Please check the following "
1607	                        "issue: https://github.com/huggingface/transformers/issues/28981"
1608	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_47.py:572
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
571	                    raise ValueError(
572	                        f"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} "
573	                        "doesn't have its forwarding implemented. See the GPT2 implementation for an example "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_47.py:1368
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1367	        doc_reference = (
1368	            "(see https://huggingface.co/docs/transformers/en/generation_strategies#universal-assisted-decoding)"
1369	        )
1370	        if self.config.get_text_config().vocab_size == assistant_model.config.get_text_config().vocab_size:
1371	            if assistant_tokenizer is not None:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_47.py:1504
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1503	                logger.warning(
1504	                    f"Both `max_new_tokens` (={generation_config.max_new_tokens}) and `max_length`(="
1505	                    f"{generation_config.max_length}) seem to have been set. `max_new_tokens` will take precedence. "
1506	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_47.py:1530
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1529	                logger.warning(
1530	                    f"Both `min_new_tokens` (={generation_config.min_new_tokens}) and `min_length`(="
1531	                    f"{generation_config.min_length}) seem to have been set. `min_new_tokens` will take precedence. "
1532	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_47.py:1576
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1575	                    warnings.warn(
1576	                        "You have modified the pretrained model configuration to control generation. This is a"
1577	                        " deprecated strategy to control generation and will be removed in v5."
1578	                        " Please use and modify the model generation configuration (see"
1579	                        " https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )",
1580	                        UserWarning,
1581	                    )
1582	                    self.generation_config = new_generation_config

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_4_47.py:1813
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1812	                    raise ValueError(
1813	                        "This model does not support `cache_implementation='static'`. Please check the following "
1814	                        "issue: https://github.com/huggingface/transformers/issues/28981"
1815	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_deepseek.py:572
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
571	                    raise ValueError(
572	                        f"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} "
573	                        "doesn't have its forwarding implemented. See the GPT2 implementation for an example "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_deepseek.py:1368
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1367	        doc_reference = (
1368	            "(see https://huggingface.co/docs/transformers/en/generation_strategies#universal-assisted-decoding)"
1369	        )
1370	        if self.config.get_text_config().vocab_size == assistant_model.config.get_text_config().vocab_size:
1371	            if assistant_tokenizer is not None:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_deepseek.py:1504
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1503	                logger.warning(
1504	                    f"Both `max_new_tokens` (={generation_config.max_new_tokens}) and `max_length`(="
1505	                    f"{generation_config.max_length}) seem to have been set. `max_new_tokens` will take precedence. "
1506	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_deepseek.py:1530
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1529	                logger.warning(
1530	                    f"Both `min_new_tokens` (={generation_config.min_new_tokens}) and `min_length`(="
1531	                    f"{generation_config.min_length}) seem to have been set. `min_new_tokens` will take precedence. "
1532	                    "Please refer to the documentation for more information. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_deepseek.py:1576
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1575	                    warnings.warn(
1576	                        "You have modified the pretrained model configuration to control generation. This is a"
1577	                        " deprecated strategy to control generation and will be removed in v5."
1578	                        " Please use and modify the model generation configuration (see"
1579	                        " https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )",
1580	                        UserWarning,
1581	                    )
1582	                    self.generation_config = new_generation_config

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/benchmark_util_deepseek.py:1813
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1812	                    raise ValueError(
1813	                        "This model does not support `cache_implementation='static'`. Please check the following "
1814	                        "issue: https://github.com/huggingface/transformers/issues/28981"
1815	                    )

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_chatglm.py:68
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
67	
68	if platform.system() == "Darwin":
69	    # cpm_kernels doesn't support macOS but transformers will check missing packages, so mock it

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_chatglm.py:68
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
67	
68	if platform.system() == "Darwin":
69	    # cpm_kernels doesn't support macOS but transformers will check missing packages, so mock it

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:314
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
313	        if self.vocabtype == "bpe":
314	            self.sentencepiece_tokenizer = json.loads(open(str(fname_tokenizer)).read())
315	        else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:742
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
741	            if self.data_type.have_g_idx:
742	                sys.stderr.write(
743	                    "Error: Input uses the newer GPTQ-for-LLaMa format (using g_idx), "
744	                    "which is not yet natively supported by GGML. For now "

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:961
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
960	            size = elm_count * dtype.itemsize
961	            data = fp.read(size)
962	            invalidInputError(len(data) == size, "Fail to load.")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1023
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1022	def lazy_load_safetensors_file(fp: IO[bytes], path: Path) -> ModelPlus:
1023	    header_size, = struct.unpack('<Q', fp.read(8))
1024	    header = json.loads(fp.read(header_size))

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1024
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1023	    header_size, = struct.unpack('<Q', fp.read(8))
1024	    header = json.loads(fp.read(header_size))
1025	    # Use mmap for the actual data to avoid race conditions with the file offset.

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1048
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1047	def must_read(fp: IO[bytes], length: int) -> bytes:
1048	    ret = fp.read(length)
1049	    invalidInputError(len(ret) >= length, "Unexpectedly reached end of file.")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1054
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1053	def lazy_load_ggml_file(fp: io.BufferedReader, path: Path) -> ModelPlus:
1054	    magic = must_read(fp, 4)[::-1]
1055	    if magic in (b'ggmf', b'ggjt'):

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1056
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1055	    if magic in (b'ggmf', b'ggjt'):
1056	        version, = struct.unpack("i", must_read(fp, 4))
1057	        invalidInputError(version == 1, "Fail to load ggml files.")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1062
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1061	    n_vocab, n_embd, n_mult, n_head, n_layer, rot, file_type = \
1062	        struct.unpack('<7i', must_read(fp, 28))
1063	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1074
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1073	            fp.seek(20, io.SEEK_CUR)
1074	            is_gpt4all = fp.read(21) == b'tok_embeddings.weight'
1075	            fp.seek(orig_pos)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1079
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1078	
1079	        length, = struct.unpack("i", must_read(fp, 4))
1080	        text = must_read(fp, length)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1080
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1079	        length, = struct.unpack("i", must_read(fp, 4))
1080	        text = must_read(fp, length)
1081	        if magic != b'ggml':

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1082
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1081	        if magic != b'ggml':
1082	            score, = struct.unpack("f", must_read(fp, 4))
1083	            tokens.append((text, score))

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1095
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1094	        # this is a function so that variables captured in `load` don't change
1095	        shape_len, name_len, ftype = struct.unpack("iii", must_read(fp, 12))
1096	        invalidInputError(0 <= shape_len <= 3, "Fail to read tensors.")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1097
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1096	        invalidInputError(0 <= shape_len <= 3, "Fail to read tensors.")
1097	        shape = list(struct.unpack(f"{shape_len}i", must_read(fp, 4 * shape_len)))
1098	        shape = shape[::-1]

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1099
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1098	        shape = shape[::-1]
1099	        name = must_read(fp, name_len).decode('utf-8')
1100	        data_type = FTYPE_TO_DATA_TYPE[ftype]

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1127
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1126	
1127	    while fp.read(1) != b'':
1128	        fp.seek(-1, io.SEEK_CUR)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1137
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1136	    fp = open(path, 'rb')
1137	    first8 = fp.read(8)
1138	    fp.seek(0)

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1162
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
1161	    output value buffered per thread.'''
1162	    with concurrent.futures.ThreadPoolExecutor() as executor:
1163	        futures = []

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1200
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1199	    def write_file_header(self, params: Params, file_type: GGMLFileType) -> None:
1200	        self.fout.write(b"ggjt"[::-1])  # magic
1201	        values = [

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1211
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1210	        ]
1211	        self.fout.write(struct.pack("i" * len(values), *values))
1212	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1215
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1214	        sname = name.encode('utf-8')
1215	        self.fout.write(struct.pack("iii", len(shape), len(sname), DATA_TYPE_TO_FTYPE[data_type]))
1216	        self.fout.write(struct.pack("i" * len(shape), *shape[::-1]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1216
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1215	        self.fout.write(struct.pack("iii", len(shape), len(sname), DATA_TYPE_TO_FTYPE[data_type]))
1216	        self.fout.write(struct.pack("i" * len(shape), *shape[::-1]))
1217	        self.fout.write(sname)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1217
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1216	        self.fout.write(struct.pack("i" * len(shape), *shape[::-1]))
1217	        self.fout.write(sname)
1218	        self.fout.seek((self.fout.tell() + 31) & -32)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1222
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1221	        for text, score in vocab.all_tokens():
1222	            self.fout.write(struct.pack("i", len(text)))
1223	            self.fout.write(text)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1223
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1222	            self.fout.write(struct.pack("i", len(text)))
1223	            self.fout.write(text)
1224	            self.fout.write(struct.pack("f", score))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1224
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1223	            self.fout.write(text)
1224	            self.fout.write(struct.pack("f", score))
1225	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1398
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1397	    if ret in model_paths:
1398	        sys.stderr.write(
1399	            f"Error: Default output path ({ret}) would overwrite the input. "
1400	            "Please explicitly specify a path using --outfile.\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1455
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1454	    hparams["multiple_of"] = 1
1455	    fout.write(struct.pack("i", ggml_file_magic))  # magic: ggmf in hex
1456	    fout.write(struct.pack("i", ggml_file_version))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1456
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1455	    fout.write(struct.pack("i", ggml_file_magic))  # magic: ggmf in hex
1456	    fout.write(struct.pack("i", ggml_file_version))
1457	    fout.write(struct.pack("i", hparams["vocab_size"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1457
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1456	    fout.write(struct.pack("i", ggml_file_version))
1457	    fout.write(struct.pack("i", hparams["vocab_size"]))
1458	    fout.write(struct.pack("i", hparams["max_position_embeddings"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1458
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1457	    fout.write(struct.pack("i", hparams["vocab_size"]))
1458	    fout.write(struct.pack("i", hparams["max_position_embeddings"]))
1459	    fout.write(struct.pack("i", hparams["hidden_size"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1459
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1458	    fout.write(struct.pack("i", hparams["max_position_embeddings"]))
1459	    fout.write(struct.pack("i", hparams["hidden_size"]))
1460	    fout.write(struct.pack("i", hparams["num_attention_heads"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1460
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1459	    fout.write(struct.pack("i", hparams["hidden_size"]))
1460	    fout.write(struct.pack("i", hparams["num_attention_heads"]))
1461	    fout.write(struct.pack("i", hparams["num_hidden_layers"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1461
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1460	    fout.write(struct.pack("i", hparams["num_attention_heads"]))
1461	    fout.write(struct.pack("i", hparams["num_hidden_layers"]))
1462	    fout.write(struct.pack("i", int((hparams["hidden_size"] / hparams["num_attention_heads"])

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1462
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1461	    fout.write(struct.pack("i", hparams["num_hidden_layers"]))
1462	    fout.write(struct.pack("i", int((hparams["hidden_size"] / hparams["num_attention_heads"])
1463	                                    * hparams["rotary_pct"])))  # rotary_dim
1464	    fout.write(struct.pack("i", int(hparams["use_parallel_residual"])))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1464
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1463	                                    * hparams["rotary_pct"])))  # rotary_dim
1464	    fout.write(struct.pack("i", int(hparams["use_parallel_residual"])))
1465	    fout.write(struct.pack("i", ftype))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1465
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1464	    fout.write(struct.pack("i", int(hparams["use_parallel_residual"])))
1465	    fout.write(struct.pack("i", ftype))
1466	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1475
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1474	            text = tokenizer.decode([i]).encode('utf-8')
1475	        fout.write(struct.pack("i", len(text)))
1476	        fout.write(text)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1476
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1475	        fout.write(struct.pack("i", len(text)))
1476	        fout.write(text)
1477	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1505
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1504	        str = name.encode('utf-8')
1505	        fout.write(struct.pack("iii", n_dims, len(str), ftype_cur))
1506	        for i in range(n_dims):

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1507
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1506	        for i in range(n_dims):
1507	            fout.write(struct.pack("i", data.shape[n_dims - 1 - i]))
1508	        fout.write(str)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1508
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1507	            fout.write(struct.pack("i", data.shape[n_dims - 1 - i]))
1508	        fout.write(str)
1509	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1549
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1548	    hparams["multiple_of"] = 1
1549	    fout.write(struct.pack("i", 0x67676d6c))  # magic: ggml in hex
1550	    fout.write(struct.pack("i", hparams["vocab_size"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1550
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1549	    fout.write(struct.pack("i", 0x67676d6c))  # magic: ggml in hex
1550	    fout.write(struct.pack("i", hparams["vocab_size"]))
1551	    # fout.write(struct.pack("i", hparams["seq_length"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1552
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1551	    # fout.write(struct.pack("i", hparams["seq_length"]))
1552	    fout.write(struct.pack("i", hparams["hidden_size"]))
1553	    fout.write(struct.pack("i", hparams["multiple_of"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1553
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1552	    fout.write(struct.pack("i", hparams["hidden_size"]))
1553	    fout.write(struct.pack("i", hparams["multiple_of"]))
1554	    fout.write(struct.pack("i", hparams["n_head"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1554
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1553	    fout.write(struct.pack("i", hparams["multiple_of"]))
1554	    fout.write(struct.pack("i", hparams["n_head"]))
1555	    fout.write(struct.pack("i", hparams["n_layer"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1555
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1554	    fout.write(struct.pack("i", hparams["n_head"]))
1555	    fout.write(struct.pack("i", hparams["n_layer"]))
1556	    fout.write(struct.pack("i", ftype))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1556
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1555	    fout.write(struct.pack("i", hparams["n_layer"]))
1556	    fout.write(struct.pack("i", ftype))
1557	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1561
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1560	        text = tokenizer.decode([i]).encode('utf-8')
1561	        fout.write(struct.pack("i", len(text)))
1562	        fout.write(text)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1562
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1561	        fout.write(struct.pack("i", len(text)))
1562	        fout.write(text)
1563	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1598
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1597	        str = name.encode('utf-8')
1598	        fout.write(struct.pack("iii", n_dims, len(str), ftype_cur))
1599	        for i in range(n_dims):

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1600
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1599	        for i in range(n_dims):
1600	            fout.write(struct.pack("i", data.shape[n_dims - 1 - i]))
1601	        fout.write(str)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1601
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1600	            fout.write(struct.pack("i", data.shape[n_dims - 1 - i]))
1601	        fout.write(str)
1602	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1637
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1636	
1637	    fout.write(struct.pack("i", 0x67676d6c))  # magic: ggml in hex
1638	    vocab_size = hparams["vocab_size"]

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1639
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1638	    vocab_size = hparams["vocab_size"]
1639	    fout.write(struct.pack("i", vocab_size))
1640	    # fout.write(struct.pack("i", len(encoder)))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1641
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1640	    # fout.write(struct.pack("i", len(encoder)))
1641	    fout.write(struct.pack("i", hparams["n_positions"]))
1642	    fout.write(struct.pack("i", hparams["n_embd"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1642
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1641	    fout.write(struct.pack("i", hparams["n_positions"]))
1642	    fout.write(struct.pack("i", hparams["n_embd"]))
1643	    fout.write(struct.pack("i", hparams["n_head"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1643
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1642	    fout.write(struct.pack("i", hparams["n_embd"]))
1643	    fout.write(struct.pack("i", hparams["n_head"]))
1644	    fout.write(struct.pack("i", hparams["n_layer"]))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1644
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1643	    fout.write(struct.pack("i", hparams["n_head"]))
1644	    fout.write(struct.pack("i", hparams["n_layer"]))
1645	    fout.write(struct.pack("i", ftype))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1645
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1644	    fout.write(struct.pack("i", hparams["n_layer"]))
1645	    fout.write(struct.pack("i", ftype))
1646	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1650
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1649	
1650	    fout.write(struct.pack("i", vocab_size))
1651	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1656
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1655	        text = bytearray([byte_decoder[c] for c in key])
1656	        fout.write(struct.pack("i", len(text)))
1657	        fout.write(text)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1657
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1656	        fout.write(struct.pack("i", len(text)))
1657	        fout.write(text)
1658	        counter += 1

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1662
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1661	    while counter < vocab_size:
1662	        fout.write(struct.pack("i", len(text)))
1663	        fout.write(text)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1663
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1662	        fout.write(struct.pack("i", len(text)))
1663	        fout.write(text)
1664	        counter += 1

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1768
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1767	        str = name.encode('utf-8')
1768	        fout.write(struct.pack("iii", n_dims, len(str), ftype_cur))
1769	        for i in range(n_dims):

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1770
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1769	        for i in range(n_dims):
1770	            fout.write(struct.pack("i", data.shape[n_dims - 1 - i]))
1771	        fout.write(str)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/convert_util.py:1771
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
1770	            fout.write(struct.pack("i", data.shape[n_dims - 1 - i]))
1771	        fout.write(str)
1772	

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/glibc_checker.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
29	    def is_linux():
30	        return platform.system() == "Linux"
31	

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/glibc_checker.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
29	    def is_linux():
30	        return platform.system() == "Linux"
31	

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/utils/glibc_checker.py:30
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
29	    def is_linux():
30	        return platform.system() == "Linux"
31	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/engine/engine.py:241
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
240	    try:
241	        signal.signal(signal.SIGTERM, signal_handler)
242	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/engine/engine.py:241
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
240	    try:
241	        signal.signal(signal.SIGTERM, signal_handler)
242	

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/api_server.py:200
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
199	        engine_alive = multiprocessing.Value('b', True, lock=False)
200	        engine_process = context.Process(target=run_mp_engine,
201	                                         args=(engine_args,
202	                                               UsageContext.OPENAI_API_SERVER,
203	                                               ipc_path, load_in_low_bit, engine_alive))
204	        engine_process.start()

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/api_server.py:241
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
240	            # Close all open connections to the backend
241	            mq_engine_client.close()
242	

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/api_server.py:712
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
711	
712	    sock = socket.socket(family=family, type=socket.SOCK_STREAM)
713	    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/api_server.py:746
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
745	
746	    signal.signal(signal.SIGTERM, signal_handler)
747	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/api_server.py:746
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
745	
746	    signal.signal(signal.SIGTERM, signal_handler)
747	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/api_server.py:770
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
769	
770	    sock.close()
771	

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/openai/api_server.py:194
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
193	        engine_alive = multiprocessing.Value('b', True, lock=False)
194	        engine_process = context.Process(target=run_mp_engine,
195	                                         args=(engine_args,
196	                                               UsageContext.OPENAI_API_SERVER,
197	                                               ipc_path, load_in_low_bit, engine_alive))
198	        engine_process.start()

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/openai/api_server.py:235
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
234	            # Close all open connections to the backend
235	            mq_engine_client.close()
236	

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/openai/api_server.py:706
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
705	
706	    sock = socket.socket(family=family, type=socket.SOCK_STREAM)
707	    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/openai/api_server.py:740
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
739	
740	    signal.signal(signal.SIGTERM, signal_handler)
741	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/openai/api_server.py:740
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
739	
740	    signal.signal(signal.SIGTERM, signal_handler)
741	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/cpu/entrypoints/openai/api_server.py:764
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
763	
764	    sock.close()
765	

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/xpu/engine/engine.py:232
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
231	    try:
232	        signal.signal(signal.SIGTERM, signal_handler)
233	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/xpu/engine/engine.py:232
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
231	    try:
232	        signal.signal(signal.SIGTERM, signal_handler)
233	

--------------------------------------------------
>> Issue: [B838:process] multiprocessing.Process
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/xpu/entrypoints/openai/api_server.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b838_process.html
189	        engine_alive = multiprocessing.Value('b', True, lock=False)
190	        engine_process = context.Process(target=run_mp_engine,
191	                                         args=(engine_args,
192	                                               UsageContext.OPENAI_API_SERVER,
193	                                               ipc_path, load_in_low_bit, engine_alive))
194	        engine_process.start()

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/xpu/entrypoints/openai/api_server.py:231
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
230	            # Close all open connections to the backend
231	            mq_engine_client.close()
232	

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/xpu/entrypoints/openai/api_server.py:829
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
828	
829	    sock = socket.socket(family=family, type=socket.SOCK_STREAM)
830	    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/xpu/entrypoints/openai/api_server.py:863
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
862	
863	    signal.signal(signal.SIGTERM, signal_handler)
864	

--------------------------------------------------
>> Issue: [B324:blacklist] signal_signal
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/xpu/entrypoints/openai/api_server.py:863
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b324-signal-signal
862	
863	    signal.signal(signal.SIGTERM, signal_handler)
864	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/ipex_llm-2.3.0b20250410-py3-none-win_amd64/ipex_llm/vllm/xpu/entrypoints/openai/api_server.py:887
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
886	
887	    sock.close()
888	

--------------------------------------------------

Code scanned:
	Total lines of code: 73466
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 70.0
		High: 158.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 214.0
		High: 14.0
Files skipped (0):
