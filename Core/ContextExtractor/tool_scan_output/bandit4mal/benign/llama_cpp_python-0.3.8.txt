Run started:2025-04-12 10:58:01.938952

Test results:
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:9
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
8	    print(f"Making request to {url}...")
9	    response = requests.get(url, params=params)
10	    if response.status_code == 200:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
18	        # Read the first 6 bytes from the file
19	        data = f.read(6)
20	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
30	    print(f"Downloading {url} to {destination}...")
31	    response = requests.get(url, stream=True)
32	    if response.status_code == 200:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
36	                if chunk:  # filter out keep-alive new chunks
37	                    f.write(chunk)
38	                    total_downloaded += len(chunk)

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:99
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
98	
99	    models = make_request('https://huggingface.co/api/models', params=params)
100	    if models is None:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:99
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
98	
99	    models = make_request('https://huggingface.co/api/models', params=params)
100	    if models is None:

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:107
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
106	        model_id = model['id']
107	        model_info = make_request(f'https://huggingface.co/api/models/{model_id}')
108	        if model_info is None:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:107
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
106	        model_id = model['id']
107	        model_info = make_request(f'https://huggingface.co/api/models/{model_id}')
108	        if model_info is None:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
110	
111	        for sibling in model_info.get('siblings', []):
112	            rfilename = sibling.get('rfilename')

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
111	        for sibling in model_info.get('siblings', []):
112	            rfilename = sibling.get('rfilename')
113	            if rfilename and args.filename in rfilename:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/docker/open_llama/hug_model.py:128
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
127	        model_id, rfilename = model_choice
128	        url = f"https://huggingface.co/{model_id}/resolve/main/{rfilename}"
129	        dest = f"{model_id.replace('/', '_')}_{rfilename}"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/examples/gradio_chat/server.py:5
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4	
5	client = OpenAI(base_url="http://localhost:8000/v1", api_key="llama.cpp")
6	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/examples/low_level_api/low_level_api_chat_cpp.py:143
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
142	            with open(self.params.file) as f:
143	                self.params.prompt = f.read()
144	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/examples/ray/llm.py:16
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
15	        prompt = input_json["prompt"]
16	        max_tokens = input_json.get("max_tokens", 64)
17	        return self._llm(prompt, max_tokens=max_tokens)

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/_ctypes_extensions.py:67
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
66	            try:
67	                return ctypes.CDLL(str(lib_path), **cdll_args)  # type: ignore
68	            except Exception as e:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_chat_format.py:1117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1116	) -> ChatFormatterResponse:
1117	    _system_message = """You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.
1118	Always answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.
1119	If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.
1120	You can speak fluently in many languages, for example: English, Chinese.
1121	You cannot access the internet, but you have vast knowledge, cutoff: 2021-09.
1122	You are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.
1123	
1124	"""
1125	    _roles = dict(user="User", assistant="Assistant")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_chat_format.py:1787
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1786	        tokenizer, "hf_tokenizer"
1787	    ), "Please provide a valid hf_tokenizer_path from https://huggingface.co/meetkai when initializing the Llama class"
1788	    from transformers import AutoTokenizer
1789	
1790	    if "<|START_OF_FUNCTION_CALL|>" in tokenizer.hf_tokenizer.additional_special_tokens:

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_chat_format.py:2947
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
2946	
2947	            image_bytes = base64.b64decode(image_url.split(",")[1])
2948	            return image_bytes

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_chat_format.py:2947
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
2946	
2947	            image_bytes = base64.b64decode(image_url.split(",")[1])
2948	            return image_bytes

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_chat_format.py:2952
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
2951	
2952	            with urllib.request.urlopen(image_url) as f:
2953	                image_bytes = f.read()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_chat_format.py:2953
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
2952	            with urllib.request.urlopen(image_url) as f:
2953	                image_bytes = f.read()
2954	                return image_bytes

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:461
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
460	
461	                        target = self._refs.get(base_url)
462	                        if target is None:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:464
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
463	                            target = self.resolve_refs(
464	                                requests.get(ref).json(), base_url
465	                            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:631
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
630	                    if not sub_is_literal:
631	                        id = sub_rule_ids.get(sub)
632	                        if id is None:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:698
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
697	    def visit(self, schema, name):
698	        schema_type = schema.get("type")
699	        schema_format = schema.get("format")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:699
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
698	        schema_type = schema.get("type")
699	        schema_format = schema.get("format")
700	        rule_name = name + "-" if name in RESERVED_NAMES else name or "root"

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:702
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
701	
702	        if (ref := schema.get("$ref")) is not None:
703	            return self._add_rule(rule_name, self._resolve_ref(ref))

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:708
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
707	                rule_name,
708	                self._generate_union_rule(name, schema.get("oneOf") or schema["anyOf"]),
709	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:733
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
732	        ):
733	            required = set(schema.get("required", []))
734	            properties = list(schema.get("properties", {}).items())

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:734
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
733	            required = set(schema.get("required", []))
734	            properties = list(schema.get("properties", {}).items())
735	            return self._add_rule(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:738
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
737	                self._build_object_rule(
738	                    properties, required, name, schema.get("additionalProperties")
739	                ),

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:748
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
747	            def add_component(comp_schema, is_required):
748	                if (ref := comp_schema.get("$ref")) is not None:
749	                    comp_schema = self._refs[ref]

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:774
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
773	        ):
774	            items = schema.get("items") or schema["prefixItems"]
775	            if isinstance(items, list):

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:787
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
786	                item_rule_name = self.visit(items, f'{name}{"-" if name else ""}item')
787	                min_items = schema.get("minItems", 0)
788	                max_items = schema.get("maxItems")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:788
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
787	                min_items = schema.get("minItems", 0)
788	                max_items = schema.get("maxItems")
789	                return self._add_rule(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:823
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
822	            char_rule = self._add_primitive("char", PRIMITIVE_RULES["char"])
823	            min_len = schema.get("minLength", 0)
824	            max_len = schema.get("maxLength")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:824
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
823	            min_len = schema.get("minLength", 0)
824	            max_len = schema.get("maxLength")
825	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:850
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
849	        for dep in rule.deps:
850	            dep_rule = PRIMITIVE_RULES.get(dep) or STRING_FORMAT_RULES.get(dep)
851	            assert dep_rule, f"Rule {dep} not known"

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:850
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
849	        for dep in rule.deps:
850	            dep_rule = PRIMITIVE_RULES.get(dep) or STRING_FORMAT_RULES.get(dep)
851	            assert dep_rule, f"Rule {dep} not known"

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/llama_grammar.py:869
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
868	                enumerate(properties),
869	                key=lambda ikv: (prop_order.get(ikv[1][0], len(prop_order)), ikv[0]),
870	            )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/server/__main__.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
72	                    config_file_settings = ConfigFileSettings.model_validate_json(
73	                        f.read()
74	                    )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/server/app.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
117	            else:
118	                config_file_settings = ConfigFileSettings.model_validate_json(f.read())
119	            server_settings = ServerSettings.model_validate(config_file_settings)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/server/app.py:288
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
287	                        "title": "Server Side Streaming response, when stream=True. "
288	                        + "See SSE format: https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format",  # noqa: E501
289	                        "example": """data: {... see CreateCompletionResponse ...} \\n\\n data: ... \\n\\n ... data: [DONE]""",
290	                    }

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/llama_cpp/server/app.py:399
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
398	                        "title": "Server Side Streaming response, when stream=True"
399	                        + "See SSE format: https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format",  # noqa: E501
400	                        "example": """data: {... see CreateChatCompletionResponse ...} \\n\\n data: ... \\n\\n ... data: [DONE]""",
401	                    }

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf.py:714
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
713	            logger.warning("**          Check your model files and convert_hf_to_gguf_update.py and update them accordingly.")
714	            logger.warning("** ref:     https://github.com/ggml-org/llama.cpp/pull/6920")
715	            logger.warning("**")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf.py:2746
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
2745	        sentencepiece_model = model.ModelProto()  # pyright: ignore[reportAttributeAccessIssue]
2746	        sentencepiece_model.ParseFromString(open(tokenizer_path, "rb").read())
2747	        add_prefix = sentencepiece_model.normalizer_spec.add_dummy_prefix

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf.py:3146
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
3145	        sentencepiece_model = model.ModelProto()  # pyright: ignore[reportAttributeAccessIssue]
3146	        sentencepiece_model.ParseFromString(open(tokenizer_path, "rb").read())
3147	        assert sentencepiece_model.trainer_spec.model_type == 1  # UNIGRAM

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf.py:3345
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
3344	    def write(self):
3345	        super().write()
3346	        if self.has_vision:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf.py:4264
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
4263	        sentencepiece_model = model.ModelProto()  # pyright: ignore[reportAttributeAccessIssue]
4264	        sentencepiece_model.ParseFromString(open(tokenizer_path, "rb").read())
4265	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf.py:4404
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
4403	        sentencepiece_model = model.ModelProto()  # pyright: ignore[reportAttributeAccessIssue]
4404	        sentencepiece_model.ParseFromString(open(tokenizer_path, "rb").read())
4405	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf.py:5191
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
5190	            logger.info("Exporting model...")
5191	            model_instance.write()
5192	            out_path = f"{model_instance.fname_out.parent}{os.sep}" if is_split else model_instance.fname_out

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:68
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
67	models = [
68	    {"name": "llama-spm",        "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/meta-llama/Llama-2-7b-hf", },
69	    {"name": "llama-bpe",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/meta-llama/Meta-Llama-3-8B", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:69
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
68	    {"name": "llama-spm",        "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/meta-llama/Llama-2-7b-hf", },
69	    {"name": "llama-bpe",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/meta-llama/Meta-Llama-3-8B", },
70	    {"name": "phi-3",            "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
69	    {"name": "llama-bpe",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/meta-llama/Meta-Llama-3-8B", },
70	    {"name": "phi-3",            "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct", },
71	    {"name": "deepseek-llm",     "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/deepseek-llm-7b-base", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
70	    {"name": "phi-3",            "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct", },
71	    {"name": "deepseek-llm",     "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/deepseek-llm-7b-base", },
72	    {"name": "deepseek-coder",   "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:72
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
71	    {"name": "deepseek-llm",     "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/deepseek-llm-7b-base", },
72	    {"name": "deepseek-coder",   "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base", },
73	    {"name": "falcon",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/tiiuae/falcon-7b", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
72	    {"name": "deepseek-coder",   "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base", },
73	    {"name": "falcon",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/tiiuae/falcon-7b", },
74	    {"name": "bert-bge",         "tokt": TOKENIZER_TYPE.WPM, "repo": "https://huggingface.co/BAAI/bge-small-en-v1.5", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:74
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
73	    {"name": "falcon",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/tiiuae/falcon-7b", },
74	    {"name": "bert-bge",         "tokt": TOKENIZER_TYPE.WPM, "repo": "https://huggingface.co/BAAI/bge-small-en-v1.5", },
75	    {"name": "falcon3",          "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/tiiuae/Falcon3-7B-Base", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:75
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
74	    {"name": "bert-bge",         "tokt": TOKENIZER_TYPE.WPM, "repo": "https://huggingface.co/BAAI/bge-small-en-v1.5", },
75	    {"name": "falcon3",          "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/tiiuae/Falcon3-7B-Base", },
76	    {"name": "bert-bge-large",   "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/BAAI/bge-large-zh-v1.5", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
75	    {"name": "falcon3",          "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/tiiuae/Falcon3-7B-Base", },
76	    {"name": "bert-bge-large",   "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/BAAI/bge-large-zh-v1.5", },
77	    {"name": "mpt",              "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/mosaicml/mpt-7b", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:77
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
76	    {"name": "bert-bge-large",   "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/BAAI/bge-large-zh-v1.5", },
77	    {"name": "mpt",              "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/mosaicml/mpt-7b", },
78	    {"name": "starcoder",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/bigcode/starcoder2-3b", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	    {"name": "mpt",              "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/mosaicml/mpt-7b", },
78	    {"name": "starcoder",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/bigcode/starcoder2-3b", },
79	    {"name": "gpt-2",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/openai-community/gpt2", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:79
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
78	    {"name": "starcoder",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/bigcode/starcoder2-3b", },
79	    {"name": "gpt-2",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/openai-community/gpt2", },
80	    {"name": "stablelm2",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:80
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
79	    {"name": "gpt-2",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/openai-community/gpt2", },
80	    {"name": "stablelm2",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b", },
81	    {"name": "refact",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/smallcloudai/Refact-1_6-base", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:81
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
80	    {"name": "stablelm2",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b", },
81	    {"name": "refact",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/smallcloudai/Refact-1_6-base", },
82	    {"name": "command-r",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/CohereForAI/c4ai-command-r-v01", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:82
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
81	    {"name": "refact",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/smallcloudai/Refact-1_6-base", },
82	    {"name": "command-r",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/CohereForAI/c4ai-command-r-v01", },
83	    {"name": "qwen2",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/Qwen/Qwen1.5-7B", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:83
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
82	    {"name": "command-r",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/CohereForAI/c4ai-command-r-v01", },
83	    {"name": "qwen2",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/Qwen/Qwen1.5-7B", },
84	    {"name": "olmo",             "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/allenai/OLMo-1.7-7B-hf", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:84
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
83	    {"name": "qwen2",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/Qwen/Qwen1.5-7B", },
84	    {"name": "olmo",             "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/allenai/OLMo-1.7-7B-hf", },
85	    {"name": "dbrx",             "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/databricks/dbrx-base", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:85
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
84	    {"name": "olmo",             "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/allenai/OLMo-1.7-7B-hf", },
85	    {"name": "dbrx",             "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/databricks/dbrx-base", },
86	    {"name": "jina-v1-en",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-reranker-v1-tiny-en", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:86
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
85	    {"name": "dbrx",             "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/databricks/dbrx-base", },
86	    {"name": "jina-v1-en",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-reranker-v1-tiny-en", },
87	    {"name": "jina-v2-en",       "tokt": TOKENIZER_TYPE.WPM, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-en", }, # WPM!

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:87
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
86	    {"name": "jina-v1-en",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-reranker-v1-tiny-en", },
87	    {"name": "jina-v2-en",       "tokt": TOKENIZER_TYPE.WPM, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-en", }, # WPM!
88	    {"name": "jina-v2-es",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-es", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:88
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
87	    {"name": "jina-v2-en",       "tokt": TOKENIZER_TYPE.WPM, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-en", }, # WPM!
88	    {"name": "jina-v2-es",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-es", },
89	    {"name": "jina-v2-de",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-de", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
88	    {"name": "jina-v2-es",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-es", },
89	    {"name": "jina-v2-de",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-de", },
90	    {"name": "smaug-bpe",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/abacusai/Smaug-Llama-3-70B-Instruct", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
89	    {"name": "jina-v2-de",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-de", },
90	    {"name": "smaug-bpe",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/abacusai/Smaug-Llama-3-70B-Instruct", },
91	    {"name": "poro-chat",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/LumiOpen/Poro-34B-chat", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:91
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
90	    {"name": "smaug-bpe",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/abacusai/Smaug-Llama-3-70B-Instruct", },
91	    {"name": "poro-chat",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/LumiOpen/Poro-34B-chat", },
92	    {"name": "jina-v2-code",     "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-code", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:92
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
91	    {"name": "poro-chat",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/LumiOpen/Poro-34B-chat", },
92	    {"name": "jina-v2-code",     "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-code", },
93	    {"name": "viking",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/LumiOpen/Viking-7B", }, # Also used for Viking 13B and 33B

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:93
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
92	    {"name": "jina-v2-code",     "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/jinaai/jina-embeddings-v2-base-code", },
93	    {"name": "viking",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/LumiOpen/Viking-7B", }, # Also used for Viking 13B and 33B
94	    {"name": "gemma",            "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/google/gemma-2b", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:94
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
93	    {"name": "viking",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/LumiOpen/Viking-7B", }, # Also used for Viking 13B and 33B
94	    {"name": "gemma",            "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/google/gemma-2b", },
95	    {"name": "gemma-2",          "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/google/gemma-2-9b", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
94	    {"name": "gemma",            "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/google/gemma-2b", },
95	    {"name": "gemma-2",          "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/google/gemma-2-9b", },
96	    {"name": "jais",             "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/core42/jais-13b", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
95	    {"name": "gemma-2",          "tokt": TOKENIZER_TYPE.SPM, "repo": "https://huggingface.co/google/gemma-2-9b", },
96	    {"name": "jais",             "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/core42/jais-13b", },
97	    {"name": "t5",               "tokt": TOKENIZER_TYPE.UGM, "repo": "https://huggingface.co/google-t5/t5-small", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
96	    {"name": "jais",             "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/core42/jais-13b", },
97	    {"name": "t5",               "tokt": TOKENIZER_TYPE.UGM, "repo": "https://huggingface.co/google-t5/t5-small", },
98	    {"name": "codeshell",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/WisdomShell/CodeShell-7B", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:98
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
97	    {"name": "t5",               "tokt": TOKENIZER_TYPE.UGM, "repo": "https://huggingface.co/google-t5/t5-small", },
98	    {"name": "codeshell",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/WisdomShell/CodeShell-7B", },
99	    {"name": "tekken",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/mistralai/Mistral-Nemo-Base-2407", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:99
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
98	    {"name": "codeshell",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/WisdomShell/CodeShell-7B", },
99	    {"name": "tekken",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/mistralai/Mistral-Nemo-Base-2407", },
100	    {"name": "smollm",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/HuggingFaceTB/SmolLM-135M", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
99	    {"name": "tekken",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/mistralai/Mistral-Nemo-Base-2407", },
100	    {"name": "smollm",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/HuggingFaceTB/SmolLM-135M", },
101	    {'name': "bloom",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/bigscience/bloom", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:101
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
100	    {"name": "smollm",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/HuggingFaceTB/SmolLM-135M", },
101	    {'name': "bloom",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/bigscience/bloom", },
102	    {'name': "gpt3-finnish",     "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/TurkuNLP/gpt3-finnish-small", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:102
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
101	    {'name': "bloom",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/bigscience/bloom", },
102	    {'name': "gpt3-finnish",     "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/TurkuNLP/gpt3-finnish-small", },
103	    {"name": "exaone",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:103
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
102	    {'name': "gpt3-finnish",     "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/TurkuNLP/gpt3-finnish-small", },
103	    {"name": "exaone",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct", },
104	    {"name": "phi-2",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/microsoft/phi-2", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:104
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
103	    {"name": "exaone",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct", },
104	    {"name": "phi-2",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/microsoft/phi-2", },
105	    {"name": "chameleon",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/facebook/chameleon-7b", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:105
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
104	    {"name": "phi-2",            "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/microsoft/phi-2", },
105	    {"name": "chameleon",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/facebook/chameleon-7b", },
106	    {"name": "minerva-7b",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/sapienzanlp/Minerva-7B-base-v1.0", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:106
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
105	    {"name": "chameleon",        "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/facebook/chameleon-7b", },
106	    {"name": "minerva-7b",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/sapienzanlp/Minerva-7B-base-v1.0", },
107	    {"name": "roberta-bpe",      "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/sentence-transformers/stsb-roberta-base"},

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:107
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
106	    {"name": "minerva-7b",       "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/sapienzanlp/Minerva-7B-base-v1.0", },
107	    {"name": "roberta-bpe",      "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/sentence-transformers/stsb-roberta-base"},
108	    {"name": "gigachat",         "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct"},

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:108
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
107	    {"name": "roberta-bpe",      "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/sentence-transformers/stsb-roberta-base"},
108	    {"name": "gigachat",         "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct"},
109	    {"name": "megrez",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/Infinigence/Megrez-3B-Instruct"},

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:109
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
108	    {"name": "gigachat",         "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct"},
109	    {"name": "megrez",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/Infinigence/Megrez-3B-Instruct"},
110	    {"name": "deepseek-v3",      "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/DeepSeek-V3"},

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:110
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
109	    {"name": "megrez",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/Infinigence/Megrez-3B-Instruct"},
110	    {"name": "deepseek-v3",      "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/DeepSeek-V3"},
111	    {"name": "deepseek-r1-qwen", "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"},

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
110	    {"name": "deepseek-v3",      "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/DeepSeek-V3"},
111	    {"name": "deepseek-r1-qwen", "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"},
112	    {"name": "gpt-4o",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/Xenova/gpt-4o", },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
111	    {"name": "deepseek-r1-qwen", "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"},
112	    {"name": "gpt-4o",           "tokt": TOKENIZER_TYPE.BPE, "repo": "https://huggingface.co/Xenova/gpt-4o", },
113	]

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
117	    headers = {"Authorization": f"Bearer {token}"}
118	    response = sess.get(url, headers=headers)
119	    response.raise_for_status()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:122
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
121	    with open(save_path, 'wb') as downloaded_file:
122	        downloaded_file.write(response.content)
123	    logger.info(f"File {save_path} downloaded successfully")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
224	
225	src_func = f"""
226	    def get_vocab_base_pre(self, tokenizer) -> str:
227	        # encoding this string and hashing the resulting tokens would (hopefully) give us a unique identifier that
228	        # is specific for the BPE pre-tokenizer used by the model
229	        # we will use this unique identifier to write a "tokenizer.ggml.pre" entry in the GGUF file which we can
230	        # use in llama.cpp to implement the same pre-tokenizer
231	
232	        chktxt = {repr(CHK_TXT)}
233	
234	        chktok = tokenizer.encode(chktxt)
235	        chkhsh = sha256(str(chktok).encode()).hexdigest()
236	
237	        logger.debug(f"chktok: {{chktok}}")
238	        logger.debug(f"chkhsh: {{chkhsh}}")
239	
240	        res = None
241	
242	        # NOTE: if you get an error here, you need to update the convert_hf_to_gguf_update.py script
243	        #       or pull the latest version of the model from Huggingface
244	        #       don't edit the hashes manually!
245	{src_ifs}
246	        if res is None:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:365
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
364	        for text in tests:
365	            f.write(f"{text}")
366	            f.write("\n__ggml_vocab_test__\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:366
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
365	            f.write(f"{text}")
366	            f.write("\n__ggml_vocab_test__\n")
367	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:372
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
371	            for r in res:
372	                f.write(f" {r}")
373	            f.write("\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_hf_to_gguf_update.py:373
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
372	                f.write(f" {r}")
373	            f.write("\n")
374	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_lora_to_gguf.py:398
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
397	                            logger.error("Embeddings is present in the adapter. This can be due to new tokens added during fine tuning")
398	                            logger.error("Please refer to https://github.com/ggml-org/llama.cpp/pull/9948")
399	                        sys.exit(1)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/convert_lora_to_gguf.py:460
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
459	        logger.info("Exporting model...")
460	        model_instance.write()
461	        logger.info(f"Model successfully exported to {model_instance.fname_out}")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/convert_legacy_llama.py:596
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
595	                size = elm_count * dtype.itemsize
596	                data = fp.read(size)
597	            assert len(data) == size

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/convert_legacy_llama.py:650
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
649	def lazy_load_safetensors_file(fp: IO[bytes], path: Path) -> ModelPlus:
650	    header_size, = struct.unpack('<Q', fp.read(8))
651	    header: dict[str, dict[str, Any]] = json.loads(fp.read(header_size))

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/convert_legacy_llama.py:651
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
650	    header_size, = struct.unpack('<Q', fp.read(8))
651	    header: dict[str, dict[str, Any]] = json.loads(fp.read(header_size))
652	    # Use mmap for the actual data to avoid race conditions with the file offset.

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/convert_legacy_llama.py:674
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
673	def must_read(fp: IO[bytes], length: int) -> bytes:
674	    ret = fp.read(length)
675	    if len(ret) < length:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/convert_legacy_llama.py:683
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
682	    fp = open(path, 'rb')
683	    first8 = fp.read(8)
684	    fp.seek(0)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_pydantic_example.py:13
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
12	
13	    def create_completion(*, response_model=None, endpoint="http://localhost:8080/v1/chat/completions", messages, **kwargs):
14	        '''

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_pydantic_example.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
31	
32	        data = requests.post(endpoint, headers={"Content-Type": "application/json"},
33	                             json=dict(messages=messages, response_format=response_format, **kwargs)).json()
34	        if 'error' in data:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_pydantic_example.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
47	    client = instructor.patch(
48	        openai.OpenAI(api_key="123", base_url="http://localhost:8080"),
49	        mode=instructor.Mode.JSON_SCHEMA)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:356
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
355	
356	                        target = self._refs.get(base_url)
357	                        if target is None:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:358
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
357	                        if target is None:
358	                            target = self.resolve_refs(requests.get(ref).json(), base_url)
359	                            self._refs[base_url] = target

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:507
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
506	                    if not sub_is_literal:
507	                        id = sub_rule_ids.get(sub)
508	                        if id is None:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:559
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
558	    def visit(self, schema, name):
559	        schema_type = schema.get('type')
560	        schema_format = schema.get('format')

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:560
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
559	        schema_type = schema.get('type')
560	        schema_format = schema.get('format')
561	        rule_name = name + '-' if name in RESERVED_NAMES else name or 'root'

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:563
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
562	
563	        if (ref := schema.get('$ref')) is not None:
564	            return self._add_rule(rule_name, self._resolve_ref(ref))

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:567
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
566	        elif 'oneOf' in schema or 'anyOf' in schema:
567	            return self._add_rule(rule_name, self._generate_union_rule(name, schema.get('oneOf') or schema['anyOf']))
568	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:582
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
581	              ('additionalProperties' in schema and schema['additionalProperties'] is not True)):
582	            required = set(schema.get('required', []))
583	            properties = list(schema.get('properties', {}).items())

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:583
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
582	            required = set(schema.get('required', []))
583	            properties = list(schema.get('properties', {}).items())
584	            return self._add_rule(rule_name, self._build_object_rule(properties, required, name, schema.get('additionalProperties')))

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:584
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
583	            properties = list(schema.get('properties', {}).items())
584	            return self._add_rule(rule_name, self._build_object_rule(properties, required, name, schema.get('additionalProperties')))
585	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:591
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
590	            def add_component(comp_schema, is_required):
591	                if (ref := comp_schema.get('$ref')) is not None:
592	                    comp_schema = self._refs[ref]

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:610
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
609	        elif schema_type in (None, 'array') and ('items' in schema or 'prefixItems' in schema):
610	            items = schema.get('items') or schema['prefixItems']
611	            if isinstance(items, list):

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:621
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
620	                item_rule_name = self.visit(items, f'{name}{"-" if name else ""}item')
621	                min_items = schema.get("minItems", 0)
622	                max_items = schema.get("maxItems")

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:622
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
621	                min_items = schema.get("minItems", 0)
622	                max_items = schema.get("maxItems")
623	                return self._add_rule(rule_name, '"[" space ' + _build_repetition(item_rule_name, min_items, max_items, separator_rule='"," space') + ' "]" space')

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:640
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
639	            char_rule = self._add_primitive('char', PRIMITIVE_RULES['char'])
640	            min_len = schema.get('minLength', 0)
641	            max_len = schema.get('maxLength')

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:641
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
640	            min_len = schema.get('minLength', 0)
641	            max_len = schema.get('maxLength')
642	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:675
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
674	        for dep in rule.deps:
675	            dep_rule = PRIMITIVE_RULES.get(dep) or STRING_FORMAT_RULES.get(dep)
676	            assert dep_rule, f'Rule {dep} not known'

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:675
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
674	        for dep in rule.deps:
675	            dep_rule = PRIMITIVE_RULES.get(dep) or STRING_FORMAT_RULES.get(dep)
676	            assert dep_rule, f'Rule {dep} not known'

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:684
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
683	        # sort by position in prop_order (if specified) then by original order
684	        sorted_props = [kv[0] for _, kv in sorted(enumerate(properties), key=lambda ikv: (prop_order.get(ikv[1][0], len(prop_order)), ikv[0]))]
685	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/json_schema_to_grammar.py:792
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
791	        import requests
792	        schema = requests.get(url).json()
793	    elif args.schema == '-':

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/llava/gemma3_convert_encoder_to_gguf.py:302
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
301	        )
302	        gemma3_vision_tower.write()
303	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/llava/glmedge-surgery.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
28	        with open(f"{args.model}/added_tokens.json", "w") as f:
29	            f.write("{}\n")
30	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/llava/llava_surgery.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
31	        with open(f"{args.model}/added_tokens.json", "w") as f:
32	            f.write("{}\n")
33	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/llava/minicpmv-convert-image-encoder-to-gguf.py:344
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
343	
344	SIGLIP_START_DOCSTRING = r"""
345	    This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the
346	    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
347	    etc.)
348	    This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.
349	    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
350	    and behavior.
351	    Parameters:
352	        config ([`SiglipVisionConfig`]): Model configuration class with all the parameters of the model.
353	            Initializing with a config file does not load the weights associated with the model, only the
354	            configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.
355	"""
356	
357	
358	SIGLIP_VISION_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/llava/minicpmv-surgery.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
28	        with open(f"{args.model}/added_tokens.json", "w") as f:
29	            f.write("{}\n")
30	

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/pydantic_models_to_grammar_examples.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
30	    data = {"prompt": prompt, "grammar": gbnf_grammar}
31	    result = requests.post(f"http://{host}/completion", headers=headers, json=data).json()
32	    assert data.get("error") is None, data

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/pydantic_models_to_grammar_examples.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
31	    result = requests.post(f"http://{host}/completion", headers=headers, json=data).json()
32	    assert data.get("error") is None, data
33	    logging.info("Result: %s", result)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/pydantic_models_to_grammar_examples.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
63	    # This finds "SendMessageToUser":
64	    tool = tools_map.get(json_data["function"])
65	    if not tool:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/pydantic_models_to_grammar_examples.py:140
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
139	    # This finds "Calculator":
140	    tool = tools_map.get(json_data["function"])
141	    if not tool:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/pydantic_models_to_grammar_examples.py:283
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
282	    for call in json_data:
283	      tool = tools_map.get(call["function"])
284	      if not tool:

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
29	    parser.add_argument("--commit", type=str, help="Commit name", default="dirty")
30	    parser.add_argument("--host", type=str, help="Server listen host", default="0.0.0.0")
31	    parser.add_argument("--port", type=int, help="Server listen host", default="8080")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:80
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
79	                            data['metrics'][metric_name][metric_metric]=value
80	                            github_env.write(
81	                                f"{escape_metric_name(metric_name)}_{escape_metric_name(metric_metric)}={value}\n")
82	                iterations = data['root_group']['checks']['success completion']['passes']

--------------------------------------------------
>> Issue: [B828:signal] signal.signal
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b828_signal.html
95	                interrupt = signal.SIGINT
96	            server_process.send_signal(interrupt)
97	            server_process.wait(0.5)

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:116
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
115	    prometheus_metrics = {}
116	    if is_server_listening("0.0.0.0", 9090):
117	        metrics = ['prompt_tokens_seconds', 'predicted_tokens_seconds',

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:121
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
120	        for metric in metrics:
121	            resp = requests.get(f"http://localhost:9090/api/v1/query_range",
122	                                params={'query': 'llamacpp:' + metric, 'start': start_time, 'end': end_time, 'step': 2})
123	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:121
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
120	        for metric in metrics:
121	            resp = requests.get(f"http://localhost:9090/api/v1/query_range",
122	                                params={'query': 'llamacpp:' + metric, 'start': start_time, 'end': end_time, 'step': 2})

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:125
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
124	            with open(f"{metric}.json", 'w') as metric_json:
125	                metric_json.write(resp.text)
126	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:159
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
158	                plt.savefig(f'{metric}.jpg', dpi=60)
159	                plt.close()
160	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:180
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
179	                    """)
180	                    mermaid_f.write(mermaid)
181	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
200	    with open("results.github.env", 'a') as github_env:
201	        github_env.write(f"BENCH_RESULTS={json.dumps(bench_results, indent=None, separators=(',', ':') )}\n")
202	        github_env.write(f"BENCH_ITERATIONS={iterations}\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:202
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
201	        github_env.write(f"BENCH_RESULTS={json.dumps(bench_results, indent=None, separators=(',', ':') )}\n")
202	        github_env.write(f"BENCH_ITERATIONS={iterations}\n")
203	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:206
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
205	        xlabel = xlabel.replace('\n', ' ')
206	        github_env.write(f"BENCH_GRAPH_TITLE={title}\n")
207	        github_env.write(f"BENCH_GRAPH_XLABEL={xlabel}\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:207
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
206	        github_env.write(f"BENCH_GRAPH_TITLE={title}\n")
207	        github_env.write(f"BENCH_GRAPH_XLABEL={xlabel}\n")
208	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:295
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
294	
295	    thread_stdout = threading.Thread(target=server_log, args=(server_process.stdout, sys.stdout))
296	    thread_stdout.start()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:297
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
296	    thread_stdout.start()
297	    thread_stderr = threading.Thread(target=server_log, args=(server_process.stderr, sys.stderr))
298	    thread_stderr.start()

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:304
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
303	def is_server_listening(server_fqdn, server_port):
304	    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
305	        result = sock.connect_ex((server_fqdn, server_port))

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/bench/bench.py:314
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
313	    url = f"http://{server_fqdn}:{server_port}/health"
314	    response = requests.get(url)
315	    return response.status_code == 200

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_basic.py:17
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
16	    server.start()
17	    res = server.make_request("GET", "/health")
18	    assert res.status_code == 200

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_basic.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
23	    server.start()
24	    res = server.make_request("GET", "/props")
25	    assert res.status_code == 200

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_basic.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
36	    server.start()
37	    res = server.make_request("GET", "/models")
38	    assert res.status_code == 200

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_basic.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
48	    server.start()
49	    res = server.make_request("GET", "/slots")
50	    assert res.status_code == 501 # ERROR_TYPE_NOT_SUPPORTED

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_basic.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
57	    server.start()
58	    res = server.make_request("GET", "/slots")
59	    assert res.status_code == 200

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_basic.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
72	    server.start()
73	    res = server.make_request("POST", "/completion", data={
74	        "n_predict": 16,
75	        "prompt": "Hello",
76	        "temperature": 0.0,
77	    })

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_basic.py:87
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
86	    url = f"http://{server.server_host}:{server.server_port}"
87	    res = requests.get(url)
88	    assert res.status_code == 200

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_basic.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
94	    server.start()
95	    res = requests.get(url)
96	    assert res.status_code == 404

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
21	    server.start()
22	    res = server.make_request("POST", "/completion", data={
23	        "n_predict": n_predict,
24	        "prompt": prompt,
25	        "return_tokens": return_tokens,
26	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
46	    server.start()
47	    res = server.make_stream_request("POST", "/completion", data={
48	        "n_predict": n_predict,
49	        "prompt": prompt,
50	        "stream": True,
51	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:75
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
74	    server.start()
75	    res_stream = server.make_stream_request("POST", "/completion", data={
76	        "n_predict": 8,
77	        "prompt": "I believe the meaning of life is",
78	        "stream": True,
79	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:80
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
79	    })
80	    res_non_stream = server.make_request("POST", "/completion", data={
81	        "n_predict": 8,
82	        "prompt": "I believe the meaning of life is",
83	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:131
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
130	    for _ in range(4):
131	        res = server.make_request("POST", "/completion", data={
132	            "prompt": "I believe the meaning of life is",
133	            "seed": 42,
134	            "temperature": 0.0,
135	            "cache_prompt": False,  # TODO: remove this once test_cache_vs_nocache_prompt is fixed
136	        })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:149
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
148	    for seed in range(4):
149	        res = server.make_request("POST", "/completion", data={
150	            "prompt": "I believe the meaning of life is",
151	            "seed": seed,
152	            "temperature": 1.0,
153	            "cache_prompt": False,  # TODO: remove this once test_cache_vs_nocache_prompt is fixed
154	        })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:169
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
168	    for _ in range(4):
169	        res = server.make_request("POST", "/completion", data={
170	            "prompt": "I believe the meaning of life is",
171	            "seed": 42,
172	            "temperature": temperature,
173	            "cache_prompt": False,  # TODO: remove this once test_cache_vs_nocache_prompt is fixed
174	        })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:184
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
183	    server.start()
184	    res_cache = server.make_request("POST", "/completion", data={
185	        "prompt": "I believe the meaning of life is",
186	        "seed": 42,
187	        "temperature": 1.0,
188	        "cache_prompt": True,
189	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
189	    })
190	    res_no_cache = server.make_request("POST", "/completion", data={
191	        "prompt": "I believe the meaning of life is",
192	        "seed": 42,
193	        "temperature": 1.0,
194	        "cache_prompt": False,
195	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:204
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
203	    prompt_str = "I believe the meaning of life is"
204	    res = server.make_request("POST", "/tokenize", data={
205	        "content": prompt_str,
206	        "add_special": True,
207	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:212
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
211	    # single completion
212	    res = server.make_request("POST", "/completion", data={
213	        "prompt": tokens,
214	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:219
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
218	    # batch completion
219	    res = server.make_request("POST", "/completion", data={
220	        "prompt": [tokens, tokens],
221	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:228
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
227	    # mixed string and tokens
228	    res = server.make_request("POST", "/completion", data={
229	        "prompt": [tokens, prompt_str],
230	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:237
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
236	    # mixed string and tokens in one sequence
237	    res = server.make_request("POST", "/completion", data={
238	        "prompt": [1, 2, 3, 4, 5, 6, prompt_str, 7, 8, 9, 10, prompt_str],
239	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:268
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
267	        time.sleep(0.1)
268	        res = server.make_request("GET", "/slots")
269	        n_busy = sum([1 for slot in res.body if slot["is_processing"]])

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:309
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
308	    server.start()
309	    res = server.make_request(
310	        "POST",
311	        "/completion",
312	        data={
313	            "n_predict": n_predict,
314	            "prompt": prompt,
315	            "response_fields": response_fields,
316	        },

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:334
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
333	    server.start()
334	    res = server.make_request("POST", "/completion", data={
335	        "prompt": "I believe the meaning of life is",
336	        "n_probs": 10,
337	        "temperature": 0.0,
338	        "n_predict": 5,
339	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:359
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
358	    server.start()
359	    res = server.make_stream_request("POST", "/completion", data={
360	        "prompt": "I believe the meaning of life is",
361	        "n_probs": 10,
362	        "temperature": 0.0,
363	        "n_predict": 5,
364	        "stream": True,
365	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:386
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
385	    server.start()
386	    res = server.make_request("POST", "/completion", data={
387	        "prompt": "I believe the meaning of life is",
388	        "n_probs": 10,
389	        "temperature": 0.0,
390	        "n_predict": 5,
391	        "post_sampling_probs": True,
392	    })

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:420
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
419	    try:
420	        server.make_request("POST", "/completion", data={
421	            "prompt": "I believe the meaning of life is",
422	        }, timeout=0.1)
423	    except requests.exceptions.ReadTimeout:

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_completion.py:427
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
426	    time.sleep(1) # wait for HTTP_POLLING_SECONDS
427	    res = server.make_request("GET", "/slots")
428	    assert res.body[0]["is_processing"] == False

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_embedding.py:227
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
226	    # Verify embedding is valid base64
227	    decoded = base64.b64decode(embedding_data["embedding"])
228	    # Verify decoded data can be converted back to float array

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_embedding.py:227
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
226	    # Verify embedding is valid base64
227	    decoded = base64.b64decode(embedding_data["embedding"])
228	    # Verify decoded data can be converted back to float array

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_lora.py:6
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
5	
6	LORA_FILE_URL = "https://huggingface.co/ggml-org/stories15M_MOE/resolve/main/moe_shakespeare15M.gguf"
7	
8	@pytest.fixture(scope="module", autouse=True)
9	def create_server():

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_lora.py:81
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
80	    server.lora_files = [
81	        download_file("https://huggingface.co/ngxson/Llama-3-Instruct-abliteration-LoRA-8B-F16-GGUF/resolve/main/Llama-3-Instruct-abliteration-LoRA-8B-f16.gguf"),
82	        # TODO: find & add other lora adapters for this model

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/unit/test_speculative.py:8
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
7	
8	MODEL_DRAFT_FILE_URL = "https://huggingface.co/ggml-org/models/resolve/main/tinyllamas/stories15M-q4_0.gguf"
9	
10	def create_server():

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/utils.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
44	    server_port: int = 8080
45	    server_host: str = "127.0.0.1"
46	    model_hf_repo: str = "ggml-org/models"

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/utils.py:222
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
221	            try:
222	                response = self.make_request("GET", "/health", headers={
223	                    "Authorization": f"Bearer {self.api_key}" if self.api_key else None
224	                })

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/utils.py:257
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
256	        if method == "GET":
257	            response = requests.get(url, headers=headers, timeout=timeout)
258	            parse_body = True

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/utils.py:260
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
259	        elif method == "POST":
260	            response = requests.post(url, headers=headers, json=data, timeout=timeout)
261	            parse_body = True

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/utils.py:282
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
281	        if method == "POST":
282	            response = requests.post(url, headers=headers, json=data, stream=True)
283	        else:

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/utils.py:389
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
388	
389	    with ThreadPoolExecutor() as executor:
390	        futures = []

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/utils.py:437
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
436	def is_slow_test_allowed():
437	    return os.environ.get("SLOW_TESTS") == "1" or os.environ.get("SLOW_TESTS") == "ON"

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server/tests/utils.py:437
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
436	def is_slow_test_allowed():
437	    return os.environ.get("SLOW_TESTS") == "1" or os.environ.get("SLOW_TESTS") == "ON"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/server_embd.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
14	async def main():
15	    model_url = "http://127.0.0.1:6900"
16	    responses: list[requests.Response] = await asyncio.gather(*[requests_post_async(

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/tts/tts-outetts.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
70	
71	    with ThreadPoolExecutor(max_workers=n_thread) as executor:
72	        args = [(l, n_fft, S, hann) for l in range(n_codes)]

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/tts/tts-outetts.py:133
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
132	if len(sys.argv) <= 3:
133	    print("usage: python tts-outetts.py http://server-llm:port http://server-dec:port \"text\"")
134	    exit(1)

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/tts/tts-outetts.py:244
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
243	
244	response = requests.post(
245	    host_llm + "/completion",
246	    json={
247	        "prompt": [prefix + words, *suffix],
248	        "n_predict": 1024,
249	        "cache_prompt": True,
250	        "return_tokens": True,
251	        "samplers": ["top_k"],
252	        "top_k": 16,
253	        "seed": 1003,
254	    }

--------------------------------------------------
>> Issue: [B821:post] requests.post
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/examples/tts/tts-outetts.py:268
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b821_post.html
267	
268	response = requests.post(
269	    host_dec + "/embeddings",
270	    json={
271	        "input": [*codes],
272	    }

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/generate_cu_files.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
57	                with open(f"fattn-vec-f{vkq_size}-instance-hs{head_size}-{get_short_name(type_k)}-{get_short_name(type_v)}.cu", "w") as f:
58	                    f.write(SOURCE_FATTN_VEC.format(vkq_size=vkq_size, head_size=head_size, type_k=type_k, type_v=type_v))
59	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/generate_cu_files.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
65	        with open(f"fattn-mma-f16-instance-ncols1_{ncols1}-ncols2_{ncols2}.cu", "w") as f:
66	            f.write(SOURCE_FATTN_MMA_START)
67	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/generate_cu_files.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
70	                    continue  # Needs too much shared memory.
71	                f.write(SOURCE_FATTN_MMA_CASE.format(ncols1=ncols1, ncols2=ncols2, head_size=head_size))
72	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/generate_cu_files.py:75
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
74	    with open(f"mmq-instance-{get_short_name(type)}.cu", "w") as f:
75	        f.write(SOURCE_MMQ.format(type=type))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/docs/conf.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
72	        'google_analytics_account': 'G-F9LD9HL8LW',
73	        'base_url': 'https://kompute.cc',
74	        'color_primary': 'red',
75	        'color_accent': 'light-blue',
76	        'repo_url': 'https://github.com/KomputeProject/kompute/',
77	        'repo_name': 'Kompute',
78	        'globaltoc_depth': 2,
79	        'globaltoc_collapse': False,
80	        'globaltoc_includehidden': False,
81	        "repo_type": "github",
82	        "nav_links": [
83	            {
84	                "href": "https://github.com/KomputeProject/kompute/",
85	                "internal": False,
86	                "title": "Kompute Repo",
87	            },
88	        ]
89	    }

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/docs/conf.py:76
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
75	        'color_accent': 'light-blue',
76	        'repo_url': 'https://github.com/KomputeProject/kompute/',
77	        'repo_name': 'Kompute',
78	        'globaltoc_depth': 2,
79	        'globaltoc_collapse': False,
80	        'globaltoc_includehidden': False,
81	        "repo_type": "github",
82	        "nav_links": [
83	            {
84	                "href": "https://github.com/KomputeProject/kompute/",
85	                "internal": False,
86	                "title": "Kompute Repo",
87	            },
88	        ]
89	    }
90	
91	    extensions.append("sphinx_material")
92	    html_theme_path = sphinx_material.html_theme_path()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/docs/conf.py:84
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
83	            {
84	                "href": "https://github.com/KomputeProject/kompute/",
85	                "internal": False,
86	                "title": "Kompute Repo",
87	            },
88	        ]

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/sh_conv.py:6
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
5	def compile_source(source):
6	    os.system("glslangValidator --stdin -S comp -V -o tmp_kp_shader.comp.spv << END\n" + source + "\nEND")
7	    return open("tmp_kp_shader.comp.spv", "rb").read()

--------------------------------------------------
>> Issue: [B316:blacklist] os.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/sh_conv.py:6
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b313-b320-os-system
5	def compile_source(source):
6	    os.system("glslangValidator --stdin -S comp -V -o tmp_kp_shader.comp.spv << END\n" + source + "\nEND")
7	    return open("tmp_kp_shader.comp.spv", "rb").read()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/sh_conv.py:7
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
6	    os.system("glslangValidator --stdin -S comp -V -o tmp_kp_shader.comp.spv << END\n" + source + "\nEND")
7	    return open("tmp_kp_shader.comp.spv", "rb").read()
8	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/utils.py:5
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
4	def compile_source(source):
5	    open("tmp_kp_shader.comp", "w").write(source)
6	    os.system("glslangValidator -V tmp_kp_shader.comp -o tmp_kp_shader.comp.spv")

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/utils.py:6
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
5	    open("tmp_kp_shader.comp", "w").write(source)
6	    os.system("glslangValidator -V tmp_kp_shader.comp -o tmp_kp_shader.comp.spv")
7	    return open("tmp_kp_shader.comp.spv", "rb").read()

--------------------------------------------------
>> Issue: [B316:blacklist] os.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/utils.py:6
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b313-b320-os-system
5	    open("tmp_kp_shader.comp", "w").write(source)
6	    os.system("glslangValidator -V tmp_kp_shader.comp -o tmp_kp_shader.comp.spv")
7	    return open("tmp_kp_shader.comp.spv", "rb").read()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/utils.py:7
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
6	    os.system("glslangValidator -V tmp_kp_shader.comp -o tmp_kp_shader.comp.spv")
7	    return open("tmp_kp_shader.comp.spv", "rb").read()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:20
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
19	
20	SHADER_GENERATED_NOTICE = """/*
21	    THIS FILE HAS BEEN AUTOMATICALLY GENERATED - DO NOT EDIT
22	
23	    ---
24	
25	    Copyright 2020 The Institute for Ethical AI & Machine Learning
26	
27	    Licensed under the Apache License, Version 2.0 (the "License");
28	    you may not use this file except in compliance with the License.
29	    You may obtain a copy of the License at
30	
31	        http://www.apache.org/licenses/LICENSE-2.0
32	
33	    Unless required by applicable law or agreed to in writing, software
34	    distributed under the License is distributed on an "AS IS" BASIS,
35	    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
36	    See the License for the specific language governing permissions and
37	    limitations under the License.
38	*/
39	"""
40	
41	@click.command()
42	@click.option(
43	    "--shader-path",
44	    "-p",
45	    envvar="KOMPUTE_SHADER_PATH",
46	    required=True,
47	    help="The path for the directory to build and convert shaders",
48	)
49	@click.option(
50	    "--shader-binary",
51	    "-s",
52	    envvar="KOMPUTE_SHADER_BINARY",
53	    required=True,
54	    help="The path for the directory to build and convert shaders",
55	)
56	@click.option(
57	    "--header-path",
58	    "-c",
59	    envvar="KOMPUTE_HEADER_PATH",
60	    default="",
61	    required=False,
62	    help="The (optional) output file for the cpp header files",
63	)
64	@click.option(
65	    "--verbose",
66	    "-v",
67	    envvar="KOMPUTE_HEADER_PATH",
68	    default=False,
69	    is_flag=True,
70	    help="Enable versbosity if flag is provided",
71	)
72	def run_cli(

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:137
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
136	            with open(os.path.join(header_path, header_file), "w+", newline='\n') as fstream:
137	                fstream.write(f"{SHADER_GENERATED_NOTICE}\n")
138	                fstream.write(f"#ifndef {header_file_define}\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:138
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
137	                fstream.write(f"{SHADER_GENERATED_NOTICE}\n")
138	                fstream.write(f"#ifndef {header_file_define}\n")
139	                fstream.write(f"#define {header_file_define}\n\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:139
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
138	                fstream.write(f"#ifndef {header_file_define}\n")
139	                fstream.write(f"#define {header_file_define}\n\n")
140	                fstream.write("namespace kp {\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:140
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
139	                fstream.write(f"#define {header_file_define}\n\n")
140	                fstream.write("namespace kp {\n")
141	                fstream.write("namespace shader_data {\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:141
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
140	                fstream.write("namespace kp {\n")
141	                fstream.write("namespace shader_data {\n")
142	                fstream.write(f"{header_data}")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:142
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
141	                fstream.write("namespace shader_data {\n")
142	                fstream.write(f"{header_data}")
143	                fstream.write("}\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:143
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
142	                fstream.write(f"{header_data}")
143	                fstream.write("}\n")
144	                fstream.write("}\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:144
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
143	                fstream.write("}\n")
144	                fstream.write("}\n")
145	                fstream.write(f"#endif // define {header_file_define}\n")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py:145
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
144	                fstream.write("}\n")
145	                fstream.write(f"#endif // define {header_file_define}\n")
146	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/setup.py:14
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
13	with open(os.path.join(curr_dir, 'README.md'), encoding='utf-8') as f:
14	    long_description = f.read()
15	

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/setup.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
59	
60	        if platform.system() == "Windows":
61	            cmake_args += [f'-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_{cfg.upper()}={extdir}']

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/setup.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
59	
60	        if platform.system() == "Windows":
61	            cmake_args += [f'-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_{cfg.upper()}={extdir}']

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/ggml/src/ggml-kompute/kompute/setup.py:60
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
59	
60	        if platform.system() == "Windows":
61	            cmake_args += [f'-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_{cfg.upper()}={extdir}']

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:224
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
223	        for fout, tensors, kv_data in zip(self.fout, self.tensors, self.kv_data):
224	            fout.write(self._pack("<I", GGUF_MAGIC, skip_pack_prefix = True))
225	            fout.write(self._pack("I", GGUF_VERSION))

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:224
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
223	        for fout, tensors, kv_data in zip(self.fout, self.tensors, self.kv_data):
224	            fout.write(self._pack("<I", GGUF_MAGIC, skip_pack_prefix = True))
225	            fout.write(self._pack("I", GGUF_VERSION))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
224	            fout.write(self._pack("<I", GGUF_MAGIC, skip_pack_prefix = True))
225	            fout.write(self._pack("I", GGUF_VERSION))
226	            fout.write(self._pack("Q", len(tensors)))

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
224	            fout.write(self._pack("<I", GGUF_MAGIC, skip_pack_prefix = True))
225	            fout.write(self._pack("I", GGUF_VERSION))
226	            fout.write(self._pack("Q", len(tensors)))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:226
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
225	            fout.write(self._pack("I", GGUF_VERSION))
226	            fout.write(self._pack("Q", len(tensors)))
227	            fout.write(self._pack("Q", len(kv_data)))

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:226
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
225	            fout.write(self._pack("I", GGUF_VERSION))
226	            fout.write(self._pack("Q", len(tensors)))
227	            fout.write(self._pack("Q", len(kv_data)))

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:227
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
226	            fout.write(self._pack("Q", len(tensors)))
227	            fout.write(self._pack("Q", len(kv_data)))
228	            fout.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:227
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
226	            fout.write(self._pack("Q", len(tensors)))
227	            fout.write(self._pack("Q", len(kv_data)))
228	            fout.flush()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:243
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
242	
243	            fout.write(kv_bytes)
244	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:243
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
242	
243	            fout.write(kv_bytes)
244	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:267
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
266	
267	            fout.write(ti_data)
268	            fout.flush()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:267
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
266	
267	            fout.write(ti_data)
268	            fout.flush()

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:393
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
392	        if pad != 0:
393	            fp.write(bytes([0] * pad))
394	

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/gguf_writer.py:393
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
392	        if pad != 0:
393	            fp.write(bytes([0] * pad))
394	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/metadata.py:421
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
420	                            if org_component is not None and model_full_name_component is not None:
421	                                base_model["repo_url"] = f"https://huggingface.co/{org_component}/{model_full_name_component}"
422	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/gguf/metadata.py:479
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
478	                            if org_component is not None and dataset_name_component is not None:
479	                                dataset["repo_url"] = f"https://huggingface.co/{org_component}/{dataset_name_component}"
480	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:182
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
181	        expect = gguf.Metadata()
182	        expect.base_models=[{'name': 'Mistral 7B Merge 14 v0', 'organization': 'EmbeddedLLM', 'version': '14-v0', 'repo_url': 'https://huggingface.co/EmbeddedLLM/Mistral-7B-Merge-14-v0'}, {'name': 'Trinity v1', 'organization': 'Janai Hq', 'version': 'v1', 'repo_url': 'https://huggingface.co/janai-hq/trinity-v1'}]
183	        expect.tags=['Llama-3', 'instruct', 'finetune', 'chatml', 'DPO', 'RLHF', 'gpt4', 'synthetic data', 'distillation', 'function calling', 'json mode', 'axolotl']

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:182
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
181	        expect = gguf.Metadata()
182	        expect.base_models=[{'name': 'Mistral 7B Merge 14 v0', 'organization': 'EmbeddedLLM', 'version': '14-v0', 'repo_url': 'https://huggingface.co/EmbeddedLLM/Mistral-7B-Merge-14-v0'}, {'name': 'Trinity v1', 'organization': 'Janai Hq', 'version': 'v1', 'repo_url': 'https://huggingface.co/janai-hq/trinity-v1'}]
183	        expect.tags=['Llama-3', 'instruct', 'finetune', 'chatml', 'DPO', 'RLHF', 'gpt4', 'synthetic data', 'distillation', 'function calling', 'json mode', 'axolotl']

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:185
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
184	        expect.languages=['en']
185	        expect.datasets=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}]
186	        self.assertEqual(got, expect)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
189	        model_card = {'base_models': 'teknium/OpenHermes-2.5'}
190	        expect = gguf.Metadata(base_models=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])
191	        got = gguf.Metadata.apply_metadata_heuristic(gguf.Metadata(), model_card, None, None)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:195
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
194	        # Base Model spec is only url
195	        model_card = {'base_models': ['https://huggingface.co/teknium/OpenHermes-2.5']}
196	        expect = gguf.Metadata(base_models=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:196
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
195	        model_card = {'base_models': ['https://huggingface.co/teknium/OpenHermes-2.5']}
196	        expect = gguf.Metadata(base_models=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])
197	        got = gguf.Metadata.apply_metadata_heuristic(gguf.Metadata(), model_card, None, None)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
200	        # Base Model spec is given directly
201	        model_card = {'base_models': [{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}]}
202	        expect = gguf.Metadata(base_models=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:202
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
201	        model_card = {'base_models': [{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}]}
202	        expect = gguf.Metadata(base_models=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])
203	        got = gguf.Metadata.apply_metadata_heuristic(gguf.Metadata(), model_card, None, None)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:208
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
207	        model_card = {'datasets': 'teknium/OpenHermes-2.5'}
208	        expect = gguf.Metadata(datasets=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])
209	        got = gguf.Metadata.apply_metadata_heuristic(gguf.Metadata(), model_card, None, None)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:213
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
212	        # Dataset spec is only url
213	        model_card = {'datasets': ['https://huggingface.co/teknium/OpenHermes-2.5']}
214	        expect = gguf.Metadata(datasets=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:214
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
213	        model_card = {'datasets': ['https://huggingface.co/teknium/OpenHermes-2.5']}
214	        expect = gguf.Metadata(datasets=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])
215	        got = gguf.Metadata.apply_metadata_heuristic(gguf.Metadata(), model_card, None, None)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:219
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
218	        # Dataset spec is given directly
219	        model_card = {'datasets': [{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}]}
220	        expect = gguf.Metadata(datasets=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_metadata.py:220
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
219	        model_card = {'datasets': [{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}]}
220	        expect = gguf.Metadata(datasets=[{'name': 'OpenHermes 2.5', 'organization': 'Teknium', 'version': '2.5', 'repo_url': 'https://huggingface.co/teknium/OpenHermes-2.5'}])
221	        got = gguf.Metadata.apply_metadata_heuristic(gguf.Metadata(), model_card, None, None)

--------------------------------------------------
>> Issue: [B841:cdll] ctypes.CDLL
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/gguf-py/tests/test_quants.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b841_cdll.html
43	    def __init__(self, libggml: Path):
44	        self.libggml = ctypes.CDLL(str(libggml))
45	        self.libggml.ggml_quantize_chunk.restype = ctypes.c_size_t

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/scripts/fetch_server_test_models.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
33	        with open(test_file) as f:
34	            tree = ast.parse(f.read())
35	    except Exception as e:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/scripts/gen-unicode-data.py:10
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
9	
10	UNICODE_DATA_URL = "https://www.unicode.org/Public/UCD/latest/ucd/UnicodeData.txt"
11	
12	
13	# see https://www.unicode.org/L2/L1999/UnicodeData.html
14	def unicode_data_iter():

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/scripts/gen-unicode-data.py:15
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
14	def unicode_data_iter():
15	    res = requests.get(UNICODE_DATA_URL)
16	    res.raise_for_status()

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/scripts/get_chat_template.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
28	        assert re.match(r"^[\w.-]+/[\w.-]+$", model_id), f"Invalid model ID: {model_id}"
29	        response = requests.get(f"https://huggingface.co/{model_id}/resolve/main/tokenizer_config.json")
30	        if response.status_code == 401:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/scripts/get_chat_template.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	        assert re.match(r"^[\w.-]+/[\w.-]+$", model_id), f"Invalid model ID: {model_id}"
29	        response = requests.get(f"https://huggingface.co/{model_id}/resolve/main/tokenizer_config.json")
30	        if response.status_code == 401:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/llama_cpp_python-0.3.8/llama_cpp_python-0.3.8/vendor/llama.cpp/scripts/verify-checksum-models.py:38
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
37	with open(hash_list_file, "r") as f:
38	    hash_list = f.read().splitlines()
39	

--------------------------------------------------

Code scanned:
	Total lines of code: 35792
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 95.0
		High: 176.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 265.0
		High: 6.0
Files skipped (0):
