Run started:2025-04-12 17:46:46.721159

Test results:
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/enterprise/enterprise_callbacks/example_logging_api.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
26	
27	    uvicorn.run(app, host="127.0.0.1", port=8000)

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/enterprise/enterprise_hooks/aporia_ai.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
89	    ):
90	        data = await self.prepare_aporia_request(
91	            new_messages=new_messages, response_string=response_string
92	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/enterprise/enterprise_hooks/aporia_ai.py:156
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
155	        if response_str is not None:
156	            await self.make_aporia_api_request(
157	                response_string=response_str, new_messages=data.get("messages", [])
158	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/enterprise/enterprise_hooks/aporia_ai.py:202
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
201	        if new_messages is not None:
202	            await self.make_aporia_api_request(new_messages=new_messages)
203	            add_guardrail_to_applied_guardrails_header(

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/enterprise/enterprise_hooks/banned_keywords.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
34	                with open(banned_keywords_list, "r") as file:
35	                    data = file.read()
36	                    self.banned_keywords_list = data.split("\n")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/enterprise/enterprise_hooks/blocked_user_list.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
35	                with open(blocked_user_list, "r") as file:
36	                    data = file.read()
37	                    self.blocked_user_list = data.split("\n")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/enterprise/enterprise_hooks/llama_guard.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
44	                with open(file_path, "r") as file:
45	                    data = file.read()
46	            except FileNotFoundError:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/enterprise/enterprise_hooks/secret_detection.py:432
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
431	        temp_file = tempfile.NamedTemporaryFile(delete=False)
432	        temp_file.write(message_content.encode("utf-8"))
433	        temp_file.close()

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/enterprise/enterprise_hooks/secret_detection.py:432
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
431	        temp_file = tempfile.NamedTemporaryFile(delete=False)
432	        temp_file.write(message_content.encode("utf-8"))
433	        temp_file.close()

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/__init__.py:270
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
269	model_cost_map_url: str = (
270	    "https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json"
271	)
272	suppress_debug_info = False
273	dynamodb_table_name: Optional[str] = None

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:114
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
113	            or os.getenv("OPENAI_API_BASE")
114	            or "https://api.openai.com/v1"
115	        )
116	        organization = (
117	            optional_params.organization
118	            or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:186
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
185	                content="Unsupported provider",
186	                request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
187	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:200
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
199	                content="Unsupported provider",
200	                request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
201	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:313
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
312	            or os.getenv("OPENAI_API_BASE")
313	            or "https://api.openai.com/v1"
314	        )
315	        organization = (
316	            optional_params.organization
317	            or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:390
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
389	                content="Unsupported provider",
390	                request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
391	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:489
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
488	            or os.getenv("OPENAI_API_BASE")
489	            or "https://api.openai.com/v1"
490	        )
491	        organization = (
492	            optional_params.organization
493	            or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:567
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
566	                request=httpx.Request(
567	                    method="delete_assistant", url="https://github.com/BerriAI/litellm"
568	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:677
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
676	            or os.getenv("OPENAI_API_BASE")
677	            or "https://api.openai.com/v1"
678	        )
679	        organization = (
680	            optional_params.organization
681	            or litellm.organization

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:692
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
691	        )
692	        response = openai_assistants_api.create_thread(
693	            messages=messages,
694	            metadata=metadata,
695	            api_base=api_base,
696	            api_key=api_key,
697	            timeout=timeout,
698	            max_retries=optional_params.max_retries,
699	            organization=organization,
700	            client=client,
701	            acreate_thread=acreate_thread,
702	        )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:732
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
731	
732	        response = azure_assistants_api.create_thread(
733	            messages=messages,
734	            metadata=metadata,
735	            api_base=api_base,
736	            api_key=api_key,
737	            azure_ad_token=azure_ad_token,
738	            api_version=api_version,
739	            timeout=timeout,
740	            max_retries=optional_params.max_retries,
741	            client=client,
742	            acreate_thread=acreate_thread,
743	            litellm_params=litellm_params_dict,
744	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:755
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
754	                content="Unsupported provider",
755	                request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
756	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:832
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
831	            or os.getenv("OPENAI_API_BASE")
832	            or "https://api.openai.com/v1"
833	        )
834	        organization = (
835	            optional_params.organization
836	            or litellm.organization

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:848
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
847	
848	        response = openai_assistants_api.get_thread(
849	            thread_id=thread_id,
850	            api_base=api_base,
851	            api_key=api_key,
852	            timeout=timeout,
853	            max_retries=optional_params.max_retries,
854	            organization=organization,
855	            client=client,
856	            aget_thread=aget_thread,
857	        )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:887
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
886	
887	        response = azure_assistants_api.get_thread(
888	            thread_id=thread_id,
889	            api_base=api_base,
890	            api_key=api_key,
891	            azure_ad_token=azure_ad_token,
892	            api_version=api_version,
893	            timeout=timeout,
894	            max_retries=optional_params.max_retries,
895	            client=client,
896	            aget_thread=aget_thread,
897	            litellm_params=litellm_params_dict,
898	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:909
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
908	                content="Unsupported provider",
909	                request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
910	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1020
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1019	            or os.getenv("OPENAI_API_BASE")
1020	            or "https://api.openai.com/v1"
1021	        )
1022	        organization = (
1023	            optional_params.organization
1024	            or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1095
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1094	                content="Unsupported provider",
1095	                request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
1096	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1181
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1180	            or os.getenv("OPENAI_API_BASE")
1181	            or "https://api.openai.com/v1"
1182	        )
1183	        organization = (
1184	            optional_params.organization
1185	            or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1254
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1253	                content="Unsupported provider",
1254	                request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
1255	            ),

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1268
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1267	    kwargs["arun_thread"] = True
1268	    return run_thread(stream=True, event_handler=event_handler, **kwargs)  # type: ignore
1269	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1335
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1334	) -> AssistantStreamManager[AssistantEventHandler]:
1335	    return run_thread(stream=True, event_handler=event_handler, **kwargs)  # type: ignore
1336	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1379
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1378	            or os.getenv("OPENAI_API_BASE")
1379	            or "https://api.openai.com/v1"
1380	        )
1381	        organization = (
1382	            optional_params.organization
1383	            or litellm.organization

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1395
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1394	
1395	        response = openai_assistants_api.run_thread(
1396	            thread_id=thread_id,
1397	            assistant_id=assistant_id,
1398	            additional_instructions=additional_instructions,
1399	            instructions=instructions,
1400	            metadata=metadata,
1401	            model=model,
1402	            stream=stream,
1403	            tools=tools,
1404	            api_base=api_base,
1405	            api_key=api_key,
1406	            timeout=timeout,
1407	            max_retries=optional_params.max_retries,
1408	            organization=organization,
1409	            client=client,
1410	            arun_thread=arun_thread,
1411	            event_handler=event_handler,
1412	        )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1439
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1438	
1439	        response = azure_assistants_api.run_thread(
1440	            thread_id=thread_id,
1441	            assistant_id=assistant_id,
1442	            additional_instructions=additional_instructions,
1443	            instructions=instructions,
1444	            metadata=metadata,
1445	            model=model,
1446	            stream=stream,
1447	            tools=tools,
1448	            api_base=str(api_base) if api_base is not None else None,
1449	            api_key=str(api_key) if api_key is not None else None,
1450	            api_version=str(api_version) if api_version is not None else None,
1451	            azure_ad_token=str(azure_ad_token) if azure_ad_token is not None else None,
1452	            timeout=timeout,
1453	            max_retries=optional_params.max_retries,
1454	            client=client,
1455	            arun_thread=arun_thread,
1456	            litellm_params=litellm_params_dict,
1457	        )  # type: ignore

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/assistants/main.py:1468
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1467	                content="Unsupported provider",
1468	                request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
1469	            ),

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batch_completion/main.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
99	
100	        with ThreadPoolExecutor(max_workers=max_workers) as executor:
101	            for sub_batch in chunks(batch_messages, 100):

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batch_completion/main.py:154
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
153	        futures = {}
154	        with ThreadPoolExecutor(max_workers=len(models)) as executor:
155	            for model in models:

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batch_completion/main.py:171
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
170	        futures = {}
171	        with ThreadPoolExecutor(max_workers=len(deployments)) as executor:
172	            for deployment in deployments:

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batch_completion/main.py:247
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
246	
247	    with concurrent.futures.ThreadPoolExecutor(max_workers=len(models)) as executor:
248	        for idx, model in enumerate(models):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batches/main.py:161
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
160	                or os.getenv("OPENAI_API_BASE")
161	                or "https://api.openai.com/v1"
162	            )
163	            organization = (
164	                optional_params.organization
165	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batches/main.py:258
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
257	                    content="Unsupported provider",
258	                    request=httpx.Request(method="create_batch", url="https://github.com/BerriAI/litellm"),  # type: ignore
259	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batches/main.py:365
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
364	                or os.getenv("OPENAI_API_BASE")
365	                or "https://api.openai.com/v1"
366	            )
367	            organization = (
368	                optional_params.organization
369	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batches/main.py:462
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
461	                    content="Unsupported provider",
462	                    request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
463	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batches/main.py:560
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
559	                or os.getenv("OPENAI_API_BASE")
560	                or "https://api.openai.com/v1"
561	            )
562	            organization = (
563	                optional_params.organization
564	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batches/main.py:620
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
619	                    content="Unsupported provider",
620	                    request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
621	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batches/main.py:717
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
716	                or os.getenv("OPENAI_API_BASE")
717	                or "https://api.openai.com/v1"
718	            )
719	            organization = (
720	                optional_params.organization
721	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/batches/main.py:787
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
786	                    content="Unsupported provider",
787	                    request=httpx.Request(method="cancel_batch", url="https://github.com/BerriAI/litellm"),  # type: ignore
788	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/budget_manager.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	        self.project_name = project_name
36	        self.api_base = api_base or "https://api.litellm.ai"
37	        self.headers = headers or {"Content-Type": "application/json"}

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/budget_manager.py:105
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
104	        }
105	        self._save_data_thread()  # [Non-Blocking] Update persistent storage without blocking execution
106	        return self.user_dict[user]

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/budget_manager.py:152
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
151	            raise ValueError(
152	                "Either a chat completion object or the text response needs to be passed in. Learn more - https://docs.litellm.ai/docs/budget_manager"
153	            )
154	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/budget_manager.py:165
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
164	
165	        self._save_data_thread()  # [Non-Blocking] Update persistent storage without blocking execution
166	        return {"user": self.user_dict[user]}

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/budget_manager.py:200
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
199	            self.user_dict[user]["last_updated_at"] = current_time
200	            self._save_data_thread()  # Save the data
201	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/budget_manager.py:208
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
207	    def _save_data_thread(self):
208	        thread = threading.Thread(
209	            target=self.save_data
210	        )  # [Non-Blocking]: saves data without blocking execution

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/caching/caching.py:575
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
574	                # high traffic - fill in results in memory and then flush
575	                await self.batch_cache_write(result, **kwargs)
576	            else:

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/caching/caching.py:641
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
640	        cache_key, cached_data, kwargs = self._add_cache_logic(result=result, **kwargs)
641	        await self.cache.batch_cache_write(cache_key, cached_data, **kwargs)
642	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/caching/caching_handler.py:280
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
279	
280	                    threading.Thread(
281	                        target=logging_obj.success_handler,
282	                        args=(cached_result, start_time, end_time, cache_hit),
283	                    ).start()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/caching/caching_handler.py:449
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
448	        )
449	        threading.Thread(
450	            target=logging_obj.success_handler,
451	            args=(cached_result, start_time, end_time, cache_hit),
452	        ).start()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/caching/caching_handler.py:702
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
701	                elif isinstance(litellm.cache.cache, S3Cache):
702	                    threading.Thread(
703	                        target=litellm.cache.add_cache,
704	                        args=(result,),
705	                        kwargs=new_kwargs,
706	                    ).start()

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/caching/dual_cache.py:186
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
185	            # to avoid nested event loop issues
186	            with ThreadPoolExecutor(max_workers=1) as executor:
187	                future = executor.submit(run_in_new_loop)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/caching/s3_cache.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
117	                cached_response = (
118	                    cached_response["Body"].read().decode("utf-8")
119	                )  # Convert bytes to string

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/constants.py:203
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
202	    "api.groq.com/openai/v1",
203	    "https://integrate.api.nvidia.com/v1",
204	    "api.deepseek.com/v1",
205	    "api.together.xyz/v1",
206	    "app.empower.dev/api/v1",
207	    "https://api.friendli.ai/serverless/v1",
208	    "api.sambanova.ai/v1",
209	    "api.x.ai/v1",
210	    "api.galadriel.ai/v1",
211	]
212	
213	
214	openai_compatible_providers: List = [
215	    "anyscale",
216	    "mistral",
217	    "groq",
218	    "nvidia_nim",
219	    "cerebras",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/constants.py:207
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
206	    "app.empower.dev/api/v1",
207	    "https://api.friendli.ai/serverless/v1",
208	    "api.sambanova.ai/v1",
209	    "api.x.ai/v1",
210	    "api.galadriel.ai/v1",
211	]
212	
213	
214	openai_compatible_providers: List = [
215	    "anyscale",
216	    "mistral",
217	    "groq",
218	    "nvidia_nim",
219	    "cerebras",
220	    "sambanova",
221	    "ai21_chat",
222	    "ai21",
223	    "volcengine",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	            request=httpx.Request(
41	                method="GET", url="https://litellm.ai"
42	            ),  # mock request object

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:87
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
86	            request=httpx.Request(
87	                method="GET", url="https://litellm.ai"
88	            ),  # mock request object

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:131
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
130	            request=httpx.Request(
131	                method="GET", url="https://litellm.ai"
132	            ),  # mock request object

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:209
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
208	            method="POST",
209	            url="https://api.openai.com/v1",
210	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:306
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
305	                method="POST",
306	                url=" https://cloud.google.com/vertex-ai/",
307	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:346
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
345	        self.litellm_debug_info = litellm_debug_info
346	        request = httpx.Request(method="POST", url="https://api.openai.com/v1")
347	        self.response = httpx.Response(status_code=400, request=request)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:392
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
391	        self.request_data = request_data
392	        request = httpx.Request(method="POST", url="https://api.openai.com/v1")
393	        response = httpx.Response(status_code=400, request=request)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:434
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
433	        self.litellm_debug_info = litellm_debug_info
434	        request = httpx.Request(method="POST", url="https://api.openai.com/v1")
435	        self.response = httpx.Response(status_code=400, request=request)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:483
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
482	                method="POST",
483	                url=" https://cloud.google.com/vertex-ai/",
484	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:529
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
528	                method="POST",
529	                url=" https://cloud.google.com/vertex-ai/",
530	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:574
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
573	        if request is None:
574	            request = httpx.Request(method="POST", url="https://api.openai.com/v1")
575	        super().__init__(self.message, request=request, body=None)  # type: ignore

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:611
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
610	        self.litellm_debug_info = litellm_debug_info
611	        self.request = httpx.Request(method="POST", url="https://api.openai.com/v1")
612	        self.max_retries = max_retries

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:647
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
646	        self.model = model
647	        request = httpx.Request(method="POST", url="https://api.openai.com/v1")
648	        response = httpx.Response(status_code=500, request=request)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:711
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
710	            request=httpx.Request(
711	                method="GET", url="https://litellm.ai"
712	            ),  # mock request object

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:765
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
764	            request=httpx.Request(
765	                method="GET", url="https://litellm.ai"
766	            ),  # mock request object

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/exceptions.py:794
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
793	        if request is None:
794	            request = httpx.Request(method="POST", url="https://api.openai.com/v1")
795	        super().__init__(self.message, request=request, body=None)  # type: ignore

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:168
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
167	                or os.getenv("OPENAI_API_BASE")
168	                or "https://api.openai.com/v1"
169	            )
170	            organization = (
171	                optional_params.organization
172	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:261
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
260	                    content="Unsupported provider",
261	                    request=httpx.Request(method="create_file", url="https://github.com/BerriAI/litellm"),  # type: ignore
262	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:347
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
346	                or os.getenv("OPENAI_API_BASE")
347	                or "https://api.openai.com/v1"
348	            )
349	            organization = (
350	                optional_params.organization
351	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:413
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
412	                    content="Unsupported provider",
413	                    request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
414	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:498
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
497	                or os.getenv("OPENAI_API_BASE")
498	                or "https://api.openai.com/v1"
499	            )
500	            organization = (
501	                optional_params.organization
502	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:563
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
562	                    content="Unsupported provider",
563	                    request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
564	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:649
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
648	                or os.getenv("OPENAI_API_BASE")
649	                or "https://api.openai.com/v1"
650	            )
651	            organization = (
652	                optional_params.organization
653	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:715
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
714	                    content="Unsupported provider",
715	                    request=httpx.Request(method="file_list", url="https://github.com/BerriAI/litellm"),  # type: ignore
716	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:806
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
805	                or os.getenv("OPENAI_API_BASE")
806	                or "https://api.openai.com/v1"
807	            )
808	            organization = (
809	                optional_params.organization
810	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/files/main.py:872
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
871	                    content="Unsupported provider",
872	                    request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
873	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/fine_tuning/main.py:146
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
145	                or os.getenv("OPENAI_API_BASE")
146	                or "https://api.openai.com/v1"
147	            )
148	            organization = (
149	                optional_params.organization
150	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/fine_tuning/main.py:281
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
280	                    content="Unsupported provider",
281	                    request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
282	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/fine_tuning/main.py:367
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
366	                or os.getenv("OPENAI_API_BASE")
367	                or "https://api.openai.com/v1"
368	            )
369	            organization = (
370	                optional_params.organization
371	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/fine_tuning/main.py:438
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
437	                    content="Unsupported provider",
438	                    request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
439	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/fine_tuning/main.py:528
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
527	                or os.getenv("OPENAI_API_BASE")
528	                or "https://api.openai.com/v1"
529	            )
530	            organization = (
531	                optional_params.organization
532	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/fine_tuning/main.py:601
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
600	                    content="Unsupported provider",
601	                    request=httpx.Request(method="create_thread", url="https://github.com/BerriAI/litellm"),  # type: ignore
602	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/fine_tuning/main.py:682
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
681	                or os.getenv("OPENAI_API_BASE")
682	                or "https://api.openai.com/v1"
683	            )
684	            organization = (
685	                optional_params.organization
686	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/fine_tuning/main.py:752
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
751	                    content="Unsupported provider",
752	                    request=httpx.Request(method="retrieve_fine_tuning_job", url="https://github.com/BerriAI/litellm"),  # type: ignore
753	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/SlackAlerting/slack_alerting.py:1081
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1080	    api_key="your_api_key",
1081	    base_url={os.getenv("PROXY_BASE_URL", "http://0.0.0.0:4000")}
1082	)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/SlackAlerting/slack_alerting.py:1204
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1203	            key_budget = webhook_event.max_budget
1204	            base_url = os.getenv("PROXY_BASE_URL", "http://0.0.0.0:4000")
1205	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/argilla.py:108
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
107	            or os.getenv("ARGILLA_BASE_URL")
108	            or "http://localhost:6900/"
109	        )
110	        if _credentials_base_url is None:
111	            raise Exception(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/arize/arize.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
65	            protocol = "otlp_grpc"
66	            endpoint = "https://otlp.arize.com/v1"
67	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/arize/arize_phoenix.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
23	
24	ARIZE_HOSTED_PHOENIX_ENDPOINT = "https://app.phoenix.arize.com/v1/traces"
25	
26	
27	class ArizePhoenixLogger:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/athina.py:16
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
15	        self.athina_logging_url = (
16	            os.getenv("ATHINA_BASE_URL", "https://log.athina.ai")
17	            + "/api/v1/log/inference"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/azure_storage/azure_storage.py:298
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
297	            client_secret=client_secret,
298	            scope="https://storage.azure.com/.default",
299	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/braintrust_logging.py:26
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
25	global_braintrust_sync_http_handler = HTTPHandler()
26	API_BASE = "https://api.braintrustdata.com/v1"
27	
28	
29	def get_utc_datetime():

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog.py:80
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
79	            self.intake_url = (
80	                f"https://http-intake.logs.{os.getenv('DD_SITE')}/api/v2/logs"
81	            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog.py:194
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
193	            if litellm.datadog_use_v1 is True:
194	                dd_payload = self._create_v0_logging_payload(
195	                    kwargs=kwargs,
196	                    response_obj=response_obj,
197	                    start_time=start_time,
198	                    end_time=end_time,
199	                )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
200	            else:
201	                dd_payload = self.create_datadog_logging_payload(
202	                    kwargs=kwargs,
203	                    response_obj=response_obj,
204	                    start_time=start_time,
205	                    end_time=end_time,
206	                )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog.py:236
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
235	    async def _log_async_event(self, kwargs, response_obj, start_time, end_time):
236	        dd_payload = self.create_datadog_logging_payload(
237	            kwargs=kwargs,
238	            response_obj=response_obj,
239	            start_time=start_time,
240	            end_time=end_time,
241	        )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog.py:258
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
257	        verbose_logger.debug("Datadog: Logger - Logging payload = %s", json_payload)
258	        dd_payload = DatadogPayload(
259	            ddsource=self._get_datadog_source(),
260	            ddtags=self._get_datadog_tags(
261	                standard_logging_object=standard_logging_object
262	            ),
263	            hostname=self._get_datadog_hostname(),
264	            message=json_payload,
265	            service=self._get_datadog_service(),
266	            status=status,
267	        )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog.py:352
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
351	            _dd_message_str = json.dumps(_payload_dict, default=str)
352	            _dd_payload = DatadogPayload(
353	                ddsource=self._get_datadog_source(),
354	                ddtags=self._get_datadog_tags(),
355	                hostname=self._get_datadog_hostname(),
356	                message=_dd_message_str,
357	                service=self._get_datadog_service(),
358	                status=DataDogStatus.WARN,
359	            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog.py:392
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
391	            _dd_message_str = json.dumps(_payload_dict, default=str)
392	            _dd_payload = DatadogPayload(
393	                ddsource=self._get_datadog_source(),
394	                ddtags=self._get_datadog_tags(),
395	                hostname=self._get_datadog_hostname(),
396	                message=_dd_message_str,
397	                service=self._get_datadog_service(),
398	                status=DataDogStatus.INFO,
399	            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog.py:482
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
481	
482	        dd_payload = DatadogPayload(
483	            ddsource=self._get_datadog_source(),
484	            ddtags=self._get_datadog_tags(),
485	            hostname=self._get_datadog_hostname(),
486	            message=json_payload,
487	            service=self._get_datadog_service(),
488	            status=DataDogStatus.INFO,
489	        )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog.py:549
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
548	
549	        standard_logging_object = create_dummy_standard_logging_payload()
550	        dd_payload = self._create_datadog_logging_payload_helper(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog_llm_obs.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
44	            self.intake_url = (
45	                f"https://api.{self.DD_SITE}/api/intake/llm-obs/v1/trace/spans"
46	            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog_llm_obs.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
65	            )
66	            payload = self.create_llm_obs_payload(
67	                kwargs, response_obj, start_time, end_time
68	            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog_llm_obs.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
89	            payload = {
90	                "data": DDIntakePayload(
91	                    type="span",
92	                    attributes=DDSpanAttributes(
93	                        ml_app=self._get_datadog_service(),
94	                        tags=[self._get_datadog_tags()],
95	                        spans=self.log_queue,
96	                    ),

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/datadog/datadog_llm_obs.py:153
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
152	
153	        return LLMObsPayload(
154	            parent_id=metadata.get("parent_id", "undefined"),
155	            trace_id=metadata.get("trace_id", str(uuid.uuid4())),
156	            span_id=metadata.get("span_id", str(uuid.uuid4())),
157	            name=metadata.get("name", "litellm_llm_call"),
158	            meta=meta,
159	            start_ns=int(start_time.timestamp() * 1e9),
160	            duration=int((end_time - start_time).total_seconds() * 1e9),
161	            metrics=metrics,
162	            tags=[
163	                self._get_datadog_tags(standard_logging_object=standard_logging_payload)
164	            ],

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/email_alerting.py:12
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
11	# we use this for the email header, please send a test email if you change this. verify it looks good on email
12	LITELLM_LOGO_URL = "https://litellm-listing.s3.amazonaws.com/litellm_logo.png"
13	LITELLM_SUPPORT_CONTACT = "support@berri.ai"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/email_templates/templates.py:5
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4	
5	KEY_CREATED_EMAIL_TEMPLATE = """
6	                    <img src="{email_logo_url}" alt="LiteLLM Logo" width="150" height="50" />
7	
8	                    <p> Hi {recipient_email}, <br/>
9	        
10	                    I'm happy to provide you with an OpenAI Proxy API Key, loaded with ${key_budget} per month. <br /> <br />
11	
12	                    <b>
13	                    Key: <pre>{key_token}</pre> <br>
14	                    </b>
15	
16	                    <h2>Usage Example</h2>
17	
18	                    Detailed Documentation on <a href="https://docs.litellm.ai/docs/proxy/user_keys">Usage with OpenAI Python SDK, Langchain, LlamaIndex, Curl</a>
19	
20	                    <pre>
21	
22	                    import openai
23	                    client = openai.OpenAI(
24	                        api_key="{key_token}",
25	                        base_url={{base_url}}
26	                    )
27	
28	                    response = client.chat.completions.create(
29	                        model="gpt-3.5-turbo", # model to send to the proxy
30	                        messages = [
31	                            {{
32	                                "role": "user",
33	                                "content": "this is a test request, write a short poem"
34	                            }}
35	                        ]
36	                    )
37	
38	                    </pre>
39	
40	
41	                    If you have any questions, please send an email to {email_support_contact} <br /> <br />
42	
43	                    Best, <br />
44	                    The LiteLLM team <br />
45	"""
46	
47	
48	USER_INVITED_EMAIL_TEMPLATE = """

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/gcs_bucket/gcs_bucket_base.py:227
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
226	
227	            url = f"https://storage.googleapis.com/storage/v1/b/{bucket_name}/o/{object_name}?alt=media"
228	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/gcs_bucket/gcs_bucket_base.py:267
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
266	
267	            url = f"https://storage.googleapis.com/storage/v1/b/{bucket_name}/o/{object_name}"
268	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/gcs_bucket/gcs_bucket_base.py:315
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
314	            headers=headers,
315	            url=f"https://storage.googleapis.com/upload/storage/v1/b/{bucket_name}/o?uploadType=media&name={object_name}",
316	            data=json_logged_payload,

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/gcs_pubsub/pub_sub.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
125	            if litellm.gcs_pub_sub_use_v1 is True:
126	                spend_logs_payload = get_logging_payload(
127	                    kwargs=kwargs,
128	                    response_obj=response_obj,
129	                    start_time=start_time,
130	                    end_time=end_time,
131	                )

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/gcs_pubsub/pub_sub.py:192
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
191	
192	            encoded_message = base64.b64encode(message_data.encode("utf-8")).decode(
193	                "utf-8"

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/gcs_pubsub/pub_sub.py:192
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
191	
192	            encoded_message = base64.b64encode(message_data.encode("utf-8")).decode(
193	                "utf-8"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/gcs_pubsub/pub_sub.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
198	
199	            url = f"https://pubsub.googleapis.com/v1/projects/{self.project_id}/topics/{self.topic_id}:publish"
200	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/helicone.py:25
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
24	        # Instance variables
25	        self.provider_url = "https://api.openai.com/v1"
26	        self.key = os.getenv("HELICONE_API_KEY")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/helicone.py:142
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
141	            provider_url = self.provider_url
142	            url = "https://api.hconeai.com/oai/v1/log"
143	            if "claude" in model:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/helicone.py:144
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
143	            if "claude" in model:
144	                url = "https://api.hconeai.com/anthropic/v1/log"
145	                provider_url = "https://api.anthropic.com/v1/messages"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/helicone.py:145
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
144	                url = "https://api.hconeai.com/anthropic/v1/log"
145	                provider_url = "https://api.anthropic.com/v1/messages"
146	            headers = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/humanloop.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
69	
70	        base_url = "https://api.humanloop.com/v5/prompts/{}".format(humanloop_prompt_id)
71	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/langfuse/langfuse.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
54	        self.langfuse_host = langfuse_host or os.getenv(
55	            "LANGFUSE_HOST", "https://cloud.langfuse.com"
56	        )
57	        if not (

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/langfuse/langfuse.py:394
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
393	        verbose_logger.warning(
394	            "Please upgrade langfuse to v2.0.0 or higher: https://github.com/langfuse/langfuse-python/releases/tag/v2.0.1"
395	        )
396	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/langfuse/langfuse_prompt_management.py:77
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
76	    langfuse_host = langfuse_host or os.getenv(
77	        "LANGFUSE_HOST", "https://cloud.langfuse.com"
78	    )
79	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/langsmith.py:93
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
92	            or os.getenv("LANGSMITH_BASE_URL")
93	            or "https://api.smith.langchain.com"
94	        )
95	        if _credentials_base_url is None:
96	            raise Exception(

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/langsmith.py:222
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
221	            )
222	            credentials = self._get_credentials_to_use_for_request(kwargs=kwargs)
223	            data = self._prepare_log_data(

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/langsmith.py:262
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
261	            )
262	            credentials = self._get_credentials_to_use_for_request(kwargs=kwargs)
263	            data = self._prepare_log_data(

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/langsmith.py:300
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
299	        try:
300	            credentials = self._get_credentials_to_use_for_request(kwargs=kwargs)
301	            data = self._prepare_log_data(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/literal_ai.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
23	        literalai_api_key=None,
24	        literalai_api_url="https://cloud.getliteral.ai",
25	        env=None,
26	        **kwargs,
27	    ):
28	        self.literalai_api_url = os.getenv("LITERAL_API_URL") or literalai_api_url
29	        self.headers = {

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/openmeter.py:83
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
82	    def log_success_event(self, kwargs, response_obj, start_time, end_time):
83	        _url = os.getenv("OPENMETER_API_ENDPOINT", "https://openmeter.cloud")
84	        if _url.endswith("/"):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/openmeter.py:109
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
108	    async def async_log_success_event(self, kwargs, response_obj, start_time, end_time):
109	        _url = os.getenv("OPENMETER_API_ENDPOINT", "https://openmeter.cloud")
110	        if _url.endswith("/"):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/opik/opik.py:46
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
45	            user_value=kwargs.get("url", None),
46	            default_value="https://www.comet.com/opik/api",
47	        )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/opik/opik.py:80
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
79	        try:
80	            opik_payload = self._create_opik_payload(
81	                kwargs=kwargs,
82	                response_obj=response_obj,
83	                start_time=start_time,
84	                end_time=end_time,
85	            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/opik/opik.py:117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
116	        try:
117	            opik_payload = self._create_opik_payload(
118	                kwargs=kwargs,
119	                response_obj=response_obj,
120	                start_time=start_time,
121	                end_time=end_time,
122	            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/opik/opik.py:124
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
123	
124	            traces, spans = get_traces_and_spans_from_payload(opik_payload)
125	            if len(traces) > 0:

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/opik/opik.py:171
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
170	        # Split the log_queue into traces and spans
171	        traces, spans = get_traces_and_spans_from_payload(self.log_queue)
172	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/opik/utils.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
43	    config = configparser.ConfigParser()
44	    config.read(config_path)
45	

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/pagerduty/pagerduty.py:288
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
287	            payload: PagerDutyRequestBody = PagerDutyRequestBody(
288	                payload=PagerDutyPayload(
289	                    summary=alert_message,
290	                    severity="critical",
291	                    source="LiteLLM Alert",
292	                    component="LiteLLM",
293	                    custom_details=custom_details,
294	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/pagerduty/pagerduty.py:300
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
299	            return await async_client.post(
300	                url="https://events.pagerduty.com/v2/enqueue",
301	                json=dict(payload),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/prompt_layer.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
50	            request_response = litellm.module_level_client.post(
51	                "https://api.promptlayer.com/rest/track-request",
52	                json={
53	                    "function_name": "openai.ChatCompletion.create",
54	                    "kwargs": new_kwargs,
55	                    "tags": tags,
56	                    "request_response": dict(response_obj),
57	                    "request_start_time": int(start_time.timestamp()),
58	                    "request_end_time": int(end_time.timestamp()),
59	                    "api_key": self.key,
60	                    # Optional params for PromptLayer
61	                    # "prompt_id": "<PROMPT ID>",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/integrations/prompt_layer.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	                    response = litellm.module_level_client.post(
78	                        "https://api.promptlayer.com/rest/track-metadata",
79	                        json={
80	                            "request_id": response_json["request_id"],
81	                            "api_key": self.key,
82	                            "metadata": metadata,
83	                        },
84	                    )

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/asyncify.py:110
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
109	        # to avoid nested event loop issues
110	        with ThreadPoolExecutor(max_workers=1) as executor:
111	            future = executor.submit(run_in_new_loop)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:141
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
140	        print(  # noqa
141	            "\033[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\033[0m"  # noqa
142	        )  # noqa
143	        print(  # noqa

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:370
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
369	                    _request = httpx.Request(
370	                        method="POST", url="https://api.openai.com/v1"
371	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:472
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
471	                        request=httpx.Request(
472	                            method="POST", url="https://api.openai.com/v1/"
473	                        ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:673
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
672	                        method="POST",
673	                        url="https://api.replicate.com/v1/deployments",
674	                    ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:905
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
904	                                request=httpx.Request(
905	                                    method="POST", url="https://api.openai.com/v1/"
906	                                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1020
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1019	                                request=httpx.Request(
1020	                                    method="POST", url="https://api.openai.com/v1/"
1021	                                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1111	                                method="POST",
1112	                                url=" https://cloud.google.com/vertex-ai/",
1113	                            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1136
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1135	                            content=str(original_exception),
1136	                            request=httpx.Request(method="completion", url="https://github.com/BerriAI/litellm"),  # type: ignore
1137	                        ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1158
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1157	                                method="POST",
1158	                                url=" https://cloud.google.com/vertex-ai/",
1159	                            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1178
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1177	                                method="POST",
1178	                                url=" https://cloud.google.com/vertex-ai/",
1179	                            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1198	                                method="POST",
1199	                                url=" https://cloud.google.com/vertex-ai/",
1200	                            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1226
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1225	                                    method="POST",
1226	                                    url="https://cloud.google.com/vertex-ai/",
1227	                                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1263
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1262	                                    method="POST",
1263	                                    url=" https://cloud.google.com/vertex-ai/",
1264	                                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1277
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1276	                                content=str(original_exception),
1277	                                request=httpx.Request(method="completion", url="https://github.com/BerriAI/litellm"),  # type: ignore
1278	                            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:1330
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1329	                                method="POST",
1330	                                url=" https://cloud.google.com/vertex-ai/",
1331	                            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:2060
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2059	                            request=httpx.Request(
2060	                                method="POST", url="https://openai.com/"
2061	                            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:2070
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2069	                        litellm_debug_info=extra_information,
2070	                        request=httpx.Request(method="POST", url="https://openai.com/"),
2071	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:2163
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2162	                        request=httpx.Request(
2163	                            method="POST", url="https://api.openai.com/v1/"
2164	                        ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/exception_mapping_utils.py:2197
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2196	                    request=httpx.Request(
2197	                        method="POST", url="https://api.openai.com/v1/"
2198	                    ),  # stub the request

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:187
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
186	                        dynamic_api_key = get_secret_str("GROQ_API_KEY")
187	                    elif endpoint == "https://integrate.api.nvidia.com/v1":
188	                        custom_llm_provider = "nvidia_nim"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
189	                        dynamic_api_key = get_secret_str("NVIDIA_NIM_API_KEY")
190	                    elif endpoint == "https://api.cerebras.ai/v1":
191	                        custom_llm_provider = "cerebras"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:193
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
192	                        dynamic_api_key = get_secret_str("CEREBRAS_API_KEY")
193	                    elif endpoint == "https://api.sambanova.ai/v1":
194	                        custom_llm_provider = "sambanova"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:196
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
195	                        dynamic_api_key = get_secret_str("SAMBANOVA_API_KEY")
196	                    elif endpoint == "https://api.ai21.com/studio/v1":
197	                        custom_llm_provider = "ai21_chat"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:199
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
198	                        dynamic_api_key = get_secret_str("AI21_API_KEY")
199	                    elif endpoint == "https://codestral.mistral.ai/v1":
200	                        custom_llm_provider = "codestral"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:202
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
201	                        dynamic_api_key = get_secret_str("CODESTRAL_API_KEY")
202	                    elif endpoint == "https://codestral.mistral.ai/v1":
203	                        custom_llm_provider = "text-completion-codestral"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:211
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
210	                        dynamic_api_key = get_secret_str("DEEPSEEK_API_KEY")
211	                    elif endpoint == "https://api.friendli.ai/serverless/v1":
212	                        custom_llm_provider = "friendliai"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:295
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
294	                or get_secret("AI21_API_BASE")
295	                or "https://api.ai21.com/studio/v1"
296	            )  # type: ignore
297	            dynamic_api_key = api_key or get_secret("AI21_API_KEY")
298	        ## aleph_alpha

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:330
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
329	                print(  # noqa
330	                    "\033[1;31mProvider List: https://docs.litellm.ai/docs/providers\033[0m"  # noqa
331	                )  # noqa
332	                print()  # noqa

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:333
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
332	                print()  # noqa
333	            error_str = f"LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model={model}\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
334	            # maps to openai.NotFoundError, this is raised when openai does not recognize the llm

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:341
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
340	                    content=error_str,
341	                    request=httpx.Request(method="completion", url="https://github.com/BerriAI/litellm"),  # type: ignore
342	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:369
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
368	                    content=error_str,
369	                    request=httpx.Request(method="completion", url="https://github.com/BerriAI/litellm"),  # type: ignore
370	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:405
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
404	        # anyscale is openai compatible, we just need to set this to custom_openai and have the api_base be https://api.endpoints.anyscale.com/v1
405	        api_base = api_base or get_secret_str("ANYSCALE_API_BASE") or "https://api.endpoints.anyscale.com/v1"  # type: ignore
406	        dynamic_api_key = api_key or get_secret_str("ANYSCALE_API_KEY")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:418
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
417	            or get_secret("EMPOWER_API_BASE")
418	            or "https://app.empower.dev/api/v1"
419	        )  # type: ignore
420	        dynamic_api_key = api_key or get_secret_str("EMPOWER_API_KEY")
421	    elif custom_llm_provider == "groq":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:433
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
432	            or get_secret("NVIDIA_NIM_API_BASE")
433	            or "https://integrate.api.nvidia.com/v1"
434	        )  # type: ignore
435	        dynamic_api_key = api_key or get_secret_str("NVIDIA_NIM_API_KEY")
436	    elif custom_llm_provider == "cerebras":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:438
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
437	        api_base = (
438	            api_base or get_secret("CEREBRAS_API_BASE") or "https://api.cerebras.ai/v1"
439	        )  # type: ignore

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:445
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
444	            or get_secret("SAMBANOVA_API_BASE")
445	            or "https://api.sambanova.ai/v1"
446	        )  # type: ignore
447	        dynamic_api_key = api_key or get_secret_str("SAMBANOVA_API_KEY")
448	    elif (custom_llm_provider == "ai21_chat") or (

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:452
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
451	        api_base = (
452	            api_base or get_secret("AI21_API_BASE") or "https://api.ai21.com/studio/v1"
453	        )  # type: ignore

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:461
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
460	            or get_secret("VOLCENGINE_API_BASE")
461	            or "https://ark.cn-beijing.volces.com/api/v3"
462	        )  # type: ignore
463	        dynamic_api_key = api_key or get_secret_str("VOLCENGINE_API_KEY")
464	    elif custom_llm_provider == "codestral":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:469
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
468	            or get_secret("CODESTRAL_API_BASE")
469	            or "https://codestral.mistral.ai/v1"
470	        )  # type: ignore
471	        dynamic_api_key = api_key or get_secret_str("CODESTRAL_API_KEY")
472	    elif custom_llm_provider == "hosted_vllm":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:493
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
492	            or get_secret("DEEPSEEK_API_BASE")
493	            or "https://api.deepseek.com/beta"
494	        )  # type: ignore
495	
496	        dynamic_api_key = api_key or get_secret_str("DEEPSEEK_API_KEY")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:517
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
516	            or get_secret_str("GITHUB_API_BASE")
517	            or "https://models.inference.ai.azure.com"  # This is github's default base url
518	        )
519	        dynamic_api_key = api_key or get_secret_str("GITHUB_API_KEY")
520	    elif custom_llm_provider == "litellm_proxy":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:550
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
549	            or get_secret_str("TOGETHER_AI_API_BASE")
550	            or "https://api.together.xyz/v1"
551	        )  # type: ignore
552	        dynamic_api_key = api_key or (
553	            get_secret_str("TOGETHER_API_KEY")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:562
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
561	            or get_secret("FRIENDLI_API_BASE")
562	            or "https://api.friendli.ai/serverless/v1"
563	        )  # type: ignore
564	        dynamic_api_key = (
565	            api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_llm_provider_logic.py:573
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
572	            or get_secret("GALADRIEL_API_BASE")
573	            or "https://api.galadriel.com/v1"
574	        )  # type: ignore
575	        dynamic_api_key = api_key or get_secret_str("GALADRIEL_API_KEY")
576	    elif custom_llm_provider == "snowflake":

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_model_cost_map.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
26	        ) as f:
27	            content = json.load(f)
28	            return content

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/get_model_cost_map.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
43	        ) as f:
44	            content = json.load(f)
45	            return content

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/litellm_logging.py:2815
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2814	                exporter="otlp_http",
2815	                endpoint="https://logfire-api.pydantic.dev/v1/traces",
2816	                headers=f"Authorization={os.getenv('LOGFIRE_TOKEN')}",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/litellm_logging.py:2859
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2858	                exporter="otlp_http",
2859	                endpoint="https://langtrace.ai/api/trace",
2860	            )

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/litellm_logging.py:3752
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
3751	        spend_logs_metadata=None,
3752	        requester_ip_address=str("127.0.0.1"),
3753	        requester_metadata=None,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/litellm_logging.py:3804
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
3803	        custom_llm_provider=str("openai"),
3804	        api_base=str("https://api.openai.com"),
3805	        metadata=metadata,

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/litellm_logging.py:3811
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
3810	        end_user=None,
3811	        requester_ip_address=str("127.0.0.1"),
3812	        messages=messages,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/llm_response_utils/get_api_base.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
110	        if stream:
111	            _api_base = "https://generativelanguage.googleapis.com/v1beta/models/{}:streamGenerateContent".format(
112	                model

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/llm_response_utils/get_api_base.py:115
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
114	        else:
115	            _api_base = "https://generativelanguage.googleapis.com/v1beta/models/{}:generateContent".format(
116	                model

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/llm_response_utils/get_api_base.py:120
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
119	    elif custom_llm_provider == "openai":
120	        _api_base = "https://api.openai.com"
121	        return _api_base

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/common_utils.py:395
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
394	        with open(file_content, "rb") as f:
395	            content = f.read()
396	    elif isinstance(file_content, io.IOBase):

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/common_utils.py:398
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
397	        # If it's a file-like object
398	        content = file_content.read()
399	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/factory.py:379
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
378	            try:
379	                url = f"https://huggingface.co/{hf_model_name}/raw/main/tokenizer_config.json"
380	                # Make a GET request to fetch the JSON data

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/factory.py:538
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
537	        client = HTTPHandler(concurrent_limit=1)
538	        response = client.get("https://api.together.xyz/models/info", headers=headers)
539	        if response.status_code == 200:

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/factory.py:2135
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
2134	                    # Decode the base64 image data
2135	                    image_data = base64.b64decode(base64_data)
2136	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/factory.py:2135
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
2134	                    # Decode the base64 image data
2135	                    image_data = base64.b64decode(base64_data)
2136	

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/factory.py:2275
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
2274	        # Convert the image content to base64 bytes
2275	        base64_bytes = base64.b64encode(response.content).decode("utf-8")
2276	

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/factory.py:2275
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
2274	        # Convert the image content to base64 bytes
2275	        base64_bytes = base64.b64encode(response.content).decode("utf-8")
2276	

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/image_handling.py:25
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
24	    image_bytes = response.content
25	    base64_image = base64.b64encode(image_bytes).decode("utf-8")
26	

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/prompt_templates/image_handling.py:25
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
24	    image_bytes = response.content
25	    base64_image = base64.b64encode(image_bytes).decode("utf-8")
26	

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/realtime_streaming.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
41	# Create a thread pool with a maximum of 10 threads
42	executor = concurrent.futures.ThreadPoolExecutor(max_workers=10)
43	

--------------------------------------------------
>> Issue: [B809:recv] socket.socket.recv
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/realtime_streaming.py:129
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b809_recv.html
128	            while True:
129	                message = await self.backend_ws.recv()
130	                await self.websocket.send_text(message)

--------------------------------------------------
>> Issue: [B805:send] socket.socket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/realtime_streaming.py:148
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b805_send.html
147	                ## FORWARD TO BACKEND
148	                await self.backend_ws.send(message)
149	        except self.websockets.exceptions.ConnectionClosed:  # type: ignore

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/streaming_chunk_builder_utils.py:437
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
436	    # Decode each base64 string and collect the resulting bytes
437	    combined_bytes = b"".join(base64.b64decode(b64_str) for b64_str in base64_strings)
438	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/streaming_chunk_builder_utils.py:437
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
436	    # Decode each base64 string and collect the resulting bytes
437	    combined_bytes = b"".join(base64.b64decode(b64_str) for b64_str in base64_strings)
438	

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/streaming_chunk_builder_utils.py:440
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
439	    # Encode the concatenated bytes back to base64
440	    return base64.b64encode(combined_bytes).decode("utf-8")

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/streaming_chunk_builder_utils.py:440
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
439	    # Encode the concatenated bytes back to base64
440	    return base64.b64encode(combined_bytes).decode("utf-8")

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/streaming_handler.py:1614
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1613	            # LOG FAILURE - handle streaming failure logging in the _next_ object, remove `handle_failure` once it's deprecated
1614	            threading.Thread(
1615	                target=self.logging_obj.failure_handler, args=(e, traceback_exception)
1616	            ).start()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/streaming_handler.py:1795
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1794	                ## LOGGING
1795	                threading.Thread(
1796	                    target=self.logging_obj.failure_handler,
1797	                    args=(e, traceback_exception),
1798	                ).start()  # log response

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/streaming_handler.py:1808
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1807	                ## LOGGING
1808	                threading.Thread(
1809	                    target=self.logging_obj.failure_handler,
1810	                    args=(e, traceback_exception),
1811	                ).start()  # log response

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/thread_pool_executor.py:5
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
4	# Create a ThreadPoolExecutor
5	executor = ThreadPoolExecutor(max_workers=MAX_THREADS)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/token_counter.py:193
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
192	        response = client.get(data)
193	        img_data = response.read()
194	    except Exception:

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/token_counter.py:197
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
196	        _header, encoded = data.split(",", 1)
197	        img_data = base64.b64decode(encoded)
198	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/token_counter.py:197
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
196	        _header, encoded = data.split(",", 1)
197	        img_data = base64.b64decode(encoded)
198	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/token_counter.py:214
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
213	                fhandle.seek(size, 1)
214	                byte = fhandle.read(1)
215	                while ord(byte) == 0xFF:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/token_counter.py:216
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
215	                while ord(byte) == 0xFF:
216	                    byte = fhandle.read(1)
217	                ftype = ord(byte)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/token_counter.py:218
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
217	                ftype = ord(byte)
218	                size = struct.unpack(">H", fhandle.read(2))[0] - 2
219	            fhandle.seek(1, 1)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/litellm_core_utils/token_counter.py:220
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
219	            fhandle.seek(1, 1)
220	            h, w = struct.unpack(">HH", fhandle.read(4))
221	        return w, h

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/aiohttp_openai/chat/transformation.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	        if api_base is None:
41	            api_base = "https://api.openai.com"
42	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/anthropic/chat/handler.py:316
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
315	
316	        data = config.transform_request(
317	            model=model,
318	            messages=messages,
319	            optional_params=optional_params,
320	            litellm_params=litellm_params,
321	            headers=headers,
322	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/anthropic/common_utils.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
30	            or get_secret_str("ANTHROPIC_API_BASE")
31	            or "https://api.anthropic.com"
32	        )
33	
34	    @staticmethod

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/anthropic/completion/transformation.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	        self.request = httpx.Request(
40	            method="POST", url="https://api.anthropic.com/v1/complete"
41	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/anthropic/experimental_pass_through/messages/transformation.py:7
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
6	
7	DEFAULT_ANTHROPIC_API_BASE = "https://api.anthropic.com"
8	DEFAULT_ANTHROPIC_API_VERSION = "2023-06-01"

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/azure.py:249
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
248	            else:
249	                data = litellm.AzureOpenAIConfig().transform_request(
250	                    model=model,
251	                    messages=messages,
252	                    optional_params=optional_params,
253	                    litellm_params=litellm_params,
254	                    headers=headers or {},
255	                )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/azure.py:343
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
342	
343	                headers, response = self.make_sync_azure_openai_chat_completion_request(
344	                    azure_client=azure_client, data=data, timeout=timeout
345	                )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/azure.py:427
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
426	
427	            headers, response = await self.make_azure_openai_chat_completion_request(
428	                azure_client=azure_client,
429	                data=data,
430	                timeout=timeout,
431	                logging_obj=logging_obj,
432	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/azure.py:548
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
547	        )
548	        headers, response = self.make_sync_azure_openai_chat_completion_request(
549	            azure_client=azure_client, data=data, timeout=timeout
550	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/azure.py:605
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
604	
605	            headers, response = await self.make_azure_openai_chat_completion_request(
606	                azure_client=azure_client,
607	                data=data,
608	                timeout=timeout,
609	                logging_obj=logging_obj,
610	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/azure.py:888
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
887	                content=json.dumps(result).encode("utf-8"),
888	                request=httpx.Request(method="POST", url="https://api.openai.com/v1"),
889	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/azure.py:986
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
985	                content=json.dumps(result).encode("utf-8"),
986	                request=httpx.Request(method="POST", url="https://api.openai.com/v1"),
987	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/azure.py:1051
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1050	            )
1051	            httpx_response: httpx.Response = await self.make_async_azure_httpx_request(
1052	                client=None,
1053	                timeout=timeout,
1054	                api_base=img_gen_api_base,
1055	                api_version=api_version,
1056	                api_key=api_key,
1057	                data=data,
1058	                headers=headers,
1059	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/azure.py:1151
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1150	            )
1151	            httpx_response: httpx.Response = self.make_sync_azure_httpx_request(
1152	                client=None,
1153	                timeout=timeout,
1154	                api_base=img_gen_api_base,
1155	                api_version=api_version or "",
1156	                api_key=api_key or "",
1157	                data=data,
1158	                headers=headers,
1159	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/chat/gpt_transformation.py:175
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
174	                            status_code=400,
175	                            message=f"""Azure does not support 'tool_choice', for api_version={api_version}. Bump your API version to '2023-12-01-preview' or later. This parameter requires 'api_version="2023-12-01-preview"' or later. Azure API Reference: https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#chat-completions""",
176	                        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/chat/gpt_transformation.py:187
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
186	                            status_code=400,
187	                            message=f"Azure does not support '{value}' as a {param} param, for api_version={api_version}. To drop 'tool_choice=required' for calls with this Azure API version, set `litellm.drop_params=True` or for proxy:\n\n`litellm_settings:\n drop_params: true`\nAzure API Reference: https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#chat-completions",
188	                        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/common_utils.py:68
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
67	    client_secret: str,
68	    scope: str = "https://cognitiveservices.azure.com/.default",
69	) -> Callable[[], str]:
70	    """
71	    Get Azure AD token provider from `client_id`, `client_secret`, and `tenant_id`
72	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/common_utils.py:124
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
123	    azure_password: str,
124	    scope: str = "https://cognitiveservices.azure.com/.default",
125	) -> Callable[[], str]:
126	    """
127	    Get Azure AD token provider from `client_id`, `azure_username`, and `azure_password`
128	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/common_utils.py:165
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
164	    azure_authority_host = os.getenv(
165	        "AZURE_AUTHORITY_HOST", "https://login.microsoftonline.com"
166	    )
167	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/common_utils.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
200	            "grant_type": "client_credentials",
201	            "scope": "https://cognitiveservices.azure.com/.default",
202	            "client_assertion_type": "urn:ietf:params:oauth:client-assertion-type:jwt-bearer",
203	            "client_assertion": oidc_token,
204	        },
205	    )
206	
207	    if req_token.status_code != 200:

--------------------------------------------------
>> Issue: [B809:recv] socket.socket.recv
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/realtime/handler.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b809_recv.html
20	        while True:
21	            message = await backend_ws.recv()
22	            await client_ws.send_text(message)

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/realtime/handler.py:61
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
60	        try:
61	            async with websockets.connect(  # type: ignore
62	                url,
63	                extra_headers={
64	                    "api-key": api_key,  # type: ignore
65	                },

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure/realtime/handler.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
72	        except websockets.exceptions.InvalidStatusCode as e:  # type: ignore
73	            await websocket.close(code=e.status_code, reason=str(e))
74	        except Exception:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure_ai/chat/transformation.py:135
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
134	                field_description="Your Azure AI Studio API Base.",
135	                field_value="https://Mistral-serverless.",
136	            ),

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure_ai/chat/transformation.py:205
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
204	        optional_params.pop("max_retries", None)
205	        return super().transform_request(
206	            model, messages, optional_params, litellm_params, headers
207	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure_ai/embed/handler.py:151
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
150	            image_embeddings_idx,
151	        ) = AzureAICohereConfig()._transform_request(
152	            input=input, optional_params=optional_params, model=model
153	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/azure_ai/embed/handler.py:238
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
237	            image_embeddings_idx,
238	        ) = AzureAICohereConfig()._transform_request(
239	            input=input, optional_params=optional_params, model=model
240	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/base_llm/chat/transformation.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
63	            self.request = httpx.Request(
64	                method="POST", url="https://docs.litellm.ai/docs"
65	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/baseten.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
40	    headers = validate_environment(api_key)
41	    completion_url_fragment_1 = "https://app.baseten.co/models/"
42	    completion_url_fragment_2 = "/predict"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/base_aws_llm.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
34	        self.request = httpx.Request(
35	            method="POST", url="https://us-west-2.console.aws.amazon.com/bedrock"
36	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/base_aws_llm.py:348
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
347	        if aws_sts_endpoint is None:
348	            sts_endpoint = f"https://sts.{aws_region_name}.amazonaws.com"
349	        else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/base_aws_llm.py:533
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
532	        else:
533	            endpoint_url = f"https://bedrock-runtime.{aws_region_name}.amazonaws.com"
534	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/converse_handler.py:116
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
115	    ) -> CustomStreamWrapper:
116	        request_data = await litellm.AmazonConverseConfig()._async_transform_request(
117	            model=model,
118	            messages=messages,
119	            optional_params=optional_params,
120	            litellm_params=litellm_params,
121	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/converse_handler.py:180
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
179	    ) -> Union[ModelResponse, CustomStreamWrapper]:
180	        request_data = await litellm.AmazonConverseConfig()._async_transform_request(
181	            model=model,
182	            messages=messages,
183	            optional_params=optional_params,
184	            litellm_params=litellm_params,
185	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/converse_handler.py:377
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
376	
377	        _data = litellm.AmazonConverseConfig()._transform_request(
378	            model=model,
379	            messages=messages,
380	            optional_params=optional_params,
381	            litellm_params=litellm_params,
382	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/converse_transformation.py:551
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
550	            dict,
551	            self._transform_request(
552	                model=model,
553	                messages=messages,
554	                optional_params=optional_params,
555	                litellm_params=litellm_params,
556	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/converse_transformation.py:702
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
701	            raise BedrockError(
702	                message="Received={}, Error converting to valid response block={}. File an issue if litellm error - https://github.com/BerriAI/litellm/issues".format(
703	                    response.text, str(e)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/invoke_handler.py:1010
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
1009	                raise BedrockError(
1010	                    status_code=response.status_code, message=str(response.read())
1011	                )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/invoke_transformations/amazon_nova_transformation.py:53
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
52	    ) -> dict:
53	        _transformed_nova_request = AmazonConverseConfig.transform_request(
54	            self,
55	            model=model,
56	            messages=messages,
57	            optional_params=optional_params,
58	            litellm_params=litellm_params,
59	            headers=headers,
60	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/invoke_transformations/anthropic_claude3_transformation.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
56	    ) -> dict:
57	        _anthropic_request = AnthropicConfig.transform_request(
58	            self,
59	            model=model,
60	            messages=messages,
61	            optional_params=optional_params,
62	            litellm_params=litellm_params,
63	            headers=headers,
64	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/invoke_transformations/base_invoke_transformation.py:234
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
233	        elif provider == "anthropic":
234	            return litellm.AmazonAnthropicClaude3Config().transform_request(
235	                model=model,
236	                messages=messages,
237	                optional_params=optional_params,
238	                litellm_params=litellm_params,
239	                headers=headers,
240	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/chat/invoke_transformations/base_invoke_transformation.py:242
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
241	        elif provider == "nova":
242	            return litellm.AmazonInvokeNovaConfig().transform_request(
243	                model=model,
244	                messages=messages,
245	                optional_params=optional_params,
246	                litellm_params=litellm_params,
247	                headers=headers,
248	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/common_utils.py:160
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
159	    else:
160	        endpoint_url = f"https://bedrock-runtime.{region_name}.amazonaws.com"
161	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/embed/embedding.py:368
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
367	        if provider == "cohere":
368	            data = BedrockCohereEmbeddingConfig()._transform_request(
369	                model=model, input=input, inference_params=inference_params
370	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/embed/embedding.py:381
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
380	                        AmazonEmbeddingRequest
381	                    ) = AmazonTitanMultimodalEmbeddingG1Config()._transform_request(
382	                        input=i, inference_params=inference_params
383	                    )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/embed/embedding.py:385
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
384	                elif model == "amazon.titan-embed-text-v1":
385	                    transformed_request = AmazonTitanG1Config()._transform_request(
386	                        input=i, inference_params=inference_params
387	                    )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/embed/embedding.py:389
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
388	                elif model == "amazon.titan-embed-text-v2:0":
389	                    transformed_request = AmazonTitanV2Config()._transform_request(
390	                        input=i, inference_params=inference_params
391	                    )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/image/image_handler.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
57	    ):
58	        prepared_request = self._prepare_request(
59	            model=model,
60	            optional_params=optional_params,
61	            api_base=api_base,
62	            extra_headers=extra_headers,
63	            logging_obj=logging_obj,
64	            prompt=prompt,
65	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/rerank/handler.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
70	        )
71	        data = BedrockRerankConfig()._transform_request(request_data)
72	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/bedrock/rerank/handler.py:73
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
72	
73	        prepared_request = self._prepare_request(
74	            model=model,
75	            optional_params=optional_params,
76	            api_base=api_base,
77	            extra_headers=extra_headers,
78	            data=cast(dict, data),
79	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/cloudflare/chat/transformation.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
28	        self.message = message
29	        self.request = httpx.Request(method="POST", url="https://api.cloudflare.com")
30	        self.response = httpx.Response(status_code=status_code, request=self.request)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/cloudflare/chat/transformation.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
89	            api_base = (
90	                f"https://api.cloudflare.com/client/v4/accounts/{account_id}/ai/run/"
91	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/codestral/completion/handler.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	                method="POST",
39	                url="https://docs.codestral.com/user-guide/inference/rest_api",
40	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/codestral/completion/handler.py:218
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
217	            completion_url = (
218	                api_base or "https://codestral.mistral.ai/v1/fim/completions"
219	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/cohere/chat/transformation.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
32	        self.message = message
33	        self.request = httpx.Request(method="POST", url="https://api.cohere.ai/v1/chat")
34	        self.response = httpx.Response(status_code=status_code, request=self.request)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/cohere/embed/handler.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
36	        self.request = httpx.Request(
37	            method="POST", url="https://api.cohere.ai/v1/generate"
38	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/cohere/embed/handler.py:127
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
126	    headers = validate_environment(api_key, headers=headers)
127	    embed_url = complete_api_base or "https://api.cohere.ai/v1/embed"
128	    model = model

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/cohere/embed/handler.py:130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
129	
130	    data = data or CohereEmbeddingConfig()._transform_request(
131	        model=model, input=input, inference_params=optional_params
132	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/cohere/rerank/transformation.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
30	            return api_base
31	        return "https://api.cohere.ai/v1/rerank"
32	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/cohere/rerank_v2/transformation.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
21	            return api_base
22	        return "https://api.cohere.ai/v2/rerank"
23	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/aiohttp_handler.py:245
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
244	
245	        data = provider_config.transform_request(
246	            model=model,
247	            messages=messages,
248	            optional_params=optional_params,
249	            litellm_params=litellm_params,
250	            headers=headers,
251	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:208
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
207	
208	            req = self.client.build_request(
209	                "POST", url, data=data, json=json, params=params, headers=headers, timeout=timeout  # type: ignore
210	            )

--------------------------------------------------
>> Issue: [B831:send] ssl.SSLSocket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:211
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b831_send.html
210	            )
211	            response = await self.client.send(req, stream=stream)
212	            response.raise_for_status()

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:220
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
219	            try:
220	                return await self.single_connection_post_request(
221	                    url=url,
222	                    client=new_client,
223	                    data=data,
224	                    json=json,
225	                    params=params,
226	                    headers=headers,
227	                    stream=stream,
228	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:248
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
247	            if stream is True:
248	                setattr(e, "message", await e.response.aread())
249	                setattr(e, "text", await e.response.aread())

--------------------------------------------------
>> Issue: [B830:read] ssl.SSLSocket.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:248
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b830_read.html
247	            if stream is True:
248	                setattr(e, "message", await e.response.aread())
249	                setattr(e, "text", await e.response.aread())

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:249
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
248	                setattr(e, "message", await e.response.aread())
249	                setattr(e, "text", await e.response.aread())
250	            else:

--------------------------------------------------
>> Issue: [B830:read] ssl.SSLSocket.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:249
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b830_read.html
248	                setattr(e, "message", await e.response.aread())
249	                setattr(e, "text", await e.response.aread())
250	            else:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:274
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
273	
274	            req = self.client.build_request(
275	                "PUT", url, data=data, json=json, params=params, headers=headers, timeout=timeout  # type: ignore
276	            )

--------------------------------------------------
>> Issue: [B831:send] ssl.SSLSocket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:277
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b831_send.html
276	            )
277	            response = await self.client.send(req)
278	            response.raise_for_status()

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:286
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
285	            try:
286	                return await self.single_connection_post_request(
287	                    url=url,
288	                    client=new_client,
289	                    data=data,
290	                    json=json,
291	                    params=params,
292	                    headers=headers,
293	                    stream=stream,
294	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:313
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
312	            if stream is True:
313	                setattr(e, "message", await e.response.aread())
314	            else:

--------------------------------------------------
>> Issue: [B830:read] ssl.SSLSocket.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:313
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b830_read.html
312	            if stream is True:
313	                setattr(e, "message", await e.response.aread())
314	            else:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:334
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
333	
334	            req = self.client.build_request(
335	                "PATCH", url, data=data, json=json, params=params, headers=headers, timeout=timeout  # type: ignore
336	            )

--------------------------------------------------
>> Issue: [B831:send] ssl.SSLSocket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:337
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b831_send.html
336	            )
337	            response = await self.client.send(req)
338	            response.raise_for_status()

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:346
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
345	            try:
346	                return await self.single_connection_post_request(
347	                    url=url,
348	                    client=new_client,
349	                    data=data,
350	                    json=json,
351	                    params=params,
352	                    headers=headers,
353	                    stream=stream,
354	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:373
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
372	            if stream is True:
373	                setattr(e, "message", await e.response.aread())
374	            else:

--------------------------------------------------
>> Issue: [B830:read] ssl.SSLSocket.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:373
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b830_read.html
372	            if stream is True:
373	                setattr(e, "message", await e.response.aread())
374	            else:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:393
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
392	                timeout = self.timeout
393	            req = self.client.build_request(
394	                "DELETE", url, data=data, json=json, params=params, headers=headers, timeout=timeout  # type: ignore
395	            )

--------------------------------------------------
>> Issue: [B831:send] ssl.SSLSocket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:396
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b831_send.html
395	            )
396	            response = await self.client.send(req, stream=stream)
397	            response.raise_for_status()

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:405
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
404	            try:
405	                return await self.single_connection_post_request(
406	                    url=url,
407	                    client=new_client,
408	                    data=data,
409	                    json=json,
410	                    params=params,
411	                    headers=headers,
412	                    stream=stream,
413	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:419
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
418	            if stream is True:
419	                setattr(e, "message", await e.response.aread())
420	            else:

--------------------------------------------------
>> Issue: [B830:read] ssl.SSLSocket.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:419
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b830_read.html
418	            if stream is True:
419	                setattr(e, "message", await e.response.aread())
420	            else:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:441
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
440	        """
441	        req = client.build_request(
442	            "POST", url, data=data, json=json, params=params, headers=headers  # type: ignore
443	        )

--------------------------------------------------
>> Issue: [B831:send] ssl.SSLSocket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:444
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b831_send.html
443	        )
444	        response = await client.send(req, stream=stream)
445	        response.raise_for_status()

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:462
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
461	        if litellm.force_ipv4:
462	            return AsyncHTTPTransport(local_address="0.0.0.0")
463	        else:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:542
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
541	            if timeout is not None:
542	                req = self.client.build_request(
543	                    "POST",
544	                    url,
545	                    data=data,  # type: ignore
546	                    json=json,
547	                    params=params,
548	                    headers=headers,
549	                    timeout=timeout,
550	                    files=files,
551	                    content=content,  # type: ignore
552	                )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:554
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
553	            else:
554	                req = self.client.build_request(
555	                    "POST", url, data=data, json=json, params=params, headers=headers, files=files, content=content  # type: ignore
556	                )

--------------------------------------------------
>> Issue: [B831:send] ssl.SSLSocket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:557
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b831_send.html
556	                )
557	            response = self.client.send(req, stream=stream)
558	            response.raise_for_status()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:568
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
567	            if stream is True:
568	                setattr(e, "message", mask_sensitive_info(e.response.read()))
569	                setattr(e, "text", mask_sensitive_info(e.response.read()))

--------------------------------------------------
>> Issue: [B830:read] ssl.SSLSocket.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:568
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b830_read.html
567	            if stream is True:
568	                setattr(e, "message", mask_sensitive_info(e.response.read()))
569	                setattr(e, "text", mask_sensitive_info(e.response.read()))

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:569
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
568	                setattr(e, "message", mask_sensitive_info(e.response.read()))
569	                setattr(e, "text", mask_sensitive_info(e.response.read()))
570	            else:

--------------------------------------------------
>> Issue: [B830:read] ssl.SSLSocket.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:569
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b830_read.html
568	                setattr(e, "message", mask_sensitive_info(e.response.read()))
569	                setattr(e, "text", mask_sensitive_info(e.response.read()))
570	            else:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:592
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
591	            if timeout is not None:
592	                req = self.client.build_request(
593	                    "PATCH", url, data=data, json=json, params=params, headers=headers, timeout=timeout  # type: ignore
594	                )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:596
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
595	            else:
596	                req = self.client.build_request(
597	                    "PATCH", url, data=data, json=json, params=params, headers=headers  # type: ignore
598	                )

--------------------------------------------------
>> Issue: [B831:send] ssl.SSLSocket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:599
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b831_send.html
598	                )
599	            response = self.client.send(req, stream=stream)
600	            response.raise_for_status()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:610
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
609	            if stream is True:
610	                setattr(e, "message", mask_sensitive_info(e.response.read()))
611	                setattr(e, "text", mask_sensitive_info(e.response.read()))

--------------------------------------------------
>> Issue: [B830:read] ssl.SSLSocket.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:610
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b830_read.html
609	            if stream is True:
610	                setattr(e, "message", mask_sensitive_info(e.response.read()))
611	                setattr(e, "text", mask_sensitive_info(e.response.read()))

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:611
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
610	                setattr(e, "message", mask_sensitive_info(e.response.read()))
611	                setattr(e, "text", mask_sensitive_info(e.response.read()))
612	            else:

--------------------------------------------------
>> Issue: [B830:read] ssl.SSLSocket.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:611
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b830_read.html
610	                setattr(e, "message", mask_sensitive_info(e.response.read()))
611	                setattr(e, "text", mask_sensitive_info(e.response.read()))
612	            else:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:635
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
634	            if timeout is not None:
635	                req = self.client.build_request(
636	                    "PUT", url, data=data, json=json, params=params, headers=headers, timeout=timeout  # type: ignore
637	                )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:639
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
638	            else:
639	                req = self.client.build_request(
640	                    "PUT", url, data=data, json=json, params=params, headers=headers  # type: ignore
641	                )

--------------------------------------------------
>> Issue: [B831:send] ssl.SSLSocket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:642
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b831_send.html
641	                )
642	            response = self.client.send(req, stream=stream)
643	            return response

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/http_handler.py:667
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
666	        if litellm.force_ipv4:
667	            return HTTPTransport(local_address="0.0.0.0")
668	        else:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:262
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
261	
262	        data = provider_config.transform_request(
263	            model=model,
264	            messages=messages,
265	            optional_params=optional_params,
266	            litellm_params=litellm_params,
267	            headers=headers,
268	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:270
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
269	
270	        headers = provider_config.sign_request(
271	            headers=headers,
272	            optional_params=optional_params,
273	            request_data=data,
274	            api_base=api_base,
275	            stream=stream,
276	            fake_stream=fake_stream,
277	            model=model,
278	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:640
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
639	
640	        data = provider_config.transform_embedding_request(
641	            model=model,
642	            input=input,
643	            optional_params=optional_params,
644	            headers=headers,
645	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:775
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
774	
775	        data = provider_config.transform_rerank_request(
776	            model=model,
777	            optional_rerank_params=optional_rerank_params,
778	            headers=headers,
779	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:916
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
915	        # Handle the audio file based on type
916	        data = provider_config.transform_audio_transcription_request(
917	            model=model,
918	            audio_file=audio_file,
919	            optional_params=optional_params,
920	            litellm_params=litellm_params,
921	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:1019
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1018	
1019	        data = responses_api_provider_config.transform_responses_api_request(
1020	            model=model,
1021	            input=input,
1022	            response_api_optional_request_params=response_api_optional_request_params,
1023	            litellm_params=litellm_params,
1024	            headers=headers,
1025	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:1045
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1044	                if fake_stream is True:
1045	                    stream, data = self._prepare_fake_stream_request(
1046	                        stream=stream,
1047	                        data=data,
1048	                        fake_stream=fake_stream,
1049	                    )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:1134
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1133	
1134	        data = responses_api_provider_config.transform_responses_api_request(
1135	            model=model,
1136	            input=input,
1137	            response_api_optional_request_params=response_api_optional_request_params,
1138	            litellm_params=litellm_params,
1139	            headers=headers,
1140	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:1159
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1158	                if fake_stream is True:
1159	                    stream, data = self._prepare_fake_stream_request(
1160	                        stream=stream,
1161	                        data=data,
1162	                        fake_stream=fake_stream,
1163	                    )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/custom_httpx/llm_http_handler.py:1249
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1248	        # Get the transformed request data for both steps
1249	        transformed_request = provider_config.transform_create_file_request(
1250	            model="",
1251	            create_file_data=create_file_data,
1252	            litellm_params=litellm_params,
1253	            optional_params={},
1254	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/databricks/chat/transformation.py:109
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
108	                field_description="Your Databricks API Base.",
109	                field_value="https://adb-..",
110	            ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/deepgram/audio_transcription/transformation.py:162
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
161	            api_base = (
162	                get_secret_str("DEEPGRAM_API_BASE") or "https://api.deepgram.com/v1"
163	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/deepinfra/chat/transformation.py:117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
116	            or get_secret_str("DEEPINFRA_API_BASE")
117	            or "https://api.deepinfra.com/v1/openai"
118	        )
119	        dynamic_api_key = api_key or get_secret_str("DEEPINFRA_API_KEY")
120	        return api_base, dynamic_api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/deepseek/chat/transformation.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	            or get_secret_str("DEEPSEEK_API_BASE")
32	            or "https://api.deepseek.com/beta"
33	        )  # type: ignore
34	        dynamic_api_key = api_key or get_secret_str("DEEPSEEK_API_KEY")
35	        return api_base, dynamic_api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/deepseek/chat/transformation.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
49	        if not api_base:
50	            api_base = "https://api.deepseek.com/beta"
51	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/deprecated_providers/aleph_alpha.py:17
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
16	        self.request = httpx.Request(
17	            method="POST", url="https://api.aleph-alpha.com/complete"
18	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/deprecated_providers/palm.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
18	            method="POST",
19	            url="https://developers.generativeai.google/api/python/google/generativeai/chat",
20	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/fireworks_ai/chat/transformation.py:228
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
227	            or get_secret_str("FIREWORKS_API_BASE")
228	            or "https://api.fireworks.ai/inference/v1"
229	        )  # type: ignore
230	        dynamic_api_key = api_key or (
231	            get_secret_str("FIREWORKS_API_KEY")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/gemini/common_utils.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
38	            or get_secret_str("GEMINI_API_BASE")
39	            or "https://generativelanguage.googleapis.com"
40	        )
41	
42	    @staticmethod

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/groq/chat/transformation.py:86
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
85	            or get_secret_str("GROQ_API_BASE")
86	            or "https://api.groq.com/openai/v1"
87	        )  # type: ignore
88	        dynamic_api_key = api_key or get_secret_str("GROQ_API_KEY")
89	        return api_base, dynamic_api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/huggingface/chat/transformation.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
22	
23	BASE_URL = "https://router.huggingface.co"
24	
25	
26	class HuggingFaceChatConfig(OpenAIGPTConfig):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/huggingface/common_utils.py:9
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
8	
9	HF_HUB_URL = "https://huggingface.co"
10	
11	
12	class HuggingFaceError(BaseLLMException):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/huggingface/embedding/handler.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
21	
22	HF_HUB_URL = "https://huggingface.co"
23	
24	hf_tasks_embeddings = Literal[  # pipeline tags + hf tei endpoints - https://huggingface.github.io/text-embeddings-inference/#/

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/huggingface/embedding/handler.py:361
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
360	            embed_url = (
361	                f"https://router.huggingface.co/hf-inference/pipeline/{task}/{model}"
362	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/huggingface/embedding/transformation.py:348
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
347	        else:
348	            completion_url = f"https://api-inference.huggingface.co/models/{model}"
349	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/infinity/rerank/common_utils.py:11
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
10	        self.request = httpx.Request(
11	            method="POST", url="https://github.com/michaelfeil/infinity"
12	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/jina_ai/embedding/transformation.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
69	        api_base = (
70	            api_base or get_secret_str("JINA_AI_API_BASE") or "https://api.jina.ai/v1"
71	        )  # type: ignore

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/jina_ai/rerank/transformation.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
61	        if api_base is None:
62	            return "https://api.jina.ai/v1/rerank"
63	        base = URL(api_base)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/mistral/mistral_chat_transformation.py:140
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
139	            or get_secret_str("MISTRAL_AZURE_API_BASE")  # for Azure AI Mistral
140	            or "https://api.mistral.ai/v1"
141	        )  # type: ignore
142	
143	        # if api_base does not end with /v1 we add it

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/nlp_cloud/chat/handler.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
54	    completion_url = completion_url_fragment_1 + model + completion_url_fragment_2
55	    data = nlp_config.transform_request(
56	        model=model,
57	        messages=messages,
58	        optional_params=optional_params,
59	        litellm_params=litellm_params,
60	        headers=headers,
61	    )

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/ollama/common_utils.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
36	    try:
37	        image_data = Image.open(io.BytesIO(base64.b64decode(image)))
38	        if image_data.format in ["JPEG", "PNG"]:

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/ollama/common_utils.py:37
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
36	    try:
37	        image_data = Image.open(io.BytesIO(base64.b64decode(image)))
38	        if image_data.format in ["JPEG", "PNG"]:

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/ollama/common_utils.py:45
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
44	    jpeg_image.seek(0)
45	    return base64.b64encode(jpeg_image.getvalue()).decode("utf-8")

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/ollama/common_utils.py:45
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
44	    jpeg_image.seek(0)
45	    return base64.b64encode(jpeg_image.getvalue()).decode("utf-8")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/ollama/completion/transformation.py:139
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
138	                field_description="Your Ollama API Base",
139	                field_value="http://10.10.11.249:11434",
140	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/ollama/completion/transformation.py:206
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
205	            model = model.split("/", 1)[1]
206	        api_base = get_secret_str("OLLAMA_API_BASE") or "http://localhost:11434"
207	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/ollama/completion/transformation.py:379
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
378	        if api_base is None:
379	            api_base = "http://localhost:11434"
380	        if api_base.endswith("/api/generate"):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/ollama_chat.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
26	        self.message = message
27	        self.request = httpx.Request(method="POST", url="http://localhost:11434")
28	        self.response = httpx.Response(status_code=status_code, request=self.request)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/ollama_chat.py:208
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
207	    logging_obj: Any,
208	    api_base="http://localhost:11434",
209	    api_key: Optional[str] = None,
210	    acompletion: bool = False,
211	    encoding=None,
212	    client: Optional[Union[HTTPHandler, AsyncHTTPHandler]] = None,
213	):
214	    if api_base.endswith("/api/chat"):
215	        url = api_base
216	    else:
217	        url = f"{api_base}/api/chat"
218	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/oobabooga/chat/oobabooga.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
48	    completion_url = completion_url + "/v1/chat/completions"
49	    data = oobabooga_config.transform_request(
50	        model=model,
51	        messages=messages,
52	        optional_params=optional_params,
53	        litellm_params=litellm_params,
54	        headers=headers,
55	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/chat/gpt_transformation.py:306
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
305	        if api_base is None:
306	            api_base = "https://api.openai.com"
307	        endpoint = "chat/completions"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/chat/gpt_transformation.py:345
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
344	        if api_base is None:
345	            api_base = "https://api.openai.com"
346	        if api_key is None:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/chat/gpt_transformation.py:375
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
374	            or get_secret_str("OPENAI_API_BASE")
375	            or "https://api.openai.com/v1"
376	        )
377	
378	    @staticmethod
379	    def get_base_model(model: str) -> str:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/common_utils.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
33	        else:
34	            self.request = httpx.Request(method="POST", url="https://api.openai.com/v1")
35	        if response:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/image_variations/handler.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
96	                    request=httpx.Request(
97	                        method="GET", url="https://litellm.ai"
98	                    ),  # mock request object

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/image_variations/handler.py:224
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
223	                    request=httpx.Request(
224	                        method="GET", url="https://litellm.ai"
225	                    ),  # mock request object

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:555
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
554	                if provider_config is not None:
555	                    data = provider_config.transform_request(
556	                        model=model,
557	                        messages=messages,
558	                        optional_params=inference_params,
559	                        litellm_params=litellm_params,
560	                        headers=headers or {},
561	                    )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:563
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
562	                else:
563	                    data = OpenAIConfig().transform_request(
564	                        model=model,
565	                        messages=messages,
566	                        optional_params=inference_params,
567	                        litellm_params=litellm_params,
568	                        headers=headers or {},
569	                    )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:652
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
651	                            response,
652	                        ) = self.make_sync_openai_chat_completion_request(
653	                            openai_client=openai_client,
654	                            data=data,
655	                            timeout=timeout,
656	                            logging_obj=logging_obj,
657	                        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:790
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
789	
790	                headers, response = await self.make_openai_chat_completion_request(
791	                    openai_aclient=openai_aclient,
792	                    data=data,
793	                    timeout=timeout,
794	                    logging_obj=logging_obj,
795	                )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:885
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
884	        )
885	        headers, response = self.make_sync_openai_chat_completion_request(
886	            openai_client=openai_client,
887	            data=data,
888	            timeout=timeout,
889	            logging_obj=logging_obj,
890	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:948
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
947	
948	                headers, response = await self.make_openai_chat_completion_request(
949	                    openai_aclient=openai_aclient,
950	                    data=data,
951	                    timeout=timeout,
952	                    logging_obj=logging_obj,
953	                )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:1095
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1094	            )
1095	            headers, response = await self.make_openai_embedding_request(
1096	                openai_aclient=openai_aclient,
1097	                data=data,
1098	                timeout=timeout,
1099	                logging_obj=logging_obj,
1100	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:1196
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1195	            headers: Optional[Dict] = None
1196	            headers, sync_embedding_response = self.make_sync_openai_embedding_request(
1197	                openai_client=openai_client,
1198	                data=data,
1199	                timeout=timeout,
1200	                logging_obj=logging_obj,
1201	            )  # type: ignore

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:2456
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
2455	
2456	        return Thread(**message_thread.dict())
2457	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:2515
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
2514	        if acreate_thread is not None and acreate_thread is True:
2515	            return self.async_create_thread(
2516	                metadata=metadata,
2517	                api_key=api_key,
2518	                api_base=api_base,
2519	                timeout=timeout,
2520	                max_retries=max_retries,
2521	                organization=organization,
2522	                client=client,
2523	                messages=messages,
2524	            )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:2542
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
2541	
2542	        return Thread(**message_thread.dict())
2543	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:2565
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
2564	
2565	        return Thread(**response.dict())
2566	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:2611
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
2610	        if aget_thread is not None and aget_thread is True:
2611	            return self.async_get_thread(
2612	                thread_id=thread_id,
2613	                api_key=api_key,
2614	                api_base=api_base,
2615	                timeout=timeout,
2616	                max_retries=max_retries,
2617	                organization=organization,
2618	                client=client,
2619	            )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:2631
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
2630	
2631	        return Thread(**response.dict())
2632	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/openai.py:2814
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
2813	                )
2814	            return self.arun_thread(
2815	                thread_id=thread_id,
2816	                assistant_id=assistant_id,
2817	                additional_instructions=additional_instructions,
2818	                instructions=instructions,
2819	                metadata=metadata,
2820	                model=model,
2821	                stream=stream,
2822	                tools=tools,
2823	                api_key=api_key,
2824	                api_base=api_base,
2825	                timeout=timeout,
2826	                max_retries=max_retries,
2827	                organization=organization,
2828	                client=client,
2829	            )

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/realtime/handler.py:44
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
43	        try:
44	            async with websockets.connect(  # type: ignore
45	                url,
46	                extra_headers={
47	                    "Authorization": f"Bearer {api_key}",  # type: ignore
48	                    "OpenAI-Beta": "realtime=v1",
49	                },

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/realtime/handler.py:57
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
56	        except websockets.exceptions.InvalidStatusCode as e:  # type: ignore
57	            await websocket.close(code=e.status_code, reason=str(e))
58	        except Exception as e:

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/realtime/handler.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
59	            try:
60	                await websocket.close(
61	                    code=1011, reason=f"Internal server error: {str(e)}"
62	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/responses/transformation.py:123
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
122	            or get_secret_str("OPENAI_API_BASE")
123	            or "https://api.openai.com/v1"
124	        )
125	
126	        # Remove trailing slashes
127	        api_base = api_base.rstrip("/")

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/transcriptions/handler.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
95	        if provider_config is not None:
96	            data = provider_config.transform_audio_transcription_request(
97	                model=model,
98	                audio_file=audio_file,
99	                optional_params=optional_params,
100	                litellm_params=litellm_params,
101	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/transcriptions/handler.py:140
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
139	        )
140	        _, response = self.make_sync_openai_audio_transcriptions_request(
141	            openai_client=openai_client,
142	            data=data,
143	            timeout=timeout,
144	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai/transcriptions/handler.py:194
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
193	            )
194	            headers, response = await self.make_openai_audio_transcriptions_request(
195	                openai_aclient=openai_aclient,
196	                data=data,
197	                timeout=timeout,
198	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openai_like/common_utils.py:10
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
9	        self.message = message
10	        self.request = httpx.Request(method="POST", url="https://www.litellm.ai")
11	        self.response = httpx.Response(status_code=status_code, request=self.request)

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/openrouter/chat/transformation.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
65	        extra_body = optional_params.pop("extra_body", {})
66	        response = super().transform_request(
67	            model, messages, optional_params, litellm_params, headers
68	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/perplexity/chat/transformation.py:16
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
15	    ) -> Tuple[Optional[str], Optional[str]]:
16	        api_base = api_base or get_secret_str("PERPLEXITY_API_BASE") or "https://api.perplexity.ai"  # type: ignore
17	        dynamic_api_key = (

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/petals/completion/handler.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
94	            raise Exception(
95	                "Importing torch, transformers, petals failed\nTry pip installing petals \npip install git+https://github.com/bigscience-workshop/petals"
96	            )
97	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/predibase/chat/handler.py:248
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
247	        input_text = ""
248	        base_url = "https://serving.app.predibase.com"
249	
250	        if "https" in model:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/replicate/chat/handler.py:148
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
147	    version_id = replicate_config.model_to_version_id(model)
148	    input_data = replicate_config.transform_request(
149	        model=model,
150	        messages=messages,
151	        optional_params=optional_params,
152	        litellm_params=litellm_params,
153	        headers=headers,
154	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/replicate/chat/transformation.py:153
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
152	            version_id = version_id.replace("deployments/", "")
153	            base_url = f"https://api.replicate.com/v1/deployments/{version_id}"
154	        else:  # assume it's a model

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/replicate/chat/transformation.py:155
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
154	        else:  # assume it's a model
155	            base_url = f"https://api.replicate.com/v1/models/{version_id}"
156	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/chat/handler.py:88
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
87	        if optional_params.get("stream") is True:
88	            api_base = f"https://runtime.sagemaker.{aws_region_name}.amazonaws.com/endpoints/{model}/invocations-response-stream"
89	        else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/chat/handler.py:90
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
89	        else:
90	            api_base = f"https://runtime.sagemaker.{aws_region_name}.amazonaws.com/endpoints/{model}/invocations"
91	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/chat/handler.py:139
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
138	        inference_params["stream"] = True if stream is True else False
139	        _data = SagemakerChatConfig().transform_request(
140	            model=model,
141	            messages=messages,
142	            optional_params=inference_params,
143	            litellm_params=litellm_params,
144	            headers=headers,
145	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/chat/handler.py:147
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
146	
147	        prepared_request = self._prepare_request(
148	            model=model,
149	            data=_data,
150	            optional_params=optional_params,
151	            credentials=credentials,
152	            aws_region_name=aws_region_name,
153	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
111	        if optional_params.get("stream") is True:
112	            api_base = f"https://runtime.sagemaker.{aws_region_name}.amazonaws.com/endpoints/{model}/invocations-response-stream"
113	        else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:114
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
113	        else:
114	            api_base = f"https://runtime.sagemaker.{aws_region_name}.amazonaws.com/endpoints/{model}/invocations"
115	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:191
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
190	            else:
191	                data = sagemaker_config.transform_request(
192	                    model=model,
193	                    messages=messages,
194	                    optional_params=optional_params,
195	                    litellm_params=litellm_params,
196	                    headers=headers,
197	                )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:198
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
197	                )
198	                prepared_request = self._prepare_request(
199	                    model=model,
200	                    data=data,
201	                    messages=messages,
202	                    optional_params=optional_params,
203	                    litellm_params=litellm_params,
204	                    credentials=credentials,
205	                    aws_region_name=aws_region_name,
206	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:224
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
223	                        status_code=sync_response.status_code,
224	                        message=str(sync_response.read()),
225	                    )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:269
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
268	        ## Non-Streaming completion CALL
269	        _data = sagemaker_config.transform_request(
270	            model=model,
271	            messages=messages,
272	            optional_params=optional_params,
273	            litellm_params=litellm_params,
274	            headers=headers,
275	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:285
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
284	        }
285	        prepared_request = self._prepare_request(**prepared_request_args)
286	        try:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:421
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
420	    ):
421	        data = await sagemaker_config.async_transform_request(
422	            model=model,
423	            messages=messages,
424	            optional_params={**optional_params, "stream": True},
425	            litellm_params=litellm_params,
426	            headers=headers,
427	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:438
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
437	        }
438	        prepared_request = await asyncified_prepare_request(**prepared_request_args)
439	        if model_id is not None:  # Fixes https://github.com/BerriAI/litellm/issues/8889

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:491
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
490	
491	        data = await sagemaker_config.async_transform_request(
492	            model=model,
493	            messages=messages,
494	            optional_params=optional_params,
495	            litellm_params=litellm_params,
496	            headers=headers,
497	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:510
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
509	
510	        prepared_request = await asyncified_prepare_request(**prepared_request_args)
511	        ## LOGGING

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/sagemaker/completion/handler.py:663
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
662	
663	        response = json.loads(response["Body"].read().decode("utf8"))
664	        ## LOGGING

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/together_ai/chat.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	            verbose_logger.debug(
36	                "Only some together models support function calling/response_format. Docs - https://docs.together.ai/docs/function-calling"
37	            )
38	            optional_params.remove("tools")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/together_ai/rerank/handler.py:52
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
51	        response = client.post(
52	            "https://api.together.xyz/v1/rerank",
53	            headers={
54	                "accept": "application/json",
55	                "content-type": "application/json",
56	                "authorization": f"Bearer {api_key}",
57	            },
58	            json=request_data_dict,
59	        )
60	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/together_ai/rerank/handler.py:78
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
77	        response = await client.post(
78	            "https://api.together.xyz/v1/rerank",
79	            headers={
80	                "accept": "application/json",
81	                "content-type": "application/json",
82	                "authorization": f"Bearer {api_key}",
83	            },
84	            json=request_data_dict,
85	        )
86	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/topaz/common_utils.py:32
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
31	        return (
32	            api_base or get_secret_str("TOPAZ_API_BASE") or "https://api.topazlabs.com"
33	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/topaz/image_variations/transformation.py:63
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
62	    ) -> str:
63	        api_base = api_base or "https://api.topazlabs.com"
64	        return f"{api_base}/image/v1/enhance"

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/topaz/image_variations/transformation.py:139
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
138	        # Convert to base64
139	        base64_image = base64.b64encode(image_content).decode("utf-8")
140	

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/topaz/image_variations/transformation.py:139
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
138	        # Convert to base64
139	        base64_image = base64.b64encode(image_content).decode("utf-8")
140	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/triton/completion/transformation.py:145
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
144	        if llm_type == "generate":
145	            return TritonGenerateConfig().transform_request(
146	                model=model,
147	                messages=messages,
148	                optional_params=optional_params,
149	                litellm_params=litellm_params,
150	                headers=headers,
151	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/triton/completion/transformation.py:153
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
152	        elif llm_type == "infer":
153	            return TritonInferConfig().transform_request(
154	                model=model,
155	                messages=messages,
156	                optional_params=optional_params,
157	                litellm_params=litellm_params,
158	                headers=headers,
159	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/batches/handler.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
70	
71	        vertex_batch_request: VertexAIBatchPredictionJob = VertexAIBatchTransformation.transform_openai_batch_request_to_vertex_ai_batch_request(
72	            request=create_batch_data
73	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/common_utils.py:40
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
39	        verbose_logger.warning(
40	            "Unable to identify if system message supported. Defaulting to 'False'. Received error message - {}\nAdd it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json".format(
41	                str(e)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/common_utils.py:126
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
125	            endpoint = "streamGenerateContent"
126	            url = "https://generativelanguage.googleapis.com/v1beta/{}:{}?key={}&alt=sse".format(
127	                _gemini_model_name, endpoint, gemini_api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/common_utils.py:131
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
130	            url = (
131	                "https://generativelanguage.googleapis.com/v1beta/{}:{}?key={}".format(
132	                    _gemini_model_name, endpoint, gemini_api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/common_utils.py:137
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
136	        endpoint = "embedContent"
137	        url = "https://generativelanguage.googleapis.com/v1beta/{}:{}?key={}".format(
138	            _gemini_model_name, endpoint, gemini_api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/common_utils.py:142
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
141	        endpoint = "batchEmbedContents"
142	        url = "https://generativelanguage.googleapis.com/v1beta/{}:{}?key={}".format(
143	            _gemini_model_name, endpoint, gemini_api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/common_utils.py:147
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
146	        raise ValueError(
147	            "LiteLLM's `gemini/` route does not support image generation yet. Let us know if you need this feature by opening an issue at https://github.com/BerriAI/litellm/issues"
148	        )
149	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/context_caching/vertex_ai_context_caching.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
57	            endpoint = "cachedContents"
58	            url = "https://generativelanguage.googleapis.com/v1beta/{}?key={}".format(
59	                endpoint, gemini_api_key

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/files/transformation.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
95	            with open(str(file_content), "rb") as f:
96	                content = f.read()
97	        elif hasattr(file_content, "read"):  # IO[bytes]

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/files/transformation.py:99
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
98	            # File-like objects need to be read
99	            content = file_content.read()
100	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/files/transformation.py:179
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
178	        )
179	        api_base = api_base or "https://storage.googleapis.com"
180	        if not api_base:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/files/transformation.py:450
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
449	            with open(str(file_content), "rb") as f:
450	                content = f.read()
451	        elif hasattr(file_content, "read"):  # IO[bytes]

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/files/transformation.py:453
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
452	            # File-like objects need to be read
453	            content = file_content.read()
454	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/gemini/transformation.py:257
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
256	                    verbose_logger.warning(
257	                        "No text in user content. Adding a blank text to user content, to ensure Gemini doesn't fail the request. Relevant Issue - https://github.com/BerriAI/litellm/issues/5515"
258	                    )
259	                    user_content.append(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/gemini/transformation.py:323
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
322	                raise Exception(
323	                    "Invalid Message passed in - {}. File an issue https://github.com/BerriAI/litellm/issues".format(
324	                        messages[msg_i]

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:800
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
799	            raise VertexAIError(
800	                message="Received={}, Error converting to valid response block={}. File an issue if litellm error - https://github.com/BerriAI/litellm/issues".format(
801	                    raw_response.text, str(e)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:869
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
868	            raise VertexAIError(
869	                message="Received={}, Error converting to valid response block={}. File an issue if litellm error - https://github.com/BerriAI/litellm/issues".format(
870	                    completion_response, str(e)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:941
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
940	    except httpx.HTTPStatusError as e:
941	        exception_string = str(await e.response.aread())
942	        raise VertexAIError(

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:988
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
987	            status_code=response.status_code,
988	            message=str(response.read()),
989	            headers=response.headers,

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/multimodal_embeddings/embedding_handler.py:86
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
85	
86	        request_data = vertex_multimodal_embedding_handler.transform_embedding_request(
87	            model, input, optional_params, headers
88	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/text_to_speech/text_to_speech_handler.py:124
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
123	
124	        url = "https://texttospeech.googleapis.com/v1/text:synthesize"
125	        ########## End of building request ############
126	
127	        ########## Log the request for debugging / logging ############
128	        logging_obj.pre_call(

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/text_to_speech/text_to_speech_handler.py:161
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
160	        # Decode base64 to get binary content
161	        binary_data = base64.b64decode(response_content)
162	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/text_to_speech/text_to_speech_handler.py:161
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
160	        # Decode base64 to get binary content
161	        binary_data = base64.b64decode(response_content)
162	

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/text_to_speech/text_to_speech_handler.py:202
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
201	        # Decode base64 to get binary content
202	        binary_data = base64.b64decode(response_content)
203	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/text_to_speech/text_to_speech_handler.py:202
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
201	        # Decode base64 to get binary content
202	        binary_data = base64.b64decode(response_content)
203	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_ai_non_gemini.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
20	        self.request = httpx.Request(
21	            method="POST", url=" https://cloud.google.com/vertex-ai/"
22	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_ai_non_gemini.py:151
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
150	                        json_obj,
151	                        scopes=["https://www.googleapis.com/auth/cloud-platform"],
152	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_ai_partner_models/anthropic/transformation.py:20
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
19	        self.request = httpx.Request(
20	            method="POST", url=" https://cloud.google.com/vertex-ai/"
21	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_ai_partner_models/anthropic/transformation.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
57	    ) -> dict:
58	        data = super().transform_request(
59	            model=model,
60	            messages=messages,
61	            optional_params=optional_params,
62	            litellm_params=litellm_params,
63	            headers=headers,
64	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_ai_partner_models/main.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
26	        self.request = httpx.Request(
27	            method="POST", url=" https://cloud.google.com/vertex-ai/"
28	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_embeddings/embedding_handler.py:89
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
88	        headers = self.set_headers(auth_header=auth_header, extra_headers=extra_headers)
89	        vertex_request: VertexEmbeddingRequest = litellm.vertexAITextEmbeddingConfig.transform_openai_request_to_vertex_embedding_request(
90	            input=input, optional_params=optional_params, model=model
91	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_embeddings/embedding_handler.py:179
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
178	        headers = self.set_headers(auth_header=auth_header, extra_headers=extra_headers)
179	        vertex_request: VertexEmbeddingRequest = litellm.vertexAITextEmbeddingConfig.transform_openai_request_to_vertex_embedding_request(
180	            input=input, optional_params=optional_params, model=model
181	        )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_llm_base.py:65
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
64	                    if os.path.exists(credentials):
65	                        json_obj = json.load(open(credentials))
66	                    else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_llm_base.py:88
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
87	                        json_obj,
88	                        scopes=["https://www.googleapis.com/auth/cloud-platform"],
89	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vertex_ai/vertex_llm_base.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
96	                quota_project_id=project_id,
97	                scopes=["https://www.googleapis.com/auth/cloud-platform"],
98	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/vllm/completion/handler.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
18	        self.message = message
19	        self.request = httpx.Request(method="POST", url="http://0.0.0.0:8000")
20	        self.response = httpx.Response(status_code=status_code, request=self.request)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/voyage/embedding/transformation.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
22	        self.request = httpx.Request(
23	            method="POST", url="https://api.voyageai.com/v1/embeddings"
24	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/voyage/embedding/transformation.py:54
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
53	            return api_base
54	        return "https://api.voyageai.com/v1/embeddings"
55	

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/watsonx/chat/handler.py:56
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
55	        ## UPDATE PAYLOAD (optional params)
56	        watsonx_auth_payload = watsonx_chat_transformation._prepare_payload(
57	            model=model,
58	            api_params=api_params,
59	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/watsonx/common_utils.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
29	    return (
30	        get_secret_str("WATSONX_IAM_URL") or "https://iam.cloud.ibm.com/identity/token"
31	    )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/watsonx/completion/transformation.py:250
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
249	
250	        watsonx_auth_payload = self._prepare_payload(
251	            model=model,
252	            api_params=watsonx_api_params,
253	        )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/watsonx/embed/transformation.py:41
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
40	        watsonx_api_params = _get_api_params(params=optional_params)
41	        watsonx_auth_payload = self._prepare_payload(
42	            model=model,
43	            api_params=watsonx_api_params,
44	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/xai/chat/transformation.py:11
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
10	
11	XAI_API_BASE = "https://api.x.ai/v1"
12	
13	
14	class XAIChatConfig(OpenAIGPTConfig):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/llms/xai/common_utils.py:13
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
12	    def get_api_base(api_base: Optional[str] = None) -> Optional[str]:
13	        return api_base or get_secret_str("XAI_API_BASE") or "https://api.x.ai"
14	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:537
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
536	            model=model,  # type: ignore
537	            request=httpx.Request(method="POST", url="https://api.openai.com/v1/"),
538	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:577
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
576	            model=model,  # type: ignore
577	            request=httpx.Request(method="POST", url="https://api.openai.com/v1/"),
578	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:1519
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1518	                or get_secret("OPENAI_API_BASE")
1519	                or "https://api.openai.com/v1"
1520	            )
1521	
1522	            openai.api_version = None
1523	            # set API KEY

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:1600
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1599	                or get_secret("GROQ_API_BASE")
1600	                or "https://api.groq.com/openai/v1"
1601	            )
1602	
1603	            # set API KEY
1604	            api_key = (

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:1646
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1645	                or get_secret("OPENAI_API_BASE")
1646	                or "https://api.openai.com/v1"
1647	            )
1648	            # set API KEY
1649	            api_key = (
1650	                api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:1699
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1698	                or get_secret("OPENAI_API_BASE")
1699	                or "https://api.openai.com/v1"
1700	            )
1701	            organization = (
1702	                organization
1703	                or litellm.organization

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:1792
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1791	                or get_secret("REPLICATE_API_BASE")
1792	                or "https://api.replicate.com/v1"
1793	            )
1794	
1795	            custom_prompt_dict = custom_prompt_dict or litellm.custom_prompt_dict
1796	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:1841
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1840	                or get_secret("CLARIFAI_API_BASE")
1841	                or "https://api.clarifai.com/v2"
1842	            )
1843	            api_base = litellm.ClarifaiConfig()._convert_model_to_url(model, api_base)
1844	            response = base_llm_http_handler.completion(
1845	                model=model,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:1874
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1873	                or get_secret("ANTHROPIC_BASE_URL")
1874	                or "https://api.anthropic.com/v1/complete"
1875	            )
1876	
1877	            if api_base is not None and not api_base.endswith("/v1/complete"):
1878	                api_base += "/v1/complete"
1879	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:1911
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1910	                or get_secret("ANTHROPIC_BASE_URL")
1911	                or "https://api.anthropic.com/v1/messages"
1912	            )
1913	
1914	            if api_base is not None and not api_base.endswith("/v1/messages"):
1915	                api_base += "/v1/messages"
1916	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:1956
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1955	                or get_secret("NLP_CLOUD_API_BASE")
1956	                or "https://api.nlpcloud.io/v1/gpu/"
1957	            )
1958	
1959	            response = nlp_cloud_chat_completion(
1960	                model=model,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2004
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2003	                or get_secret("ALEPH_ALPHA_API_BASE")
2004	                or "https://api.aleph-alpha.com/complete"
2005	            )
2006	
2007	            model_response = aleph_alpha.completion(
2008	                model=model,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2045
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2044	                or get_secret("COHERE_API_BASE")
2045	                or "https://api.cohere.ai/v1/generate"
2046	            )
2047	
2048	            headers = headers or litellm.headers or {}
2049	            if headers is None:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2085
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2084	                or get_secret_str("COHERE_API_BASE")
2085	                or "https://api.cohere.ai/v1/chat"
2086	            )
2087	
2088	            headers = headers or litellm.headers or {}
2089	            if headers is None:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2123
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2122	                or get_secret("MARITALK_API_BASE")
2123	                or "https://chat.maritaca.ai/api"
2124	            )
2125	
2126	            model_response = openai_like_chat_completion.completion(
2127	                model=model,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2253
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2252	                or get_secret_str("OPENROUTER_API_BASE")
2253	                or "https://openrouter.ai/api/v1"
2254	            )
2255	
2256	            api_key = (
2257	                api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2264
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2263	
2264	            openrouter_site_url = get_secret("OR_SITE_URL") or "https://litellm.ai"
2265	            openrouter_app_name = get_secret("OR_APP_NAME") or "liteLLM"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2325
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2324	            raise ValueError(
2325	                "Palm was decommisioned on October 2024. Please use the `gemini/` route for Gemini Google AI Studio Models. Announcement: https://ai.google.dev/palm_docs/palm?hl=en"
2326	            )
2327	        elif custom_llm_provider == "vertex_ai_beta" or custom_llm_provider == "gemini":

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2563
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2562	                or litellm.api_base
2563	                or "https://codestral.mistral.ai/v1/fim/completions"
2564	            )
2565	
2566	            api_key = api_key or litellm.api_key or get_secret("CODESTRAL_API_KEY")
2567	
2568	            text_completion_model_response = litellm.TextCompletionResponse(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2641
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2640	                verbose_logger.warning(
2641	                    "'aws_bedrock_client' is a deprecated param. Please move to another auth method - https://docs.litellm.ai/docs/providers/bedrock#boto3---authentication."
2642	                )
2643	                # Extract credentials for legacy boto3 client and pass thru to httpx

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2834
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2833	                or get_secret("OLLAMA_API_BASE")
2834	                or "http://localhost:11434"
2835	            )
2836	            response = base_llm_http_handler.completion(
2837	                model=model,
2838	                stream=stream,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2859
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2858	                or get_secret("OLLAMA_API_BASE")
2859	                or "http://localhost:11434"
2860	            )
2861	
2862	            api_key = (
2863	                api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2916
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2915	                or get_secret("CLOUDFLARE_API_BASE")
2916	                or f"https://api.cloudflare.com/client/v4/accounts/{account_id}/ai/run/"
2917	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:2938
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2937	            custom_llm_provider == "baseten"
2938	            or litellm.api_base == "https://app.baseten.co"
2939	        ):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:3485
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
3484	                or get_secret_str("OPENAI_API_BASE")
3485	                or "https://api.openai.com/v1"
3486	            )
3487	            openai.organization = (
3488	                litellm.organization
3489	                or get_secret_str("OPENAI_ORGANIZATION")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:3773
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
3772	                or get_secret_str("OLLAMA_API_BASE")
3773	                or "http://localhost:11434"
3774	            )  # type: ignore
3775	
3776	            if isinstance(input, str):
3777	                input = [input]

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:3889
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
3888	                or get_secret_str("XINFERENCE_API_BASE")
3889	                or "http://127.0.0.1:9997/v1"
3890	            )
3891	            response = openai_chat_completions.embedding(
3892	                model=model,
3893	                input=input,

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:4208
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
4207	
4208	                with concurrent.futures.ThreadPoolExecutor() as executor:
4209	                    completed_futures = [

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:4251
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4250	        raise Exception(
4251	            f"Unmapped prompt format. Your prompt is neither a list of strings nor a string. prompt={prompt}. File an issue - https://github.com/BerriAI/litellm/issues"
4252	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:5154
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
5153	            or get_secret("OPENAI_API_BASE")
5154	            or "https://api.openai.com/v1"
5155	        )  # type: ignore
5156	        openai.organization = (
5157	            litellm.organization
5158	            or get_secret("OPENAI_ORGANIZATION")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:5324
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
5323	            or get_secret("OPENAI_API_BASE")
5324	            or "https://api.openai.com/v1"
5325	        )  # type: ignore
5326	        # set API KEY
5327	        api_key = (
5328	            api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:5472
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
5471	        raise Exception(
5472	            f"Unable to health check wildcard model for provider {custom_llm_provider}. Add a model on your config.yaml or contribute here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"
5473	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:5598
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
5597	            raise Exception(
5598	                f"Mode {mode} not supported. See modes here: https://docs.litellm.ai/docs/proxy/health"
5599	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/main.py:5607
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
5606	            return {
5607	                "error": f"error:{str(e)}. Missing `mode`. Set the `mode` for the model - https://docs.litellm.ai/docs/proxy/health#embedding-models  \nstacktrace: {stack_trace}"
5608	            }

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_experimental/mcp_server/sse_transport.py:115
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
114	
115	        session_id_param = request.query_params.get("session_id")
116	        if session_id_param is None:

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_experimental/mcp_server/sse_transport.py:129
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
128	
129	        writer = self._read_stream_writers.get(session_id)
130	        if not writer:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:1354
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1353	        None,
1354	        description="override user_api_key_auth with your own auth script - https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth",
1355	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:1391
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1390	        None,
1391	        description="Mapping of alert type to webhook url. e.g. `alert_to_webhook_url: {'budget_alerts': 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX'}`",
1392	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:1412
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1411	        default=None,
1412	        description="Set-up pass-through endpoints for provider-specific endpoints. Docs - https://docs.litellm.ai/docs/proxy/pass_through",
1413	    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:2078
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2077	    db_not_connected_error = (
2078	        "DB not connected. See https://docs.litellm.ai/docs/proxy/virtual_keys"
2079	    )
2080	    no_llm_router = "No models configured on proxy"
2081	    not_allowed_access = "Admin-only endpoint. Not allowed to access this."

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:2082
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2081	    not_allowed_access = "Admin-only endpoint. Not allowed to access this."
2082	    not_premium_user = "You must be a LiteLLM Enterprise user to use this feature. If you have a license please set `LITELLM_LICENSE` in your env. Get a 7 day trial key here: https://www.litellm.ai/#trial. \nPricing: https://www.litellm.ai/#pricing"
2083	    max_parallel_request_limit_reached = (

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:2430
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2429	    )
2430	    user_role_doc_str = """Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`"""
2431	    max_budget_doc_str = """Optional[float] - Specify max budget for a given user."""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:2441
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2440	    auto_create_key_doc_str = """bool - Default=True. Flag used for returning a key as part of the /user/new response"""
2441	    aliases_doc_str = """Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)"""
2442	    config_doc_str = """Optional[dict] - [DEPRECATED PARAM] User-specific config."""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:2443
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2442	    config_doc_str = """Optional[dict] - [DEPRECATED PARAM] User-specific config."""
2443	    allowed_cache_controls_doc_str = """Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-"""
2444	    blocked_doc_str = (

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:2452
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2451	    soft_budget_doc_str = """Optional[float] - Get alerts when user crosses given budget, doesn't block requests."""
2452	    model_max_budget_doc_str = """Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)"""
2453	    model_rpm_limit_doc_str = """Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:2453
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2452	    model_max_budget_doc_str = """Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)"""
2453	    model_rpm_limit_doc_str = """Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)"""
2454	    model_tpm_limit_doc_str = """Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/_types.py:2454
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2453	    model_rpm_limit_doc_str = """Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)"""
2454	    model_tpm_limit_doc_str = """Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)"""
2455	    spend_doc_str = """Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used."""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/analytics_endpoints/analytics_endpoints.py:69
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
68	            raise ValueError(
69	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
70	            )
71	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/anthropic_endpoints/endpoints.py:115
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
114	
115	        data = await add_litellm_data_to_request(
116	            data=data,  # type: ignore
117	            request=request,
118	            general_settings=general_settings,
119	            user_api_key_dict=user_api_key_dict,
120	            version=version,
121	            proxy_config=proxy_config,
122	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/auth_checks.py:908
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
907	        raise Exception(
908	            "No DB Connected. See - https://docs.litellm.ai/docs/proxy/virtual_keys"
909	        )
910	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/auth_checks.py:964
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
963	        raise Exception(
964	            "No DB Connected. See - https://docs.litellm.ai/docs/proxy/virtual_keys"
965	        )
966	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/auth_checks.py:1031
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1030	        raise Exception(
1031	            "No DB Connected. See - https://docs.litellm.ai/docs/proxy/virtual_keys"
1032	        )
1033	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/auth_utils.py:173
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
172	            raise ValueError(
173	                f"Rejected Request: {param} is not allowed in request body. "
174	                "Enable with `general_settings::allow_client_side_credentials` on proxy config.yaml. "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/litellm_license.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
21	
22	    base_url = "https://license.litellm.ai"
23	
24	    def __init__(self) -> None:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/litellm_license.py:42
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
41	                with open(_path_to_public_key, "rb") as key_file:
42	                    self.public_key = serialization.load_pem_public_key(key_file.read())
43	            else:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/litellm_license.py:116
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
115	            elif (
116	                self.verify_license_without_api_request(
117	                    public_key=self.public_key, license_key=self.license_str
118	                )

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/litellm_license.py:134
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
133	            # Decode the license key
134	            decoded = base64.b64decode(license_key)
135	            message, signature = decoded.split(b".", 1)

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/litellm_license.py:134
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
133	            # Decode the license key
134	            decoded = base64.b64decode(license_key)
135	            message, signature = decoded.split(b".", 1)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/rds_iam_token.py:80
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
79	        try:
80	            oidc_token = open(aws_web_identity_token).read()  # check if filepath
81	        except Exception:

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/user_api_key_auth.py:344
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
343	        if general_settings.get("enable_oauth2_proxy_auth", False) is True:
344	            return await handle_oauth2_proxy_request(request=request)
345	

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/user_api_key_auth.py:454
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
453	                        api_key = api_key.replace("Basic ", "").strip()
454	                        decoded_bytes = base64.b64decode(api_key)
455	                        decoded_str = decoded_bytes.decode("utf-8")

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/user_api_key_auth.py:454
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
453	                        api_key = api_key.replace("Basic ", "").strip()
454	                        decoded_bytes = base64.b64decode(api_key)
455	                        decoded_str = decoded_bytes.decode("utf-8")

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/auth/user_api_key_auth.py:750
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
749	            else:
750	                model = get_model_from_request(request_data, route)
751	                fallback_models = cast(

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/batches_endpoints/endpoints.py:87
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
86	        # Include original request and headers in the data
87	        data = await add_litellm_data_to_request(
88	            data=data,
89	            request=request,
90	            general_settings=general_settings,
91	            user_api_key_dict=user_api_key_dict,
92	            version=version,
93	            proxy_config=proxy_config,
94	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/batches_endpoints/endpoints.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
224	        # Include original request and headers in the data
225	        data = await add_litellm_data_to_request(
226	            data=data,
227	            request=request,
228	            general_settings=general_settings,
229	            user_api_key_dict=user_api_key_dict,
230	            version=version,
231	            proxy_config=proxy_config,
232	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/batches_endpoints/endpoints.py:428
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
427	        # Include original request and headers in the data
428	        data = await add_litellm_data_to_request(
429	            data=data,
430	            request=request,
431	            general_settings=general_settings,
432	            user_api_key_dict=user_api_key_dict,
433	            version=version,
434	            proxy_config=proxy_config,
435	        )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:71
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
70	            "x-litellm-response-duration-ms": str(
71	                hidden_params.get("_response_ms", None)
72	            ),

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:74
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
73	            "x-litellm-overhead-duration-ms": str(
74	                hidden_params.get("litellm_overhead_time_ms", None)
75	            ),

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:120
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
119	    ) -> Tuple[dict, LiteLLMLoggingObj]:
120	        self.data = await add_litellm_data_to_request(
121	            data=self.data,
122	            request=request,
123	            general_settings=general_settings,
124	            user_api_key_dict=user_api_key_dict,
125	            version=version,
126	            proxy_config=proxy_config,
127	        )

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:120
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
119	    ) -> Tuple[dict, LiteLLMLoggingObj]:
120	        self.data = await add_litellm_data_to_request(
121	            data=self.data,
122	            request=request,
123	            general_settings=general_settings,
124	            user_api_key_dict=user_api_key_dict,
125	            version=version,
126	            proxy_config=proxy_config,
127	        )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
129	        self.data["model"] = (
130	            general_settings.get("completion_model", None)  # server default
131	            or user_model  # model name passed via cli args

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:133
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
132	            or model  # for azure deployments
133	            or self.data.get("model", None)  # default passed in http request
134	        )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:162
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
161	        ## IMPORTANT Note: - initialize this before running pre-call checks. Ensures we log rejected requests to langfuse.
162	        self.data["litellm_call_id"] = request.headers.get(
163	            "x-litellm-call-id", str(uuid.uuid4())
164	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:231
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
230	        # Do not change this - it should be a constant time fetch - ALWAYS
231	        llm_call = await route_request(
232	            data=self.data,
233	            route_type=route_type,
234	            llm_router=llm_router,
235	            user_model=user_model,
236	        )

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:231
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
230	        # Do not change this - it should be a constant time fetch - ALWAYS
231	        llm_call = await route_request(
232	            data=self.data,
233	            route_type=route_type,
234	            llm_router=llm_router,
235	            user_model=user_model,
236	        )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:249
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
248	        hidden_params = getattr(response, "_hidden_params", {}) or {}
249	        model_id = hidden_params.get("model_id", None) or ""
250	        cache_key = hidden_params.get("cache_key", None) or ""

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:250
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
249	        model_id = hidden_params.get("model_id", None) or ""
250	        cache_key = hidden_params.get("cache_key", None) or ""
251	        api_base = hidden_params.get("api_base", None) or ""

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:251
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
250	        cache_key = hidden_params.get("cache_key", None) or ""
251	        api_base = hidden_params.get("api_base", None) or ""
252	        response_cost = hidden_params.get("response_cost", None) or ""

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:252
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
251	        api_base = hidden_params.get("api_base", None) or ""
252	        response_cost = hidden_params.get("response_cost", None) or ""
253	        fastest_response_batch_completion = hidden_params.get(

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:253
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
252	        response_cost = hidden_params.get("response_cost", None) or ""
253	        fastest_response_batch_completion = hidden_params.get(
254	            "fastest_response_batch_completion", None
255	        )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:256
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
255	        )
256	        additional_headers: dict = hidden_params.get("additional_headers", {}) or {}
257	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:263
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
262	            proxy_logging_obj.update_request_status(
263	                litellm_call_id=self.data.get("litellm_call_id", ""), status="success"
264	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:302
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
301	        )  # get any updated response headers
302	        additional_headers = hidden_params.get("additional_headers", {}) or {}
303	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_request_processing.py:350
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
349	        )  # returns the timeout set by the wrapper. Used for testing if model-specific timeout are set correctly
350	        _litellm_logging_obj: Optional[LiteLLMLoggingObj] = self.data.get(
351	            "litellm_logging_obj", None
352	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/admin_ui_utils.py:27
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
26	def missing_keys_form(missing_key_names: str):
27	    missing_keys_html_form = """
28	        <!DOCTYPE html>
29	        <html lang="en">
30	        <head>
31	            <meta charset="UTF-8">
32	            <meta name="viewport" content="width=device-width, initial-scale=1.0">
33	            <style>
34	                body {{
35	                    font-family: Arial, sans-serif;
36	                    background-color: #f4f4f9;
37	                    color: #333;
38	                    margin: 20px;
39	                    line-height: 1.6;
40	                }}
41	                .container {{
42	                    max-width: 800px;
43	                    margin: auto;
44	                    padding: 20px;
45	                    background: #fff;
46	                    border: 1px solid #ddd;
47	                    border-radius: 5px;
48	                    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
49	                }}
50	                h1 {{
51	                    font-size: 24px;
52	                    margin-bottom: 20px;
53	                }}
54	                pre {{
55	                    background: #f8f8f8;
56	                    padding: 1px;
57	                    border: 1px solid #ccc;
58	                    border-radius: 4px;
59	                    overflow-x: auto;
60	                    font-size: 14px;
61	                }}
62	                .env-var {{
63	                    font-weight: normal;
64	                }}
65	                .comment {{
66	                    font-weight: normal;
67	                    color: #777;
68	                }}
69	            </style>
70	            <title>Environment Setup Instructions</title>
71	        </head>
72	        <body>
73	            <div class="container">
74	                <h1>Environment Setup Instructions</h1>
75	                <p>Please add the following variables to your environment variables:</p>
76	                <pre>
77	    <span class="env-var">LITELLM_MASTER_KEY="sk-1234"</span> <span class="comment"># Your master key for the proxy server. Can use this to send /chat/completion requests etc</span>
78	    <span class="env-var">LITELLM_SALT_KEY="sk-XXXXXXXX"</span> <span class="comment"># Can NOT CHANGE THIS ONCE SET - It is used to encrypt/decrypt credentials stored in DB. If value of 'LITELLM_SALT_KEY' changes your models cannot be retrieved from DB</span>
79	    <span class="env-var">DATABASE_URL="postgres://..."</span> <span class="comment"># Need a postgres database? (Check out Supabase, Neon, etc)</span>
80	    <span class="comment">## OPTIONAL ##</span>
81	    <span class="env-var">PORT=4000</span> <span class="comment"># DO THIS FOR RENDER/RAILWAY</span>
82	    <span class="env-var">STORE_MODEL_IN_DB="True"</span> <span class="comment"># Allow storing models in db</span>
83	                </pre>
84	                <h1>Missing Environment Variables</h1>
85	                <p>{missing_keys}</p>
86	            </div>
87	
88	            <div class="container">
89	            <h1>Need Help? Support</h1>
90	            <p>Discord: <a href="https://discord.com/invite/wuPM9dRgDw" target="_blank">https://discord.com/invite/wuPM9dRgDw</a></p>
91	            <p>Docs: <a href="https://docs.litellm.ai/docs/" target="_blank">https://docs.litellm.ai/docs/</a></p>
92	            </div>
93	        </body>
94	        </html>
95	    """
96	    return missing_keys_html_form.format(missing_keys=missing_key_names)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/admin_ui_utils.py:102
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
101	
102	    ui_disabled_html = """
103	        <!DOCTYPE html>
104	        <html lang="en">
105	        <head>
106	            <meta charset="UTF-8">
107	            <meta name="viewport" content="width=device-width, initial-scale=1.0">
108	            <style>
109	                body {{
110	                    font-family: Arial, sans-serif;
111	                    background-color: #f4f4f9;
112	                    color: #333;
113	                    margin: 20px;
114	                    line-height: 1.6;
115	                }}
116	                .container {{
117	                    max-width: 800px;
118	                    margin: auto;
119	                    padding: 20px;
120	                    background: #fff;
121	                    border: 1px solid #ddd;
122	                    border-radius: 5px;
123	                    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
124	                }}
125	                h1 {{
126	                    font-size: 24px;
127	                    margin-bottom: 20px;
128	                }}
129	                pre {{
130	                    background: #f8f8f8;
131	                    padding: 1px;
132	                    border: 1px solid #ccc;
133	                    border-radius: 4px;
134	                    overflow-x: auto;
135	                    font-size: 14px;
136	                }}
137	                .env-var {{
138	                    font-weight: normal;
139	                }}
140	                .comment {{
141	                    font-weight: normal;
142	                    color: #777;
143	                }}
144	            </style>
145	            <title>Admin UI Disabled</title>
146	        </head>
147	        <body>
148	            <div class="container">
149	                <h1>Admin UI is Disabled</h1>
150	                <p>The Admin UI has been disabled by the administrator. To re-enable it, please update the following environment variable:</p>
151	                <pre>
152	    <span class="env-var">DISABLE_ADMIN_UI="False"</span> <span class="comment"># Set this to "False" to enable the Admin UI.</span>
153	                </pre>
154	                <p>After making this change, restart the application for it to take effect.</p>
155	            </div>
156	
157	            <div class="container">
158	            <h1>Need Help? Support</h1>
159	            <p>Discord: <a href="https://discord.com/invite/wuPM9dRgDw" target="_blank">https://discord.com/invite/wuPM9dRgDw</a></p>
160	            <p>Docs: <a href="https://docs.litellm.ai/docs/" target="_blank">https://docs.litellm.ai/docs/</a></p>
161	            </div>
162	        </body>
163	        </html>
164	    """
165	
166	    return HTMLResponse(

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/encrypt_decrypt_utils.py:29
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
28	            encrypted_value = encrypt_value(value=value, signing_key=signing_key)  # type: ignore
29	            encrypted_value = base64.b64encode(encrypted_value).decode("utf-8")
30	

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/encrypt_decrypt_utils.py:29
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
28	            encrypted_value = encrypt_value(value=value, signing_key=signing_key)  # type: ignore
29	            encrypted_value = base64.b64encode(encrypted_value).decode("utf-8")
30	

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/encrypt_decrypt_utils.py:47
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
46	        if isinstance(value, str):
47	            decoded_b64 = base64.b64decode(value)
48	            value = decrypt_value(value=decoded_b64, signing_key=signing_key)  # type: ignore

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/encrypt_decrypt_utils.py:47
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
46	        if isinstance(value, str):
47	            decoded_b64 = base64.b64decode(value)
48	            value = decrypt_value(value=decoded_b64, signing_key=signing_key)  # type: ignore

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/encrypt_decrypt_utils.py:55
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
54	        verbose_proxy_logger.error(
55	            f"Error decrypting value, Did your master_key/salt key change recently? \nError: {str(e)}\nSet permanent salt key - https://docs.litellm.ai/docs/proxy/prod#5-set-litellm-salt-key"
56	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/html_forms/jwt_display_template.py:2
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1	# JWT display template for SSO debug callback
2	jwt_display_template = """
3	<!DOCTYPE html>

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/html_forms/ui_login.py:5
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4	url_to_redirect_to += "/login"
5	html_form = f"""
6	<!DOCTYPE html>
7	<html lang="en">
8	<head>
9	    <meta charset="UTF-8">
10	    <title>LiteLLM Login</title>
11	    <meta name="viewport" content="width=device-width, initial-scale=1.0">
12	    <style>
13	        body {{
14	            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
15	            background-color: #f8fafc;
16	            margin: 0;
17	            padding: 20px;
18	            display: flex;
19	            justify-content: center;
20	            align-items: center;
21	            min-height: 100vh;
22	            color: #333;
23	        }}
24	
25	        form {{
26	            background-color: #fff;
27	            padding: 40px;
28	            border-radius: 8px;
29	            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
30	            width: 450px;
31	            max-width: 100%;
32	        }}
33	        
34	        .logo-container {{
35	            text-align: center;
36	            margin-bottom: 30px;
37	        }}
38	        
39	        .logo {{
40	            font-size: 24px;
41	            font-weight: 600;
42	            color: #1e293b;
43	        }}
44	        
45	        h2 {{
46	            margin: 0 0 10px;
47	            color: #1e293b;
48	            font-size: 28px;
49	            font-weight: 600;
50	            text-align: center;
51	        }}
52	        
53	        .subtitle {{
54	            color: #64748b;
55	            margin: 0 0 20px;
56	            font-size: 16px;
57	            text-align: center;
58	        }}
59	
60	        .info-box {{
61	            background-color: #f1f5f9;
62	            border-radius: 6px;
63	            padding: 20px;
64	            margin-bottom: 30px;
65	            border-left: 4px solid #2563eb;
66	        }}
67	        
68	        .info-header {{
69	            display: flex;
70	            align-items: center;
71	            margin-bottom: 12px;
72	            color: #1e40af;
73	            font-weight: 600;
74	            font-size: 16px;
75	        }}
76	        
77	        .info-header svg {{
78	            margin-right: 8px;
79	        }}
80	        
81	        .info-box p {{
82	            color: #475569;
83	            margin: 8px 0;
84	            line-height: 1.5;
85	            font-size: 14px;
86	        }}
87	
88	        label {{
89	            display: block;
90	            margin-bottom: 8px;
91	            font-weight: 500;
92	            color: #334155;
93	            font-size: 14px;
94	        }}
95	        
96	        .required {{
97	            color: #dc2626;
98	            margin-left: 2px;
99	        }}
100	
101	        input[type="text"],
102	        input[type="password"] {{
103	            width: 100%;
104	            padding: 10px 14px;
105	            margin-bottom: 20px;
106	            box-sizing: border-box;
107	            border: 1px solid #e2e8f0;
108	            border-radius: 6px;
109	            font-size: 15px;
110	            color: #1e293b;
111	            background-color: #fff;
112	            transition: border-color 0.2s, box-shadow 0.2s;
113	        }}
114	        
115	        input[type="text"]:focus,
116	        input[type="password"]:focus {{
117	            outline: none;
118	            border-color: #3b82f6;
119	            box-shadow: 0 0 0 2px rgba(59, 130, 246, 0.2);
120	        }}
121	
122	        .toggle-password {{
123	            display: flex;
124	            align-items: center;
125	            margin-top: -15px;
126	            margin-bottom: 20px;
127	        }}
128	        
129	        .toggle-password input {{
130	            margin-right: 6px;
131	        }}
132	
133	        input[type="submit"] {{
134	            background-color: #6466E9;
135	            color: #fff;
136	            cursor: pointer;
137	            font-weight: 500;
138	            border: none;
139	            padding: 10px 16px;
140	            transition: background-color 0.2s;
141	            border-radius: 6px;
142	            margin-top: 10px;
143	            font-size: 14px;
144	            width: 100%;
145	        }}
146	
147	        input[type="submit"]:hover {{
148	            background-color: #4138C2;
149	        }}
150	        
151	        a {{
152	            color: #3b82f6;
153	            text-decoration: none;
154	        }}
155	
156	        a:hover {{
157	            text-decoration: underline;
158	        }}
159	        
160	        code {{
161	            background-color: #f1f5f9;
162	            padding: 2px 4px;
163	            border-radius: 4px;
164	            font-family: monospace;
165	            font-size: 13px;
166	            color: #334155;
167	        }}
168	        
169	        .help-text {{
170	            color: #64748b;
171	            font-size: 14px;
172	            margin-top: -12px;
173	            margin-bottom: 20px;
174	        }}
175	    </style>
176	</head>
177	<body>
178	    <form action="{url_to_redirect_to}" method="post">
179	        <div class="logo-container">

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/load_config_utils.py:30
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
29	        # Read the file contents
30	        file_contents = response["Body"].read().decode("utf-8")
31	        verbose_proxy_logger.debug("File contents retrieved from S3")

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/load_config_utils.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
34	        with tempfile.NamedTemporaryFile(delete=False, suffix=".yaml") as temp_file:
35	            temp_file.write(file_contents.encode("utf-8"))
36	            temp_file_path = temp_file.name

--------------------------------------------------
>> Issue: [B832:write] tempfile_NamedTemporaryFile_write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/common_utils/load_config_utils.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b832_write.html
34	        with tempfile.NamedTemporaryFile(delete=False, suffix=".yaml") as temp_file:
35	            temp_file.write(file_contents.encode("utf-8"))
36	            temp_file_path = temp_file.name

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/config_management_endpoints/pass_through_endpoints.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
18	    tags=["pass-through-endpoints"],
19	    summary="Create pass-through endpoints for provider specific endpoints - https://docs.litellm.ai/docs/proxy/pass_through",
20	)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/aim.py:54
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
53	        self.api_base = (
54	            api_base or os.environ.get("AIM_API_BASE") or "https://api.aim.security"
55	        )

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/aim.py:207
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
206	        )
207	        async with connect(
208	            f"{self.ws_api_base}/detect/output/ws",
209	            additional_headers=self._build_aim_headers(
210	                hook="output",
211	                key_alias=user_api_key_dict.key_alias,
212	                user_email=user_email,
213	            ),

--------------------------------------------------
>> Issue: [B809:recv] socket.socket.recv
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/aim.py:219
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b809_recv.html
218	            while True:
219	                result = json.loads(await websocket.recv())
220	                if verified_chunk := result.get("verified_chunk"):

--------------------------------------------------
>> Issue: [B805:send] socket.socket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/aim.py:243
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b805_send.html
242	                chunk = json.dumps(chunk)
243	            await websocket.send(chunk)
244	        await websocket.send(json.dumps({"done": True}))

--------------------------------------------------
>> Issue: [B805:send] socket.socket.send
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/aim.py:244
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b805_send.html
243	            await websocket.send(chunk)
244	        await websocket.send(json.dumps({"done": True}))

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/aporia_ai.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
96	    ):
97	        data = await self.prepare_aporia_request(
98	            new_messages=new_messages, response_string=response_string
99	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/aporia_ai.py:168
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
167	        if response_str is not None:
168	            await self.make_aporia_api_request(
169	                request_data=data,
170	                response_string=response_str,
171	                new_messages=data.get("messages", []),
172	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/aporia_ai.py:217
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
216	        if new_messages is not None:
217	            await self.make_aporia_api_request(
218	                request_data=data,
219	                new_messages=new_messages,
220	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/bedrock_guardrails.py:172
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
171	        sigv4 = SigV4Auth(credentials, "bedrock", aws_region_name)
172	        api_base = f"https://bedrock-runtime.{aws_region_name}.amazonaws.com/guardrail/{self.guardrailIdentifier}/version/{self.guardrailVersion}/apply"
173	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/bedrock_guardrails.py:204
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
203	        )
204	        prepared_request = self._prepare_request(
205	            credentials=credentials,
206	            data=bedrock_request_data,
207	            optional_params=self.optional_params,
208	            aws_region_name=aws_region_name,
209	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/bedrock_guardrails.py:265
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
264	        if new_messages is not None:
265	            await self.make_bedrock_api_request(kwargs=data)
266	            add_guardrail_to_applied_guardrails_header(

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/bedrock_guardrails.py:297
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
296	        if new_messages is not None:
297	            await self.make_bedrock_api_request(kwargs=data, response=response)
298	            add_guardrail_to_applied_guardrails_header(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/guardrails_ai.py:48
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
47	        # store kwargs as optional_params
48	        self.guardrails_ai_api_base = api_base or "http://0.0.0.0:8000"
49	        self.guardrails_ai_guard_name = guard_name

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/guardrails_ai.py:106
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
105	        if response_str is not None and len(response_str) > 0:
106	            await self.make_guardrails_ai_api_request(
107	                llm_output=response_str, request_data=data
108	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/lakera_ai.py:66
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
65	        self.api_base = (
66	            api_base or get_secret("LAKERA_API_BASE") or "https://api.lakera.ai"
67	        )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/presidio.py:77
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
76	                with open(ad_hoc_recognizers, "r") as file:
77	                    self.ad_hoc_recognizers = json.load(file)
78	            except FileNotFoundError:

--------------------------------------------------
>> Issue: [B840:executor] concurrent.futures.Executor
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/guardrails/guardrail_hooks/presidio.py:289
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b840_executor.html
288	            # to avoid nested event loop issues
289	            with ThreadPoolExecutor(max_workers=1) as executor:
290	                future = executor.submit(run_in_new_loop)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/hooks/dynamic_rate_limiter.py:115
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
114	                    verbose_proxy_logger.error(
115	                        "PREMIUM FEATURE: Reserving tpm/rpm by priority is a premium feature. Please add a 'LITELLM_LICENSE' to your .env to enable this.\nGet a license: https://docs.litellm.ai/docs/proxy/enterprise."
116	                    )
117	                else:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/hooks/key_management_event_hooks.py:304
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
303	            raise ValueError(
304	                "Email alerting not setup on config.yaml. Please set `alerting=['email']. \nDocs: https://docs.litellm.ai/docs/proxy/email`"
305	            )
306	        event = WebhookEvent(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/hooks/proxy_track_cost_callback.py:191
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
190	                    raise Exception(
191	                        f"Cost tracking failed for model={model}.\nDebug info - {cost_tracking_failure_debug_info}\nAdd custom pricing - https://docs.litellm.ai/docs/proxy/custom_pricing"
192	                    )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/internal_user_endpoints.py:277
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
276	                raise ValueError(
277	                    "Email alerting not setup on config.yaml. Please set `alerting=['email']. \nDocs: https://docs.litellm.ai/docs/proxy/email`"
278	                )
279	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/internal_user_endpoints.py:431
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
430	            raise Exception(
431	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
432	            )
433	        if (

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/internal_user_endpoints.py:550
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
549	        raise Exception(
550	            "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
551	        )
552	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/key_management_endpoints.py:967
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
966	            raise Exception(
967	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
968	            )
969	        if data is None:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/key_management_endpoints.py:1031
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1030	            raise Exception(
1031	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
1032	            )
1033	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/key_management_endpoints.py:1160
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1159	        raise Exception(
1160	            "Connect Proxy to database to generate keys - https://docs.litellm.ai/docs/proxy/virtual_keys "
1161	        )
1162	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/key_management_endpoints.py:2617
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2616	        raise ValueError(
2617	            f"Invalid model_max_budget: {str(e)}. Example of valid model_max_budget: https://docs.litellm.ai/docs/proxy/users"
2618	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/model_management_endpoints.py:475
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
474	                detail={
475	                    "error": "No DB Connected. Here's how to do it - https://docs.litellm.ai/docs/proxy/virtual_keys"
476	                },
477	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/model_management_endpoints.py:585
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
584	                detail={
585	                    "error": "No DB Connected. Here's how to do it - https://docs.litellm.ai/docs/proxy/virtual_keys"
586	                },
587	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/model_management_endpoints.py:722
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
721	                detail={
722	                    "error": "No DB Connected. Here's how to do it - https://docs.litellm.ai/docs/proxy/virtual_keys"
723	                },
724	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/team_endpoints.py:1291
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1290	                detail={
1291	                    "error": "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
1292	                },
1293	            )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/team_endpoints.py:1509
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1508	            detail={
1509	                "error": "No available teams for user to join. See how to set available teams here: https://docs.litellm.ai/docs/proxy/self_serve#all-settings-for-self-serve--sso-flow"
1510	            },
1511	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/ui_sso.py:100
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
99	            raise ProxyException(
100	                message="You must be a LiteLLM Enterprise user to use SSO. If you have a license please set `LITELLM_LICENSE` in your env. If you want to obtain a license meet with us here: https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat You are seeing this error message because You set one of `MICROSOFT_CLIENT_ID`, `GOOGLE_CLIENT_ID`, or `GENERIC_CLIENT_ID` in your env. Please unset this",
101	                type=ProxyErrorTypes.auth_error,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/ui_sso.py:346
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
345	        raise ProxyException(
346	            message="Master Key not set for Proxy. Please set Master Key to use Admin UI. Set `LITELLM_MASTER_KEY` in .env or set general_settings:master_key in config.yaml.  https://docs.litellm.ai/docs/proxy/virtual_keys. If set, use `--detailed_debug` to debug issue.",
347	            type=ProxyErrorTypes.auth_error,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/ui_sso.py:492
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
491	        raise Exception(
492	            "Unable to map user identity to known values. 'user_defined_values' is None. File an issue - https://github.com/BerriAI/litellm/issues"
493	        )
494	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/ui_sso.py:795
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
794	        raise ValueError(
795	            "Unknown SSO provider. Please setup SSO with client IDs https://docs.litellm.ai/docs/proxy/admin_ui_sso"
796	        )
797	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/ui_sso.py:977
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
976	
977	    graph_api_base_url = "https://graph.microsoft.com/v1.0"
978	    graph_api_user_groups_endpoint = f"{graph_api_base_url}/me/memberOf"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/ui_sso.py:1210
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1209	        """
1210	        base_url = "https://graph.microsoft.com/v1.0"
1211	        # Endpoint to get app role assignments for the given service principal
1212	        endpoint = f"/servicePrincipals/{service_principal_id}/appRoleAssignedTo"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_endpoints/ui_sso.py:1340
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1339	            raise ProxyException(
1340	                message="You must be a LiteLLM Enterprise user to use SSO. If you have a license please set `LITELLM_LICENSE` in your env. If you want to obtain a license meet with us here: https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat You are seeing this error message because You set one of `MICROSOFT_CLIENT_ID`, `GOOGLE_CLIENT_ID`, or `GENERIC_CLIENT_ID` in your env. Please unset this",
1341	                type=ProxyErrorTypes.auth_error,

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_helpers/utils.py:314
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
313	
314	                            logging_payload = ManagementEndpointLoggingPayload(
315	                                route=_route,
316	                                request_data=_request_body,
317	                                response=_response,
318	                                start_time=start_time,
319	                                end_time=end_time,
320	                            )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/management_helpers/utils.py:357
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
356	                        )
357	                        logging_payload = ManagementEndpointLoggingPayload(
358	                            route=_route,
359	                            request_data=_request_body,
360	                            response=None,
361	                            start_time=start_time,
362	                            end_time=end_time,
363	                            exception=e,
364	                        )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/openai_files_endpoints/files_endpoints.py:210
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
209	        # Read the file content
210	        file_content = await file.read()
211	        custom_llm_provider = (

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/openai_files_endpoints/files_endpoints.py:238
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
237	        # Include original request and headers in the data
238	        data = await add_litellm_data_to_request(
239	            data=data,
240	            request=request,
241	            general_settings=general_settings,
242	            user_api_key_dict=user_api_key_dict,
243	            version=version,
244	            proxy_config=proxy_config,
245	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/openai_files_endpoints/files_endpoints.py:396
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
395	        # Include original request and headers in the data
396	        data = await add_litellm_data_to_request(
397	            data=data,
398	            request=request,
399	            general_settings=general_settings,
400	            user_api_key_dict=user_api_key_dict,
401	            version=version,
402	            proxy_config=proxy_config,
403	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/openai_files_endpoints/files_endpoints.py:527
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
526	        # Include original request and headers in the data
527	        data = await add_litellm_data_to_request(
528	            data=data,
529	            request=request,
530	            general_settings=general_settings,
531	            user_api_key_dict=user_api_key_dict,
532	            version=version,
533	            proxy_config=proxy_config,
534	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/openai_files_endpoints/files_endpoints.py:643
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
642	        # Include original request and headers in the data
643	        data = await add_litellm_data_to_request(
644	            data=data,
645	            request=request,
646	            general_settings=general_settings,
647	            user_api_key_dict=user_api_key_dict,
648	            version=version,
649	            proxy_config=proxy_config,
650	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/openai_files_endpoints/files_endpoints.py:759
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
758	        # Include original request and headers in the data
759	        data = await add_litellm_data_to_request(
760	            data=data,
761	            request=request,
762	            general_settings=general_settings,
763	            user_api_key_dict=user_api_key_dict,
764	            version=version,
765	            proxy_config=proxy_config,
766	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_passthrough_endpoints.py:68
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
67	
68	    base_target_url = "https://generativelanguage.googleapis.com"
69	    encoded_endpoint = httpx.URL(endpoint).path

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_passthrough_endpoints.py:127
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
126	    """
127	    base_target_url = "https://api.cohere.com"
128	    encoded_endpoint = httpx.URL(endpoint).path

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_passthrough_endpoints.py:179
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
178	    """
179	    base_target_url = "https://api.anthropic.com"
180	    encoded_endpoint = httpx.URL(endpoint).path

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_passthrough_endpoints.py:247
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
246	        base_target_url = (
247	            f"https://bedrock-agent-runtime.{aws_region_name}.amazonaws.com"
248	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_passthrough_endpoints.py:250
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
249	    else:
250	        base_target_url = f"https://bedrock-runtime.{aws_region_name}.amazonaws.com"
251	    encoded_endpoint = httpx.URL(endpoint).path

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_passthrough_endpoints.py:569
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
568	    """
569	    base_target_url = "https://api.openai.com/"
570	    # Add or update query parameters
571	    openai_api_key = passthrough_endpoint_router.get_credentials(

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_passthrough_endpoints.py:644
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
643	        if (
644	            RouteChecks._is_assistants_api_request(request) is True
645	            and "OpenAI-Beta" not in headers

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_provider_handlers/anthropic_passthrough_logging_handler.py:58
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
57	
58	        kwargs = AnthropicPassthroughLoggingHandler._create_anthropic_response_logging_payload(
59	            litellm_model_response=litellm_model_response,
60	            model=model,
61	            kwargs=kwargs,
62	            start_time=start_time,
63	            end_time=end_time,
64	            logging_obj=logging_obj,
65	        )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_provider_handlers/anthropic_passthrough_logging_handler.py:170
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
169	            }
170	        kwargs = AnthropicPassthroughLoggingHandler._create_anthropic_response_logging_payload(
171	            litellm_model_response=complete_streaming_response,
172	            model=model,
173	            kwargs={},
174	            start_time=start_time,
175	            end_time=end_time,
176	            logging_obj=litellm_logging_obj,
177	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_provider_handlers/assembly_passthrough_logging_handler.py:35
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
34	    def __init__(self):
35	        self.assembly_ai_base_url = "https://api.assemblyai.com"
36	        self.assembly_ai_eu_base_url = "https://eu.assemblyai.com"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_provider_handlers/assembly_passthrough_logging_handler.py:36
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
35	        self.assembly_ai_base_url = "https://api.assemblyai.com"
36	        self.assembly_ai_eu_base_url = "https://eu.assemblyai.com"
37	        """

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_provider_handlers/assembly_passthrough_logging_handler.py:125
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
124	        # Make standard logging object for Vertex AI
125	        standard_logging_object = get_standard_logging_object_payload(
126	            kwargs=kwargs,
127	            init_response_obj=transcript_response,
128	            start_time=start_time,
129	            end_time=end_time,
130	            logging_obj=logging_obj,
131	            status="success",
132	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_provider_handlers/assembly_passthrough_logging_handler.py:329
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
328	        if region == "eu":
329	            return "https://api.eu.assemblyai.com"
330	        return "https://api.assemblyai.com"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/llm_provider_handlers/assembly_passthrough_logging_handler.py:330
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
329	            return "https://api.eu.assemblyai.com"
330	        return "https://api.assemblyai.com"

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:87
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
86	                _langfuse_secret_key = get_secret_str(_langfuse_secret_key)
87	            headers["Authorization"] = "Basic " + b64encode(
88	                f"{_langfuse_public_key}:{_langfuse_secret_key}".encode("utf-8")
89	            ).decode("ascii")

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:87
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
86	                _langfuse_secret_key = get_secret_str(_langfuse_secret_key)
87	            headers["Authorization"] = "Basic " + b64encode(
88	                f"{_langfuse_public_key}:{_langfuse_secret_key}".encode("utf-8")
89	            ).decode("ascii")

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:154
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
153	
154	        data = await add_litellm_data_to_request(
155	            data=data,  # type: ignore
156	            request=request,
157	            general_settings=general_settings,
158	            user_api_key_dict=user_api_key_dict,
159	            version=version,
160	            proxy_config=proxy_config,
161	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:355
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
354	        if request.method == "GET":
355	            response = await async_client.request(
356	                method=request.method,
357	                url=url,
358	                headers=headers,
359	                params=requested_query_params,
360	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:362
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
361	        else:
362	            response = await async_client.request(
363	                method=request.method,
364	                url=url,
365	                headers=headers,
366	                params=requested_query_params,
367	                json=custom_body,
368	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:386
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
385	        if request.method == "GET":
386	            response = await async_client.request(
387	                method=request.method,
388	                url=url,
389	                headers=headers,
390	                params=requested_query_params,
391	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:393
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
392	        elif HttpPassThroughEndpointHelpers.is_multipart(request) is True:
393	            return await HttpPassThroughEndpointHelpers.make_multipart_http_request(
394	                request=request,
395	                async_client=async_client,
396	                url=url,
397	                headers=headers,
398	                requested_query_params=requested_query_params,
399	            )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:402
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
401	            # Generic httpx method
402	            response = await async_client.request(
403	                method=request.method,
404	                url=url,
405	                headers=headers,
406	                params=requested_query_params,
407	                json=_parsed_body,
408	            )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:421
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
420	        """Build a request files dict from an UploadFile object"""
421	        file_content = await upload_file.read()
422	        return (upload_file.filename, file_content, upload_file.content_type)

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:447
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
446	
447	        response = await async_client.request(
448	            method=request.method,
449	            url=url,
450	            headers=headers,
451	            params=requested_query_params,
452	            files=files,
453	            data=form_data_dict,
454	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:477
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
476	        headers = custom_headers
477	        headers = HttpPassThroughEndpointHelpers.forward_headers_from_request(
478	            request=request, headers=headers, forward_headers=forward_headers
479	        )

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:530
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
529	        )
530	        passthrough_logging_payload = PassthroughStandardLoggingPayload(
531	            url=str(url),
532	            request_body=_parsed_body,
533	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:581
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
580	        if stream:
581	            req = async_client.build_request(
582	                "POST",
583	                url,
584	                json=_parsed_body,
585	                params=requested_query_params,
586	                headers=headers,
587	            )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:595
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
594	                raise HTTPException(
595	                    status_code=e.response.status_code, detail=await e.response.aread()
596	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:640
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
639	                raise HTTPException(
640	                    status_code=e.response.status_code, detail=await e.response.aread()
641	                )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:670
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
669	
670	        content = await response.aread()
671	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py:838
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
837	        ):
838	            return await pass_through_request(  # type: ignore
839	                request=request,
840	                target=target,
841	                custom_headers=custom_headers or {},
842	                user_api_key_dict=user_api_key_dict,
843	                forward_headers=_forward_headers,
844	                merge_query_params=_merge_query_params,
845	                query_params=query_params,
846	                stream=stream,
847	                custom_body=custom_body,
848	            )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/streaming_handler.py:125
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
124	            )
125	        threading.Thread(
126	            target=litellm_logging_obj.success_handler,
127	            args=(
128	                standard_logging_response_object,
129	                start_time,
130	                end_time,
131	                False,
132	            ),

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/pass_through_endpoints/success_handler.py:130
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
129	            if (
130	                AssemblyAIPassthroughLoggingHandler._should_log_request(
131	                    httpx_response.request.method
132	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_cli.py:196
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
195	                _endpoint_str = (
196	                    f"curl --location 'http://0.0.0.0:{port}/chat/completions' \\"
197	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_cli.py:222
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
221	                print(  # noqa
222	                    "\033[1;34mDocs: https://docs.litellm.ai/docs/simple_proxy\033[0m\n"
223	                )  # noqa
224	                print(  # noqa

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_cli.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
224	                print(  # noqa
225	                    f"\033[1;34mSee all Router/Swagger docs on http://0.0.0.0:{port} \033[0m\n"
226	                )  # noqa

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_cli.py:286
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
285	
286	        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
287	            return s.connect_ex(("localhost", port)) == 0

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_cli.py:299
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
298	@click.option(
299	    "--host", default="0.0.0.0", help="Host for the server to listen on.", envvar="HOST"
300	)

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:52
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
51	    if file is not None:
52	        file.write(traceback_info)
53	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:101
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
100	        "\033[1;37m"
101	        + "# {:^59} #\033[0m".format("https://github.com/BerriAI/litellm/issues/new")
102	    )  # noqa

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:111
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
110	    print(  # noqa
111	        "\033[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\033[0m"
112	    )  # noqa
113	    print()  # noqa

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:411
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
410	)
411	ui_message += "\n\n [```LiteLLM Model Cost Map```](https://models.litellm.ai/)."
412	
413	custom_swagger_message = "[**Customize Swagger Docs**](https://docs.litellm.ai/docs/proxy/enterprise#swagger-docs---custom-routes--branding)"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:413
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
412	
413	custom_swagger_message = "[**Customize Swagger Docs**](https://docs.litellm.ai/docs/proxy/enterprise#swagger-docs---custom-routes--branding)"
414	
415	### CUSTOM BRANDING [ENTERPRISE FEATURE] ###
416	_title = os.getenv("DOCS_TITLE", "LiteLLM API") if premium_user else "LiteLLM API"

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:448
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
447	        verbose_proxy_logger.debug("Disconnecting from Prisma")
448	        await prisma_client.disconnect()
449	

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:451
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
450	    if litellm.cache is not None:
451	        await litellm.cache.disconnect()
452	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:453
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
452	
453	    await jwt_handler.close()
454	

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:456
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
455	    if db_writer_client is not None:
456	        await db_writer_client.close()
457	

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:1259
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
1258	            with open(file_path, "r") as file:
1259	                return yaml.safe_load(file) or {}
1260	        except Exception as e:

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:1282
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
1281	            with open(f"{file_path}", "r") as config_file:
1282	                config = yaml.safe_load(config_file)
1283	        elif file_path is not None:

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:3222
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
3221	
3222	                await prisma_client.connect()
3223	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:3390
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
3389	    try:
3390	        return await base_llm_response_processor.base_process_llm_request(
3391	            request=request,
3392	            fastapi_response=fastapi_response,
3393	            user_api_key_dict=user_api_key_dict,
3394	            route_type="acompletion",
3395	            proxy_logging_obj=proxy_logging_obj,
3396	            llm_router=llm_router,
3397	            general_settings=general_settings,
3398	            proxy_config=proxy_config,
3399	            select_data_generator=select_data_generator,
3400	            model=model,
3401	            user_model=user_model,
3402	            user_temperature=user_temperature,
3403	            user_request_timeout=user_request_timeout,
3404	            user_max_tokens=user_max_tokens,
3405	            user_api_base=user_api_base,
3406	            version=version,
3407	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:3503
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
3502	
3503	        data = await add_litellm_data_to_request(
3504	            data=data,
3505	            request=request,
3506	            general_settings=general_settings,
3507	            user_api_key_dict=user_api_key_dict,
3508	            version=version,
3509	            proxy_config=proxy_config,
3510	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:3534
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
3533	        ### ROUTE THE REQUESTs ###
3534	        llm_call = await route_request(
3535	            data=data,
3536	            route_type="atext_completion",
3537	            llm_router=llm_router,
3538	            user_model=user_model,
3539	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:3722
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
3721	        # Include original request and headers in the data
3722	        data = await add_litellm_data_to_request(
3723	            data=data,
3724	            request=request,
3725	            general_settings=general_settings,
3726	            user_api_key_dict=user_api_key_dict,
3727	            version=version,
3728	            proxy_config=proxy_config,
3729	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:3787
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
3786	        ## ROUTE TO CORRECT ENDPOINT ##
3787	        llm_call = await route_request(
3788	            data=data,
3789	            route_type="aembedding",
3790	            llm_router=llm_router,
3791	            user_model=user_model,
3792	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:3897
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
3896	        # Include original request and headers in the data
3897	        data = await add_litellm_data_to_request(
3898	            data=data,
3899	            request=request,
3900	            general_settings=general_settings,
3901	            user_api_key_dict=user_api_key_dict,
3902	            version=version,
3903	            proxy_config=proxy_config,
3904	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:3926
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
3925	        ## ROUTE TO CORRECT ENDPOINT ##
3926	        llm_call = await route_request(
3927	            data=data,
3928	            route_type="aimage_generation",
3929	            llm_router=llm_router,
3930	            user_model=user_model,
3931	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4020
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4019	        # Include original request and headers in the data
4020	        data = await add_litellm_data_to_request(
4021	            data=data,
4022	            request=request,
4023	            general_settings=general_settings,
4024	            user_api_key_dict=user_api_key_dict,
4025	            version=version,
4026	            proxy_config=proxy_config,
4027	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4041
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4040	        ## ROUTE TO CORRECT ENDPOINT ##
4041	        llm_call = await route_request(
4042	            data=data,
4043	            route_type="aspeech",
4044	            llm_router=llm_router,
4045	            user_model=user_model,
4046	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4132
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4131	        # Include original request and headers in the data
4132	        data = await add_litellm_data_to_request(
4133	            data=data,
4134	            request=request,
4135	            general_settings=general_settings,
4136	            user_api_key_dict=user_api_key_dict,
4137	            version=version,
4138	            proxy_config=proxy_config,
4139	        )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4169
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
4168	
4169	        file_content = await file.read()
4170	        file_object = io.BytesIO(file_content)

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4182
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4181	            ## ROUTE TO CORRECT ENDPOINT ##
4182	            llm_call = await route_request(
4183	                data=data,
4184	                route_type="atranscription",
4185	                llm_router=llm_router,
4186	                user_model=user_model,
4187	            )

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4192
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
4191	        finally:
4192	            file_object.close()  # close the file read in by io library
4193	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4321
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4320	        )
4321	        llm_call = await route_request(
4322	            data=data,
4323	            route_type="_arealtime",
4324	            llm_router=llm_router,
4325	            user_model=user_model,
4326	        )

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4331
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
4330	        verbose_proxy_logger.exception("Invalid status code")
4331	        await websocket.close(code=e.status_code, reason="Invalid status code")
4332	    except Exception:

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4334
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
4333	        verbose_proxy_logger.exception("Internal server error")
4334	        await websocket.close(code=1011, reason="Internal server error")
4335	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4372
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4371	        # Include original request and headers in the data
4372	        data = await add_litellm_data_to_request(
4373	            data=data,
4374	            request=request,
4375	            general_settings=general_settings,
4376	            user_api_key_dict=user_api_key_dict,
4377	            version=version,
4378	            proxy_config=proxy_config,
4379	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4471
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4470	        # Include original request and headers in the data
4471	        data = await add_litellm_data_to_request(
4472	            data=data,
4473	            request=request,
4474	            general_settings=general_settings,
4475	            user_api_key_dict=user_api_key_dict,
4476	            version=version,
4477	            proxy_config=proxy_config,
4478	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4568
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4567	        # Include original request and headers in the data
4568	        data = await add_litellm_data_to_request(
4569	            data=data,
4570	            request=request,
4571	            general_settings=general_settings,
4572	            user_api_key_dict=user_api_key_dict,
4573	            version=version,
4574	            proxy_config=proxy_config,
4575	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4665
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4664	        # Include original request and headers in the data
4665	        data = await add_litellm_data_to_request(
4666	            data=data,
4667	            request=request,
4668	            general_settings=general_settings,
4669	            user_api_key_dict=user_api_key_dict,
4670	            version=version,
4671	            proxy_config=proxy_config,
4672	        )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4679
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
4678	            )
4679	        response = await llm_router.acreate_thread(**data)
4680	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4760
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4759	        # Include original request and headers in the data
4760	        data = await add_litellm_data_to_request(
4761	            data=data,
4762	            request=request,
4763	            general_settings=general_settings,
4764	            user_api_key_dict=user_api_key_dict,
4765	            version=version,
4766	            proxy_config=proxy_config,
4767	        )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4774
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
4773	            )
4774	        response = await llm_router.aget_thread(thread_id=thread_id, **data)
4775	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4859
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4858	        # Include original request and headers in the data
4859	        data = await add_litellm_data_to_request(
4860	            data=data,
4861	            request=request,
4862	            general_settings=general_settings,
4863	            user_api_key_dict=user_api_key_dict,
4864	            version=version,
4865	            proxy_config=proxy_config,
4866	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:4954
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
4953	        # Include original request and headers in the data
4954	        data = await add_litellm_data_to_request(
4955	            data=data,
4956	            request=request,
4957	            general_settings=general_settings,
4958	            user_api_key_dict=user_api_key_dict,
4959	            version=version,
4960	            proxy_config=proxy_config,
4961	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:5051
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
5050	        # Include original request and headers in the data
5051	        data = await add_litellm_data_to_request(
5052	            data=data,
5053	            request=request,
5054	            general_settings=general_settings,
5055	            user_api_key_dict=user_api_key_dict,
5056	            version=version,
5057	            proxy_config=proxy_config,
5058	        )

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:5065
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
5064	            )
5065	        response = await llm_router.arun_thread(thread_id=thread_id, **data)
5066	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:5169
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
5168	        # Include original request and headers in the data
5169	        data = await add_litellm_data_to_request(
5170	            data=data,
5171	            request=request,
5172	            general_settings=general_settings,
5173	            user_api_key_dict=user_api_key_dict,
5174	            version=version,
5175	            proxy_config=proxy_config,
5176	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:5194
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
5193	        ## ROUTE TO CORRECT ENDPOINT ##
5194	        llm_call = await route_request(
5195	            data=data,
5196	            route_type="amoderation",
5197	            llm_router=llm_router,
5198	            user_model=user_model,
5199	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:5371
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
5370	
5371	    return return_raw_request(endpoint=request.call_type, kwargs=request.request_body)
5372	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:6120
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
6119	            detail={
6120	                "error": "LLM Model List not loaded in. Make sure you passed models in your config.yaml or on the LiteLLM Admin UI. - https://docs.litellm.ai/docs/proxy/configs"
6121	            },
6122	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:6128
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
6127	            detail={
6128	                "error": "LLM Router is not loaded in. Make sure you passed models in your config.yaml or on the LiteLLM Admin UI. - https://docs.litellm.ai/docs/proxy/configs"
6129	            },
6130	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:6705
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
6704	        raise ProxyException(
6705	            message="Master Key not set for Proxy. Please set Master Key to use Admin UI. Set `LITELLM_MASTER_KEY` in .env or set general_settings:master_key in config.yaml.  https://docs.litellm.ai/docs/proxy/virtual_keys. If set, use `--detailed_debug` to debug issue.",
6706	            type=ProxyErrorTypes.auth_error,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:6719
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
6718	        raise ProxyException(
6719	            message="set Proxy master key to use UI. https://docs.litellm.ai/docs/proxy/virtual_keys. If set, use `--detailed_debug` to debug issue.",
6720	            type=ProxyErrorTypes.auth_error,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:6928
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
6927	        raise ProxyException(
6928	            message="Master Key not set for Proxy. Please set Master Key to use Admin UI. Set `LITELLM_MASTER_KEY` in .env or set general_settings:master_key in config.yaml.  https://docs.litellm.ai/docs/proxy/virtual_keys. If set, use `--detailed_debug` to debug issue.",
6929	            type=ProxyErrorTypes.auth_error,

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:7081
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
7080	            detail={
7081	                "error": "The invitation link was never validated. Please file an issue, if this is not intended - https://github.com/BerriAI/litellm/issues."
7082	            },
7083	        )

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/proxy_server.py:7129
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
7128	            with open(cache_path, "wb") as f:
7129	                f.write(response.content)
7130	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:51
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
50	            raise Exception(
51	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
52	            )
53	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
95	            raise Exception(
96	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
97	            )
98	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:158
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
157	            raise Exception(
158	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
159	            )
160	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:278
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
277	            raise Exception(
278	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
279	            )
280	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:444
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
443	            raise Exception(
444	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
445	            )
446	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:596
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
595	            raise Exception(
596	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
597	            )
598	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:729
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
728	            raise Exception(
729	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
730	            )
731	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:835
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
834	            raise Exception(
835	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
836	            )
837	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:994
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
993	            raise Exception(
994	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
995	            )
996	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:1285
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1284	            raise Exception(
1285	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
1286	            )
1287	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:1366
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1365	            raise Exception(
1366	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
1367	            )
1368	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:1879
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1878	            raise Exception(
1879	                "Database not connected. Connect a database to your proxy - https://docs.litellm.ai/docs/simple_proxy#managing-auth---virtual-keys"
1880	            )
1881	        spend_logs = []

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/spend_tracking/spend_management_endpoints.py:2716
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
2715	            raise ValueError(
2716	                "No provider budget config found. Please set a provider budget config in the router settings. https://docs.litellm.ai/docs/proxy/provider_budget_routing"
2717	            )
2718	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/utils.py:932
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
931	
932	            threading.Thread(
933	                target=litellm_logging_obj.failure_handler,
934	                args=(
935	                    original_exception,
936	                    traceback.format_exc(),
937	                ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/utils.py:1306
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1305	                        verbose_proxy_logger.warning(
1306	                            "\n\n\033[93mNot all views exist in db, needed for UI 'Usage' tab. Missing={}.\nRun 'create_views.py' from https://github.com/BerriAI/litellm/tree/main/db_scripts to create missing views.\033[0m\n".format(
1307	                                missing_views

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/vertex_ai_endpoints/langfuse_endpoints.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
63	
64	    decoded_bytes = base64.b64decode(api_key)
65	    decoded_str = decoded_bytes.decode("utf-8")

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/vertex_ai_endpoints/langfuse_endpoints.py:64
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
63	
64	    decoded_bytes = base64.b64decode(api_key)
65	    decoded_str = decoded_bytes.decode("utf-8")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/vertex_ai_endpoints/langfuse_endpoints.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
94	        dynamic_langfuse_host
95	        or os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com")
96	        or "https://cloud.langfuse.com"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/vertex_ai_endpoints/langfuse_endpoints.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
95	        or os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com")
96	        or "https://cloud.langfuse.com"
97	    )
98	    if not (
99	        base_target_url.startswith("http://") or base_target_url.startswith("https://")

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/vertex_ai_endpoints/langfuse_endpoints.py:122
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
121	
122	    langfuse_combined_key = "Basic " + b64encode(
123	        f"{langfuse_public_key}:{langfuse_secret_key}".encode("utf-8")
124	    ).decode("ascii")

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/proxy/vertex_ai_endpoints/langfuse_endpoints.py:122
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
121	
122	    langfuse_combined_key = "Basic " + b64encode(
123	        f"{langfuse_public_key}:{langfuse_secret_key}".encode("utf-8")
124	    ).decode("ascii")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/realtime_api/main.py:96
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
95	            or litellm.api_base
96	            or "https://api.openai.com/"
97	        )
98	        # set API KEY
99	        api_key = (
100	            dynamic_api_key

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/realtime_api/main.py:152
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
151	        url = openai_realtime._construct_url(
152	            api_base=api_base or "https://api.openai.com/", model=model
153	        )

--------------------------------------------------
>> Issue: [B804:connect] socket.socket.connect
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/realtime_api/main.py:156
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b804_connect.html
155	        raise ValueError(f"Unsupported model: {model}")
156	    async with websockets.connect(  # type: ignore
157	        url,
158	        extra_headers={
159	            "api-key": api_key,  # type: ignore
160	        },

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/rerank_api/main.py:179
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
178	                or get_secret("COHERE_API_BASE")  # type: ignore
179	                or "https://api.cohere.com"
180	            )
181	
182	            if api_base is None:
183	                raise Exception(
184	                    "Invalid api base. api_base=None. Set in call or via `COHERE_API_BASE` env var."

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router.py:1521
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1520	        ## ADDS REQUEST TO QUEUE ##
1521	        await self.scheduler.add_request(request=item)
1522	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router.py:1583
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
1582	        ## ADDS REQUEST TO QUEUE ##
1583	        await self.scheduler.add_request(request=item)
1584	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router.py:3245
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
3244	                    else:
3245	                        error_message = "model={}. context_window_fallbacks={}. fallbacks={}.\n\nSet 'context_window_fallback' - https://docs.litellm.ai/docs/routing#fallbacks".format(
3246	                            model_group, context_window_fallbacks, fallbacks

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router.py:3280
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
3279	                    else:
3280	                        error_message = "model={}. content_policy_fallback={}. fallbacks={}.\n\nSet 'content_policy_fallback' - https://docs.litellm.ai/docs/routing#fallbacks".format(
3281	                            model_group, content_policy_fallbacks, fallbacks

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router.py:4174
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
4173	                        ## LOGGING
4174	                        threading.Thread(
4175	                            target=logging_obj.failure_handler,
4176	                            args=(e, traceback.format_exc()),
4177	                        ).start()  # log response

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router.py:4197
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
4196	                        ## LOGGING
4197	                        threading.Thread(
4198	                            target=logging_obj.failure_handler,
4199	                            args=(e, traceback.format_exc()),
4200	                        ).start()  # log response

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router.py:4247
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
4246	                        ## LOGGING
4247	                        threading.Thread(
4248	                            target=logging_obj.failure_handler,
4249	                            args=(e, traceback.format_exc()),
4250	                        ).start()  # log response

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router.py:4759
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4758	            verbose_router_logger.error(
4759	                "Could not identify azure model. Set azure 'base_model' for accurate max tokens, cost tracking, etc.- https://docs.litellm.ai/docs/proxy/cost_tracking#spend-tracking-for-azure-openai-models"
4760	            )
4761	        elif custom_llm_provider != "azure":

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router.py:6056
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
6055	                    ## LOGGING
6056	                    threading.Thread(
6057	                        target=logging_obj.failure_handler,
6058	                        args=(e, traceback_exception),
6059	                    ).start()  # log response

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_strategy/base_routing_strategy.py:37
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
36	                else:
37	                    self._create_sync_thread(default_sync_interval)
38	            except RuntimeError:  # No event loop in current thread

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_strategy/base_routing_strategy.py:39
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
38	            except RuntimeError:  # No event loop in current thread
39	                self._create_sync_thread(default_sync_interval)
40	

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_strategy/base_routing_strategy.py:181
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
180	        """Helper method to create a new thread for periodic sync"""
181	        thread = threading.Thread(
182	            target=asyncio.run,
183	            args=(
184	                self.periodic_sync_in_memory_spend_with_redis(
185	                    default_sync_interval=default_sync_interval
186	                ),
187	            ),
188	            daemon=True,
189	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_strategy/lowest_tpm_rpm_v2.py:112
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
111	                        ),
112	                        request=httpx.Request(method="tpm_rpm_limits", url="https://github.com/BerriAI/litellm"),  # type: ignore
113	                    ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_strategy/lowest_tpm_rpm_v2.py:135
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
134	                            ),
135	                            request=httpx.Request(method="tpm_rpm_limits", url="https://github.com/BerriAI/litellm"),  # type: ignore
136	                        ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_strategy/lowest_tpm_rpm_v2.py:196
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
195	                        headers={"retry-after": str(60)},  # type: ignore
196	                        request=httpx.Request(method="tpm_rpm_limits", url="https://github.com/BerriAI/litellm"),  # type: ignore
197	                    ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_strategy/lowest_tpm_rpm_v2.py:220
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
219	                            headers={"retry-after": str(60)},  # type: ignore
220	                            request=httpx.Request(method="tpm_rpm_limits", url="https://github.com/BerriAI/litellm"),  # type: ignore
221	                        ),

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_strategy/lowest_tpm_rpm_v2.py:563
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
562	                    headers={"retry-after": str(60)},  # type: ignore
563	                    request=httpx.Request(method="tpm_rpm_limits", url="https://github.com/BerriAI/litellm"),  # type: ignore
564	                ),

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_utils/client_initalization_utils.py:19
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
18	    ):
19	        litellm_params = model.get("litellm_params", {})
20	        model_id = model["model_info"]["id"]

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_utils/client_initalization_utils.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
20	        model_id = model["model_info"]["id"]
21	        rpm = litellm_params.get("rpm", None)
22	        tpm = litellm_params.get("tpm", None)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_utils/client_initalization_utils.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
21	        rpm = litellm_params.get("rpm", None)
22	        tpm = litellm_params.get("tpm", None)
23	        max_parallel_requests = litellm_params.get("max_parallel_requests", None)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/router_utils/client_initalization_utils.py:23
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
22	        tpm = litellm_params.get("tpm", None)
23	        max_parallel_requests = litellm_params.get("max_parallel_requests", None)
24	        calculated_max_parallel_requests = calculate_max_parallel_requests(

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/aws_secret_manager.py:98
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
97	        # Decode the base64 encoded ciphertext
98	        ciphertext_blob = base64.b64decode(encrypted_value)
99	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/aws_secret_manager.py:98
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
97	        # Decode the base64 encoded ciphertext
98	        ciphertext_blob = base64.b64decode(encrypted_value)
99	

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/aws_secret_manager_v2.py:80
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
79	
80	        endpoint_url, headers, body = self._prepare_request(
81	            action="GetSecretValue",
82	            secret_name=secret_name,
83	            optional_params=optional_params,
84	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/aws_secret_manager_v2.py:134
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
133	
134	        endpoint_url, headers, body = self._prepare_request(
135	            action="GetSecretValue",
136	            secret_name=secret_name,
137	            optional_params=optional_params,
138	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/aws_secret_manager_v2.py:227
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
226	
227	        endpoint_url, headers, body = self._prepare_request(
228	            action="CreateSecret",
229	            secret_name=secret_name,
230	            secret_value=secret_value,
231	            optional_params=optional_params,
232	            request_data=data,  # Pass the complete request data
233	        )

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/aws_secret_manager_v2.py:276
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
275	
276	        endpoint_url, headers, body = self._prepare_request(
277	            action="DeleteSecret",
278	            secret_name=secret_name,
279	            optional_params=optional_params,
280	            request_data=data,
281	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/get_azure_ad_token_provider.py:21
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
20	    azure_scope = os.environ.get(
21	        "AZURE_SCOPE", "https://cognitiveservices.azure.com/.default"
22	    )
23	    cred = os.environ.get("AZURE_CREDENTIAL", "ClientSecretCredential")

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/google_secret_manager.py:83
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
82	        headers = self.sync_construct_request_headers()
83	        url = f"https://secretmanager.googleapis.com/v1/{_secret_name}:access"
84	

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/google_secret_manager.py:110
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
109	        if _base64_encoded_value is not None:
110	            _decoded_value = base64.b64decode(_base64_encoded_value).decode("utf-8")
111	            self.cache.set_cache(

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/google_secret_manager.py:110
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
109	        if _base64_encoded_value is not None:
110	            _decoded_value = base64.b64decode(_base64_encoded_value).decode("utf-8")
111	            self.cache.set_cache(

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/hashicorp_secret_manager.py:25
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
24	        # Vault-specific config
25	        self.vault_addr = os.getenv("HCP_VAULT_ADDR", "http://127.0.0.1:8200")
26	        self.vault_token = os.getenv("HCP_VAULT_TOKEN", "")

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
23	    try:
24	        return base64.b64encode(base64.b64decode(s)).decode() == s
25	    except binascii.Error:

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:24
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
23	    try:
24	        return base64.b64encode(base64.b64decode(s)).decode() == s
25	    except binascii.Error:

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:24
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
23	    try:
24	        return base64.b64encode(base64.b64decode(s)).decode() == s
25	    except binascii.Error:

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:24
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
23	    try:
24	        return base64.b64encode(base64.b64decode(s)).decode() == s
25	    except binascii.Error:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:114
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
113	            response = oidc_client.get(
114	                "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/identity",
115	                params={"audience": oidc_aud},
116	                headers={"Metadata-Flavor": "Google"},
117	            )
118	            if response.status_code == 200:

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:173
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
172	            with open(azure_federated_token_file, "r") as f:
173	                oidc_token = f.read()
174	                return oidc_token

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:178
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
177	            with open(oidc_aud, "r") as f:
178	                oidc_token = f.read()
179	                return oidc_token

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:192
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
191	            with open(token_file_path, "r") as f:
192	                oidc_token = f.read()
193	                return oidc_token

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:232
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
231	                    if b64_flag is True:  # if passed in as encoded b64 string
232	                        encrypted_secret = base64.b64decode(encrypted_secret)
233	                        ciphertext = encrypted_secret

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:232
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
231	                    if b64_flag is True:  # if passed in as encoded b64 string
232	                        encrypted_secret = base64.b64decode(encrypted_secret)
233	                        ciphertext = encrypted_secret

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:259
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
258	                    # Decode the base64 encoded ciphertext
259	                    ciphertext_blob = base64.b64decode(encrypted_value)
260	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/secret_managers/main.py:259
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
258	                    # Decode the base64 encoded ciphertext
259	                    ciphertext_blob = base64.b64decode(encrypted_value)
260	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/types/integrations/slack_alerting.py:31
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
30	# we use this for the email header, please send a test email if you change this. verify it looks good on email
31	LITELLM_LOGO_URL = "https://litellm-listing.s3.amazonaws.com/litellm_logo.png"
32	LITELLM_SUPPORT_CONTACT = "support@berri.ai"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/types/utils.py:70
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
69	    redacted_by_litellm = "redacted by litellm. 'litellm.turn_off_message_logging=True'"
70	    llm_provider_not_provided = "Unmapped LLM provider for this endpoint. You passed model={model}, custom_llm_provider={custom_llm_provider}. Check supported provider and route: https://docs.litellm.ai/docs/providers"
71	

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:186
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
185	) as f:
186	    json_data = json.load(f)
187	# Convert to str (if necessary)

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:970
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
969	        call_type = original_function.__name__
970	        if _is_async_request(kwargs):
971	            # [OPTIONAL] CHECK MAX RETRIES / REQUEST

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:1642
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1641	        raise NotImplementedError(
1642	            f"""num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens."""
1643	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:4148
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4147	        # Construct the URL for the config.json file
4148	        config_url = f"https://huggingface.co/{model_name}/raw/main/config.json"
4149	        try:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:4185
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4184	        raise Exception(
4185	            f"Model {model} isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"
4186	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:4328
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4327	    # Construct the URL for the config.json file
4328	    config_url = f"https://huggingface.co/{model_name}/raw/main/config.json"
4329	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:4491
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4490	                raise ValueError(
4491	                    "This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"
4492	                )
4493	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:4611
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
4610	        raise Exception(
4611	            "This model isn't mapped yet. model={}, custom_llm_provider={}. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.".format(
4612	                model, custom_llm_provider

--------------------------------------------------
>> Issue: [B835:load] http.cookiejar.FileCookieJar.load
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:5581
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b835_load.html
5580	        with open(config_path, "r") as config_file:
5581	            config = json.load(config_file)
5582	

--------------------------------------------------
>> Issue: [B801:b64decode] base64.b64decode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:6043
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b801_b64decode.html
6042	        # Try to decode the string
6043	        decoded_bytes = base64.b64decode(s, validate=True)
6044	

--------------------------------------------------
>> Issue: [B300:blacklist] base64.b64decode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:6043
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b300-base64-b64decode
6042	        # Try to decode the string
6043	        decoded_bytes = base64.b64decode(s, validate=True)
6044	

--------------------------------------------------
>> Issue: [B802:b64encode] base64.b64encode
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:6046
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b802_b64encode.html
6045	        # Check if the original string can be re-encoded to the same string
6046	        return base64.b64encode(decoded_bytes).decode("utf-8") == s
6047	    except Exception:

--------------------------------------------------
>> Issue: [B301:blacklist] base64.b64encode
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/litellm-1.65.7/litellm-1.65.7/litellm/utils.py:6046
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-base64-b64encode
6045	        # Check if the original string can be re-encoded to the same string
6046	        return base64.b64encode(decoded_bytes).decode("utf-8") == s
6047	    except Exception:

--------------------------------------------------

Code scanned:
	Total lines of code: 161608
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 426.0
		High: 372.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 770.0
		High: 28.0
Files skipped (0):
