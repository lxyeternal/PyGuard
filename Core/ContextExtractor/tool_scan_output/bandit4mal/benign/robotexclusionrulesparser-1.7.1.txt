Run started:2025-04-12 13:51:52.621834

Test results:
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser.py:411
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
410	            if timeout:
411	                f = urllib_request.urlopen(req, timeout=timeout)
412	            else:

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser.py:413
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
412	            else:
413	                f = urllib_request.urlopen(req)
414	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/setup.py:12
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
11	maintainer = "Philip Semanchuk"
12	url = "http://nikitathespider.com/python/rerp/"
13	download_url = \

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/setup.py:14
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
13	download_url = \
14	    "http://nikitathespider.com/python/rerp/robotexclusionrulesparser-%s.tar.gz" % VERSION
15	py_modules = ["robotexclusionrulesparser"]

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/setup.py:28
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
27	               'Topic :: Utilities']
28	license = "http://creativecommons.org/licenses/BSD/"
29	keywords = "robots.txt robot parser"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_fetch.py:34
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
33	PORT = None
34	HOST_NAME = 'http://localhost:{}'
35	
36	
37	def setUpModule():

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_fetch.py:50
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
49	
50	    http_server_thread = threading.Thread(target=run_http_server)
51	    http_server_thread.start()

--------------------------------------------------
>> Issue: [B818:urlopen] urllib.request.urlopen
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_fetch.py:62
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b818_urlopen.html
61	    req = urllib_request.Request(HOST_NAME + "/die_die_die/")
62	    urllib_request.urlopen(req)
63	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_fetch.py:74
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
73	        """Test handling of non-existent domain"""
74	        url = 'http://ThisDomainIsGuaranteedNotToExistPerRfc2606.invalid'
75	
76	        with self.assertRaises(urllib_error.URLError):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:22
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
21	
22	        s = """
23	        # robots.txt for http://www.example.com/
24	
25	        User-agent: *
26	        Disallow:    /
27	
28	        User-agent: foobot
29	        Disallow:
30	
31	        """
32	        self.parser.parse(s)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:49
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
48	
49	        s = """
50	        # robots.txt for http://www.example.com/
51	
52	        # In the classic syntax, * is treated literally, not as a wildcard.
53	        # A Webmaster might expect the line below to disallow everything, but
54	        # that's not how it works.
55	        User-agent: foobot
56	        Disallow: *
57	
58	        User-agent: barbot
59	        Disallow: /private/*
60	        """
61	        self.parser.parse(s)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:94
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
93	        """Test the parser with the example from MK1994"""
94	        robots_txt = """
95	# robots.txt for http://www.example.com/
96	
97	User-agent: *
98	Disallow: /cyberworld/map/ # This is an infinite virtual URL space
99	Disallow: /tmp/ # these will soon disappear
100	Disallow: /foo.html
101	        """
102	        self.parser.parse(robots_txt)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:116
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
115	        # host name and protocol.
116	        self.assertFalse(self.parser.is_allowed(user_agent, "http://example.com/foo.html"))
117	        self.assertFalse(self.parser.is_allowed(user_agent, "http://www.example.com/foo.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:117
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
116	        self.assertFalse(self.parser.is_allowed(user_agent, "http://example.com/foo.html"))
117	        self.assertFalse(self.parser.is_allowed(user_agent, "http://www.example.com/foo.html"))
118	        self.assertFalse(self.parser.is_allowed(user_agent, "http://www.example.org/foo.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:118
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
117	        self.assertFalse(self.parser.is_allowed(user_agent, "http://www.example.com/foo.html"))
118	        self.assertFalse(self.parser.is_allowed(user_agent, "http://www.example.org/foo.html"))
119	        self.assertFalse(self.parser.is_allowed(user_agent, "https://www.example.org/foo.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:119
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
118	        self.assertFalse(self.parser.is_allowed(user_agent, "http://www.example.org/foo.html"))
119	        self.assertFalse(self.parser.is_allowed(user_agent, "https://www.example.org/foo.html"))
120	        self.assertFalse(self.parser.is_allowed(user_agent, "ftp://example.net/foo.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:124
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
123	        """Test the parser with example A from MK1996"""
124	        robots_txt = """
125	# robots.txt for http://www.example.com/
126	
127	User-agent: 1bot
128	Allow: /tmp
129	Disallow: /
130	
131	User-agent: 2bot
132	Allow: /tmp/
133	Disallow: /
134	
135	User-agent: 3bot
136	Allow: /a%3cd.html
137	Disallow: /
138	
139	User-agent: 4bot
140	Allow: /a%3Cd.html
141	Disallow: /
142	
143	User-agent: 5bot
144	Allow: /a%2fb.html
145	Disallow: /
146	
147	User-agent: 6bot
148	Allow: /a/b.html
149	Disallow: /
150	
151	User-agent: 7bot
152	Allow: /%7ejoe/index.html
153	Disallow: /
154	
155	User-agent: 8bot
156	Allow: /~joe/index.html
157	Disallow: /
158	
159	        """
160	        self.parser.parse(robots_txt)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:181
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
180	        """Test the parser with example B from MK1996 with the domain changed to example.org"""
181	        robots_txt = """
182	# /robots.txt for http://www.example.org/
183	# comments to webmaster@example.org
184	
185	User-agent: unhipbot
186	Disallow: /
187	
188	User-agent: webcrawler
189	User-agent: excite
190	Disallow:
191	
192	User-agent: *
193	Disallow: /org/plans.html
194	Allow: /org/
195	Allow: /serv
196	Allow: /~mak
197	Disallow: /
198	
199	        """
200	        self.parser.parse(robots_txt)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:202
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
201	
202	        self.assertFalse(self.parser.is_allowed("unhipbot", "http://www.example.org/"))
203	        self.assertTrue(self.parser.is_allowed("webcrawler", "http://www.example.org/"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:203
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
202	        self.assertFalse(self.parser.is_allowed("unhipbot", "http://www.example.org/"))
203	        self.assertTrue(self.parser.is_allowed("webcrawler", "http://www.example.org/"))
204	        self.assertTrue(self.parser.is_allowed("excite", "http://www.example.org/"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:204
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
203	        self.assertTrue(self.parser.is_allowed("webcrawler", "http://www.example.org/"))
204	        self.assertTrue(self.parser.is_allowed("excite", "http://www.example.org/"))
205	        self.assertFalse(self.parser.is_allowed("OtherBot", "http://www.example.org/"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:205
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
204	        self.assertTrue(self.parser.is_allowed("excite", "http://www.example.org/"))
205	        self.assertFalse(self.parser.is_allowed("OtherBot", "http://www.example.org/"))
206	        self.assertFalse(self.parser.is_allowed("unhipbot", "http://www.example.org/index.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:206
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
205	        self.assertFalse(self.parser.is_allowed("OtherBot", "http://www.example.org/"))
206	        self.assertFalse(self.parser.is_allowed("unhipbot", "http://www.example.org/index.html"))
207	        self.assertTrue(self.parser.is_allowed("webcrawler", "http://www.example.org/index.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:207
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
206	        self.assertFalse(self.parser.is_allowed("unhipbot", "http://www.example.org/index.html"))
207	        self.assertTrue(self.parser.is_allowed("webcrawler", "http://www.example.org/index.html"))
208	        self.assertTrue(self.parser.is_allowed("excite", "http://www.example.org/index.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:208
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
207	        self.assertTrue(self.parser.is_allowed("webcrawler", "http://www.example.org/index.html"))
208	        self.assertTrue(self.parser.is_allowed("excite", "http://www.example.org/index.html"))
209	        self.assertFalse(self.parser.is_allowed("OtherBot", "http://www.example.org/index.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:209
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
208	        self.assertTrue(self.parser.is_allowed("excite", "http://www.example.org/index.html"))
209	        self.assertFalse(self.parser.is_allowed("OtherBot", "http://www.example.org/index.html"))
210	        # The original document contains tests for robots.txt. I dropped them. I presume that no

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:216
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
215	        #   assert(parser.is_allowed("OtherBot", "http://www.example.org/robots.txt") == True)
216	        self.assertFalse(self.parser.is_allowed("unhipbot", "http://www.example.org/server.html"))
217	        self.assertTrue(self.parser.is_allowed("webcrawler", "http://www.example.org/server.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:217
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
216	        self.assertFalse(self.parser.is_allowed("unhipbot", "http://www.example.org/server.html"))
217	        self.assertTrue(self.parser.is_allowed("webcrawler", "http://www.example.org/server.html"))
218	        self.assertTrue(self.parser.is_allowed("excite", "http://www.example.org/server.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:218
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
217	        self.assertTrue(self.parser.is_allowed("webcrawler", "http://www.example.org/server.html"))
218	        self.assertTrue(self.parser.is_allowed("excite", "http://www.example.org/server.html"))
219	        self.assertTrue(self.parser.is_allowed("OtherBot", "http://www.example.org/server.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:219
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
218	        self.assertTrue(self.parser.is_allowed("excite", "http://www.example.org/server.html"))
219	        self.assertTrue(self.parser.is_allowed("OtherBot", "http://www.example.org/server.html"))
220	        self.assertFalse(self.parser.is_allowed("unhipbot",

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:221
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
220	        self.assertFalse(self.parser.is_allowed("unhipbot",
221	                                                "http://www.example.org/services/fast.html"))
222	        self.assertTrue(self.parser.is_allowed("webcrawler",
223	                                               "http://www.example.org/services/fast.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:223
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
222	        self.assertTrue(self.parser.is_allowed("webcrawler",
223	                                               "http://www.example.org/services/fast.html"))
224	        self.assertTrue(self.parser.is_allowed("excite",
225	                                               "http://www.example.org/services/fast.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
224	        self.assertTrue(self.parser.is_allowed("excite",
225	                                               "http://www.example.org/services/fast.html"))
226	        self.assertTrue(self.parser.is_allowed("OtherBot",
227	                                               "http://www.example.org/services/fast.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:227
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
226	        self.assertTrue(self.parser.is_allowed("OtherBot",
227	                                               "http://www.example.org/services/fast.html"))
228	        self.assertFalse(self.parser.is_allowed("unhipbot",
229	                                                "http://www.example.org/services/slow.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:229
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
228	        self.assertFalse(self.parser.is_allowed("unhipbot",
229	                                                "http://www.example.org/services/slow.html"))
230	        self.assertTrue(self.parser.is_allowed("webcrawler",
231	                                               "http://www.example.org/services/slow.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:231
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
230	        self.assertTrue(self.parser.is_allowed("webcrawler",
231	                                               "http://www.example.org/services/slow.html"))
232	        self.assertTrue(self.parser.is_allowed("excite",
233	                                               "http://www.example.org/services/slow.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:233
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
232	        self.assertTrue(self.parser.is_allowed("excite",
233	                                               "http://www.example.org/services/slow.html"))
234	        self.assertTrue(self.parser.is_allowed("OtherBot",
235	                                               "http://www.example.org/services/slow.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:235
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
234	        self.assertTrue(self.parser.is_allowed("OtherBot",
235	                                               "http://www.example.org/services/slow.html"))
236	        self.assertFalse(self.parser.is_allowed("unhipbot",
237	                                                "http://www.example.org/orgo.gif"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:237
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
236	        self.assertFalse(self.parser.is_allowed("unhipbot",
237	                                                "http://www.example.org/orgo.gif"))
238	        self.assertTrue(self.parser.is_allowed("webcrawler",
239	                                               "http://www.example.org/orgo.gif"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:239
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
238	        self.assertTrue(self.parser.is_allowed("webcrawler",
239	                                               "http://www.example.org/orgo.gif"))
240	        self.assertTrue(self.parser.is_allowed("excite",
241	                                               "http://www.example.org/orgo.gif"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:241
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
240	        self.assertTrue(self.parser.is_allowed("excite",
241	                                               "http://www.example.org/orgo.gif"))
242	        self.assertFalse(self.parser.is_allowed("OtherBot",
243	                                                "http://www.example.org/orgo.gif"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:243
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
242	        self.assertFalse(self.parser.is_allowed("OtherBot",
243	                                                "http://www.example.org/orgo.gif"))
244	        self.assertFalse(self.parser.is_allowed("unhipbot",
245	                                                "http://www.example.org/org/about.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:245
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
244	        self.assertFalse(self.parser.is_allowed("unhipbot",
245	                                                "http://www.example.org/org/about.html"))
246	        self.assertTrue(self.parser.is_allowed("webcrawler",
247	                                               "http://www.example.org/org/about.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:247
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
246	        self.assertTrue(self.parser.is_allowed("webcrawler",
247	                                               "http://www.example.org/org/about.html"))
248	        self.assertTrue(self.parser.is_allowed("excite",
249	                                               "http://www.example.org/org/about.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:249
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
248	        self.assertTrue(self.parser.is_allowed("excite",
249	                                               "http://www.example.org/org/about.html"))
250	        self.assertTrue(self.parser.is_allowed("OtherBot",
251	                                               "http://www.example.org/org/about.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:251
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
250	        self.assertTrue(self.parser.is_allowed("OtherBot",
251	                                               "http://www.example.org/org/about.html"))
252	        self.assertFalse(self.parser.is_allowed("unhipbot",
253	                                                "http://www.example.org/org/plans.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:253
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
252	        self.assertFalse(self.parser.is_allowed("unhipbot",
253	                                                "http://www.example.org/org/plans.html"))
254	        self.assertTrue(self.parser.is_allowed("webcrawler",
255	                                               "http://www.example.org/org/plans.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:255
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
254	        self.assertTrue(self.parser.is_allowed("webcrawler",
255	                                               "http://www.example.org/org/plans.html"))
256	        self.assertTrue(self.parser.is_allowed("excite",
257	                                               "http://www.example.org/org/plans.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:257
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
256	        self.assertTrue(self.parser.is_allowed("excite",
257	                                               "http://www.example.org/org/plans.html"))
258	        self.assertFalse(self.parser.is_allowed("OtherBot",
259	                                                "http://www.example.org/org/plans.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:259
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
258	        self.assertFalse(self.parser.is_allowed("OtherBot",
259	                                                "http://www.example.org/org/plans.html"))
260	        self.assertFalse(self.parser.is_allowed("unhipbot",
261	                                                "http://www.example.org/%7Ejim/jim.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:261
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
260	        self.assertFalse(self.parser.is_allowed("unhipbot",
261	                                                "http://www.example.org/%7Ejim/jim.html"))
262	        self.assertTrue(self.parser.is_allowed("webcrawler",
263	                                               "http://www.example.org/%7Ejim/jim.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:263
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
262	        self.assertTrue(self.parser.is_allowed("webcrawler",
263	                                               "http://www.example.org/%7Ejim/jim.html"))
264	        self.assertTrue(self.parser.is_allowed("excite",
265	                                               "http://www.example.org/%7Ejim/jim.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:265
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
264	        self.assertTrue(self.parser.is_allowed("excite",
265	                                               "http://www.example.org/%7Ejim/jim.html"))
266	        self.assertFalse(self.parser.is_allowed("OtherBot",
267	                                                "http://www.example.org/%7Ejim/jim.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:267
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
266	        self.assertFalse(self.parser.is_allowed("OtherBot",
267	                                                "http://www.example.org/%7Ejim/jim.html"))
268	        self.assertFalse(self.parser.is_allowed("unhipbot",
269	                                                "http://www.example.org/%7Emak/mak.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:269
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
268	        self.assertFalse(self.parser.is_allowed("unhipbot",
269	                                                "http://www.example.org/%7Emak/mak.html"))
270	        self.assertTrue(self.parser.is_allowed("webcrawler",
271	                                               "http://www.example.org/%7Emak/mak.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:271
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
270	        self.assertTrue(self.parser.is_allowed("webcrawler",
271	                                               "http://www.example.org/%7Emak/mak.html"))
272	        self.assertTrue(self.parser.is_allowed("excite",
273	                                               "http://www.example.org/%7Emak/mak.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:273
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
272	        self.assertTrue(self.parser.is_allowed("excite",
273	                                               "http://www.example.org/%7Emak/mak.html"))
274	        self.assertTrue(self.parser.is_allowed("OtherBot",
275	                                               "http://www.example.org/%7Emak/mak.html"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:275
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
274	        self.assertTrue(self.parser.is_allowed("OtherBot",
275	                                               "http://www.example.org/%7Emak/mak.html"))
276	
277	    def test_blank_or_not_present(self):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:306
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
305	        """Test the parser's ability to handle non-ASCII"""
306	        robots_txt = """
307	# robots.txt for http://www.example.com/
308	
309	UserAgent: JÃ¤vla-Foobot
310	Disallow: /
311	
312	UserAgent: \u041b\u044c\u0432\u0456\u0432-bot
313	Disallow: /totalitarianism/
314	
315	"""
316	        if PY_MAJOR_VERSION < 3:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:333
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
332	        """Test implicit allow rule"""
333	        robots_txt = """
334	# robots.txt for http://www.example.com/
335	
336	User-agent: *
337	Disallow:    /
338	
339	User-agent: foobot
340	Disallow:
341	"""
342	        self.parser.parse(robots_txt)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:351
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
350	        """Test parsing of GYM2008 wildcard syntax"""
351	        robots_txt = """
352	# robots.txt for http://www.example.com/
353	
354	User-agent: Rule1TestBot
355	Disallow:  /foo*
356	
357	User-agent: Rule2TestBot
358	Disallow:  /foo*/bar.html
359	
360	# Disallows anything containing the letter m!
361	User-agent: Rule3TestBot
362	Disallow:  *m
363	
364	User-agent: Rule4TestBot
365	Allow:  /foo/bar.html
366	Disallow: *
367	
368	User-agent: Rule5TestBot
369	Disallow:  /foo*/*bar.html
370	
371	User-agent: Rule6TestBot
372	Allow:  /foo$
373	Disallow:  /foo
374	
375	# Exercise excessive wildcards
376	# https://bitbucket.org/philip_semanchuk/robotexclusionrulesparser/issues/1
377	User-agent: Rule7TestBot
378	Allow: *****************/****.js
379	
380	"""
381	        self.parser.parse(robots_txt)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:424
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
423	        """Test parsing of the GYM2008-specific directives crawl-delay and sitemap"""
424	        robots_txt = """
425	# robots.txt for http://www.example.com/
426	
427	User-agent: Foobot
428	Disallow:  *
429	Crawl-Delay: 5
430	
431	Sitemap: http://www.example.org/banana.xml
432	
433	User-agent: Somebot
434	Allow: /foo.html
435	Crawl-Delay: .3
436	Allow: /bar.html
437	Disallow: *
438	
439	User-agent: AnotherBot
440	Disallow:  *
441	Sitemap: http://www.example.net/sitemap.xml
442	Sitemap: http://www.example.com/another_sitemap.xml
443	
444	User-agent: CamelBot
445	Disallow: /foo.html
446	Crawl-Delay: go away!
447	"""
448	        self.parser.parse(robots_txt)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:458
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
457	        self.assertFalse(self.parser.is_allowed("AnotherBot", "/foo.html"))
458	        self.assertEqual(self.parser.sitemaps[1], "http://www.example.net/sitemap.xml")
459	        self.assertIsNone(self.parser.get_crawl_delay("CamelBot"))

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:463
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
462	        """Test parsing of malformed robots.txt files"""
463	        robots_txt = """
464	# robots.txt for http://www.example.com/
465	
466	# This is nonsense; UA most come first.
467	Disallow: /
468	User-agent: *
469	
470	# With apologies to Dr. Seuss, this syntax won't act as the author expects.
471	# It will only match UA strings that contain "onebot twobot greenbot bluebot".
472	# To match multiple UAs to a single rule, use multiple "User-agent:" lines.
473	User-agent: onebot twobot greenbot bluebot
474	Disallow: /
475	
476	# Blank lines indicate an end-of-record so the first UA listed here is ignored.
477	User-agent: OneTwoFiveThreeSirBot
478	
479	# Note from Webmaster: add new user-agents below:
480	User-agent: WotBehindTheRabbitBot
481	User-agent: ItIsTheRabbitBot
482	Disallow: /HolyHandGrenade/
483	"""
484	        self.parser.parse(robots_txt)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/test_parser.py:497
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
496	        """Test that user agents are not case sensitive"""
497	        robots_txt = """
498	# robots.txt for http://www.example.com/
499	
500	User-agent: Foobot
501	Disallow: /
502	"""
503	        self.parser.parse(robots_txt)

--------------------------------------------------
>> Issue: [B304:blacklist] socket.socket
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/utils_for_tests.py:30
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b304-b305-ciphers-and-modes
29	    """
30	    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
31	    s.bind(('localhost', 0))

--------------------------------------------------
>> Issue: [B807:close] socket.socket.close
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/utils_for_tests.py:33
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b807_close.html
32	    addr, port = s.getsockname()
33	    s.close()
34	    return port

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/utils_for_tests.py:91
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
90	        if self.path.startswith('/encoding/'):
91	            self._handle_encoding_request()
92	        elif self.path.startswith('/response_code/'):

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/utils_for_tests.py:93
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
92	        elif self.path.startswith('/response_code/'):
93	            self._handle_response_code_request()
94	        elif self.path.startswith('/sleep/'):

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/utils_for_tests.py:95
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
94	        elif self.path.startswith('/sleep/'):
95	            self._handle_sleep_request()
96	        elif self.path.startswith('/expires/'):

--------------------------------------------------
>> Issue: [B825:request] http.client.HTTPConnection.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/utils_for_tests.py:97
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b825_request.html
96	        elif self.path.startswith('/expires/'):
97	            self._handle_expires_request()
98	        elif self.path.startswith('/die_die_die/'):

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/utils_for_tests.py:103
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
102	
103	            kill_thread = threading.Thread(target=kill_server, args=(self.server,))
104	            kill_thread.start()

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/utils_for_tests.py:123
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
122	        with open(filename) as f:
123	            content = f.read().decode('utf-8')
124	

--------------------------------------------------
>> Issue: [B815:write] os.write
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/robotexclusionrulesparser-1.7.1/robotexclusionrulesparser-1.7.1/tests/utils_for_tests.py:128
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b815_write.html
127	        self.end_headers()
128	        self.wfile.write(content)
129	

--------------------------------------------------

Code scanned:
	Total lines of code: 1129
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 62.0
		High: 12.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 73.0
		High: 1.0
Files skipped (0):
