Run started:2025-04-13 00:31:18.001182

Test results:
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/exporters/openvino/__main__.py:265
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
264	                raise ValueError(
265	                    f"Trying to export a {model_type} model, that is a custom or unsupported architecture, but no custom export configuration was passed as `custom_export_configs`. Please refer to https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#custom-export-of-transformers-models for an example on how to export custom models. Please open an issue at https://github.com/huggingface/optimum-intel/issues if you would like the model type {model_type} to be supported natively in the OpenVINO export."
266	                )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/exporters/openvino/__main__.py:278
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
277	            raise ValueError(
278	                f"Asked to export a {model_type} model for the task {task}{autodetected_message}, but the Optimum OpenVINO exporter only supports the tasks {', '.join(model_tasks.keys())} for {model_type}. Please use a supported task. Please open an issue at https://github.com/huggingface/optimum/issues if you would like the task {task} to be supported in the ONNX export for {model_type}."
279	            )

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/exporters/openvino/__main__.py:305
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
304	            trust_remote_code = False
305	        dtype = loading_kwargs.get("torch_dtype")
306	        if isinstance(dtype, str):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/exporters/openvino/convert.py:661
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
660	        raise ValueError(
661	            f"Trying to export a {model_type} model, that is a custom or unsupported architecture, but no custom export configuration was passed as `custom_export_configs`. Please refer to https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#custom-export-of-transformers-models for an example on how to export custom models. Please open an issue at https://github.com/huggingface/optimum-intel/issues if you would like the model type {model_type} to be supported natively in the OpenVINO export."
662	        )

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/exporters/openvino/convert.py:666
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
665	        raise ValueError(
666	            f"model.config.is_encoder_decoder is True and task is `{task}`, which are incompatible. If the task was auto-inferred, please fill a bug report"
667	            f"at https://github.com/huggingface/optimum, if --task was explicitely passed, make sure you selected the right task for the model,"

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/exporters/openvino/model_patcher.py:94
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
93	            COLOR_RED
94	            + f"[WARNING] Stateful models are not supported for Llama, Gemma and GPTBigCode with Transformers "
95	            f"{_transformers_version} and OpenVINO {display_version}. For good performance, consider using a nightly OpenVINO build: "
96	            "https://docs.openvino.ai/2024/get-started/install-openvino.html. For gpt-bigcode and llama models, "

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/neural_compressor/modeling_base.py:59
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
58	
59	MODEL_START_DOCSTRING = r"""
60	    This model check the superclass documentation for the generic methods the
61	    library implements for all its model (such as downloading or saving)
62	    Parameters:
63	        model (`PyTorch model`): is the main class used to run inference.
64	        config (`transformers.PretrainedConfig`): [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
65	            is the Model configuration class with all the parameters of the model.
66	        device (`str`, defaults to `"cpu"`):
67	            The device type for which the model will be optimized for. The resulting compiled model will contains nodes specific to this device.
68	"""
69	
70	
71	class INCModel(OptimizedModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/neural_compressor/modeling_base.py:204
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
203	                    logger.info(
204	                        "The weight only quantized model loading only supports the same format as GPTQ, such as https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ/tree/main."
205	                    )
206	                    _BaseINCAutoModelClass.ORIG_MODEL = cls.auto_model_class

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/neural_compressor/modeling_base.py:225
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
224	            logger.info(
225	                "The quantized model parameters will be saved in the same format as GPTQ, here is the sample model https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ/tree/main for details."
226	            )
227	            model = _weight_only_quantization(

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/neural_compressor/trainer.py:664
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
663	                    logger.info(f"Deleting older checkpoint [{checkpoint}] due to args.save_total_limit")
664	                    shutil.rmtree(checkpoint)
665	

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling.py:64
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
63	
64	MODEL_START_DOCSTRING = r"""
65	    This model inherits from [`optimum.intel.openvino.modeling.OVBaseModel`]. Check the superclass documentation for the generic methods the
66	    library implements for all its model (such as downloading or saving)
67	    Parameters:
68	        model (`openvino.runtime.Model`): is the main class used to run OpenVINO Runtime inference.
69	        config (`transformers.PretrainedConfig`): [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
70	            is the Model configuration class with all the parameters of the model.
71	            Initializing with a config file does not load the weights associated with the model, only the configuration.
72	            Check out the [`~intel.openvino.modeling.OVBaseModel.from_pretrained`] method to load the model weights.
73	        device (`str`, defaults to `"CPU"`):
74	            The device type for which the model will be optimized for. The resulting compiled model will contains nodes specific to this device.
75	        dynamic_shapes (`bool`, defaults to `True`):
76	            All the model's dimension will be set to dynamic when set to `True`. Should be set to `False` for the model to not be dynamically reshaped by default.
77	        ov_config (`Optional[Dict]`, defaults to `None`):
78	            The dictionnary containing the informations related to the model compilation.
79	        compile (`bool`, defaults to `True`):
80	            Disable the model compilation during the loading step when set to `False`.
81	            Can be useful to avoid unnecessary compilation, in the case where the model needs to be statically reshaped, the device modified or if FP16 conversion is enabled.
82	"""
83	
84	INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling.py:84
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
83	
84	INPUTS_DOCSTRING = r"""
85	    Args:
86	        input_ids (`torch.Tensor`):
87	            Indices of input sequence tokens in the vocabulary.
88	            Indices can be obtained using [`AutoTokenizer`](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer).
89	            [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)
90	        attention_mask (`torch.Tensor`), *optional*):
91	            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:
92	            - 1 for tokens that are **not masked**,
93	            - 0 for tokens that are **masked**.
94	            [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)
95	        token_type_ids (`torch.Tensor`, *optional*):
96	            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0, 1]`:
97	            - 1 for tokens that are **sentence A**,
98	            - 0 for tokens that are **sentence B**.
99	            [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)
100	"""
101	
102	IMAGE_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling.py:102
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
101	
102	IMAGE_INPUTS_DOCSTRING = r"""
103	    Args:
104	        pixel_values (`torch.Tensor`):
105	            Pixel values corresponding to the images in the current batch.
106	            Pixel values can be obtained from encoded images using [`AutoFeatureExtractor`](https://huggingface.co/docs/transformers/autoclass_tutorial#autofeatureextractor).
107	"""
108	
109	AUDIO_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling.py:109
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
108	
109	AUDIO_INPUTS_DOCSTRING = r"""
110	    Args:
111	        input_values (`torch.Tensor` of shape `({0})`):
112	            Float values of input raw speech waveform..
113	            Input values can be obtained from audio file loaded into an array using [`AutoFeatureExtractor`](https://huggingface.co/docs/transformers/autoclass_tutorial#autofeatureextractor).
114	"""
115	
116	
117	class OVModel(OVBaseModel):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling.py:469
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
468	
469	IMAGE_CLASSIFICATION_EXAMPLE = r"""
470	    Example of image classification using `transformers.pipelines`:
471	    ```python
472	    >>> from transformers import {processor_class}, pipeline
473	    >>> from optimum.intel import {model_class}
474	
475	    >>> preprocessor = {processor_class}.from_pretrained("{checkpoint}")
476	    >>> model = {model_class}.from_pretrained("{checkpoint}", export=True)
477	    >>> model.reshape(batch_size=1, sequence_length=3, height=224, width=224)
478	    >>> pipe = pipeline("image-classification", model=model, feature_extractor=preprocessor)
479	    >>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
480	    >>> outputs = pipe(url)
481	    ```
482	    This class can also be used with [timm](https://github.com/huggingface/pytorch-image-models)
483	    models hosted on [HuggingFaceHub](https://huggingface.co/timm). Example:
484	    ```python
485	    >>> from transformers import pipeline
486	    >>> from optimum.intel.openvino.modeling_timm import TimmImageProcessor
487	    >>> from optimum.intel import OVModelForImageClassification
488	
489	    >>> model_id = "timm/vit_tiny_patch16_224.augreg_in21k"
490	    >>> preprocessor = TimmImageProcessor.from_pretrained(model_id)
491	    >>> model = OVModelForImageClassification.from_pretrained(model_id, export=True)
492	    >>> pipe = pipeline("image-classification", model=model, feature_extractor=preprocessor)
493	    >>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
494	    >>> outputs = pipe(url)
495	    ```
496	"""
497	
498	
499	@add_start_docstrings(
500	    """
501	    OpenVINO Model with a ImageClassifierOutput for image classification tasks.
502	    """,
503	    MODEL_START_DOCSTRING,
504	)
505	class OVModelForImageClassification(OVModel):

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling_base.py:439
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
438	                with open(refs_file) as f:
439	                    revision = f.read()
440	                model_dir = os.path.join(cached_model_dir, "snapshots", revision)

--------------------------------------------------
>> Issue: [B814:read] os.read
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling_open_clip.py:148
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b814_read.html
147	                with open(refs_file) as f:
148	                    revision = f.read()
149	                model_dir = os.path.join(cached_model_dir, "snapshots", revision)

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling_seq2seq.py:60
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
59	
60	INPUTS_DOCSTRING = r"""
61	    Arguments:
62	        encoder (`openvino.runtime.Model`):
63	            The OpenVINO Runtime model associated to the encoder.
64	        decoder (`openvino.runtime.Model`):
65	            The OpenVINO Runtime model associated to the decoder.
66	        decoder_with_past (`openvino.runtime.Model`):
67	            The OpenVINO Runtime model associated  to the decoder with past key values.
68	        config (`transformers.PretrainedConfig`):
69	            [PretrainedConfig](https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig)
70	            is an instance of the configuration associated to the model. Initializing with a config file does
71	            not load the weights associated with the model, only the configuration.
72	"""
73	
74	ENCODER_INPUTS_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling_seq2seq.py:190
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
189	
190	PIX2STRUCT_EXAMPLE = r"""
191	    Example of pix2struct:
192	
193	    ```python
194	    >>> from transformers import {processor_class}
195	    >>> from optimum.intel import {model_class}
196	    >>> from PIL import Image
197	    >>> import requests
198	
199	    >>> processor = {processor_class}.from_pretrained("{checkpoint}")
200	    >>> model = {model_class}.from_pretrained("{checkpoint}", export=True)
201	
202	    >>> url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/ai2d-demo.jpg"
203	    >>> image = Image.open(requests.get(url, stream=True).raw)
204	    >>> question = "What does the label 15 represent? (1) lava (2) core (3) tunnel (4) ash cloud"
205	    >>> inputs = processor(images=image, text=question, return_tensors="pt")
206	
207	    >>> gen_tokens = model.generate(**inputs)
208	    >>> outputs = processor.batch_decode(gen_tokens, skip_special_tokens=True)
209	    ```
210	"""
211	
212	SPEECH_SEQ2SEQ_MODEL_DOCSTRING = r"""

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling_seq2seq.py:262
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
261	
262	IMAGE_TO_TEXT_EXAMPLE = r"""
263	    Example of text generation:
264	
265	    ```python
266	    >>> from transformers import {processor_class}, {tokenizer_class}
267	    >>> from optimum.intel import {model_class}
268	    >>> from PIL import Image
269	    >>> import requests
270	
271	
272	    >>> processor = {processor_class}.from_pretrained("{checkpoint}")
273	    >>> tokenizer = {tokenizer_class}.from_pretrained("{checkpoint}")
274	    >>> model = {model_class}.from_pretrained("{checkpoint}", export=True)
275	
276	    >>> url = "https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg"
277	    >>> image = Image.open(requests.get(url, stream=True).raw)
278	    >>> inputs = processor(image, return_tensors="pt")
279	
280	    >>> gen_tokens = model.generate(**inputs)
281	    >>> outputs = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)
282	
283	    ```
284	
285	    Example using `transformers.pipeline`:
286	
287	    ```python
288	    >>> from transformers import {processor_class}, {tokenizer_class}, pipeline
289	    >>> from optimum.intel import {model_class}
290	    >>> from PIL import Image
291	    >>> import requests
292	
293	
294	    >>> processor = {processor_class}.from_pretrained("{checkpoint}")
295	    >>> tokenizer = {tokenizer_class}.from_pretrained("{checkpoint}")
296	    >>> model = {model_class}.from_pretrained("{checkpoint}", export=True)
297	
298	    >>> url = "https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg"
299	    >>> image = Image.open(requests.get(url, stream=True).raw)
300	
301	    >>> image_to_text = pipeline("image-to-text", model=model, tokenizer=tokenizer, feature_extractor=processor, image_processor=processor)
302	    >>> pred = image_to_text(image)
303	    ```
304	"""
305	
306	
307	@add_start_docstrings(
308	    """
309	    Sequence-to-sequence model with a language modeling head for OpenVINO inference.
310	    """,
311	    INPUTS_DOCSTRING,
312	)
313	class OVModelForSeq2SeqLM(OVBaseModelForSeq2SeqLM, GenerationMixin):

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/modeling_visual_language.py:1465
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
1464	                    warnings.warn(
1465	                        "You have modified the pretrained model configuration to control generation. This is a"
1466	                        " deprecated strategy to control generation and will be removed in v5."
1467	                        " Please use and modify the model generation configuration (see"
1468	                        " https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )",
1469	                        UserWarning,
1470	                    )
1471	                    self.generation_config = new_generation_config

--------------------------------------------------
>> Issue: [B822:request] requests.request
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/quantization.py:158
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b822_request.html
157	        self.collect_inputs(bound_args["inputs"])
158	        return self.request(*args, **kwargs)
159	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/quantization.py:618
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
617	
618	        self.task = _TASK_ALIASES.get(self.task, self.task)
619	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/quantization.py:781
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
780	            image_url = item[dataset_metadata["inputs"]["image_url"]]
781	            image = Image.open(requests.get(image_url, stream=True).raw)
782	

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/quantization.py:792
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
791	
792	            input_ids = inputs.get("input_ids")
793	            position_ids = torch.arange(input_ids.size(1)).unsqueeze(0).to(input_ids.device)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/quantization.py:916
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
915	
916	        size = diffuser.config.get("sample_size", 64) * self.model.vae_scale_factor
917	        height, width = 2 * (min(size, 512),)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/quantization.py:1181
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1180	    wc_ignored_types = ["Convolution"] if any(op.get_type_name() == "Convolution" for op in model.get_ops()) else []
1181	    wc_config.ignored_scope["types"] = wc_config.ignored_scope.get("types", []) + wc_ignored_types
1182	    compressed_model = _weight_only_quantization(model, wc_config, **kwargs)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/quantization.py:1212
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1211	    if "nncf" in rt_info:
1212	        model_weight_compression_config = rt_info["nncf"].get("weight_compression", None)
1213	        model_quantization_config = rt_info["nncf"].get("quantization", None)

--------------------------------------------------
>> Issue: [B820:get] requests.get
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/quantization.py:1213
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b820_get.html
1212	        model_weight_compression_config = rt_info["nncf"].get("weight_compression", None)
1213	        model_quantization_config = rt_info["nncf"].get("quantization", None)
1214	        if model_weight_compression_config is not None:

--------------------------------------------------
>> Issue: [B836:rmtree] shutil.rmtree
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/trainer.py:799
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b836_rmtree.html
798	                    logger.info(f"Deleting older checkpoint [{checkpoint}] due to args.save_total_limit")
799	                    shutil.rmtree(checkpoint)
800	

--------------------------------------------------
>> Issue: [B837:rmdir] pathlib.Path.rmdir
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/utils.py:365
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b837_rmdir.html
364	            if func is os.rmdir:
365	                os.rmdir(name, dir_fd=dirfd)
366	                return

--------------------------------------------------
>> Issue: [B837:rmdir] pathlib.Path.rmdir
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/utils.py:417
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b837_rmdir.html
416	                try:
417	                    os.rmdir(fullname)
418	                except OSError as err:

--------------------------------------------------
>> Issue: [B837:rmdir] pathlib.Path.rmdir
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/openvino/utils.py:427
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b837_rmdir.html
426	        try:
427	            os.rmdir(path)
428	        except OSError as err:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/utils/import_utils.py:222
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
221	        logger.info(
222	            "OpenVINO Tokenizers is not available. To deploy models in production "
223	            "with C++ code, please follow installation instructions: "
224	            "https://github.com/openvinotoolkit/openvino_tokenizers?tab=readme-ov-file#installation\n"

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/utils/import_utils.py:245
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
244	
245	        if tokenizers_version == "0.0.0.0":
246	            try:

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/utils/import_utils.py:258
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
257	            message += (
258	                "For archive installation of OpenVINO try to build OpenVINO Tokenizers from source: "
259	                "https://github.com/openvinotoolkit/openvino_tokenizers/tree/master?tab=readme-ov-file"
260	                "#build-and-install-from-source"
261	            )
262	            if sys.platform == "linux":
263	                message += (

--------------------------------------------------
>> Issue: [B824:url_found] url_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/utils/import_utils.py:283
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b824_url_found.html
282	            message += (
283	                "pip install --pre -U openvino openvino-tokenizers "
284	                "--extra-index-url https://storage.openvinotoolkit.org/simple/wheels/nightly"
285	            )

--------------------------------------------------
>> Issue: [B823:ip_found] ip_found
   Severity: Medium   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/utils/import_utils.py:402
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b823_ip_found.html
401	
402	    if tokenizers_version == "0.0.0.0":
403	        try:

--------------------------------------------------
>> Issue: [B812:system] os.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/utils/modeling_utils.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b812_system.html
200	    """
201	    if platform.system() != "Linux":
202	        logger.error("bind_cores_for_best_perf: OS not supported, this function can only be run on Linux systems.")

--------------------------------------------------
>> Issue: [B817:system] platform.system
   Severity: High   Confidence: Medium
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/utils/modeling_utils.py:201
   More Info: https://bandit.readthedocs.io/en/latest/plugins/b817_system.html
200	    """
201	    if platform.system() != "Linux":
202	        logger.error("bind_cores_for_best_perf: OS not supported, this function can only be run on Linux systems.")

--------------------------------------------------
>> Issue: [B308:blacklist] platform.system
   Severity: Medium   Confidence: High
   Location: /home/blue/PyPIAgent/Dataset/study/unzip_benign/optimum_intel-1.22.0-py3-none-any/optimum/intel/utils/modeling_utils.py:201
   More Info: https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b308-platform-system
200	    """
201	    if platform.system() != "Linux":
202	        logger.error("bind_cores_for_best_perf: OS not supported, this function can only be run on Linux systems.")

--------------------------------------------------

Code scanned:
	Total lines of code: 24940
	Total lines skipped (#nosec): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0.0
		Low: 0.0
		Medium: 23.0
		High: 18.0
	Total issues (by confidence):
		Undefined: 0.0
		Low: 0.0
		Medium: 40.0
		High: 1.0
Files skipped (0):
