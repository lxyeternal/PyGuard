[
  {
    "metadata": {
      "package_name": "numpy-2.2.4",
      "total_matches": 4,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "depfixer.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/numpy-2.2.4/numpy-2.2.4/vendored-meson/meson/mesonbuild/scripts/depfixer.py",
    "line_number": "82",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "81\t# Elf64_Word\n82\t        self.sh_type = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n83\t# Elf64_Xword",
    "code_snippet": "class SectionHeader(DataSizes):\n    def __init__(self, ifile: T.BinaryIO, ptrsize: int, is_le: bool) -> None:\n        super().__init__(ptrsize, is_le)\n        is_64 = ptrsize == 64\n\n# Elf64_Word\n        self.sh_name = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n# Elf64_Word\n        self.sh_type = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n# Elf64_Xword\n        if is_64:\n            self.sh_flags = struct.unpack(self.XWord, ifile.read(self.XWordSize))[0]\n        else:\n            self.sh_flags = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n# Elf64_Addr\n        self.sh_addr = struct.unpack(self.Addr, ifile.read(self.AddrSize))[0]\n# Elf64_Off\n        self.sh_offset = struct.unpack(self.Off, ifile.read(self.OffSize))[0]\n# Elf64_Xword\n        if is_64:\n            self.sh_size = struct.unpack(self.XWord, ifile.read(self.XWordSize))[0]\n        else:\n            self.sh_size = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n# Elf64_Word\n        self.sh_link = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n# Elf64_Word\n        self.sh_info = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n# Elf64_Xword\n        if is_64:\n            self.sh_addralign = struct.unpack(self.XWord, ifile.read(self.XWordSize))[0]\n        else:\n            self.sh_addralign = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n# Elf64_Xword\n        if is_64:\n            self.sh_entsize = struct.unpack(self.XWord, ifile.read(self.XWordSize))[0]\n        else:\n            self.sh_entsize = struct.unpack(self.Word, ifile.read(self.WordSize))[0]",
    "pattern_analysis": {
      "api_sequence": [
        "ifile.read",
        "struct.unpack",
        "ifile.read",
        "struct.unpack",
        "ifile.read",
        "struct.unpack",
        "ifile.read",
        "struct.unpack",
        "ifile.read",
        "struct.unpack",
        "ifile.read",
        "struct.unpack",
        "ifile.read",
        "struct.unpack",
        "ifile.read",
        "struct.unpack",
        "ifile.read",
        "struct.unpack",
        "ifile.read",
        "struct.unpack"
      ],
      "api_sequence_with_args": [
        "ifile.read(self.WordSize)",
        "struct.unpack(self.Word, ...)",
        "ifile.read(self.WordSize)",
        "struct.unpack(self.Word, ...)",
        "ifile.read(self.XWordSize or self.WordSize)",
        "struct.unpack(self.XWord or self.Word, ...)",
        "ifile.read(self.AddrSize)",
        "struct.unpack(self.Addr, ...)",
        "ifile.read(self.OffSize)",
        "struct.unpack(self.Off, ...)",
        "ifile.read(self.XWordSize or self.WordSize)",
        "struct.unpack(self.XWord or self.Word, ...)",
        "ifile.read(self.WordSize)",
        "struct.unpack(self.Word, ...)",
        "ifile.read(self.WordSize)",
        "struct.unpack(self.Word, ...)",
        "ifile.read(self.XWordSize or self.WordSize)",
        "struct.unpack(self.XWord or self.Word, ...)",
        "ifile.read(self.XWordSize or self.WordSize)",
        "struct.unpack(self.XWord or self.Word, ...)"
      ],
      "mapped_sequence": [
        {
          "api_name": "ifile.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "ifile.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "ifile.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "ifile.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "ifile.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "ifile.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "ifile.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "ifile.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "ifile.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        }
      ],
      "contextual_code": "class SectionHeader(DataSizes):\n    def __init__(self, ifile: T.BinaryIO, ptrsize: int, is_le: bool) -> None:\n        super().__init__(ptrsize, is_le)\n        is_64 = ptrsize == 64\n\n        self.sh_name = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n        self.sh_type = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n        if is_64:\n            self.sh_flags = struct.unpack(self.XWord, ifile.read(self.XWordSize))[0]\n        else:\n            self.sh_flags = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n        self.sh_addr = struct.unpack(self.Addr, ifile.read(self.AddrSize))[0]\n        self.sh_offset = struct.unpack(self.Off, ifile.read(self.OffSize))[0]\n        if is_64:\n            self.sh_size = struct.unpack(self.XWord, ifile.read(self.XWordSize))[0]\n        else:\n            self.sh_size = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n        self.sh_link = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n        self.sh_info = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n        if is_64:\n            self.sh_addralign = struct.unpack(self.XWord, ifile.read(self.XWordSize))[0]\n        else:\n            self.sh_addralign = struct.unpack(self.Word, ifile.read(self.WordSize))[0]\n        if is_64:\n            self.sh_entsize = struct.unpack(self.XWord, ifile.read(self.XWordSize))[0]\n        else:\n            self.sh_entsize = struct.unpack(self.Word, ifile.read(self.WordSize))[0]"
    }
  },
  {
    "pyfile": "xcodebackend.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/numpy-2.2.4/numpy-2.2.4/vendored-meson/meson/mesonbuild/backend/xcodebackend.py",
    "line_number": "186",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "185\t                    else:\n186\t                        ofile.write(indent_level*INDENT + f'{i.key} = ')\n187\t                    i.value.write(ofile, indent_level)",
    "code_snippet": "class PbxDict:\n    def __init__(self) -> None:\n        # This class is a bit weird, because we want to write PBX dicts in\n        # defined order _and_ we want to write intermediate comments also in order.\n        self.keys: T.Set[str] = set()\n        self.items: T.List[T.Union[PbxDictItem, PbxComment]] = []\n\n    def add_item(self, key: str, value: T.Union[PbxArray, PbxDict, str, int], comment: str = '') -> None:\n        assert key not in self.keys\n        item = PbxDictItem(key, value, comment)\n        self.keys.add(key)\n        self.items.append(item)\n\n    def has_item(self, key: str) -> bool:\n        return key in self.keys\n\n    def add_comment(self, comment: PbxComment) -> None:\n        assert isinstance(comment, PbxComment)\n        self.items.append(comment)\n\n    def write(self, ofile: T.TextIO, indent_level: int) -> None:\n        ofile.write('{\n')\n        indent_level += 1\n        for i in self.items:\n            if isinstance(i, PbxComment):\n                i.write(ofile, indent_level)\n            elif isinstance(i, PbxDictItem):\n                if isinstance(i.value, (str, int)):\n                    if i.comment:\n                        ofile.write(indent_level*INDENT + f'{i.key} = {i.value} {i.comment};\\n')\n                    else:\n                        ofile.write(indent_level*INDENT + f'{i.key} = {i.value};\\n')\n                elif isinstance(i.value, PbxDict):\n                    if i.comment:\n                        ofile.write(indent_level*INDENT + f'{i.key} {i.comment} = ')\n                    else:\n                        ofile.write(indent_level*INDENT + f'{i.key} = ')\n                    i.value.write(ofile, indent_level)\n                elif isinstance(i.value, PbxArray):\n                    if i.comment:\n                        ofile.write(indent_level*INDENT + f'{i.key} {i.comment} = ')\n                    else:\n                        ofile.write(indent_level*INDENT + f'{i.key} = ')\n                    i.value.write(ofile, indent_level)\n                else:\n                    print(i)\n                    print(i.key)\n                    print(i.value)\n                    raise RuntimeError('missing code')\n            else:\n                print(i)\n                raise RuntimeError('missing code2')\n\n        indent_level -= 1\n        ofile.write(indent_level*INDENT + '}')\n        if indent_level == 0:\n            ofile.write('\\n')\n        else:\n            ofile.write(';\n')",
    "pattern_analysis": {
      "api_sequence": [
        "ofile.write",
        "isinstance",
        "isinstance",
        "ofile.write",
        "ofile.write",
        "ofile.write",
        "ofile.write",
        "ofile.write",
        "ofile.write",
        "print",
        "print",
        "print",
        "ofile.write",
        "print",
        "ofile.write",
        "ofile.write"
      ],
      "api_sequence_with_args": [
        "ofile.write('{\n')",
        "isinstance(i, PbxComment)",
        "isinstance(i, PbxDictItem)",
        "ofile.write(indent_level*INDENT + f'{i.key} = {i.value} {i.comment};\\n')",
        "ofile.write(indent_level*INDENT + f'{i.key} = {i.value};\\n')",
        "ofile.write(indent_level*INDENT + f'{i.key} {i.comment} = ')",
        "ofile.write(indent_level*INDENT + f'{i.key} = ')",
        "ofile.write(indent_level*INDENT + f'{i.key} {i.comment} = ')",
        "ofile.write(indent_level*INDENT + f'{i.key} = ')",
        "print(i)",
        "print(i.key)",
        "print(i.value)",
        "ofile.write(indent_level*INDENT + '}')",
        "print(i)",
        "ofile.write('\\n')",
        "ofile.write(';\n')"
      ],
      "mapped_sequence": [
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "isinstance",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "isinstance",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "print",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "print",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "print",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "print",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "ofile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        }
      ],
      "contextual_code": "def write(self, ofile: T.TextIO, indent_level: int) -> None:\n    ofile.write('{\n')\n    indent_level += 1\n    for i in self.items:\n        if isinstance(i, PbxComment):\n            i.write(ofile, indent_level)\n        elif isinstance(i, PbxDictItem):\n            if isinstance(i.value, (str, int)):\n                if i.comment:\n                    ofile.write(indent_level*INDENT + f'{i.key} = {i.value} {i.comment};\\n')\n                else:\n                    ofile.write(indent_level*INDENT + f'{i.key} = {i.value};\\n')\n            elif isinstance(i.value, PbxDict):\n                if i.comment:\n                    ofile.write(indent_level*INDENT + f'{i.key} {i.comment} = ')\n                else:\n                    ofile.write(indent_level*INDENT + f'{i.key} = ')\n                i.value.write(ofile, indent_level)\n            elif isinstance(i.value, PbxArray):\n                if i.comment:\n                    ofile.write(indent_level*INDENT + f'{i.key} {i.comment} = ')\n                else:\n                    ofile.write(indent_level*INDENT + f'{i.key} = ')\n                i.value.write(ofile, indent_level)\n            else:\n                print(i)\n                print(i.key)\n                print(i.value)\n                raise RuntimeError('missing code')\n        else:\n            print(i)\n            raise RuntimeError('missing code2')\n\n    indent_level -= 1\n    ofile.write(indent_level*INDENT + '}')\n    if indent_level == 0:\n        ofile.write('\\n')\n    else:\n        ofile.write(';\n')"
    }
  },
  {
    "pyfile": "wrap.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/numpy-2.2.4/numpy-2.2.4/vendored-meson/meson/mesonbuild/wrap/wrap.py",
    "line_number": "276",
    "type_description": "B832:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "275\t            with open(self.get_hashfile(subproject_directory), 'w', encoding='utf-8') as file:\n276\t                file.write(self.wrapfile_hash + '\\n')\n277",
    "code_snippet": "def update_hash_cache(self, subproject_directory: str) -> None:\n    if self.wrapfile_hash:\n        with open(self.get_hashfile(subproject_directory), 'w', encoding='utf-8') as file:\n            file.write(self.wrapfile_hash + '\\n')",
    "pattern_analysis": {
      "api_sequence": [
        "open",
        "file.write"
      ],
      "api_sequence_with_args": [
        "open(self.get_hashfile(subproject_directory), 'w', encoding='utf-8')",
        "file.write(self.wrapfile_hash + '\\n')"
      ],
      "mapped_sequence": [
        {
          "api_name": "open",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "file.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        }
      ],
      "contextual_code": "def update_hash_cache(self, subproject_directory: str) -> None:\n    if self.wrapfile_hash:\n        with open(self.get_hashfile(subproject_directory), 'w', encoding='utf-8') as file:\n            file.write(self.wrapfile_hash + '\\n')"
    }
  },
  {
    "pyfile": "misc_util.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/numpy-2.2.4/numpy-2.2.4/numpy/distutils/misc_util.py",
    "line_number": "28",
    "type_description": "B836:rmtree",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "27\t            try:\n28\t                shutil.rmtree(d)\n29\t            except OSError:",
    "code_snippet": "def clean_up_temporary_directory():\n    if _tmpdirs is not None:\n        for d in _tmpdirs:\n            try:\n                shutil.rmtree(d)\n            except OSError:\n                pass",
    "pattern_analysis": {
      "api_sequence": [
        "shutil.rmtree"
      ],
      "api_sequence_with_args": [
        "shutil.rmtree(d)"
      ],
      "mapped_sequence": [
        {
          "api_name": "shutil.rmtree",
          "id": "delete_directory",
          "description": "Recursively deletes directory and its contents",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        }
      ],
      "contextual_code": "def clean_up_temporary_directory():\n    if _tmpdirs is not None:\n        for d in _tmpdirs:\n            try:\n                shutil.rmtree(d)\n            except OSError:\n                pass"
    }
  }
]