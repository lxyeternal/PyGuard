[
  {
    "metadata": {
      "package_name": "tf_models_nightly-2.20.0.dev20250411-py2.py3-none-any",
      "total_matches": 1,
      "processing_date": "2025-05-18 01:49:40"
    }
  },
  {
    "pyfile": "data_download.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/tf_models_nightly-2.20.0.dev20250411-py2.py3-none-any/official/legacy/transformer/data_download.py",
    "line_number": "205",
    "type_description": "B834:open",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "204\t  logging.info(\"Extracting %s.\", compressed_file)\n205\t  with tarfile.open(compressed_file, \"r:gz\") as corpus_tar:\n206\t    corpus_tar.extractall(path)",
    "code_snippet": "def download_and_extract(path, url, input_filename, target_filename):\n  \"\"\"Extract files from downloaded compressed archive file.\n\n  Args:\n    path: string directory where the files will be downloaded\n    url: url containing the compressed input and target files\n    input_filename: name of file containing data in source language\n    target_filename: name of file containing data in target language\n\n  Returns:\n    Full paths to extracted input and target files.\n\n  Raises:\n    OSError: if the download/extraction fails.\n  \"\"\"\n  # Check if extracted files already exist in path\n  input_file = find_file(path, input_filename)\n  target_file = find_file(path, target_filename)\n  if input_file and target_file:\n    logging.info(\"Already downloaded and extracted %s.\", url)\n    return input_file, target_file\n\n  # Download archive file if it doesn't already exist.\n  compressed_file = download_from_url(path, url)\n\n  # Extract compressed files\n  logging.info(\"Extracting %s.\", compressed_file)\n  with tarfile.open(compressed_file, \"r:gz\") as corpus_tar:\n    corpus_tar.extractall(path)\n\n  # Return file paths of the requested files.\n  input_file = find_file(path, input_filename)\n  target_file = find_file(path, target_filename)\n\n  if input_file and target_file:\n    return input_file, target_file\n\n  raise OSError(\"Download/extraction failed for url %s to path %s\" %\n                (url, path))",
    "pattern_analysis": {
      "api_sequence": [
        "find_file",
        "find_file",
        "download_from_url",
        "tarfile.open",
        "tarfile.TarFile.extractall",
        "find_file",
        "find_file"
      ],
      "api_sequence_with_args": [
        "find_file(path, input_filename)",
        "find_file(path, target_filename)",
        "download_from_url(path, url)",
        "tarfile.open(compressed_file, \"r:gz\")",
        "tarfile.TarFile.extractall(path)",
        "find_file(path, input_filename)",
        "find_file(path, target_filename)"
      ],
      "mapped_sequence": [
        {
          "api_name": "find_file",
          "id": "check_path_exists",
          "description": "Checks if specified path exists in filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "find_file",
          "id": "check_path_exists",
          "description": "Checks if specified path exists in filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "download_from_url",
          "id": "download_file_url",
          "description": "Downloads file from URL to specified local path",
          "first_id": "network_file_transfer",
          "second_id": "file_download",
          "third_id": "url_file_acquisition"
        },
        {
          "api_name": "tarfile.open",
          "id": "open_zip_read",
          "description": "Opens ZIP archive for reading",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "tarfile.TarFile.extractall",
          "id": "extract_zip_files",
          "description": "Extracts all files from ZIP archive to specified directory",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "find_file",
          "id": "check_path_exists",
          "description": "Checks if specified path exists in filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "find_file",
          "id": "check_path_exists",
          "description": "Checks if specified path exists in filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        }
      ],
      "contextual_code": "def download_and_extract(path, url, input_filename, target_filename):\n  # Check if extracted files already exist in path\n  input_file = find_file(path, input_filename)\n  target_file = find_file(path, target_filename)\n  if input_file and target_file:\n    logging.info(\"Already downloaded and extracted %s.\", url)\n    return input_file, target_file\n\n  # Download archive file if it doesn't already exist.\n  compressed_file = download_from_url(path, url)\n\n  # Extract compressed files\n  logging.info(\"Extracting %s.\", compressed_file)\n  with tarfile.open(compressed_file, \"r:gz\") as corpus_tar:\n    corpus_tar.extractall(path)\n\n  # Return file paths of the requested files.\n  input_file = find_file(path, input_filename)\n  target_file = find_file(path, target_filename)\n\n  if input_file and target_file:\n    return input_file, target_file\n\n  raise OSError(\"Download/extraction failed for url %s to path %s\" %\n                (url, path))"
    }
  }
]