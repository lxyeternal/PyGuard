[
  {
    "metadata": {
      "package_name": "boltons-25.0.0",
      "total_matches": 3,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "jsonutils.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/boltons-25.0.0/boltons-25.0.0/boltons/jsonutils.py",
    "line_number": "259",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "258\t                    if verbose and obj_count and obj_count % 100 == 0:\n259\t                        sys.stdout.write('.')\n260\t                        if obj_count % 10000:",
    "code_snippet": "if __name__ == '__main__':\n    def _main():\n        import sys\n        if '-h' in sys.argv or '--help' in sys.argv:\n            print('loads one or more JSON Line files for basic validation.')\n            return\n        verbose = False\n        if '-v' in sys.argv or '--verbose' in sys.argv:\n            verbose = True\n        file_count, obj_count = 0, 0\n        filenames = sys.argv[1:]\n        for filename in filenames:\n            if filename in ('-h', '--help', '-v', '--verbose'):\n                continue\n            file_count += 1\n            with open(filename, 'rb') as file_obj:\n                iterator = JSONLIterator(file_obj)\n                cur_obj_count = 0\n                while 1:\n                    try:\n                        next(iterator)\n                    except ValueError:\n                        print('error reading object #%s around byte %s in %s'\n                              % (cur_obj_count + 1, iterator.cur_byte_pos, filename))\n                        return\n                    except StopIteration:\n                        break\n                    obj_count += 1\n                    cur_obj_count += 1\n                    if verbose and obj_count and obj_count % 100 == 0:\n                        sys.stdout.write('.')\n                        if obj_count % 10000:\n                            sys.stdout.write('%s\\n' % obj_count)\n        if verbose:\n            print('files checked: %s' % file_count)\n            print('objects loaded: %s' % obj_count)\n        return\n\n    _main()",
    "pattern_analysis": {
      "api_sequence": [
        "open",
        "JSONLIterator",
        "next",
        "print",
        "sys.stdout.write",
        "sys.stdout.write",
        "print",
        "print"
      ],
      "api_sequence_with_args": [
        "open(filename, 'rb')",
        "JSONLIterator(file_obj)",
        "next(iterator)",
        "print('error reading object #%s around byte %s in %s' % (cur_obj_count + 1, iterator.cur_byte_pos, filename))",
        "sys.stdout.write('.')",
        "sys.stdout.write('%s\\n' % obj_count)",
        "print('files checked: %s' % file_count)",
        "print('objects loaded: %s' % obj_count)"
      ],
      "mapped_sequence": [
        {
          "api_name": "open",
          "id": "basic_read_operations",
          "description": "ic file opening operations for reading (normal reading, binary reading)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "JSONLIterator",
          "id": "import_dynamic",
          "description": "Dynamically imports specified module",
          "first_id": "code_execution",
          "second_id": "module_management",
          "third_id": "module_importing"
        },
        {
          "api_name": "next",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "print",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "sys.stdout.write",
          "id": "get_stdout_stream",
          "description": "Retrieves standard output stream object",
          "first_id": "persistence_stealth",
          "second_id": "user_interaction",
          "third_id": "interface_control"
        },
        {
          "api_name": "sys.stdout.write",
          "id": "get_stdout_stream",
          "description": "Retrieves standard output stream object",
          "first_id": "persistence_stealth",
          "second_id": "user_interaction",
          "third_id": "interface_control"
        },
        {
          "api_name": "print",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "print",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        }
      ],
      "contextual_code": "for filename in filenames:\n    if filename in ('-h', '--help', '-v', '--verbose'):\n        continue\n    file_count += 1\n    with open(filename, 'rb') as file_obj:\n        iterator = JSONLIterator(file_obj)\n        cur_obj_count = 0\n        while 1:\n            try:\n                next(iterator)\n            except ValueError:\n                print('error reading object #%s around byte %s in %s'\n                      % (cur_obj_count + 1, iterator.cur_byte_pos, filename))\n                return\n            except StopIteration:\n                break\n            obj_count += 1\n            cur_obj_count += 1\n            if verbose and obj_count and obj_count % 100 == 0:\n                sys.stdout.write('.')\n                if obj_count % 10000:\n                    sys.stdout.write('%s\\n' % obj_count)\nif verbose:\n    print('files checked: %s' % file_count)\n    print('objects loaded: %s' % obj_count)"
    }
  },
  {
    "pyfile": "test_ioutils.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/boltons-25.0.0/boltons-25.0.0/tests/test_ioutils.py",
    "line_number": "234",
    "type_description": "B832:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "233\t        a = ioutils.SpooledBytesIO()\n234\t        a.write(b\"I am a!\")\n235\t        b = ioutils.SpooledBytesIO()",
    "code_snippet": "def test_compare_not_equal_instances(self):\n    \"\"\"Make sure instances with different values fail == check.\"\"\"\n    a = ioutils.SpooledBytesIO()\n    a.write(b\"I am a!\")\n    b = ioutils.SpooledBytesIO()\n    b.write(b\"I am b!\")\n    self.assertNotEqual(a, b)",
    "pattern_analysis": {
      "api_sequence": [],
      "api_sequence_with_args": [],
      "mapped_sequence": [],
      "contextual_code": "def test_compare_not_equal_instances(self):\n    \"\"\"Make sure instances with different values fail == check.\"\"\"\n    a = ioutils.SpooledBytesIO()\n    a.write(b\"I am a!\")\n    b = ioutils.SpooledBytesIO()\n    b.write(b\"I am b!\")\n    self.assertNotEqual(a, b)"
    }
  },
  {
    "pyfile": "namedutils.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/boltons-25.0.0/boltons-25.0.0/boltons/namedutils.py",
    "line_number": "204",
    "type_description": "B800:exec_used",
    "severity": "Medium",
    "confidence": "High",
    "original_snippet": "203\t    try:\n204\t        exec(class_definition, namespace)\n205\t    except SyntaxError as e:",
    "code_snippet": "def namedtuple(typename, field_names, verbose=False, rename=False):\n    \"\"\"Returns a new subclass of tuple with named fields.\n\n    >>> Point = namedtuple('Point', ['x', 'y'])\n    >>> Point.__doc__                   # docstring for the new class\n    'Point(x, y)'\n    >>> p = Point(11, y=22)             # instantiate with pos args or keywords\n    >>> p[0] + p[1]                     # indexable like a plain tuple\n    33\n    >>> x, y = p                        # unpack like a regular tuple\n    >>> x, y\n    (11, 22)\n    >>> p.x + p.y                       # fields also accessible by name\n    33\n    >>> d = p._asdict()                 # convert to a dictionary\n    >>> d['x']\n    11\n    >>> Point(**d)                      # convert from a dictionary\n    Point(x=11, y=22)\n    >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields\n    Point(x=100, y=22)\n    \"\"\"\n\n    # Validate the field names.  At the user's option, either generate an error\n    # message or automatically replace the field name with a valid name.\n    if isinstance(field_names, str):\n        field_names = field_names.replace(',', ' ').split()\n    field_names = [str(x) for x in field_names]\n    if rename:\n        seen = set()\n        for index, name in enumerate(field_names):\n            if (not all(c.isalnum() or c == '_' for c in name)\n                or _iskeyword(name)\n                or not name\n                or name[0].isdigit()\n                or name.startswith('_')\n                or name in seen):\n                field_names[index] = '_%d' % index\n            seen.add(name)\n    for name in [typename] + field_names:\n        if not all(c.isalnum() or c == '_' for c in name):\n            raise ValueError('Type names and field names can only contain '\n                             'alphanumeric characters and underscores: %r'\n                             % name)\n        if _iskeyword(name):\n            raise ValueError('Type names and field names cannot be a '\n                             'keyword: %r' % name)\n        if name[0].isdigit():\n            raise ValueError('Type names and field names cannot start with '\n                             'a number: %r' % name)\n    seen = set()\n    for name in field_names:\n        if name.startswith('_') and not rename:\n            raise ValueError('Field names cannot start with an underscore: '\n                             '%r' % name)\n        if name in seen:\n            raise ValueError('Encountered duplicate field name: %r' % name)\n        seen.add(name)\n\n    # Fill-in the class template\n    fmt_kw = {'typename': typename}\n    fmt_kw['field_names'] = tuple(field_names)\n    fmt_kw['num_fields'] = len(field_names)\n    fmt_kw['arg_list'] = repr(tuple(field_names)).replace(\"'\", \"\")[1:-1]\n    fmt_kw['repr_fmt'] = ', '.join(_repr_tmpl.format(name=name)\n                                   for name in field_names)\n    fmt_kw['field_defs'] = '\\n'.join(_imm_field_tmpl.format(index=index, name=name)\n                                     for index, name in enumerate(field_names))\n    class_definition = _namedtuple_tmpl.format(**fmt_kw)\n\n    if verbose:\n        print(class_definition)\n\n    # Execute the template string in a temporary namespace and support\n    # tracing utilities by setting a value for frame.f_globals['__name__']\n    namespace = dict(_itemgetter=_itemgetter,\n                     __name__='namedtuple_%s' % typename,\n                     OrderedDict=OrderedDict,\n                     _property=property,\n                     _tuple=tuple)\n    try:\n        exec(class_definition, namespace)\n    except SyntaxError as e:\n        raise SyntaxError(e.msg + ':\\n' + class_definition)\n    result = namespace[typename]\n\n    # For pickling to work, the __module__ variable needs to be set to the frame\n    # where the named tuple is created.  Bypass this step in environments where\n    # sys._getframe is not defined (Jython for example) or sys._getframe is not\n    # defined for arguments greater than 0 (IronPython).\n    try:\n        frame = _sys._getframe(1)\n        result.__module__ = frame.f_globals.get('__name__', '__main__')\n    except (AttributeError, ValueError):\n        pass\n\n    return result",
    "pattern_analysis": {
      "api_sequence": [
        "isinstance",
        "str",
        "str.replace",
        "str.split",
        "str",
        "all",
        "_iskeyword",
        "str.isdigit",
        "str.startswith",
        "set.add",
        "all",
        "_iskeyword",
        "str.isdigit",
        "set.add",
        "str.startswith",
        "set.add",
        "len",
        "repr",
        "str.replace",
        "str.join",
        "str.format",
        "str.join",
        "str.format",
        "str.format",
        "print",
        "exec",
        "setattr"
      ],
      "api_sequence_with_args": [
        "isinstance(field_names, str)",
        "str(x) for x in field_names",
        "field_names.replace(',', ' ')",
        "field_names.split()",
        "str(x)",
        "all(c.isalnum() or c == '_' for c in name)",
        "_iskeyword(name)",
        "name[0].isdigit()",
        "name.startswith('_')",
        "seen.add(name)",
        "all(c.isalnum() or c == '_' for c in name)",
        "_iskeyword(name)",
        "name[0].isdigit()",
        "seen.add(name)",
        "name.startswith('_')",
        "seen.add(name)",
        "len(field_names)",
        "repr(tuple(field_names))",
        "repr(tuple(field_names)).replace(\"'\", \"\")",
        "', '.join(_repr_tmpl.format(name=name) for name in field_names)",
        "_repr_tmpl.format(name=name)",
        "'\\n'.join(_imm_field_tmpl.format(index=index, name=name) for index, name in enumerate(field_names))",
        "_imm_field_tmpl.format(index=index, name=name)",
        "_namedtuple_tmpl.format(**fmt_kw)",
        "print(class_definition)",
        "exec(class_definition, namespace)",
        "setattr(result, '__module__', frame.f_globals.get('__name__', '__main__'))"
      ],
      "mapped_sequence": [
        {
          "api_name": "isinstance",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "str",
          "id": "encode_string_to_bytes",
          "description": "Encodes string to bytes using default encoding",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "str.replace",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "str.split",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "str",
          "id": "encode_string_to_bytes",
          "description": "Encodes string to bytes using default encoding",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "all",
          "id": "apply_lambda_to_lists",
          "description": "Applies lambda function to elements of two lists",
          "first_id": "data_transformation_processing",
          "second_id": "function_application",
          "third_id": "lambda_application"
        },
        {
          "api_name": "_iskeyword",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "str.isdigit",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "str.startswith",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "set.add",
          "id": "apply_lambda_to_lists",
          "description": "Applies lambda function to elements of two lists",
          "first_id": "data_transformation_processing",
          "second_id": "function_application",
          "third_id": "lambda_application"
        },
        {
          "api_name": "all",
          "id": "apply_lambda_to_lists",
          "description": "Applies lambda function to elements of two lists",
          "first_id": "data_transformation_processing",
          "second_id": "function_application",
          "third_id": "lambda_application"
        },
        {
          "api_name": "_iskeyword",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "str.isdigit",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "set.add",
          "id": "apply_lambda_to_lists",
          "description": "Applies lambda function to elements of two lists",
          "first_id": "data_transformation_processing",
          "second_id": "function_application",
          "third_id": "lambda_application"
        },
        {
          "api_name": "str.startswith",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "set.add",
          "id": "apply_lambda_to_lists",
          "description": "Applies lambda function to elements of two lists",
          "first_id": "data_transformation_processing",
          "second_id": "function_application",
          "third_id": "lambda_application"
        },
        {
          "api_name": "len",
          "id": "apply_lambda_to_lists",
          "description": "Applies lambda function to elements of two lists",
          "first_id": "data_transformation_processing",
          "second_id": "function_application",
          "third_id": "lambda_application"
        },
        {
          "api_name": "repr",
          "id": "serialize_to_json",
          "description": "Serializes Python object to JSON string",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "str.replace",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "str.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "str.format",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "str.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "str.format",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "str.format",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "print",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "exec",
          "id": "exec_python_code",
          "description": "Dynamically executes Python code string",
          "first_id": "code_execution",
          "second_id": "code_evaluation_execution",
          "third_id": "string_execution"
        },
        {
          "api_name": "setattr",
          "id": "set_builtin_attr",
          "description": "Sets attribute on builtins object",
          "first_id": "persistence_stealth",
          "second_id": "stealth_techniques",
          "third_id": "warning_disabling"
        }
      ],
      "contextual_code": "def namedtuple(typename, field_names, verbose=False, rename=False):\n    if isinstance(field_names, str):\n        field_names = field_names.replace(',', ' ').split()\n    field_names = [str(x) for x in field_names]\n    if rename:\n        seen = set()\n        for index, name in enumerate(field_names):\n            if (not all(c.isalnum() or c == '_' for c in name)\n                or _iskeyword(name)\n                or not name\n                or name[0].isdigit()\n                or name.startswith('_')\n                or name in seen):\n                field_names[index] = '_%d' % index\n            seen.add(name)\n    for name in [typename] + field_names:\n        if not all(c.isalnum() or c == '_' for c in name):\n            raise ValueError('Type names and field names can only contain '\n                             'alphanumeric characters and underscores: %r'\n                             % name)\n        if _iskeyword(name):\n            raise ValueError('Type names and field names cannot be a '\n                             'keyword: %r' % name)\n        if name[0].isdigit():\n            raise ValueError('Type names and field names cannot start with '\n                             'a number: %r' % name)\n    seen = set()\n    for name in field_names:\n        if name.startswith('_') and not rename:\n            raise ValueError('Field names cannot start with an underscore: '\n                             '%r' % name)\n        if name in seen:\n            raise ValueError('Encountered duplicate field name: %r' % name)\n        seen.add(name)\n    fmt_kw = {'typename': typename}\n    fmt_kw['field_names'] = tuple(field_names)\n    fmt_kw['num_fields'] = len(field_names)\n    fmt_kw['arg_list'] = repr(tuple(field_names)).replace(\"'\", \"\")[1:-1]\n    fmt_kw['repr_fmt'] = ', '.join(_repr_tmpl.format(name=name)\n                                   for name in field_names)\n    fmt_kw['field_defs'] = '\\n'.join(_imm_field_tmpl.format(index=index, name=name)\n                                     for index, name in enumerate(field_names))\n    class_definition = _namedtuple_tmpl.format(**fmt_kw)\n    if verbose:\n        print(class_definition)\n    namespace = dict(_itemgetter=_itemgetter,\n                     __name__='namedtuple_%s' % typename,\n                     OrderedDict=OrderedDict,\n                     _property=property,\n                     _tuple=tuple)\n    try:\n        exec(class_definition, namespace)\n    except SyntaxError as e:\n        raise SyntaxError(e.msg + ':\\n' + class_definition)\n    result = namespace[typename]\n    try:\n        frame = _sys._getframe(1)\n        result.__module__ = frame.f_globals.get('__name__', '__main__')\n    except (AttributeError, ValueError):\n        pass\n    return result"
    }
  }
]