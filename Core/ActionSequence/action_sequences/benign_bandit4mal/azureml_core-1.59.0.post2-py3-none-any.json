[
  {
    "metadata": {
      "package_name": "azureml_core-1.59.0.post2-py3-none-any",
      "total_matches": 2,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "operations.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/azureml_core-1.59.0.post2-py3-none-any/azureml/_vendor/azure_cli_core/extension/operations.py",
    "line_number": "279",
    "type_description": "B820:get",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "278\t        ext_name = azext_metadata.get('name')\n279\t        ext_version = azext_metadata.get('version')\n280\t        min_max_msgs = [",
    "code_snippet": "def check_version_compatibility(azext_metadata):\n    is_compatible, cli_core_version, min_required, max_required, min_ext_required = ext_compat_with_cli(azext_metadata)\n    # logger.debug(\"Extension compatibility result: is_compatible=%s cli_core_version=%s min_required=%s \"\n    #              \"max_required=%s\", is_compatible, cli_core_version, min_required, max_required)\n    if not is_compatible:\n        ext_name = azext_metadata.get('name')\n        ext_version = azext_metadata.get('version')\n        min_max_msgs = [\n            f\"The '{ext_name}' extension version {ext_version} is not compatible with your current CLI core version {cli_core_version}.\"\n        ]\n        if min_ext_required:\n            min_max_msgs.append(f\"This CLI core requires a min of {min_ext_required} for the '{ext_name}' extension.\")\n            min_max_msgs.append(f\"Please run 'az extension update -n {ext_name}' to update it.\")\n        elif min_required and max_required:\n            min_max_msgs.append(f'This extension requires a min of {min_required} and max of {max_required} CLI core.')\n            min_max_msgs.append(\"Please run 'az upgrade' to upgrade to a compatible version.\")\n        elif min_required:\n            min_max_msgs.append(f'This extension requires a min of {min_required} CLI core.')\n            min_max_msgs.append(\"Please run 'az upgrade' to upgrade to a compatible version.\")\n        elif max_required:\n            min_max_msgs.append(f'This extension requires a max of {max_required} CLI core.')\n            # we do not want users to downgrade CLI core version, so we suggest updating the extension in this case\n            min_max_msgs.append(f\"Please run 'az extension update -n {ext_name}' to update the extension.\")\n\n        raise AzureMLException(\"\\n\".join(min_max_msgs))",
    "pattern_analysis": {
      "api_sequence": [
        "ext_compat_with_cli",
        "azext_metadata.get",
        "azext_metadata.get",
        "AzureMLException"
      ],
      "api_sequence_with_args": [
        "ext_compat_with_cli(azext_metadata)",
        "azext_metadata.get('name')",
        "azext_metadata.get('version')",
        "AzureMLException(\"\\n\".join(min_max_msgs))"
      ],
      "mapped_sequence": [
        {
          "api_name": "ext_compat_with_cli",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "azext_metadata.get",
          "id": "deserialize_from_json",
          "description": "Deserializes JSON string to Python object",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "azext_metadata.get",
          "id": "deserialize_from_json",
          "description": "Deserializes JSON string to Python object",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "AzureMLException",
          "id": "log_error",
          "description": "Logs error message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        }
      ],
      "contextual_code": "def check_version_compatibility(azext_metadata):\n    is_compatible, cli_core_version, min_required, max_required, min_ext_required = ext_compat_with_cli(azext_metadata)\n    if not is_compatible:\n        ext_name = azext_metadata.get('name')\n        ext_version = azext_metadata.get('version')\n        min_max_msgs = [\n            f\"The '{ext_name}' extension version {ext_version} is not compatible with your current CLI core version {cli_core_version}.\"\n        ]\n        if min_ext_required:\n            min_max_msgs.append(f\"This CLI core requires a min of {min_ext_required} for the '{ext_name}' extension.\")\n            min_max_msgs.append(f\"Please run 'az extension update -n {ext_name}' to update it.\")\n        elif min_required and max_required:\n            min_max_msgs.append(f'This extension requires a min of {min_required} and max of {max_required} CLI core.')\n            min_max_msgs.append(\"Please run 'az upgrade' to upgrade to a compatible version.\")\n        elif min_required:\n            min_max_msgs.append(f'This extension requires a min of {min_required} CLI core.')\n            min_max_msgs.append(\"Please run 'az upgrade' to upgrade to a compatible version.\")\n        elif max_required:\n            min_max_msgs.append(f'This extension requires a max of {max_required} CLI core.')\n            min_max_msgs.append(f\"Please run 'az extension update -n {ext_name}' to update the extension.\")\n\n        raise AzureMLException(\"\\n\".join(min_max_msgs))"
    }
  },
  {
    "pyfile": "datafile.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/azureml_core-1.59.0.post2-py3-none-any/azureml/_vendor/azure_storage/blob/_shared/avro/datafile.py",
    "line_number": "210",
    "type_description": "B816:decompress",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "209\t            # \"raw\" (no zlib headers) decompression.  See zlib.h.\n210\t            uncompressed = zlib.decompress(data, -15)\n211\t            self._datum_decoder = avro_io.BinaryDecoder(io.BytesIO(uncompressed))",
    "code_snippet": "def _read_block_header(self):\n    self._block_count = self.raw_decoder.read_long()\n    if self.codec == \"null\":\n        # Skip a long; we don't need to use the length.\n        self.raw_decoder.skip_long()\n        self._datum_decoder = self._raw_decoder\n    elif self.codec == 'deflate':\n        # Compressed data is stored as (length, data), which\n        # corresponds to how the \"bytes\" type is encoded.\n        data = self.raw_decoder.read_bytes()\n        # -15 is the log of the window size; negative indicates\n        # \"raw\" (no zlib headers) decompression.  See zlib.h.\n        uncompressed = zlib.decompress(data, -15)\n        self._datum_decoder = avro_io.BinaryDecoder(io.BytesIO(uncompressed))\n    else:\n        raise DataFileException(\"Unknown codec: %r\" % self.codec)",
    "pattern_analysis": {
      "api_sequence": [
        "self.raw_decoder.read_long",
        "self.raw_decoder.skip_long",
        "self.raw_decoder.read_bytes",
        "zlib.decompress",
        "io.BytesIO",
        "avro_io.BinaryDecoder"
      ],
      "api_sequence_with_args": [
        "self.raw_decoder.read_long()",
        "self.raw_decoder.skip_long()",
        "self.raw_decoder.read_bytes()",
        "zlib.decompress(data, -15)",
        "io.BytesIO(uncompressed)",
        "avro_io.BinaryDecoder(io.BytesIO(uncompressed))"
      ],
      "mapped_sequence": [
        {
          "api_name": "self.raw_decoder.read_long",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "self.raw_decoder.skip_long",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "self.raw_decoder.read_bytes",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "zlib.decompress",
          "id": "decompress_data_zlib",
          "description": "Decompresses zlib-compressed data",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "compression_decompression"
        },
        {
          "api_name": "io.BytesIO",
          "id": "create_memory_bytes",
          "description": "Creates in-memory bytes buffer from encoded string",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "avro_io.BinaryDecoder",
          "id": "open_image_buffer",
          "description": "Opens image from in-memory bytes buffer",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        }
      ],
      "contextual_code": "def _read_block_header(self):\n    self._block_count = self.raw_decoder.read_long()\n    if self.codec == \"null\":\n        self.raw_decoder.skip_long()\n        self._datum_decoder = self._raw_decoder\n    elif self.codec == 'deflate':\n        data = self.raw_decoder.read_bytes()\n        uncompressed = zlib.decompress(data, -15)\n        self._datum_decoder = avro_io.BinaryDecoder(io.BytesIO(uncompressed))\n    else:\n        raise DataFileException(\"Unknown codec: %r\" % self.codec)"
    }
  }
]