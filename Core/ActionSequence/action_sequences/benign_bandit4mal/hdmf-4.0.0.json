[
  {
    "metadata": {
      "package_name": "hdmf-4.0.0",
      "total_matches": 2,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "test_io_hdf5_h5tools.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/hdmf-4.0.0/hdmf-4.0.0/tests/unit/test_io_hdf5_h5tools.py",
    "line_number": "1757",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1756\t        with HDF5IO(self.path, manager=get_foo_buildmanager(), mode='r') as io:\n1757\t            read_foofile = io.read()\n1758\t            self.assertListEqual(self.foofile2.buckets['bucket2'].foos['foo2'].my_data,",
    "code_snippet": "def test_write_w(self):\n    # mode 'w' should overwrite contents of file\n    with HDF5IO(self.path, manager=get_foo_buildmanager(), mode='w') as io:\n        io.write(self.foofile2)\n\n    with HDF5IO(self.path, manager=get_foo_buildmanager(), mode='r') as io:\n        read_foofile = io.read()\n        self.assertListEqual(self.foofile2.buckets['bucket2'].foos['foo2'].my_data,\n                             read_foofile.buckets['bucket2'].foos['foo2'].my_data[:].tolist())",
    "pattern_analysis": {
      "api_sequence": [
        "HDF5IO",
        "get_foo_buildmanager",
        "HDF5IO.write",
        "HDF5IO",
        "get_foo_buildmanager",
        "HDF5IO.read"
      ],
      "api_sequence_with_args": [
        "HDF5IO(self.path, manager=get_foo_buildmanager(), mode='w')",
        "get_foo_buildmanager()",
        "HDF5IO.write(self.foofile2)",
        "HDF5IO(self.path, manager=get_foo_buildmanager(), mode='r')",
        "get_foo_buildmanager()",
        "HDF5IO.read()"
      ],
      "mapped_sequence": [
        {
          "api_name": "HDF5IO",
          "id": "combined_mode_operations",
          "description": "Combined mode file opening operations (read-write mode, append mode, etc.)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "get_foo_buildmanager",
          "id": "init_parent_class",
          "description": "Initializes parent class with provided arguments",
          "first_id": "code_execution",
          "second_id": "object_initialization",
          "third_id": "class_initialization"
        },
        {
          "api_name": "HDF5IO.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "HDF5IO",
          "id": "basic_read_operations",
          "description": "ic file opening operations for reading (normal reading, binary reading)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "get_foo_buildmanager",
          "id": "init_parent_class",
          "description": "Initializes parent class with provided arguments",
          "first_id": "code_execution",
          "second_id": "object_initialization",
          "third_id": "class_initialization"
        },
        {
          "api_name": "HDF5IO.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        }
      ],
      "contextual_code": "def test_write_w(self):\n    # mode 'w' should overwrite contents of file\n    with HDF5IO(self.path, manager=get_foo_buildmanager(), mode='w') as io:\n        io.write(self.foofile2)\n\n    with HDF5IO(self.path, manager=get_foo_buildmanager(), mode='r') as io:\n        read_foofile = io.read()\n        self.assertListEqual(self.foofile2.buckets['bucket2'].foos['foo2'].my_data,\n                             read_foofile.buckets['bucket2'].foos['foo2'].my_data[:].tolist())"
    }
  },
  {
    "pyfile": "test_io_hdf5_h5tools.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/hdmf-4.0.0/hdmf-4.0.0/tests/unit/test_io_hdf5_h5tools.py",
    "line_number": "1451",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1450\t        with HDF5IO(self.path1, mode='a', manager=get_foo_buildmanager()) as new_io3:\n1451\t            new_io3.read()\n1452",
    "code_snippet": "    def test_close_linked_files_auto(self):\n        \"\"\"Test closing a file with close_links=True (default).\n        \"\"\"\n        # Create the first file\n        foo1 = Foo('foo1', [0, 1, 2, 3, 4], \"I am foo1\", 17, 3.14)\n        bucket1 = FooBucket('bucket1', [foo1])\n        foofile1 = FooFile(buckets=[bucket1])\n\n        # Write the first file\n        with HDF5IO(self.path1, mode='w', manager=get_foo_buildmanager()) as io:\n            io.write(foofile1)\n\n        # Create the second file\n        manager = get_foo_buildmanager()  # use the same manager for read and write so that links work\n        with HDF5IO(self.path1, mode='r', manager=manager) as read_io:\n            read_foofile1 = read_io.read()\n            foofile2 = FooFile(foo_link=read_foofile1.buckets['bucket1'].foos['foo1'])  # cross-file link\n\n            # Write the second file\n            with HDF5IO(self.path2, mode='w', manager=manager) as write_io:\n                write_io.write(foofile2)\n\n        with HDF5IO(self.path2, mode='a', manager=get_foo_buildmanager()) as new_io1:\n            read_foofile2 = new_io1.read()  # keep reference to container in memory\n\n        self.assertFalse(read_foofile2.foo_link.my_data)\n\n        # should be able to reopen both files\n        with HDF5IO(self.path1, mode='a', manager=get_foo_buildmanager()) as new_io3:\n            new_io3.read()\n",
    "pattern_analysis": {
      "api_sequence": [
        "HDF5IO",
        "HDF5IO.write",
        "HDF5IO",
        "HDF5IO.read",
        "HDF5IO",
        "HDF5IO.write",
        "HDF5IO",
        "HDF5IO.read",
        "HDF5IO",
        "HDF5IO.read"
      ],
      "api_sequence_with_args": [
        "HDF5IO(self.path1, mode='w', manager=get_foo_buildmanager())",
        "HDF5IO.write(foofile1)",
        "HDF5IO(self.path1, mode='r', manager=manager)",
        "HDF5IO.read()",
        "HDF5IO(self.path2, mode='w', manager=manager)",
        "HDF5IO.write(foofile2)",
        "HDF5IO(self.path2, mode='a', manager=get_foo_buildmanager())",
        "HDF5IO.read()",
        "HDF5IO(self.path1, mode='a', manager=get_foo_buildmanager())",
        "HDF5IO.read()"
      ],
      "mapped_sequence": [
        {
          "api_name": "HDF5IO",
          "id": "combined_mode_operations",
          "description": "Combined mode file opening operations (read-write mode, append mode, etc.)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "HDF5IO.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "HDF5IO",
          "id": "basic_read_operations",
          "description": "ic file opening operations for reading (normal reading, binary reading)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "HDF5IO.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "HDF5IO",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "HDF5IO.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "HDF5IO",
          "id": "combined_mode_operations",
          "description": "Combined mode file opening operations (read-write mode, append mode, etc.)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "HDF5IO.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "HDF5IO",
          "id": "combined_mode_operations",
          "description": "Combined mode file opening operations (read-write mode, append mode, etc.)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "HDF5IO.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        }
      ],
      "contextual_code": "        # Write the first file\n        with HDF5IO(self.path1, mode='w', manager=get_foo_buildmanager()) as io:\n            io.write(foofile1)\n\n        # Create the second file\n        manager = get_foo_buildmanager()  # use the same manager for read and write so that links work\n        with HDF5IO(self.path1, mode='r', manager=manager) as read_io:\n            read_foofile1 = read_io.read()\n            foofile2 = FooFile(foo_link=read_foofile1.buckets['bucket1'].foos['foo1'])  # cross-file link\n\n            # Write the second file\n            with HDF5IO(self.path2, mode='w', manager=manager) as write_io:\n                write_io.write(foofile2)\n\n        with HDF5IO(self.path2, mode='a', manager=get_foo_buildmanager()) as new_io1:\n            read_foofile2 = new_io1.read()  # keep reference to container in memory\n\n        # should be able to reopen both files\n        with HDF5IO(self.path1, mode='a', manager=get_foo_buildmanager()) as new_io3:\n            new_io3.read()"
    }
  }
]