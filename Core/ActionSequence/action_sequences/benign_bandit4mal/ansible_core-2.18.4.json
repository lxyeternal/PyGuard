[
  {
    "metadata": {
      "package_name": "ansible_core-2.18.4",
      "total_matches": 3,
      "processing_date": "2025-05-18 01:49:40"
    }
  },
  {
    "pyfile": "payload.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/ansible_core-2.18.4/ansible_core-2.18.4/test/lib/ansible_test/_internal/payload.py",
    "line_number": "178",
    "type_description": "B834:open",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "177\n178\t    with tarfile.open(dst_path, mode='w:gz', compresslevel=4, format=tarfile.GNU_FORMAT) as tar:\n179\t        for src, dst in files:",
    "code_snippet": "def create_payload(args: CommonConfig, dst_path: str) -> None:\n    \"\"\"Create a payload for delegation.\"\"\"\n    if args.explain:\n        return\n\n    files = list(data_context().ansible_source)\n    permissions: dict[str, int] = {}\n    filters: dict[str, t.Callable[[tarfile.TarInfo], t.Optional[tarfile.TarInfo]]] = {}\n\n    # Exclude vendored files from the payload.\n    # They may not be compatible with the delegated environment.\n    files = [\n        (abs_path, rel_path) for abs_path, rel_path in files\n        if not rel_path.startswith('lib/ansible/_vendor/')\n        or rel_path == 'lib/ansible/_vendor/__init__.py'\n    ]\n\n    def apply_permissions(tar_info: tarfile.TarInfo, mode: int) -> t.Optional[tarfile.TarInfo]:\n        \"\"\"\n        Apply the specified permissions to the given file.\n        Existing file type bits are preserved.\n        \"\"\"\n        tar_info.mode &= ~(stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n        tar_info.mode |= mode\n\n        return tar_info\n\n    def make_executable(tar_info: tarfile.TarInfo) -> t.Optional[tarfile.TarInfo]:\n        \"\"\"\n        Make the given file executable and readable by all, and writeable by the owner.\n        Existing file type bits are preserved.\n        This ensures consistency of test results when using unprivileged users.\n        \"\"\"\n        return apply_permissions(\n            tar_info,\n            stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH |\n            stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH |\n            stat.S_IWUSR\n        )  # fmt: skip\n\n    def make_non_executable(tar_info: tarfile.TarInfo) -> t.Optional[tarfile.TarInfo]:\n        \"\"\"\n        Make the given file readable by all, and writeable by the owner.\n        Existing file type bits are preserved.\n        This ensures consistency of test results when using unprivileged users.\n        \"\"\"\n        return apply_permissions(\n            tar_info,\n            stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH |\n            stat.S_IWUSR\n        )  # fmt: skip\n\n    def detect_permissions(tar_info: tarfile.TarInfo) -> t.Optional[tarfile.TarInfo]:\n        \"\"\"\n        Detect and apply the appropriate permissions for a file.\n        Existing file type bits are preserved.\n        This ensures consistency of test results when using unprivileged users.\n        \"\"\"\n        if tar_info.path.startswith('ansible/'):\n            mode = permissions.get(os.path.relpath(tar_info.path, 'ansible'))\n        elif data_context().content.collection and is_subdir(tar_info.path, data_context().content.collection.directory):\n            mode = permissions.get(os.path.relpath(tar_info.path, data_context().content.collection.directory))\n        else:\n            mode = None\n\n        if mode:\n            tar_info = apply_permissions(tar_info, mode)\n        elif tar_info.mode & (stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH):\n            # If any execute bit is set, treat the file as executable.\n            # This ensures that sanity tests which check execute bits behave correctly.\n            tar_info = make_executable(tar_info)\n        else:\n            tar_info = make_non_executable(tar_info)\n\n        return tar_info\n\n    if not ANSIBLE_SOURCE_ROOT:\n        # reconstruct the bin directory which is not available when running from an ansible install\n        files.extend(create_temporary_bin_files(args))\n        filters.update(dict((os.path.join('ansible', path[3:]), make_executable) for path in ANSIBLE_BIN_SYMLINK_MAP.values() if path.startswith('../')))\n\n    if not data_context().content.is_ansible:\n        # exclude unnecessary files when not testing ansible itself\n        files = [f for f in files if\n                 is_subdir(f[1], 'bin/') or\n                 is_subdir(f[1], 'lib/ansible/') or\n                 is_subdir(f[1], 'test/lib/ansible_test/')]\n\n        if not isinstance(args, (ShellConfig, IntegrationConfig)):\n            # exclude built-in ansible modules when they are not needed\n            files = [f for f in files if not is_subdir(f[1], 'lib/ansible/modules/') or f[1] == 'lib/ansible/modules/__init__.py']\n\n        collection_layouts = data_context().create_collection_layouts()\n\n        content_files: list[tuple[str, str]] = []\n        extra_files: list[tuple[str, str]] = []\n\n        for layout in collection_layouts:\n            if layout == data_context().content:\n                # include files from the current collection (layout.collection.directory will be added later)\n                content_files.extend((os.path.join(layout.root, path), path) for path in data_context().content.all_files())\n            else:\n                # include files from each collection in the same collection root as the content being tested\n                extra_files.extend((os.path.join(layout.root, path), os.path.join(layout.collection.directory, path)) for path in layout.all_files())\n    else:\n        # when testing ansible itself the ansible source is the content\n        content_files = files\n        # there are no extra files when testing ansible itself\n        extra_files = []\n\n    payload_config = PayloadConfig(\n        files=content_files,\n        permissions=permissions,\n    )\n\n    for callback in data_context().payload_callbacks:\n        # execute callbacks only on the content paths\n        # this is done before placing them in the appropriate subdirectory (see below)\n        callback(payload_config)\n\n    # place ansible source files under the 'ansible' directory on the delegated host\n    files = [(src, os.path.join('ansible', dst)) for src, dst in files]\n\n    if data_context().content.collection:\n        # place collection files under the 'ansible_collections/{namespace}/{collection}' directory on the delegated host\n        files.extend((src, os.path.join(data_context().content.collection.directory, dst)) for src, dst in content_files)\n        # extra files already have the correct destination path\n        files.extend(extra_files)\n\n    # maintain predictable file order\n    files = sorted(set(files))\n\n    display.info('Creating a payload archive containing %d files...' % len(files), verbosity=1)\n\n    start = time.time()\n\n    with tarfile.open(dst_path, mode='w:gz', compresslevel=4, format=tarfile.GNU_FORMAT) as tar:\n        for src, dst in files:\n            display.info('%s -> %s' % (src, dst), verbosity=4)\n            tar.add(src, dst, filter=filters.get(dst, detect_permissions))\n\n    duration = time.time() - start\n    payload_size_bytes = os.path.getsize(dst_path)\n\n    display.info('Created a %d byte payload archive containing %d files in %d seconds.' % (payload_size_bytes, len(files), duration), verbosity=1)",
    "pattern_analysis": {
      "api_sequence": [
        "data_context",
        "data_context",
        "os.path.relpath",
        "os.path.relpath",
        "os.path.relpath",
        "os.path.relpath",
        "os.path.join",
        "os.path.join",
        "os.path.join",
        "os.path.join",
        "os.path.join",
        "os.path.join",
        "os.path.join",
        "os.path.getsize",
        "tarfile.open",
        "tarfile.TarFile.add",
        "time.time",
        "time.time"
      ],
      "api_sequence_with_args": [
        "data_context()",
        "data_context().content.collection",
        "os.path.relpath(tar_info.path, 'ansible')",
        "os.path.relpath(tar_info.path, data_context().content.collection.directory)",
        "os.path.relpath(tar_info.path, 'ansible')",
        "os.path.relpath(tar_info.path, data_context().content.collection.directory)",
        "os.path.join('ansible', dst)",
        "os.path.join(layout.root, path)",
        "os.path.join(layout.collection.directory, path)",
        "os.path.join('ansible', dst)",
        "os.path.join(data_context().content.collection.directory, dst)",
        "os.path.join(layout.root, path)",
        "os.path.join(layout.collection.directory, path)",
        "os.path.getsize(dst_path)",
        "tarfile.open(dst_path, mode='w:gz', compresslevel=4, format=tarfile.GNU_FORMAT)",
        "tar.add(src, dst, filter=filters.get(dst, detect_permissions))",
        "time.time()",
        "time.time() - start"
      ],
      "mapped_sequence": [
        {
          "api_name": "data_context",
          "id": "import_dynamic",
          "description": "Dynamically imports specified module",
          "first_id": "code_execution",
          "second_id": "module_management",
          "third_id": "module_importing"
        },
        {
          "api_name": "data_context",
          "id": "import_dynamic",
          "description": "Dynamically imports specified module",
          "first_id": "code_execution",
          "second_id": "module_management",
          "third_id": "module_importing"
        },
        {
          "api_name": "os.path.relpath",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.relpath",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.relpath",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.relpath",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.getsize",
          "id": "get_disk_usage",
          "description": "Retrieves disk usage statistics (total, used, free) for given path",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "system_resource_information"
        },
        {
          "api_name": "tarfile.open",
          "id": "open_zip_write",
          "description": "Opens ZIP archive for writing",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "tarfile.TarFile.add",
          "id": "add_file_zip",
          "description": "Adds file to ZIP archive with specified archive name",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "time.time",
          "id": "get_current_time",
          "description": "Returns current time in seconds since epoch",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "time_operations"
        },
        {
          "api_name": "time.time",
          "id": "get_current_time",
          "description": "Returns current time in seconds since epoch",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "time_operations"
        }
      ],
      "contextual_code": "def create_payload(args: CommonConfig, dst_path: str) -> None:\n    if args.explain:\n        return\n\n    files = list(data_context().ansible_source)\n    ...\n    def detect_permissions(tar_info: tarfile.TarInfo) -> t.Optional[tarfile.TarInfo]:\n        if tar_info.path.startswith('ansible/'):\n            mode = permissions.get(os.path.relpath(tar_info.path, 'ansible'))\n        elif data_context().content.collection and is_subdir(tar_info.path, data_context().content.collection.directory):\n            mode = permissions.get(os.path.relpath(tar_info.path, data_context().content.collection.directory))\n        else:\n            mode = None\n        ...\n    ...\n    files = [(src, os.path.join('ansible', dst)) for src, dst in files]\n    if data_context().content.collection:\n        files.extend((src, os.path.join(data_context().content.collection.directory, dst)) for src, dst in content_files)\n        files.extend(extra_files)\n    ...\n    files = sorted(set(files))\n    ...\n    start = time.time()\n    with tarfile.open(dst_path, mode='w:gz', compresslevel=4, format=tarfile.GNU_FORMAT) as tar:\n        for src, dst in files:\n            tar.add(src, dst, filter=filters.get(dst, detect_permissions))\n    duration = time.time() - start\n    payload_size_bytes = os.path.getsize(dst_path)"
    }
  },
  {
    "pyfile": "__init__.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/ansible_core-2.18.4/ansible_core-2.18.4/lib/ansible/galaxy/collection/__init__.py",
    "line_number": "1604",
    "type_description": "B834:open",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1603\t    try:\n1604\t        with tarfile.open(b_coll_targz_path, mode='r') as collection_tar:\n1605\t            # Verify the signature on the MANIFEST.json before extracting anything else",
    "code_snippet": "def install_artifact(b_coll_targz_path, b_collection_path, b_temp_path, signatures, keyring, required_signature_count, ignore_signature_errors):\n    \"\"\"Install a collection from tarball under a given path.\n\n    :param b_coll_targz_path: Collection tarball to be installed.\n    :param b_collection_path: Collection dirs layout path.\n    :param b_temp_path: Temporary dir path.\n    :param signatures: frozenset of signatures to verify the MANIFEST.json\n    :param keyring: The keyring used during GPG verification\n    :param required_signature_count: The number of signatures that must successfully verify the collection\n    :param ignore_signature_errors: GPG errors to ignore during signature verification\n    \"\"\"\n    try:\n        with tarfile.open(b_coll_targz_path, mode='r') as collection_tar:\n            # Verify the signature on the MANIFEST.json before extracting anything else\n            _extract_tar_file(collection_tar, MANIFEST_FILENAME, b_collection_path, b_temp_path)\n\n            if keyring is not None:\n                manifest_file = os.path.join(to_text(b_collection_path, errors='surrogate_or_strict'), MANIFEST_FILENAME)\n                verify_artifact_manifest(manifest_file, signatures, keyring, required_signature_count, ignore_signature_errors)\n\n            files_member_obj = collection_tar.getmember('FILES.json')\n            with _tarfile_extract(collection_tar, files_member_obj) as (dummy, files_obj):\n                files = json.loads(to_text(files_obj.read(), errors='surrogate_or_strict'))\n\n            _extract_tar_file(collection_tar, 'FILES.json', b_collection_path, b_temp_path)\n\n            for file_info in files['files']:\n                file_name = file_info['name']\n                if file_name == '.':\n                    continue\n\n                if file_info['ftype'] == 'file':\n                    _extract_tar_file(collection_tar, file_name, b_collection_path, b_temp_path,\n                                      expected_hash=file_info['chksum_sha256'])\n\n                else:\n                    _extract_tar_dir(collection_tar, file_name, b_collection_path)\n\n    except Exception:\n        # Ensure we don't leave the dir behind in case of a failure.\n        shutil.rmtree(b_collection_path)\n\n        b_namespace_path = os.path.dirname(b_collection_path)\n        if not os.listdir(b_namespace_path):\n            os.rmdir(b_namespace_path)\n\n        raise",
    "pattern_analysis": {
      "api_sequence": [
        "tarfile.open",
        "_extract_tar_file",
        "os.path.join",
        "to_text",
        "verify_artifact_manifest",
        "tarfile.TarFile.getmember",
        "_tarfile_extract",
        "to_text",
        "json.loads",
        "_extract_tar_file",
        "_extract_tar_file",
        "_extract_tar_dir",
        "shutil.rmtree",
        "os.path.dirname",
        "os.listdir",
        "os.rmdir"
      ],
      "api_sequence_with_args": [
        "tarfile.open(b_coll_targz_path, mode='r')",
        "_extract_tar_file(collection_tar, MANIFEST_FILENAME, b_collection_path, b_temp_path)",
        "os.path.join(to_text(b_collection_path, errors='surrogate_or_strict'), MANIFEST_FILENAME)",
        "to_text(b_collection_path, errors='surrogate_or_strict')",
        "verify_artifact_manifest(manifest_file, signatures, keyring, required_signature_count, ignore_signature_errors)",
        "collection_tar.getmember('FILES.json')",
        "_tarfile_extract(collection_tar, files_member_obj)",
        "to_text(files_obj.read(), errors='surrogate_or_strict')",
        "json.loads(to_text(files_obj.read(), errors='surrogate_or_strict'))",
        "_extract_tar_file(collection_tar, 'FILES.json', b_collection_path, b_temp_path)",
        "_extract_tar_file(collection_tar, file_name, b_collection_path, b_temp_path, expected_hash=file_info['chksum_sha256'])",
        "_extract_tar_dir(collection_tar, file_name, b_collection_path)",
        "shutil.rmtree(b_collection_path)",
        "os.path.dirname(b_collection_path)",
        "os.listdir(b_namespace_path)",
        "os.rmdir(b_namespace_path)"
      ],
      "mapped_sequence": [
        {
          "api_name": "tarfile.open",
          "id": "open_zip_read",
          "description": "Opens ZIP archive for reading",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "_extract_tar_file",
          "id": "extract_zip_files",
          "description": "Extracts all files from ZIP archive to specified directory",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "to_text",
          "id": "decode_bytes_codec",
          "description": "Decodes bytes using specified codec",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "verify_artifact_manifest",
          "id": "deserialize_from_json",
          "description": "Deserializes JSON string to Python object",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "tarfile.TarFile.getmember",
          "id": "open_zip_read",
          "description": "Opens ZIP archive for reading",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "_tarfile_extract",
          "id": "extract_zip_files",
          "description": "Extracts all files from ZIP archive to specified directory",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "to_text",
          "id": "decode_bytes_codec",
          "description": "Decodes bytes using specified codec",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "json.loads",
          "id": "deserialize_from_json",
          "description": "Deserializes JSON string to Python object",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "_extract_tar_file",
          "id": "extract_zip_files",
          "description": "Extracts all files from ZIP archive to specified directory",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "_extract_tar_file",
          "id": "extract_zip_files",
          "description": "Extracts all files from ZIP archive to specified directory",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "_extract_tar_dir",
          "id": "extract_zip_files",
          "description": "Extracts all files from ZIP archive to specified directory",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "shutil.rmtree",
          "id": "delete_directory",
          "description": "Recursively deletes directory and its contents",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "os.path.dirname",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.listdir",
          "id": "list_files_directories",
          "description": "Lists files and directories in specified path",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "os.rmdir",
          "id": "delete_directory",
          "description": "Recursively deletes directory and its contents",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        }
      ],
      "contextual_code": "def install_artifact(b_coll_targz_path, b_collection_path, b_temp_path, signatures, keyring, required_signature_count, ignore_signature_errors):\n    try:\n        with tarfile.open(b_coll_targz_path, mode='r') as collection_tar:\n            _extract_tar_file(collection_tar, MANIFEST_FILENAME, b_collection_path, b_temp_path)\n\n            if keyring is not None:\n                manifest_file = os.path.join(to_text(b_collection_path, errors='surrogate_or_strict'), MANIFEST_FILENAME)\n                verify_artifact_manifest(manifest_file, signatures, keyring, required_signature_count, ignore_signature_errors)\n\n            files_member_obj = collection_tar.getmember('FILES.json')\n            with _tarfile_extract(collection_tar, files_member_obj) as (dummy, files_obj):\n                files = json.loads(to_text(files_obj.read(), errors='surrogate_or_strict'))\n\n            _extract_tar_file(collection_tar, 'FILES.json', b_collection_path, b_temp_path)\n\n            for file_info in files['files']:\n                file_name = file_info['name']\n                if file_name == '.':\n                    continue\n\n                if file_info['ftype'] == 'file':\n                    _extract_tar_file(collection_tar, file_name, b_collection_path, b_temp_path,\n                                      expected_hash=file_info['chksum_sha256'])\n                else:\n                    _extract_tar_dir(collection_tar, file_name, b_collection_path)\n\n    except Exception:\n        shutil.rmtree(b_collection_path)\n        b_namespace_path = os.path.dirname(b_collection_path)\n        if not os.listdir(b_namespace_path):\n            os.rmdir(b_namespace_path)\n        raise"
    }
  },
  {
    "pyfile": "basic.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/ansible_core-2.18.4/ansible_core-2.18.4/lib/ansible/module_utils/basic.py",
    "line_number": "1691",
    "type_description": "B810:chmod",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1690\t            os.umask(umask)\n1691\t            os.chmod(b_dest, S_IRWU_RWG_RWO & ~umask)\n1692\t            dest_dir_stat = os.stat(os.path.dirname(b_dest))",
    "code_snippet": "    def atomic_move(self, src, dest, unsafe_writes=False, keep_dest_attrs=True):\n        '''atomically move src to dest, copying attributes from dest, returns true on success\n        it uses os.rename to ensure this as it is an atomic operation, rest of the function is\n        to work around limitations, corner cases and ensure selinux context is saved if possible'''\n        context = None\n        dest_stat = None\n        b_src = to_bytes(src, errors='surrogate_or_strict')\n        b_dest = to_bytes(dest, errors='surrogate_or_strict')\n        if os.path.exists(b_dest) and keep_dest_attrs:\n            try:\n                dest_stat = os.stat(b_dest)\n                os.chown(b_src, dest_stat.st_uid, dest_stat.st_gid)\n                shutil.copystat(b_dest, b_src)\n                os.utime(b_src, times=(time.time(), time.time()))\n            except OSError as e:\n                if e.errno != errno.EPERM:\n                    raise\n            if self.selinux_enabled():\n                context = self.selinux_context(dest)\n        else:\n            if self.selinux_enabled():\n                context = self.selinux_default_context(dest)\n\n        creating = not os.path.exists(b_dest)\n\n        try:\n            # Optimistically try a rename, solves some corner cases and can avoid useless work, throws exception if not atomic.\n            os.rename(b_src, b_dest)\n        except (IOError, OSError) as e:\n            if e.errno not in [errno.EPERM, errno.EXDEV, errno.EACCES, errno.ETXTBSY, errno.EBUSY]:\n                # only try workarounds for errno 18 (cross device), 1 (not permitted),  13 (permission denied)\n                # and 26 (text file busy) which happens on vagrant synced folders and other 'exotic' non posix file systems\n                self.fail_json(msg='Could not replace file: %s to %s: %s' % (src, dest, to_native(e)), exception=traceback.format_exc())\n            else:\n                # Use bytes here.  In the shippable CI, this fails with\n                # a UnicodeError with surrogateescape'd strings for an unknown\n                # reason (doesn't happen in a local Ubuntu16.04 VM)\n                b_dest_dir = os.path.dirname(b_dest)\n                b_suffix = os.path.basename(b_dest)\n                error_msg = None\n                tmp_dest_name = None\n                try:\n                    tmp_dest_fd, tmp_dest_name = tempfile.mkstemp(prefix=b'.ansible_tmp', dir=b_dest_dir, suffix=b_suffix)\n                except (OSError, IOError) as e:\n                    error_msg = 'The destination directory (%s) is not writable by the current user. Error was: %s' % (os.path.dirname(dest), to_native(e))\n                finally:\n                    if error_msg:\n                        if unsafe_writes:\n                            self._unsafe_writes(b_src, b_dest)\n                        else:\n                            self.fail_json(msg=error_msg, exception=traceback.format_exc())\n\n                if tmp_dest_name:\n                    b_tmp_dest_name = to_bytes(tmp_dest_name, errors='surrogate_or_strict')\n\n                    try:\n                        try:\n                            # close tmp file handle before file operations to prevent text file busy errors on vboxfs synced folders (windows host)\n                            os.close(tmp_dest_fd)\n                            # leaves tmp file behind when sudo and not root\n                            try:\n                                shutil.move(b_src, b_tmp_dest_name, copy_function=shutil.copy if keep_dest_attrs else shutil.copy2)\n                            except OSError:\n                                # cleanup will happen by 'rm' of tmpdir\n                                # copy2 will preserve some metadata\n                                if keep_dest_attrs:\n                                    shutil.copy(b_src, b_tmp_dest_name)\n                                else:\n                                    shutil.copy2(b_src, b_tmp_dest_name)\n\n                            if self.selinux_enabled():\n                                self.set_context_if_different(\n                                    b_tmp_dest_name, context, False)\n                            try:\n                                tmp_stat = os.stat(b_tmp_dest_name)\n                                if keep_dest_attrs:\n                                    if dest_stat and (tmp_stat.st_uid != dest_stat.st_uid or tmp_stat.st_gid != dest_stat.st_gid):\n                                        os.chown(b_tmp_dest_name, dest_stat.st_uid, dest_stat.st_gid)\n                                    os.utime(b_tmp_dest_name, times=(time.time(), time.time()))\n                            except OSError as e:\n                                if e.errno != errno.EPERM:\n                                    raise\n                            try:\n                                os.rename(b_tmp_dest_name, b_dest)\n                            except (shutil.Error, OSError, IOError) as e:\n                                if unsafe_writes and e.errno == errno.EBUSY:\n                                    self._unsafe_writes(b_tmp_dest_name, b_dest)\n                                else:\n                                    self.fail_json(msg='Unable to make %s into to %s, failed final rename from %s: %s' %\n                                                       (src, dest, b_tmp_dest_name, to_native(e)), exception=traceback.format_exc())\n                        except (shutil.Error, OSError, IOError) as e:\n                            if unsafe_writes:\n                                self._unsafe_writes(b_src, b_dest)\n                            else:\n                                self.fail_json(msg='Failed to replace file: %s to %s: %s' % (src, dest, to_native(e)), exception=traceback.format_exc())\n                    finally:\n                        self.cleanup(b_tmp_dest_name)\n\n        if creating:\n            # make sure the file has the correct permissions\n            # based on the current value of umask\n            umask = os.umask(0)\n            os.umask(umask)\n            os.chmod(b_dest, S_IRWU_RWG_RWO & ~umask)\n            dest_dir_stat = os.stat(os.path.dirname(b_dest))\n            try:\n                if dest_dir_stat.st_mode & stat.S_ISGID:\n                    os.chown(b_dest, os.geteuid(), dest_dir_stat.st_gid)\n                else:\n                    os.chown(b_dest, os.geteuid(), os.getegid())\n            except OSError:\n                # We're okay with trying our best here.  If the user is not\n                # root (or old Unices) they won't be able to chown.\n                pass\n\n        if self.selinux_enabled():\n            # rename might not preserve context\n            self.set_context_if_different(dest, context, False)\n",
    "pattern_analysis": {
      "api_sequence": [
        "os.path.exists",
        "os.stat",
        "os.chown",
        "shutil.copystat",
        "os.utime",
        "self.selinux_enabled",
        "self.selinux_context",
        "self.selinux_enabled",
        "self.selinux_default_context",
        "os.path.exists",
        "os.rename",
        "os.path.dirname",
        "os.path.basename",
        "tempfile.mkstemp",
        "os.close",
        "shutil.move",
        "shutil.copy",
        "shutil.copy2",
        "self.selinux_enabled",
        "self.set_context_if_different",
        "os.stat",
        "os.chown",
        "os.utime",
        "os.rename",
        "self._unsafe_writes",
        "self.fail_json",
        "self.cleanup",
        "os.umask",
        "os.umask",
        "os.chmod",
        "os.stat",
        "os.path.dirname",
        "os.chown",
        "os.geteuid",
        "os.getegid",
        "self.selinux_enabled",
        "self.set_context_if_different"
      ],
      "api_sequence_with_args": [
        "os.path.exists(b_dest)",
        "os.stat(b_dest)",
        "os.chown(b_src, dest_stat.st_uid, dest_stat.st_gid)",
        "shutil.copystat(b_dest, b_src)",
        "os.utime(b_src, times=(time.time(), time.time()))",
        "self.selinux_enabled()",
        "self.selinux_context(dest)",
        "self.selinux_enabled()",
        "self.selinux_default_context(dest)",
        "os.path.exists(b_dest)",
        "os.rename(b_src, b_dest)",
        "os.path.dirname(b_dest)",
        "os.path.basename(b_dest)",
        "tempfile.mkstemp(prefix=b'.ansible_tmp', dir=b_dest_dir, suffix=b_suffix)",
        "os.close(tmp_dest_fd)",
        "shutil.move(b_src, b_tmp_dest_name, copy_function=shutil.copy if keep_dest_attrs else shutil.copy2)",
        "shutil.copy(b_src, b_tmp_dest_name)",
        "shutil.copy2(b_src, b_tmp_dest_name)",
        "self.selinux_enabled()",
        "self.set_context_if_different(b_tmp_dest_name, context, False)",
        "os.stat(b_tmp_dest_name)",
        "os.chown(b_tmp_dest_name, dest_stat.st_uid, dest_stat.st_gid)",
        "os.utime(b_tmp_dest_name, times=(time.time(), time.time()))",
        "os.rename(b_tmp_dest_name, b_dest)",
        "self._unsafe_writes(b_tmp_dest_name, b_dest)",
        "self.fail_json(msg=..., exception=traceback.format_exc())",
        "self.cleanup(b_tmp_dest_name)",
        "os.umask(0)",
        "os.umask(umask)",
        "os.chmod(b_dest, S_IRWU_RWG_RWO & ~umask)",
        "os.stat(os.path.dirname(b_dest))",
        "os.path.dirname(b_dest)",
        "os.chown(b_dest, os.geteuid(), dest_dir_stat.st_gid)",
        "os.geteuid()",
        "os.getegid()",
        "self.selinux_enabled()",
        "self.set_context_if_different(dest, context, False)"
      ],
      "mapped_sequence": [
        {
          "api_name": "os.path.exists",
          "id": "check_path_exists",
          "description": "Checks if specified path exists in filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "os.stat",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.chown",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "shutil.copystat",
          "id": "copy_file",
          "description": "Copies file to destination, preserving metadata",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "os.utime",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "self.selinux_enabled",
          "id": "path_special_operations",
          "description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "self.selinux_context",
          "id": "path_special_operations",
          "description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "self.selinux_enabled",
          "id": "path_special_operations",
          "description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "self.selinux_default_context",
          "id": "path_special_operations",
          "description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.exists",
          "id": "check_path_exists",
          "description": "Checks if specified path exists in filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "os.rename",
          "id": "rename_file",
          "description": "Renames file or moves it to new location",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "os.path.dirname",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.basename",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "tempfile.mkstemp",
          "id": "create_temp_file",
          "description": "Creates temporary file that is not deleted on close",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "os.close",
          "id": "close_file",
          "description": "Closes the opened file",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_closing"
        },
        {
          "api_name": "shutil.move",
          "id": "move_file",
          "description": "Moves file to destination, preserving metadata",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "shutil.copy",
          "id": "copy_file",
          "description": "Copies file to destination, preserving metadata",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "shutil.copy2",
          "id": "copy_file",
          "description": "Copies file to destination, preserving metadata",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "self.selinux_enabled",
          "id": "path_special_operations",
          "description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "self.set_context_if_different",
          "id": "path_special_operations",
          "description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.stat",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.chown",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "os.utime",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "os.rename",
          "id": "rename_file",
          "description": "Renames file or moves it to new location",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "self._unsafe_writes",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "self.fail_json",
          "id": "log_error",
          "description": "Logs error message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "self.cleanup",
          "id": "delete_file",
          "description": "Deletes specified file from filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "os.umask",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "os.umask",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "os.chmod",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "os.stat",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.dirname",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.chown",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "os.geteuid",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "os.getegid",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "self.selinux_enabled",
          "id": "path_special_operations",
          "description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "self.set_context_if_different",
          "id": "path_special_operations",
          "description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        }
      ],
      "contextual_code": "def atomic_move(self, src, dest, unsafe_writes=False, keep_dest_attrs=True):\n    context = None\n    dest_stat = None\n    b_src = to_bytes(src, errors='surrogate_or_strict')\n    b_dest = to_bytes(dest, errors='surrogate_or_strict')\n    if os.path.exists(b_dest) and keep_dest_attrs:\n        try:\n            dest_stat = os.stat(b_dest)\n            os.chown(b_src, dest_stat.st_uid, dest_stat.st_gid)\n            shutil.copystat(b_dest, b_src)\n            os.utime(b_src, times=(time.time(), time.time()))\n        except OSError as e:\n            if e.errno != errno.EPERM:\n                raise\n        if self.selinux_enabled():\n            context = self.selinux_context(dest)\n    else:\n        if self.selinux_enabled():\n            context = self.selinux_default_context(dest)\n\n    creating = not os.path.exists(b_dest)\n\n    try:\n        os.rename(b_src, b_dest)\n    except (IOError, OSError) as e:\n        if e.errno not in [errno.EPERM, errno.EXDEV, errno.EACCES, errno.ETXTBSY, errno.EBUSY]:\n            self.fail_json(msg='Could not replace file: %s to %s: %s' % (src, dest, to_native(e)), exception=traceback.format_exc())\n        else:\n            b_dest_dir = os.path.dirname(b_dest)\n            b_suffix = os.path.basename(b_dest)\n            error_msg = None\n            tmp_dest_name = None\n            try:\n                tmp_dest_fd, tmp_dest_name = tempfile.mkstemp(prefix=b'.ansible_tmp', dir=b_dest_dir, suffix=b_suffix)\n            except (OSError, IOError) as e:\n                error_msg = 'The destination directory (%s) is not writable by the current user. Error was: %s' % (os.path.dirname(dest), to_native(e))\n            finally:\n                if error_msg:\n                    if unsafe_writes:\n                        self._unsafe_writes(b_src, b_dest)\n                    else:\n                        self.fail_json(msg=error_msg, exception=traceback.format_exc())\n\n            if tmp_dest_name:\n                b_tmp_dest_name = to_bytes(tmp_dest_name, errors='surrogate_or_strict')\n\n                try:\n                    try:\n                        os.close(tmp_dest_fd)\n                        try:\n                            shutil.move(b_src, b_tmp_dest_name, copy_function=shutil.copy if keep_dest_attrs else shutil.copy2)\n                        except OSError:\n                            if keep_dest_attrs:\n                                shutil.copy(b_src, b_tmp_dest_name)\n                            else:\n                                shutil.copy2(b_src, b_tmp_dest_name)\n\n                        if self.selinux_enabled():\n                            self.set_context_if_different(b_tmp_dest_name, context, False)\n                        try:\n                            tmp_stat = os.stat(b_tmp_dest_name)\n                            if keep_dest_attrs:\n                                if dest_stat and (tmp_stat.st_uid != dest_stat.st_uid or tmp_stat.st_gid != dest_stat.st_gid):\n                                    os.chown(b_tmp_dest_name, dest_stat.st_uid, dest_stat.st_gid)\n                                os.utime(b_tmp_dest_name, times=(time.time(), time.time()))\n                        except OSError as e:\n                            if e.errno != errno.EPERM:\n                                raise\n                        try:\n                            os.rename(b_tmp_dest_name, b_dest)\n                        except (shutil.Error, OSError, IOError) as e:\n                            if unsafe_writes and e.errno == errno.EBUSY:\n                                self._unsafe_writes(b_tmp_dest_name, b_dest)\n                            else:\n                                self.fail_json(msg='Unable to make %s into to %s, failed final rename from %s: %s' %\n                                                   (src, dest, b_tmp_dest_name, to_native(e)), exception=traceback.format_exc())\n                    except (shutil.Error, OSError, IOError) as e:\n                        if unsafe_writes:\n                            self._unsafe_writes(b_src, b_dest)\n                        else:\n                            self.fail_json(msg='Failed to replace file: %s to %s: %s' % (src, dest, to_native(e)), exception=traceback.format_exc())\n                finally:\n                    self.cleanup(b_tmp_dest_name)\n\n    if creating:\n        umask = os.umask(0)\n        os.umask(umask)\n        os.chmod(b_dest, S_IRWU_RWG_RWO & ~umask)\n        dest_dir_stat = os.stat(os.path.dirname(b_dest))\n        try:\n            if dest_dir_stat.st_mode & stat.S_ISGID:\n                os.chown(b_dest, os.geteuid(), dest_dir_stat.st_gid)\n            else:\n                os.chown(b_dest, os.geteuid(), os.getegid())\n        except OSError:\n            pass\n\n    if self.selinux_enabled():\n        self.set_context_if_different(dest, context, False)"
    }
  }
]