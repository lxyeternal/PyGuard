[
  {
    "metadata": {
      "package_name": "yolov5-7.0.14",
      "total_matches": 1,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "val.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/yolov5-7.0.14/yolov5-7.0.14/yolov5/val.py",
    "line_number": "316",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "315\t    text_file = open(save_dir / \"results.html\", \"w\")\n316\t    text_file.write(results_html)\n317\t    text_file.close()",
    "code_snippet": "def run(\n        data,\n        weights=None,  # model.pt path(s)\n        batch_size=None,  # batch size\n        batch=None,  # batch size\n        imgsz=None,  # inference size (pixels)\n        img=None,  # inference size (pixels)\n        conf_thres=0.001,  # confidence threshold\n        iou_thres=0.6,  # NMS IoU threshold\n        max_det=300,  # maximum detections per image\n        task='val',  # train, val, test, speed or study\n        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n        workers=8,  # max dataloader workers (per RANK in DDP mode)\n        single_cls=False,  # treat as single-class dataset\n        augment=False,  # augmented inference\n        verbose=False,  # verbose output\n        save_txt=False,  # save results to *.txt\n        save_hybrid=False,  # save label+prediction hybrid results to *.txt\n        save_conf=False,  # save confidences in --save-txt labels\n        save_json=False,  # save a COCO-JSON results file\n        project='runs/val',  # save to project/name\n        name='exp',  # save to project/name\n        exist_ok=False,  # existing project/name ok, do not increment\n        half=True,  # use FP16 half-precision inference\n        dnn=False,  # use OpenCV DNN for ONNX inference\n        model=None,\n        dataloader=None,\n        save_dir=Path(''),\n        plots=True,\n        callbacks=Callbacks(),\n        compute_loss=None,\n):\n    ...\n    # Export results as html\n    header = \"Class Images Labels P R mAP@.5 mAP@.5:.95\"\n    headers = header.split()\n    data = []\n    data.append(['all', seen, nt.sum(), f\"{float(mp):0.3f}\", f\"{float(mr):0.3f}\", f\"{float(map50):0.3f}\", f\"{float(map):0.3f}\"])\n    for i, c in enumerate(ap_class):\n        data.append([names[c], seen, nt[c], f\"{float(p[i]):0.3f}\", f\"{float(r[i]):0.3f}\", f\"{float(ap50[i]):0.3f}\", f\"{float(ap[i]):0.3f}\"])\n    results_df = pd.DataFrame(data,columns=headers)\n    results_html = results_df.to_html()\n    text_file = open(save_dir / \"results.html\", \"w\")\n    text_file.write(results_html)\n    text_file.close()\n    ...",
    "pattern_analysis": {
      "api_sequence": [
        "open",
        "pandas.DataFrame",
        "pandas.DataFrame.to_html",
        "open",
        "write",
        "close"
      ],
      "api_sequence_with_args": [
        "open(save_dir / \"results.html\", \"w\")",
        "pandas.DataFrame(data, columns=headers)",
        "pandas.DataFrame.to_html()",
        "open(save_dir / \"results.html\", \"w\")",
        "text_file.write(results_html)",
        "text_file.close()"
      ],
      "mapped_sequence": [
        {
          "api_name": "open",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "pandas.DataFrame",
          "id": "serialize_to_json",
          "description": "Serializes Python object to JSON string",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "pandas.DataFrame.to_html",
          "id": "serialize_to_json",
          "description": "Serializes Python object to JSON string",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "open",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "close",
          "id": "close_file",
          "description": "Closes the opened file",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_closing"
        }
      ],
      "contextual_code": "# Export results as html\nheader = \"Class Images Labels P R mAP@.5 mAP@.5:.95\"\nheaders = header.split()\ndata = []\ndata.append(['all', seen, nt.sum(), f\"{float(mp):0.3f}\", f\"{float(mr):0.3f}\", f\"{float(map50):0.3f}\", f\"{float(map):0.3f}\"])\nfor i, c in enumerate(ap_class):\n    data.append([names[c], seen, nt[c], f\"{float(p[i]):0.3f}\", f\"{float(r[i]):0.3f}\", f\"{float(ap50[i]):0.3f}\", f\"{float(ap[i]):0.3f}\"])\nresults_df = pd.DataFrame(data,columns=headers)\nresults_html = results_df.to_html()\ntext_file = open(save_dir / \"results.html\", \"w\")\ntext_file.write(results_html)\ntext_file.close()"
    }
  }
]