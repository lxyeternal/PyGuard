[
  {
    "metadata": {
      "package_name": "ml_pipelines_sdk-1.16.0-py3-none-any",
      "total_matches": 1,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "iris_pipeline_async.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/ml_pipelines_sdk-1.16.0-py3-none-any/tfx/dsl/compiler/testdata/iris_pipeline_async.py",
    "line_number": "119",
    "type_description": "B812:system",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "118\t      push_destination=pusher_pb2.PushDestination(\n119\t          filesystem=pusher_pb2.PushDestination.Filesystem(\n120\t              base_directory=serving_model_dir)))\n121",
    "code_snippet": "def create_test_pipeline():\n  \"\"\"Builds an Iris example pipeline with slight changes.\"\"\"\n  pipeline_name = \"iris\"\n  iris_root = \"iris_root\"\n  serving_model_dir = os.path.join(iris_root, \"serving_model\", pipeline_name)\n  tfx_root = \"tfx_root\"\n  data_path = os.path.join(tfx_root, \"data_path\")\n  pipeline_root = os.path.join(tfx_root, \"pipelines\", pipeline_name)\n\n  example_gen = CsvExampleGen(input_base=data_path)\n\n  statistics_gen = StatisticsGen(examples=example_gen.outputs[\"examples\"])\n\n  my_importer = importer.Importer(\n      source_uri=\"m/y/u/r/i\",\n      properties={\n          \"split_names\": \"['train', 'eval']\",\n      },\n      custom_properties={\n          \"int_custom_property\": 42,\n          \"str_custom_property\": \"42\",\n      },\n      artifact_type=standard_artifacts.Examples).with_id(\"my_importer\")\n\n  schema_gen = SchemaGen(\n      statistics=statistics_gen.outputs[\"statistics\"], infer_feature_shape=True)\n\n  example_validator = ExampleValidator(\n      statistics=statistics_gen.outputs[\"statistics\"],\n      schema=schema_gen.outputs[\"schema\"])\n\n  trainer = Trainer(\n      # Use RuntimeParameter as module_file to test out RuntimeParameter in\n      # compiler.\n      module_file=data_types.RuntimeParameter(\n          name=\"module_file\",\n          default=os.path.join(iris_root, \"iris_utils.py\"),\n          ptype=str),\n      custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n      examples=example_gen.outputs[\"examples\"],\n      schema=schema_gen.outputs[\"schema\"],\n      train_args=trainer_pb2.TrainArgs(num_steps=2000),\n      # Attaching `TrainerArgs` as platform config is not sensible practice,\n      # but is only for testing purpose.\n      eval_args=trainer_pb2.EvalArgs(num_steps=5)).with_platform_config(\n          config=trainer_pb2.TrainArgs(num_steps=2000))\n\n  # TODO(b/257197093): Use corresponding resolver function instead.\n  # model_resolver = resolver.Resolver(\n  #     strategy_class=latest_blessed_model_strategy.LatestBlessedModelStrategy,\n  #     baseline_model=Channel(\n  #         type=standard_artifacts.Model, producer_component_id=\"Trainer\"),\n  #     # Cannot add producer_component_id=\"Evaluator\" for model_blessing as it\n  #     # raises \"producer component should have already been compiled\" error.\n  #     model_blessing=Channel(type=standard_artifacts.ModelBlessing)).with_id(\n  #         \"latest_blessed_model_resolver\")\n\n  eval_config = tfma.EvalConfig(\n      model_specs=[tfma.ModelSpec(signature_name=\"eval\")],\n      slicing_specs=[tfma.SlicingSpec()],\n      metrics_specs=[\n          tfma.MetricsSpec(\n              thresholds={\n                  \"sparse_categorical_accuracy\":\n                      tfma.MetricThreshold(\n                          value_threshold=tfma.GenericValueThreshold(\n                              lower_bound={\"value\": 0.6}),\n                          change_threshold=tfma.GenericChangeThreshold(\n                              direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                              absolute={\"value\": -1e-10}))\n              })\n      ])\n  evaluator = Evaluator(\n      examples=example_gen.outputs[\"examples\"].no_trigger(),\n      model=trainer.outputs[\"model\"],\n      # TODO(b/257197093): Use corresponding resolver function instead.\n      # baseline_model=model_resolver.outputs[\"baseline_model\"],\n      eval_config=eval_config,\n  )\n\n  pusher = Pusher(\n      model=trainer.outputs[\"model\"],\n      model_blessing=evaluator.outputs[\"blessing\"],\n      push_destination=pusher_pb2.PushDestination(\n          filesystem=pusher_pb2.PushDestination.Filesystem(\n              base_directory=serving_model_dir)))\n\n  return pipeline.Pipeline(\n      pipeline_name=pipeline_name,\n      pipeline_root=pipeline_root,\n      components=[\n          example_gen,\n          statistics_gen,\n          my_importer,\n          schema_gen,\n          example_validator,\n          trainer,\n          evaluator,\n          pusher,\n      ],\n      enable_cache=False,\n      beam_pipeline_args=[\"--my_testing_beam_pipeline_args=bar\"],\n      # Attaching `TrainerArgs` as platform config is not sensible practice,\n      # but is only for testing purpose.\n      platform_config=trainer_pb2.TrainArgs(num_steps=2000),\n      execution_mode=pipeline.ExecutionMode.ASYNC)\n",
    "pattern_analysis": {
      "api_sequence": [
        "os.path.join",
        "os.path.join",
        "os.path.join"
      ],
      "api_sequence_with_args": [
        "os.path.join(iris_root, \"serving_model\", pipeline_name)",
        "os.path.join(tfx_root, \"data_path\")",
        "os.path.join(tfx_root, \"pipelines\", pipeline_name)"
      ],
      "mapped_sequence": [
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        }
      ],
      "contextual_code": "def create_test_pipeline():\n  pipeline_name = \"iris\"\n  iris_root = \"iris_root\"\n  serving_model_dir = os.path.join(iris_root, \"serving_model\", pipeline_name)\n  tfx_root = \"tfx_root\"\n  data_path = os.path.join(tfx_root, \"data_path\")\n  pipeline_root = os.path.join(tfx_root, \"pipelines\", pipeline_name)\n  # ... rest of the pipeline construction code"
    }
  }
]