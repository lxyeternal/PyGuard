[
  {
    "metadata": {
      "package_name": "obspy-1.4.1",
      "total_matches": 2,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "test_core.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/obspy-1.4.1/obspy-1.4.1/obspy/io/wav/tests/test_core.py",
    "line_number": "112",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "111\t                testfile1 = \"%s%03d%s\" % (base, 1, ext)\n112\t                tr30 = read(testfile0)[0]\n113\t                tr31 = read(testfile1)[0]",
    "code_snippet": "def test_write_stream_via_obspy(self, testdata):\n    \"\"\"\n    Write streams, i.e. multiple files via obspy.core.Trace\n    \"\"\"\n    data = np.array([111, 111, 111, 111, 111, 109, 106, 103, 103,\n                     110, 121, 132, 139])\n    with NamedTemporaryFile() as fh:\n        testfile = fh.name\n        self.file = testdata['3cssan.reg.8.1.RNON.wav']\n        tr = read(self.file, format='WAV')[0]\n        np.testing.assert_array_equal(tr.data[:13], data)\n        # write\n        st2 = Stream([Trace(), Trace()])\n        st2[0].data = tr.data.copy()       # copy the data\n        st2[1].data = tr.data.copy() // 2  # be sure data are different\n        st2.write(testfile, format='WAV', framerate=7000)\n        try:\n            # read without giving the WAV format option\n            base, ext = os.path.splitext(testfile)\n            testfile0 = \"%s%03d%s\" % (base, 0, ext)\n            testfile1 = \"%s%03d%s\" % (base, 1, ext)\n            tr30 = read(testfile0)[0]\n            tr31 = read(testfile1)[0]\n            assert tr30.stats == tr.stats\n            assert tr31.stats == tr.stats\n            np.testing.assert_array_equal(tr30.data[:13], data)\n            np.testing.assert_array_equal(tr31.data[:13], data // 2)\n        finally:\n            os.remove(testfile0)\n            os.remove(testfile1)",
    "pattern_analysis": {
      "api_sequence": [
        "NamedTemporaryFile",
        "os.path.splitext",
        "os.remove",
        "os.remove"
      ],
      "api_sequence_with_args": [
        "NamedTemporaryFile()",
        "os.path.splitext(testfile)",
        "os.remove(testfile0)",
        "os.remove(testfile1)"
      ],
      "mapped_sequence": [
        {
          "api_name": "NamedTemporaryFile",
          "id": "create_temp_file",
          "description": "Creates temporary file that is not deleted on close",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "os.path.splitext",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.remove",
          "id": "delete_file",
          "description": "Deletes specified file from filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "os.remove",
          "id": "delete_file",
          "description": "Deletes specified file from filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        }
      ],
      "contextual_code": "from tempfile import NamedTemporaryFile\nimport os\n\ndef test_write_stream_via_obspy(self, testdata):\n    data = np.array([111, 111, 111, 111, 111, 109, 106, 103, 103,\n                     110, 121, 132, 139])\n    with NamedTemporaryFile() as fh:\n        testfile = fh.name\n        # ...\n        try:\n            base, ext = os.path.splitext(testfile)\n            testfile0 = \"%s%03d%s\" % (base, 0, ext)\n            testfile1 = \"%s%03d%s\" % (base, 1, ext)\n            # ...\n        finally:\n            os.remove(testfile0)\n            os.remove(testfile1)"
    }
  },
  {
    "pyfile": "arrayio.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/obspy-1.4.1/obspy-1.4.1/obspy/io/sac/arrayio.py",
    "line_number": "131",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "130\t    hf = from_buffer(f.read(4 * 70), dtype=endian_str + 'f4')\n131\t    hi = from_buffer(f.read(4 * 40), dtype=endian_str + 'i4')\n132\t    hs = from_buffer(f.read(24 * 8), dtype='|S8')",
    "code_snippet": "def read_sac(source, headonly=False, byteorder=None, checksize=False):\n    \"\"\"\n    Read a SAC binary file.\n\n    :param source: Full path string for File-like object from a SAC binary file\n        on disk.  If it is an open File object, open 'rb'.\n    :type source: str or file\n    :param headonly: If headonly is True, only read the header arrays not the\n        data array.\n    :type headonly: bool\n    :param byteorder: If omitted or None, automatic byte-order checking is\n        done, starting with native order. If byteorder is specified,\n        {'little', 'big'} and incorrect, a SacIOError is raised.\n    :type byteorder: str, optional\n    :param checksize: If True, check that the theoretical file size from the\n        header matches the size on disk.\n    :type checksize: bool\n\n    :return: The float, integer, and string header arrays, and data array,\n        in that order. Data array will be None if headonly is True.\n    :rtype: tuple(:class:`numpy.ndarray`)\n\n    :raises: :class:`ValueError` if unrecognized byte order.  :class:`IOError`\n        if file not found, incorrect specified byteorder, theoretical file size\n        doesn't match header, or header arrays are incorrect length.\n\n    \"\"\"\n    # TODO: rewrite using \"with\" statement instead of open/close management.\n    # check byte order, header array length, file size, npts == data length\n    try:\n        f = open(source, 'rb')\n        is_file_name = True\n    except TypeError:\n        # source is already a file-like object\n        f = source\n        is_file_name = False\n\n    is_byteorder_specified = byteorder is not None\n    if not is_byteorder_specified:\n        byteorder = sys.byteorder\n\n    if byteorder == 'little':\n        endian_str = '<'\n    elif byteorder == 'big':\n        endian_str = '>'\n    else:\n        raise ValueError(\"Unrecognized byteorder. Use {'little', 'big'}\")\n\n    # --------------------------------------------------------------\n    # READ HEADER\n    # The sac header has 70 floats, 40 integers, then 192 bytes\n    #    in strings. Store them in array (and convert the char to a\n    #    list). That's a total of 632 bytes.\n    # --------------------------------------------------------------\n    hf = from_buffer(f.read(4 * 70), dtype=endian_str + 'f4')\n    hi = from_buffer(f.read(4 * 40), dtype=endian_str + 'i4')\n    hs = from_buffer(f.read(24 * 8), dtype='|S8')\n\n    if not is_valid_byteorder(hi):\n        if is_byteorder_specified:\n            if is_file_name:\n                f.close()\n            # specified but not valid. you dun messed up.\n            raise SacIOError(\"Incorrect byteorder {}\".format(byteorder))\n        else:\n            # not valid, but not specified.\n            # swap the dtype interpretation (dtype.byteorder), but keep the\n            # bytes, so the arrays in memory reflect the bytes on disk\n            hf = hf.newbyteorder('S')\n            hi = hi.newbyteorder('S')\n\n    # we now have correct headers, let's use their correct byte order.\n    endian_str = hi.dtype.byteorder\n\n    # check header lengths\n    if len(hf) != 70 or len(hi) != 40 or len(hs) != 24:\n        hf = hi = hs = None\n        if is_file_name:\n            f.close()\n        raise SacIOError(\"Cannot read all header values\")\n\n    npts = hi[HD.INTHDRS.index('npts')]\n\n    # check file size\n    if checksize:\n        cur_pos = f.tell()\n        f.seek(0, os.SEEK_END)\n        length = f.tell()\n        f.seek(cur_pos, os.SEEK_SET)\n        th_length = (632 + 4 * int(npts))\n        if length != th_length:\n            if is_file_name:\n                f.close()\n            msg = \"Actual and theoretical file size are inconsistent.\\n\" \\\n                  \"Actual/Theoretical: {}/{}\\n\" \\\n                  \"Check that headers are consistent with time series.\"\n            raise SacIOError(msg.format(length, th_length))\n\n    # --------------------------------------------------------------\n    # READ DATA\n    # --------------------------------------------------------------\n    if headonly:\n        data = None\n    else:\n        data = from_buffer(f.read(int(npts) * 4),\n                           dtype=endian_str + 'f4')\n\n        if len(data) != npts:\n            if is_file_name:\n                f.close()\n            raise SacIOError(\"Cannot read all data points\")\n\n    if is_file_name:\n        f.close()\n\n    return hf, hi, hs, data",
    "pattern_analysis": {
      "api_sequence": [
        "open",
        "file.read",
        "file.read",
        "file.read",
        "file.close",
        "file.tell",
        "file.seek",
        "file.tell",
        "file.seek",
        "file.close",
        "file.read",
        "file.close"
      ],
      "api_sequence_with_args": [
        "open(source, 'rb')",
        "f.read(4 * 70)",
        "f.read(4 * 40)",
        "f.read(24 * 8)",
        "f.close()",
        "f.tell()",
        "f.seek(0, os.SEEK_END)",
        "f.tell()",
        "f.seek(cur_pos, os.SEEK_SET)",
        "f.close()",
        "f.read(int(npts) * 4)",
        "f.close()"
      ],
      "mapped_sequence": [
        {
          "api_name": "open",
          "id": "basic_read_operations",
          "description": "ic file opening operations for reading (normal reading, binary reading)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "file.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "file.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "file.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "file.close",
          "id": "close_file",
          "description": "Closes the opened file",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_closing"
        },
        {
          "api_name": "file.tell",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "file.seek",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "file.tell",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "file.seek",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "file.close",
          "id": "close_file",
          "description": "Closes the opened file",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_closing"
        },
        {
          "api_name": "file.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "file.close",
          "id": "close_file",
          "description": "Closes the opened file",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_closing"
        }
      ],
      "contextual_code": "def read_sac(source, headonly=False, byteorder=None, checksize=False):\n    try:\n        f = open(source, 'rb')\n        is_file_name = True\n    except TypeError:\n        f = source\n        is_file_name = False\n\n    # ...\n    hf = from_buffer(f.read(4 * 70), dtype=endian_str + 'f4')\n    hi = from_buffer(f.read(4 * 40), dtype=endian_str + 'i4')\n    hs = from_buffer(f.read(24 * 8), dtype='|S8')\n\n    # ...\n    if not is_valid_byteorder(hi):\n        if is_byteorder_specified:\n            if is_file_name:\n                f.close()\n            raise SacIOError(...)\n        else:\n            hf = hf.newbyteorder('S')\n            hi = hi.newbyteorder('S')\n\n    # ...\n    if len(hf) != 70 or len(hi) != 40 or len(hs) != 24:\n        hf = hi = hs = None\n        if is_file_name:\n            f.close()\n        raise SacIOError(...)\n\n    npts = hi[HD.INTHDRS.index('npts')]\n\n    if checksize:\n        cur_pos = f.tell()\n        f.seek(0, os.SEEK_END)\n        length = f.tell()\n        f.seek(cur_pos, os.SEEK_SET)\n        th_length = (632 + 4 * int(npts))\n        if length != th_length:\n            if is_file_name:\n                f.close()\n            raise SacIOError(...)\n\n    if headonly:\n        data = None\n    else:\n        data = from_buffer(f.read(int(npts) * 4), dtype=endian_str + 'f4')\n        if len(data) != npts:\n            if is_file_name:\n                f.close()\n            raise SacIOError(...)\n\n    if is_file_name:\n        f.close()"
    }
  }
]