[
  {
    "metadata": {
      "package_name": "semgrep-1.118.0",
      "total_matches": 1,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "scans.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/semgrep-1.118.0/semgrep-1.118.0/src/semgrep/app/scans.py",
    "line_number": "579",
    "type_description": "B821:post",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "578\t            # mark as complete\n579\t            response = state.app_session.post(\n580\t                f\"{state.env.semgrep_url}/api/agent/scans/{self.scan_id}/complete\",\n581\t                timeout=state.env.upload_findings_timeout,\n582\t                json=complete.to_json(),\n583\t            )",
    "code_snippet": "@tracing.trace()\ndef report_findings(\n    self,\n    *,\n    matches_by_rule: RuleMatchMap,\n    rules: List[Rule],\n    targets: Set[Path],\n    renamed_targets: Set[Path],\n    ignored_targets: FrozenSet[Path],\n    cli_suggested_exit_code: int,\n    parse_rate: ParsingData,\n    total_time: float,\n    commit_date: str,\n    lockfile_dependencies: Dict[str, List[out.FoundDependency]],\n    dependency_parser_errors: List[DependencyParserError],\n    all_subprojects: List[Union[out.UnresolvedSubproject, out.ResolvedSubproject]],\n    contributions: out.Contributions,\n    engine_requested: \"EngineType\",\n    progress_bar: \"Progress\",\n) -> out.CiScanCompleteResponse:\n    \"\"\"\n    commit_date here for legacy reasons. epoch time of latest commit\n\n    Returns (success, block_scan, block_reason)\n    \"\"\"\n    state = get_state()\n    rule_ids = [out.RuleId(r.id) for r in rules]\n    all_matches = [\n        match\n        for matches_of_rule in matches_by_rule.values()\n        for match in matches_of_rule\n    ]\n    # we want date stamps assigned by the app to be assigned such that the\n    # current sort by relevant_since results in findings within a given scan\n    # appear in an intuitive order.  this requires reversed ordering here.\n    all_matches.reverse()\n    sort_order = {  # used only to order rules by severity\n        out.Experiment(): 0,\n        out.Inventory(): 1,\n        out.Info(): 2,\n        out.Low(): 2,\n        out.Warning(): 3,\n        out.Medium(): 3,\n        out.Error(): 4,\n        out.High(): 4,\n        out.Critical(): 5,\n    }\n    # NB: sorted guarantees stable sort, so within a given severity level\n    # issues remain sorted as before\n    all_matches = sorted(\n        all_matches, key=lambda match: sort_order[match.severity.value]\n    )\n    new_ignored, new_matches = partition(\n        all_matches, lambda match: match.match.extra.is_ignored\n    )\n\n    # Autofix is currently the only toggle in the App that\n    # indicates we are going to store your code. Until we\n    # have a dedicated toggle that allows users to opt-in\n    # to us storing their code we ommit code unless autofix\n    # is set.\n\n    findings = [\n        match.to_app_finding_format(\n            commit_date,\n            remove_dataflow_content=not self.autofix,\n        )\n        for match in new_matches\n    ]\n    ignores = [\n        match.to_app_finding_format(\n            commit_date,\n            remove_dataflow_content=not self.autofix,\n        )\n        for match in new_ignored\n    ]\n    token = (\n        # GitHub (cloud)\n        os.getenv(\"GITHUB_TOKEN\")\n        # GitLab.com (cloud)\n        or os.getenv(\"GITLAB_TOKEN\")\n        # Bitbucket Cloud\n        or os.getenv(\"BITBUCKET_TOKEN\")\n    )\n\n    self.ci_scan_results = out.CiScanResults(\n        # send a backup token in case the app is not available\n        token=token,\n        findings=findings,\n        ignores=ignores,\n        searched_paths=[out.Fpath(str(t)) for t in sorted(targets)],\n        renamed_paths=[out.Fpath(str(rt)) for rt in sorted(renamed_targets)],\n        rule_ids=rule_ids,\n        contributions=contributions,\n    )\n    if self.dependency_query:\n        self.ci_scan_results.dependencies = out.CiScanDependencies(\n            lockfile_dependencies\n        )\n\n    findings_and_ignores = self.ci_scan_results.to_json()\n\n    if any(\n        isinstance(match.severity.value, out.Experiment) for match in new_ignored\n    ):\n        logger.info(\"Some experimental rules were run during execution.\")\n\n    ignored_ext_freqs = Counter(\n        [os.path.splitext(path)[1] for path in ignored_targets]\n    )\n    ignored_ext_freqs.pop(\"\", None)  # don't count files with no extension\n\n    dependency_counts = {k: len(v) for k, v in lockfile_dependencies.items()}\n\n    # NOTE: This mirrors the logic in metrics.py to show the number of\n    #  findings by product for SCP customers. See PA-3312\n    #  We should consider refactoring this logic into a shared function\n    #  in a future PR for metric and behavioral consistency.\n    #  An open question remains on whether we should be including the number\n    #  of ignored findings in this count.\n\n    findings_by_product: Dict[str, int] = Counter()\n    for r, f in matches_by_rule.items():\n        # NOTE: For parity with metrics.py, we are using the human-readable product name,\n        #  (i.e. code) and falling back to the internal json string (i.e. sast) if we\n        #  somehow drift out of sync with the product enum.\n        name = USER_FRIENDLY_PRODUCT_NAMES.get(r.product, r.product.to_json())\n        findings_by_product[f\"{name}\"] += len(f)\n\n    subproject_stats: List[out.SubprojectStats] = []\n    if all_subprojects:\n        for subproject in all_subprojects:\n            if isinstance(subproject, out.UnresolvedSubproject):\n                stats = subproject_to_stats(subproject.info)\n            else:\n                stats = resolved_subproject_to_stats(subproject)\n            subproject_stats.append(stats)\n\n    complete = out.CiScanComplete(\n        exit_code=cli_suggested_exit_code,\n        dependency_parser_errors=dependency_parser_errors,\n        stats=out.CiScanCompleteStats(\n            findings=len(\n                [match for match in new_matches if not match.from_transient_scan]\n            ),\n            # We do not report errors anymore since they are large and have\n            # caused issues in the past with overloading api endpoints\n            #\n            # Also, we now use opentelemetry to report these, so they're not\n            # useful to us as it stands\n            # TODO: Remove this from the interface file?\n            errors=[],\n            total_time=total_time,\n            unsupported_exts=dict(ignored_ext_freqs),\n            lockfile_scan_info=dependency_counts,\n            parse_rate={\n                lang: out.ParsingStats(\n                    targets_parsed=data.num_targets - data.targets_with_errors,\n                    num_targets=data.num_targets,\n                    bytes_parsed=data.num_bytes - data.error_bytes,\n                    num_bytes=data.num_bytes,\n                )\n                for (lang, data) in parse_rate.get_errors_by_lang().items()\n            },\n            engine_requested=engine_requested.name,\n            findings_by_product=findings_by_product,\n            supply_chain_stats=out.SupplyChainStats(subproject_stats),\n        ),\n    )\n\n    if self.partial_output:\n        self.partial_output.write_text(\n            out.PartialScanResult(\n                out.PartialScanOk((self.ci_scan_results, complete)),\n            ).to_json_string()\n        )\n\n    if self.dry_run:\n        logger.info(\n            f\"Would have sent findings and ignores blob: {json.dumps(findings_and_ignores, indent=4)}\"\n        )\n        logger.info(\n            f\"Would have sent complete blob: {json.dumps(complete.to_json(), indent=4)}\"\n        )\n        return out.CiScanCompleteResponse(success=True)\n\n    # old: was also logging {json.dumps(findings_and_ignores, indent=4)}\n    # alt: save it in ~/.semgrep/logs/findings_and_ignores.json?\n    logger.debug(f\"Sending findings and ignores blob\")\n\n    results_task = progress_bar.add_task(\"Uploading scan results\")\n    response = state.app_session.post(\n        f\"{state.env.semgrep_url}/api/agent/scans/{self.scan_id}/results\",\n        timeout=state.env.upload_findings_timeout,\n        json=findings_and_ignores,\n    )\n\n    try:\n        response.raise_for_status()\n\n        res = response.json()\n        resp_errors = res[\"errors\"]\n        for error in resp_errors:\n            message = error[\"message\"]\n            click.echo(f\"Server returned following warning: {message}\", err=True)\n\n        if \"task_id\" in res:\n            complete.task_id = res[\"task_id\"]\n\n        progress_bar.update(results_task, completed=100)\n\n    except requests.RequestException as exc:\n        raise Exception(f\"API server returned this error: {response.text}\") from exc\n\n    complete_task = progress_bar.add_task(\"Finalizing scan\")\n    # The largest scans we've seen so far can take up to 30\n    # minutes to wait for completion. Eventually, this wait may\n    # be configurable as we see larger scans and increased backend\n    # load.\n    now = datetime.now().replace(tzinfo=None)\n    try_until = now + timedelta(minutes=30)\n    slow_down_after = now + timedelta(minutes=2)\n\n    while True:\n        # old: was also logging {json.dumps(complete.to_json(), indent=4)}\n        # alt: save it in ~/.semgrep/logs/complete.json?\n        logger.debug(f\"Sending /complete\")\n\n        if datetime.now().replace(tzinfo=None) > try_until:\n            # let the backend know we won't be trying again\n            complete.final_attempt = True\n\n        # mark as complete\n        response = state.app_session.post(\n            f\"{state.env.semgrep_url}/api/agent/scans/{self.scan_id}/complete\",\n            timeout=state.env.upload_findings_timeout,\n            json=complete.to_json(),\n        )\n\n        try:\n            response.raise_for_status()\n        except requests.RequestException:\n            raise Exception(\n                f\"API server at {state.env.semgrep_url} returned this error: {response.text}\"\n            )\n\n        ret = out.CiScanCompleteResponse.from_json(response.json())\n        success = ret.success\n\n        if success or complete.final_attempt:\n            progress_bar.update(complete_task, completed=100)\n            return ret\n        progress_bar.advance(complete_task)\n        sleep(5 if datetime.now().replace(tzinfo=None) < slow_down_after else 30)\n",
    "pattern_analysis": {
      "api_sequence": [
        "os.getenv",
        "os.getenv",
        "os.getenv",
        "json.dumps",
        "logger.info",
        "json.dumps",
        "logger.info",
        "logger.debug",
        "progress_bar.add_task",
        "state.app_session.post",
        "response.raise_for_status",
        "response.json",
        "progress_bar.update",
        "progress_bar.add_task",
        "datetime.now",
        "timedelta",
        "datetime.now",
        "datetime.now",
        "state.app_session.post",
        "response.raise_for_status",
        "response.json",
        "out.CiScanCompleteResponse.from_json",
        "progress_bar.update",
        "progress_bar.advance",
        "sleep"
      ],
      "api_sequence_with_args": [
        "os.getenv(\"GITHUB_TOKEN\")",
        "os.getenv(\"GITLAB_TOKEN\")",
        "os.getenv(\"BITBUCKET_TOKEN\")",
        "json.dumps(findings_and_ignores, indent=4)",
        "logger.info(f\"Would have sent findings and ignores blob: {json.dumps(findings_and_ignores, indent=4)}\")",
        "json.dumps(complete.to_json(), indent=4)",
        "logger.info(f\"Would have sent complete blob: {json.dumps(complete.to_json(), indent=4)}\")",
        "logger.debug(f\"Sending findings and ignores blob\")",
        "progress_bar.add_task(\"Uploading scan results\")",
        "state.app_session.post(f\"{state.env.semgrep_url}/api/agent/scans/{self.scan_id}/results\", timeout=state.env.upload_findings_timeout, json=findings_and_ignores)",
        "response.raise_for_status()",
        "response.json()",
        "progress_bar.update(results_task, completed=100)",
        "progress_bar.add_task(\"Finalizing scan\")",
        "datetime.now().replace(tzinfo=None)",
        "timedelta(minutes=30)",
        "datetime.now().replace(tzinfo=None)",
        "datetime.now().replace(tzinfo=None)",
        "state.app_session.post(f\"{state.env.semgrep_url}/api/agent/scans/{self.scan_id}/complete\", timeout=state.env.upload_findings_timeout, json=complete.to_json())",
        "response.raise_for_status()",
        "response.json()",
        "out.CiScanCompleteResponse.from_json(response.json())",
        "progress_bar.update(complete_task, completed=100)",
        "progress_bar.advance(complete_task)",
        "sleep(5 if datetime.now().replace(tzinfo=None) < slow_down_after else 30)"
      ],
      "mapped_sequence": [
        {
          "api_name": "os.getenv",
          "id": "get_env_var",
          "description": "Retrieves value of environment variable",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "environment_information"
        },
        {
          "api_name": "os.getenv",
          "id": "get_env_var",
          "description": "Retrieves value of environment variable",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "environment_information"
        },
        {
          "api_name": "os.getenv",
          "id": "get_env_var",
          "description": "Retrieves value of environment variable",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "environment_information"
        },
        {
          "api_name": "json.dumps",
          "id": "serialize_to_json",
          "description": "Serializes Python object to JSON string",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "logger.info",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "json.dumps",
          "id": "serialize_to_json",
          "description": "Serializes Python object to JSON string",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "logger.info",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "logger.debug",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "progress_bar.add_task",
          "id": "create_async_task",
          "description": "Creates asynchronous task for coroutine",
          "first_id": "system_operations",
          "second_id": "thread_management",
          "third_id": "thread_creation"
        },
        {
          "api_name": "state.app_session.post",
          "id": "send_http_post",
          "description": "Sends HTTP POST request with data and parameters",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_sending"
        },
        {
          "api_name": "response.raise_for_status",
          "id": "raise_http_error",
          "description": "Raises HTTPError if response status code indicates error",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "response_processing"
        },
        {
          "api_name": "response.json",
          "id": "deserialize_json_response",
          "description": "Deserializes JSON response body to Python object",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "response_processing"
        },
        {
          "api_name": "progress_bar.update",
          "id": "start_thread",
          "description": "Starts thread execution",
          "first_id": "system_operations",
          "second_id": "thread_management",
          "third_id": "thread_control"
        },
        {
          "api_name": "progress_bar.add_task",
          "id": "create_async_task",
          "description": "Creates asynchronous task for coroutine",
          "first_id": "system_operations",
          "second_id": "thread_management",
          "third_id": "thread_creation"
        },
        {
          "api_name": "datetime.now",
          "id": "parse_datetime",
          "description": "Parses string into datetime object using format",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "time_operations"
        },
        {
          "api_name": "timedelta",
          "id": "create_timedelta",
          "description": "Creates timedelta object with specified microseconds",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "time_operations"
        },
        {
          "api_name": "datetime.now",
          "id": "parse_datetime",
          "description": "Parses string into datetime object using format",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "time_operations"
        },
        {
          "api_name": "datetime.now",
          "id": "parse_datetime",
          "description": "Parses string into datetime object using format",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "time_operations"
        },
        {
          "api_name": "state.app_session.post",
          "id": "send_http_post",
          "description": "Sends HTTP POST request with data and parameters",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_sending"
        },
        {
          "api_name": "response.raise_for_status",
          "id": "raise_http_error",
          "description": "Raises HTTPError if response status code indicates error",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "response_processing"
        },
        {
          "api_name": "response.json",
          "id": "deserialize_json_response",
          "description": "Deserializes JSON response body to Python object",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "response_processing"
        },
        {
          "api_name": "out.CiScanCompleteResponse.from_json",
          "id": "deserialize_from_json",
          "description": "Deserializes JSON string to Python object",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "progress_bar.update",
          "id": "start_thread",
          "description": "Starts thread execution",
          "first_id": "system_operations",
          "second_id": "thread_management",
          "third_id": "thread_control"
        },
        {
          "api_name": "progress_bar.advance",
          "id": "start_thread",
          "description": "Starts thread execution",
          "first_id": "system_operations",
          "second_id": "thread_management",
          "third_id": "thread_control"
        },
        {
          "api_name": "sleep",
          "id": "suspend_execution",
          "description": "Suspends execution for specified seconds",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "time_operations"
        }
      ],
      "contextual_code": "@tracing.trace()\ndef report_findings(self, *, ...):\n    ...\n    token = (\n        os.getenv(\"GITHUB_TOKEN\")\n        or os.getenv(\"GITLAB_TOKEN\")\n        or os.getenv(\"BITBUCKET_TOKEN\")\n    )\n    ...\n    if self.dry_run:\n        logger.info(\n            f\"Would have sent findings and ignores blob: {json.dumps(findings_and_ignores, indent=4)}\"\n        )\n        logger.info(\n            f\"Would have sent complete blob: {json.dumps(complete.to_json(), indent=4)}\"\n        )\n        return out.CiScanCompleteResponse(success=True)\n    logger.debug(f\"Sending findings and ignores blob\")\n    results_task = progress_bar.add_task(\"Uploading scan results\")\n    response = state.app_session.post(\n        f\"{state.env.semgrep_url}/api/agent/scans/{self.scan_id}/results\",\n        timeout=state.env.upload_findings_timeout,\n        json=findings_and_ignores,\n    )\n    try:\n        response.raise_for_status()\n        res = response.json()\n        ...\n        progress_bar.update(results_task, completed=100)\n    except requests.RequestException as exc:\n        raise Exception(f\"API server returned this error: {response.text}\") from exc\n    complete_task = progress_bar.add_task(\"Finalizing scan\")\n    now = datetime.now().replace(tzinfo=None)\n    try_until = now + timedelta(minutes=30)\n    slow_down_after = now + timedelta(minutes=2)\n    while True:\n        logger.debug(f\"Sending /complete\")\n        if datetime.now().replace(tzinfo=None) > try_until:\n            complete.final_attempt = True\n        response = state.app_session.post(\n            f\"{state.env.semgrep_url}/api/agent/scans/{self.scan_id}/complete\",\n            timeout=state.env.upload_findings_timeout,\n            json=complete.to_json(),\n        )\n        try:\n            response.raise_for_status()\n        except requests.RequestException:\n            raise Exception(\n                f\"API server at {state.env.semgrep_url} returned this error: {response.text}\"\n            )\n        ret = out.CiScanCompleteResponse.from_json(response.json())\n        success = ret.success\n        if success or complete.final_attempt:\n            progress_bar.update(complete_task, completed=100)\n            return ret\n        progress_bar.advance(complete_task)\n        sleep(5 if datetime.now().replace(tzinfo=None) < slow_down_after else 30)\n"
    }
  }
]