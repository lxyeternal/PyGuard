[
  {
    "metadata": {
      "package_name": "clearml-1.18.0-py2.py3-none-any",
      "total_matches": 1,
      "processing_date": "2025-05-18 01:49:40"
    }
  },
  {
    "pyfile": "mp.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/clearml-1.18.0-py2.py3-none-any/clearml/utilities/process/mp.py",
    "line_number": "276",
    "type_description": "B839:pool",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "275\t    \"\"\"\n276\t    __thread_pool = SingletonThreadPool()\n277",
    "code_snippet": "class SafeQueue(object):\n    \"\"\"\n    Many writers Single Reader multiprocessing safe Queue\n    \"\"\"\n    __thread_pool = SingletonThreadPool()\n\n    def __init__(self, *args, **kwargs):\n        self._reader_thread = None\n        self._reader_thread_started = False\n        # Fix the python Queue and Use SimpleQueue write so it uses a single OS write,\n        # making it atomic message passing\n        self._q = SimpleQueue(*args, **kwargs)\n\n        # on Windows, queue communication is done via pipes, no need to override the _send_bytes method\n        if sys.platform != 'win32':\n            # noinspection PyBroadException\n            try:\n                # noinspection PyUnresolvedReferences,PyProtectedMember\n                self._q._writer._send_bytes = partial(SafeQueue._pipe_override_send_bytes, self._q._writer)\n            except Exception:\n                pass\n\n        self._internal_q = None\n        # Note we should Never! assign a new object to `self._q_size`, just work with the initial object\n        self._q_size = []  # list of PIDs we pushed, so this is atomic.\n\n    def empty(self):\n        return self._q.empty() and (not self._internal_q or self._internal_q.empty())\n\n    def is_pending(self):\n        # check if we have pending requests to be pushed (it does not mean they were pulled)\n        # only call from main put process\n        return self._get_q_size_len() > 0\n\n    def close(self, event, timeout=3.0):\n        # wait until all pending requests pushed\n        tic = time()\n        pid = os.getpid()\n        prev_q_size = self._get_q_size_len(pid)\n        while self.is_pending():\n            if event:\n                event.set()\n            if not self.__thread_pool.is_active():\n                break\n            sleep(0.1)\n            # timeout is for the maximum time to pull a single object from the queue,\n            # this way if we get stuck we notice quickly and abort\n            if timeout and (time()-tic) > timeout:\n                if prev_q_size == self._get_q_size_len(pid):\n                    break\n                else:\n                    prev_q_size = self._get_q_size_len(pid)\n                    tic = time()\n\n    def get(self, *args, **kwargs):\n        return self._get_internal_queue(*args, **kwargs)\n\n    def batch_get(self, max_items=1000, timeout=0.2, throttle_sleep=0.1):\n        buffer = []\n        timeout_count = int(timeout/throttle_sleep)\n        empty_count = timeout_count\n        while len(buffer) < max_items:\n            while not self.empty() and len(buffer) < max_items:\n                try:\n                    buffer.append(self._get_internal_queue(block=False))\n                    empty_count = 0\n                except Empty:\n                    break\n            empty_count += 1\n            if empty_count > timeout_count or len(buffer) >= max_items:\n                break\n            sleep(throttle_sleep)\n        return buffer\n\n    def put(self, obj):\n        # not atomic when forking for the first time\n        # GIL will make sure it is atomic\n        self._q_size.append(os.getpid())\n        try:\n            # make sure the block put is done in the thread pool i.e. in the background\n            obj = pickle.dumps(obj)\n            if BackgroundMonitor.get_at_exit_state():\n                self._q_put(obj)\n                return\n            self.__thread_pool.get().apply_async(self._q_put, args=(obj, False))\n        except:  # noqa\n            pid = os.getpid()\n            p = None\n            while p != pid and self._q_size:\n                p = self._q_size.pop()\n\n    def _get_q_size_len(self, pid=None):\n        pid = pid or os.getpid()\n        return len([p for p in self._q_size if p == pid])\n\n    def _q_put(self, obj, allow_raise=True):\n        # noinspection PyBroadException\n        try:\n            self._q.put(obj)\n        except BaseException:\n            # make sure we zero the _q_size of the process dies (i.e. queue put fails)\n            self._q_size.clear()\n            if allow_raise:\n                raise\n            return\n        pid = os.getpid()\n        # GIL will make sure it is atomic\n        # pop the First \"counter\" that is ours (i.e. pid == os.getpid())\n        p = None\n        while p != pid and self._q_size:\n            p = self._q_size.pop()\n\n    def _init_reader_thread(self):\n        if not self._internal_q:\n            self._internal_q = ForkQueue()\n        if not self._reader_thread or not self._reader_thread.is_alive():\n            # read before we start the thread\n            self._reader_thread = Thread(target=self._reader_daemon)\n            self._reader_thread.daemon = True\n            self._reader_thread.start()\n            # if we have waiting results\n            # wait until thread is up and pushed some results\n            while not self._reader_thread_started:\n                sleep(0.2)\n            # just in case make sure we pulled some stuff if we had any\n            # todo: wait until a queue is not empty, but for some reason that might fail\n            sleep(1.0)\n\n    def _get_internal_queue(self, *args, **kwargs):\n        self._init_reader_thread()\n        obj = self._internal_q.get(*args, **kwargs)\n        # deserialize\n        return pickle.loads(obj)\n\n    def _reader_daemon(self):\n        self._reader_thread_started = True\n        # pull from process queue and push into thread queue\n        while True:\n            # noinspection PyBroadException\n            try:\n                obj = self._q.get()\n                if obj is None:\n                    break\n            except Exception:\n                break\n            self._internal_q.put(obj)\n\n    @staticmethod\n    def _pipe_override_send_bytes(self, buf):\n        n = len(buf)\n        # For wire compatibility with 3.2 and lower\n        header = struct.pack(\"!i\", n)\n        # Issue #20540: concatenate before sending, to avoid delays due\n        # to Nagle's algorithm on a TCP socket.\n        # Also note we want to avoid sending a 0-length buffer separately,\n        # to avoid \"broken pipe\" errors if the other end closed the pipe.\n        self._send(header + buf)\n",
    "pattern_analysis": {
      "api_sequence": [
        "sys.platform",
        "os.getpid",
        "os.getpid",
        "os.getpid",
        "os.getpid",
        "os.getpid",
        "os.getpid",
        "os.getpid",
        "os.getpid",
        "os.getpid",
        "os.getpid",
        "os.getpid"
      ],
      "api_sequence_with_args": [
        "sys.platform",
        "os.getpid()",
        "os.getpid()",
        "os.getpid()",
        "os.getpid()",
        "os.getpid()",
        "os.getpid()",
        "os.getpid()",
        "os.getpid()",
        "os.getpid()",
        "os.getpid()",
        "os.getpid()"
      ],
      "mapped_sequence": [
        {
          "api_name": "sys.platform",
          "id": "get_os_id",
          "description": "Retrieves operating system identifier",
          "first_id": "information_gathering",
          "second_id": "system_information_collection",
          "third_id": "os_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        },
        {
          "api_name": "os.getpid",
          "id": "get_process_info",
          "description": "Retrieves process information as dictionary",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_information"
        }
      ],
      "contextual_code": "if sys.platform != 'win32':\n    try:\n        self._q._writer._send_bytes = partial(SafeQueue._pipe_override_send_bytes, self._q._writer)\n    except Exception:\n        pass\n\n# ...\n\ndef close(self, event, timeout=3.0):\n    tic = time()\n    pid = os.getpid()\n    prev_q_size = self._get_q_size_len(pid)\n    while self.is_pending():\n        if event:\n            event.set()\n        if not self.__thread_pool.is_active():\n            break\n        sleep(0.1)\n        if timeout and (time()-tic) > timeout:\n            if prev_q_size == self._get_q_size_len(pid):\n                break\n            else:\n                prev_q_size = self._get_q_size_len(pid)\n                tic = time()\n\n# ...\n\ndef put(self, obj):\n    self._q_size.append(os.getpid())\n    try:\n        obj = pickle.dumps(obj)\n        if BackgroundMonitor.get_at_exit_state():\n            self._q_put(obj)\n            return\n        self.__thread_pool.get().apply_async(self._q_put, args=(obj, False))\n    except:  # noqa\n        pid = os.getpid()\n        p = None\n        while p != pid and self._q_size:\n            p = self._q_size.pop()\n\n# ...\n\ndef _get_q_size_len(self, pid=None):\n    pid = pid or os.getpid()\n    return len([p for p in self._q_size if p == pid])\n\n# ...\n\ndef _q_put(self, obj, allow_raise=True):\n    try:\n        self._q.put(obj)\n    except BaseException:\n        self._q_size.clear()\n        if allow_raise:\n            raise\n        return\n    pid = os.getpid()\n    p = None\n    while p != pid and self._q_size:\n        p = self._q_size.pop()\n"
    }
  }
]