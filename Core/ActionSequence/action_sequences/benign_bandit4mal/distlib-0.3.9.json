[
  {
    "metadata": {
      "package_name": "distlib-0.3.9",
      "total_matches": 2,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "wheel.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/distlib-0.3.9/distlib-0.3.9/distlib/wheel.py",
    "line_number": "336",
    "type_description": "B802:b64encode",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "335\t        result = hasher(data).digest()\n336\t        result = base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')\n337\t        return hash_kind, result",
    "code_snippet": "def get_hash(self, data, hash_kind=None):\n    if hash_kind is None:\n        hash_kind = self.hash_kind\n    try:\n        hasher = getattr(hashlib, hash_kind)\n    except AttributeError:\n        raise DistlibException('Unsupported hash algorithm: %r' % hash_kind)\n    result = hasher(data).digest()\n    result = base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')\n    return hash_kind, result",
    "pattern_analysis": {
      "api_sequence": [
        "getattr",
        "hashlib.<hash_kind>",
        "base64.urlsafe_b64encode",
        "bytes.rstrip",
        "bytes.decode"
      ],
      "api_sequence_with_args": [
        "getattr(hashlib, hash_kind)",
        "hashlib.<hash_kind>(data).digest()",
        "base64.urlsafe_b64encode(result)",
        "base64.urlsafe_b64encode(result).rstrip(b'=')",
        "base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')"
      ],
      "mapped_sequence": [
        {
          "api_name": "hashlib.<hash_kind>",
          "id": "create_sha256_hash",
          "description": "Creates SHA-256 hash object from encoded string",
          "first_id": "encryption_hashing",
          "second_id": "hash_calculation",
          "third_id": "hash_object_creation"
        },
        {
          "api_name": "base64.urlsafe_b64encode",
          "id": "encode_bytes_to_base64",
          "description": "Encodes bytes to base64-encoded bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "base_encoding"
        }
      ],
      "contextual_code": "def get_hash(self, data, hash_kind=None):\n    if hash_kind is None:\n        hash_kind = self.hash_kind\n    try:\n        hasher = getattr(hashlib, hash_kind)\n    except AttributeError:\n        raise DistlibException('Unsupported hash algorithm: %r' % hash_kind)\n    result = hasher(data).digest()\n    result = base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')\n    return hash_kind, result"
    }
  },
  {
    "pyfile": "wheel.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/distlib-0.3.9/distlib-0.3.9/distlib/wheel.py",
    "line_number": "732",
    "type_description": "B836:rmtree",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "731\t            finally:\n732\t                shutil.rmtree(workdir)\n733",
    "code_snippet": "def install(self, paths, maker, **kwargs):\n    \"\"\"\n    Install a wheel to the specified paths. If kwarg ``warner`` is\n    specified, it should be a callable, which will be called with two\n    tuples indicating the wheel version of this software and the wheel\n    version in the file, if there is a discrepancy in the versions.\n    This can be used to issue any warnings to raise any exceptions.\n    If kwarg ``lib_only`` is True, only the purelib/platlib files are\n    installed, and the headers, scripts, data and dist-info metadata are\n    not written. If kwarg ``bytecode_hashed_invalidation`` is True, written\n    bytecode will try to use file-hash based invalidation (PEP-552) on\n    supported interpreter versions (CPython 3.7+).\n\n    The return value is a :class:`InstalledDistribution` instance unless\n    ``options.lib_only`` is True, in which case the return value is ``None``.\n    \"\"\"\n\n    dry_run = maker.dry_run\n    warner = kwargs.get('warner')\n    lib_only = kwargs.get('lib_only', False)\n    bc_hashed_invalidation = kwargs.get('bytecode_hashed_invalidation', False)\n\n    pathname = os.path.join(self.dirname, self.filename)\n    name_ver = '%s-%s' % (self.name, self.version)\n    data_dir = '%s.data' % name_ver\n    info_dir = '%s.dist-info' % name_ver\n\n    metadata_name = posixpath.join(info_dir, LEGACY_METADATA_FILENAME)\n    wheel_metadata_name = posixpath.join(info_dir, 'WHEEL')\n    record_name = posixpath.join(info_dir, 'RECORD')\n\n    wrapper = codecs.getreader('utf-8')\n\n    with ZipFile(pathname, 'r') as zf:\n        with zf.open(wheel_metadata_name) as bwf:\n            wf = wrapper(bwf)\n            message = message_from_file(wf)\n        wv = message['Wheel-Version'].split('.', 1)\n        file_version = tuple([int(i) for i in wv])\n        if (file_version != self.wheel_version) and warner:\n            warner(self.wheel_version, file_version)\n\n        if message['Root-Is-Purelib'] == 'true':\n            libdir = paths['purelib']\n        else:\n            libdir = paths['platlib']\n\n        records = {}\n        with zf.open(record_name) as bf:\n            with CSVReader(stream=bf) as reader:\n                for row in reader:\n                    p = row[0]\n                    records[p] = row\n\n        data_pfx = posixpath.join(data_dir, '')\n        info_pfx = posixpath.join(info_dir, '')\n        script_pfx = posixpath.join(data_dir, 'scripts', '')\n\n        # make a new instance rather than a copy of maker's,\n        # as we mutate it\n        fileop = FileOperator(dry_run=dry_run)\n        fileop.record = True  # so we can rollback if needed\n\n        bc = not sys.dont_write_bytecode  # Double negatives. Lovely!\n\n        outfiles = []  # for RECORD writing\n\n        # for script copying/shebang processing\n        workdir = tempfile.mkdtemp()\n        # set target dir later\n        # we default add_launchers to False, as the\n        # Python Launcher should be used instead\n        maker.source_dir = workdir\n        maker.target_dir = None\n        try:\n            for zinfo in zf.infolist():\n                arcname = zinfo.filename\n                if isinstance(arcname, text_type):\n                    u_arcname = arcname\n                else:\n                    u_arcname = arcname.decode('utf-8')\n                if self.skip_entry(u_arcname):\n                    continue\n                row = records[u_arcname]\n                if row[2] and str(zinfo.file_size) != row[2]:\n                    raise DistlibException('size mismatch for '\n                                           '%s' % u_arcname)\n                if row[1]:\n                    kind, value = row[1].split('=', 1)\n                    with zf.open(arcname) as bf:\n                        data = bf.read()\n                    _, digest = self.get_hash(data, kind)\n                    if digest != value:\n                        raise DistlibException('digest mismatch for '\n                                               '%s' % arcname)\n\n                if lib_only and u_arcname.startswith((info_pfx, data_pfx)):\n                    logger.debug('lib_only: skipping %s', u_arcname)\n                    continue\n                is_script = (u_arcname.startswith(script_pfx) and not u_arcname.endswith('.exe'))\n\n                if u_arcname.startswith(data_pfx):\n                    _, where, rp = u_arcname.split('/', 2)\n                    outfile = os.path.join(paths[where], convert_path(rp))\n                else:\n                    # meant for site-packages.\n                    if u_arcname in (wheel_metadata_name, record_name):\n                        continue\n                    outfile = os.path.join(libdir, convert_path(u_arcname))\n                if not is_script:\n                    with zf.open(arcname) as bf:\n                        fileop.copy_stream(bf, outfile)\n                    # Issue #147: permission bits aren't preserved. Using\n                    # zf.extract(zinfo, libdir) should have worked, but didn't,\n                    # see https://www.thetopsites.net/article/53834422.shtml\n                    # So ... manually preserve permission bits as given in zinfo\n                    if os.name == 'posix':\n                        # just set the normal permission bits\n                        os.chmod(outfile, (zinfo.external_attr >> 16) & 0x1FF)\n                    outfiles.append(outfile)\n                    # Double check the digest of the written file\n                    if not dry_run and row[1]:\n                        with open(outfile, 'rb') as bf:\n                            data = bf.read()\n                            _, newdigest = self.get_hash(data, kind)\n                            if newdigest != digest:\n                                raise DistlibException('digest mismatch '\n                                                       'on write for '\n                                                       '%s' % outfile)\n                    if bc and outfile.endswith('.py'):\n                        try:\n                            pyc = fileop.byte_compile(outfile, hashed_invalidation=bc_hashed_invalidation)\n                            outfiles.append(pyc)\n                        except Exception:\n                            # Don't give up if byte-compilation fails,\n                            # but log it and perhaps warn the user\n                            logger.warning('Byte-compilation failed', exc_info=True)\n                else:\n                    fn = os.path.basename(convert_path(arcname))\n                    workname = os.path.join(workdir, fn)\n                    with zf.open(arcname) as bf:\n                        fileop.copy_stream(bf, workname)\n\n                    dn, fn = os.path.split(outfile)\n                    maker.target_dir = dn\n                    filenames = maker.make(fn)\n                    fileop.set_executable_mode(filenames)\n                    outfiles.extend(filenames)\n\n            if lib_only:\n                logger.debug('lib_only: returning None')\n                dist = None\n            else:\n                # Generate scripts\n\n                # Try to get pydist.json so we can see if there are\n                # any commands to generate. If this fails (e.g. because\n                # of a legacy wheel), log a warning but don't give up.\n                commands = None\n                file_version = self.info['Wheel-Version']\n                if file_version == '1.0':\n                    # Use legacy info\n                    ep = posixpath.join(info_dir, 'entry_points.txt')\n                    try:\n                        with zf.open(ep) as bwf:\n                            epdata = read_exports(bwf)\n                        commands = {}\n                        for key in ('console', 'gui'):\n                            k = '%s_scripts' % key\n                            if k in epdata:\n                                commands['wrap_%s' % key] = d = {}\n                                for v in epdata[k].values():\n                                    s = '%s:%s' % (v.prefix, v.suffix)\n                                    if v.flags:\n                                        s += ' [%s]' % ','.join(v.flags)\n                                    d[v.name] = s\n                    except Exception:\n                        logger.warning('Unable to read legacy script '\n                                       'metadata, so cannot generate '\n                                       'scripts')\n                else:\n                    try:\n                        with zf.open(metadata_name) as bwf:\n                            wf = wrapper(bwf)\n                            commands = json.load(wf).get('extensions')\n                            if commands:\n                                commands = commands.get('python.commands')\n                    except Exception:\n                        logger.warning('Unable to read JSON metadata, so '\n                                       'cannot generate scripts')\n                if commands:\n                    console_scripts = commands.get('wrap_console', {})\n                    gui_scripts = commands.get('wrap_gui', {})\n                    if console_scripts or gui_scripts:\n                        script_dir = paths.get('scripts', '')\n                        if not os.path.isdir(script_dir):\n                            raise ValueError('Valid script path not '\n                                             'specified')\n                        maker.target_dir = script_dir\n                        for k, v in console_scripts.items():\n                            script = '%s = %s' % (k, v)\n                            filenames = maker.make(script)\n                            fileop.set_executable_mode(filenames)\n\n                        if gui_scripts:\n                            options = {'gui': True}\n                            for k, v in gui_scripts.items():\n                                script = '%s = %s' % (k, v)\n                                filenames = maker.make(script, options)\n                                fileop.set_executable_mode(filenames)\n\n                p = os.path.join(libdir, info_dir)\n                dist = InstalledDistribution(p)\n\n                # Write SHARED\n                paths = dict(paths)  # don't change passed in dict\n                del paths['purelib']\n                del paths['platlib']\n                paths['lib'] = libdir\n                p = dist.write_shared_locations(paths, dry_run)\n                if p:\n                    outfiles.append(p)\n\n                # Write RECORD\n                dist.write_installed_files(outfiles, paths['prefix'], dry_run)\n            return dist\n        except Exception:  # pragma: no cover\n            logger.exception('installation failed.')\n            fileop.rollback()\n            raise\n        finally:\n            shutil.rmtree(workdir)",
    "pattern_analysis": {
      "api_sequence": [
        "os.path.join",
        "posixpath.join",
        "posixpath.join",
        "posixpath.join",
        "codecs.getreader",
        "ZipFile",
        "ZipFile.open",
        "message_from_file",
        "ZipFile.open",
        "CSVReader",
        "os.path.join",
        "os.path.join",
        "tempfile.mkdtemp",
        "shutil.rmtree",
        "os.path.basename",
        "os.path.join",
        "os.path.split",
        "os.path.isdir",
        "os.chmod",
        "open",
        "open",
        "json.load"
      ],
      "api_sequence_with_args": [
        "os.path.join(self.dirname, self.filename)",
        "posixpath.join(info_dir, LEGACY_METADATA_FILENAME)",
        "posixpath.join(info_dir, 'WHEEL')",
        "posixpath.join(info_dir, 'RECORD')",
        "codecs.getreader('utf-8')",
        "ZipFile(pathname, 'r')",
        "ZipFile.open(wheel_metadata_name)",
        "message_from_file(wf)",
        "ZipFile.open(record_name)",
        "CSVReader(stream=bf)",
        "os.path.join(paths[where], convert_path(rp))",
        "os.path.join(libdir, convert_path(u_arcname))",
        "tempfile.mkdtemp()",
        "shutil.rmtree(workdir)",
        "os.path.basename(convert_path(arcname))",
        "os.path.join(workdir, fn)",
        "os.path.split(outfile)",
        "os.path.isdir(script_dir)",
        "os.chmod(outfile, (zinfo.external_attr >> 16) & 0x1FF)",
        "open(outfile, 'rb')",
        "open(outfile, 'rb')",
        "json.load(wf)"
      ],
      "mapped_sequence": [
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "posixpath.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "posixpath.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "posixpath.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "codecs.getreader",
          "id": "create_bytes_encoded",
          "description": "Creates bytes object from encoded string",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "ZipFile",
          "id": "open_zip_read",
          "description": "Opens ZIP archive for reading",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "ZipFile.open",
          "id": "extract_zip_files",
          "description": "Extracts all files from ZIP archive to specified directory",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "message_from_file",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "ZipFile.open",
          "id": "extract_zip_files",
          "description": "Extracts all files from ZIP archive to specified directory",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "CSVReader",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "tempfile.mkdtemp",
          "id": "create_temp_dir",
          "description": "Creates temporary directory and returns its path",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "shutil.rmtree",
          "id": "delete_directory",
          "description": "Recursively deletes directory and its contents",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "os.path.basename",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.split",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.path.isdir",
          "id": "check_directory_exists",
          "description": "Checks if specified path exists and is a directory",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "os.chmod",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "open",
          "id": "basic_read_operations",
          "description": "ic file opening operations for reading (normal reading, binary reading)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "open",
          "id": "basic_read_operations",
          "description": "ic file opening operations for reading (normal reading, binary reading)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "json.load",
          "id": "deserialize_from_json",
          "description": "Deserializes JSON string to Python object",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        }
      ],
      "contextual_code": "import os\nimport posixpath\nimport codecs\nimport tempfile\nimport shutil\nfrom zipfile import ZipFile\n\n# ...\n\npathname = os.path.join(self.dirname, self.filename)\nmetadata_name = posixpath.join(info_dir, LEGACY_METADATA_FILENAME)\nwheel_metadata_name = posixpath.join(info_dir, 'WHEEL')\nrecord_name = posixpath.join(info_dir, 'RECORD')\nwrapper = codecs.getreader('utf-8')\n\nwith ZipFile(pathname, 'r') as zf:\n    with zf.open(wheel_metadata_name) as bwf:\n        wf = wrapper(bwf)\n        message = message_from_file(wf)\n    with zf.open(record_name) as bf:\n        with CSVReader(stream=bf) as reader:\n            for row in reader:\n                # ...\n                pass\n    workdir = tempfile.mkdtemp()\n    try:\n        # ...\n        if not os.path.isdir(script_dir):\n            raise ValueError('Valid script path not specified')\n        # ...\n        if os.name == 'posix':\n            os.chmod(outfile, (zinfo.external_attr >> 16) & 0x1FF)\n        if not dry_run and row[1]:\n            with open(outfile, 'rb') as bf:\n                data = bf.read()\n        # ...\n        with open(outfile, 'rb') as bf:\n            data = bf.read()\n        # ...\n        with zf.open(metadata_name) as bwf:\n            wf = wrapper(bwf)\n            commands = json.load(wf).get('extensions')\n    finally:\n        shutil.rmtree(workdir)"
    }
  }
]