[
  {
    "metadata": {
      "package_name": "catboost_dev-1.2rc0",
      "total_matches": 11,
      "processing_date": "2025-05-18 01:49:39"
    }
  },
  {
    "pyfile": "stata.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/python/pandas/py3/pandas/io/stata.py",
    "line_number": "1334",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1333\n1334\t        return [self._decode(self.path_or_buf.read(b)) for _ in range(self.nvar)]\n1335",
    "code_snippet": "def _get_varlist(self) -> list[str]:\n    # 33 in order formats, 129 in formats 118 and 119\n    b = 33 if self.format_version < 118 else 129\n    return [self._decode(self.path_or_buf.read(b)) for _ in range(self.nvar)]",
    "pattern_analysis": {
      "api_sequence": [
        "self.path_or_buf.read",
        "self._decode"
      ],
      "api_sequence_with_args": [
        "self.path_or_buf.read(b)",
        "self._decode(self.path_or_buf.read(b))"
      ],
      "mapped_sequence": [
        {
          "api_name": "self.path_or_buf.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "self._decode",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        }
      ],
      "contextual_code": "def _get_varlist(self) -> list[str]:\n    b = 33 if self.format_version < 118 else 129\n    return [self._decode(self.path_or_buf.read(b)) for _ in range(self.nvar)]"
    }
  },
  {
    "pyfile": "test_io.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/python/numpy/py3/numpy/lib/tests/test_io.py",
    "line_number": "259",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "258\t        errors = []\n259\t        threads = [threading.Thread(target=writer, args=(errors,))\n260\t                   for j in range(3)]",
    "code_snippet": "def test_savez_filename_clashes(self):\n    # Test that issue #852 is fixed\n    # and savez functions in multithreaded environment\n\n    def writer(error_list):\n        with temppath(suffix='.npz') as tmp:\n            arr = np.random.randn(500, 500)\n            try:\n                np.savez(tmp, arr=arr)\n            except OSError as err:\n                error_list.append(err)\n\n    errors = []\n    threads = [threading.Thread(target=writer, args=(errors,))\n               for j in range(3)]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n\n    if errors:\n        raise AssertionError(errors)",
    "pattern_analysis": {
      "api_sequence": [
        "temppath",
        "numpy.random.randn",
        "numpy.savez",
        "threading.Thread",
        "threading.Thread.start",
        "threading.Thread.join"
      ],
      "api_sequence_with_args": [
        "temppath(suffix='.npz')",
        "numpy.random.randn(500, 500)",
        "numpy.savez(tmp, arr=arr)",
        "threading.Thread(target=writer, args=(errors,))",
        "threading.Thread.start()",
        "threading.Thread.join()"
      ],
      "mapped_sequence": [
        {
          "api_name": "temppath",
          "id": "create_temp_file",
          "description": "Creates temporary file that is not deleted on close",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "numpy.random.randn",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "numpy.savez",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "threading.Thread",
          "id": "create_thread",
          "description": "Creates new thread to execute target function",
          "first_id": "system_operations",
          "second_id": "thread_management",
          "third_id": "thread_creation"
        },
        {
          "api_name": "threading.Thread.start",
          "id": "start_thread",
          "description": "Starts thread execution",
          "first_id": "system_operations",
          "second_id": "thread_management",
          "third_id": "thread_control"
        },
        {
          "api_name": "threading.Thread.join",
          "id": "wait_thread",
          "description": "Waits for thread to finish execution",
          "first_id": "system_operations",
          "second_id": "thread_management",
          "third_id": "thread_control"
        }
      ],
      "contextual_code": "def writer(error_list):\n    with temppath(suffix='.npz') as tmp:\n        arr = np.random.randn(500, 500)\n        try:\n            np.savez(tmp, arr=arr)\n        except OSError as err:\n            error_list.append(err)\n\nerrors = []\nthreads = [threading.Thread(target=writer, args=(errors,)) for j in range(3)]\nfor t in threads:\n    t.start()\nfor t in threads:\n    t.join()"
    }
  },
  {
    "pyfile": "stata.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/python/pandas/py3/pandas/io/stata.py",
    "line_number": "1254",
    "type_description": "B814:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1253\n1254\t        self.path_or_buf.read(8)  # <characteristics>\n1255\t        self.data_location = (",
    "code_snippet": "def _read_new_header(self) -> None:\n    # The first part of the header is common to 117 - 119.\n    self.path_or_buf.read(27)  # stata_dta><header><release>\n    self.format_version = int(self.path_or_buf.read(3))\n    if self.format_version not in [117, 118, 119]:\n        raise ValueError(_version_error.format(version=self.format_version))\n    self._set_encoding()\n    self.path_or_buf.read(21)  # </release><byteorder>\n    self.byteorder = self.path_or_buf.read(3) == b\"MSF\" and \">\" or \"<\"\n    self.path_or_buf.read(15)  # </byteorder><K>\n    nvar_type = \"H\" if self.format_version <= 118 else \"I\"\n    nvar_size = 2 if self.format_version <= 118 else 4\n    self.nvar = struct.unpack(\n        self.byteorder + nvar_type, self.path_or_buf.read(nvar_size)\n    )[0]\n    self.path_or_buf.read(7)  # </K><N>\n\n    self.nobs = self._get_nobs()\n    self.path_or_buf.read(11)  # </N><label>\n    self._data_label = self._get_data_label()\n    self.path_or_buf.read(19)  # </label><timestamp>\n    self.time_stamp = self._get_time_stamp()\n    self.path_or_buf.read(26)  # </timestamp></header><map>\n    self.path_or_buf.read(8)  # 0x0000000000000000\n    self.path_or_buf.read(8)  # position of <map>\n\n    self._seek_vartypes = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 16\n    )\n    self._seek_varnames = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 10\n    )\n    self._seek_sortlist = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 10\n    )\n    self._seek_formats = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 9\n    )\n    self._seek_value_label_names = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 19\n    )\n\n    # Requires version-specific treatment\n    self._seek_variable_labels = self._get_seek_variable_labels()\n\n    self.path_or_buf.read(8)  # <characteristics>\n    self.data_location = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 6\n    )\n    self.seek_strls = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 7\n    )\n    self.seek_value_labels = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 14\n    )\n\n    self.typlist, self.dtyplist = self._get_dtypes(self._seek_vartypes)\n\n    self.path_or_buf.seek(self._seek_varnames)\n    self.varlist = self._get_varlist()\n\n    self.path_or_buf.seek(self._seek_sortlist)\n    self.srtlist = struct.unpack(\n        self.byteorder + (\"h\" * (self.nvar + 1)),\n        self.path_or_buf.read(2 * (self.nvar + 1)),\n    )[:-1]\n\n    self.path_or_buf.seek(self._seek_formats)\n    self.fmtlist = self._get_fmtlist()\n\n    self.path_or_buf.seek(self._seek_value_label_names)\n    self.lbllist = self._get_lbllist()\n\n    self.path_or_buf.seek(self._seek_variable_labels)\n    self._variable_labels = self._get_variable_labels()",
    "pattern_analysis": {
      "api_sequence": [
        "self.path_or_buf.read",
        "self.path_or_buf.read",
        "self.path_or_buf.read",
        "self.path_or_buf.read",
        "struct.unpack",
        "self.path_or_buf.read",
        "self._get_nobs",
        "self.path_or_buf.read",
        "self._get_data_label",
        "self.path_or_buf.read",
        "self._get_time_stamp",
        "self.path_or_buf.read",
        "self.path_or_buf.read",
        "self.path_or_buf.read",
        "struct.unpack",
        "self.path_or_buf.read",
        "struct.unpack",
        "self.path_or_buf.read",
        "struct.unpack",
        "self.path_or_buf.read",
        "struct.unpack",
        "self.path_or_buf.read",
        "self._get_seek_variable_labels",
        "self.path_or_buf.read",
        "struct.unpack",
        "self.path_or_buf.read",
        "struct.unpack",
        "self.path_or_buf.read",
        "struct.unpack",
        "self._get_dtypes",
        "self.path_or_buf.seek",
        "self._get_varlist",
        "self.path_or_buf.seek",
        "struct.unpack",
        "self.path_or_buf.read",
        "self.path_or_buf.seek",
        "self._get_fmtlist",
        "self.path_or_buf.seek",
        "self._get_lbllist",
        "self.path_or_buf.seek",
        "self._get_variable_labels"
      ],
      "api_sequence_with_args": [
        "self.path_or_buf.read(27)",
        "self.path_or_buf.read(3)",
        "self.path_or_buf.read(21)",
        "self.path_or_buf.read(15)",
        "struct.unpack(self.byteorder + nvar_type, self.path_or_buf.read(nvar_size))",
        "self.path_or_buf.read(7)",
        "self._get_nobs()",
        "self.path_or_buf.read(11)",
        "self._get_data_label()",
        "self.path_or_buf.read(19)",
        "self._get_time_stamp()",
        "self.path_or_buf.read(26)",
        "self.path_or_buf.read(8)",
        "self.path_or_buf.read(8)",
        "struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))",
        "self.path_or_buf.read(8)",
        "struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))",
        "self.path_or_buf.read(8)",
        "struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))",
        "self.path_or_buf.read(8)",
        "struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))",
        "self.path_or_buf.read(8)",
        "self._get_seek_variable_labels()",
        "self.path_or_buf.read(8)",
        "struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))",
        "self.path_or_buf.read(8)",
        "struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))",
        "self.path_or_buf.read(8)",
        "struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))",
        "self._get_dtypes(self._seek_vartypes)",
        "self.path_or_buf.seek(self._seek_varnames)",
        "self._get_varlist()",
        "self.path_or_buf.seek(self._seek_sortlist)",
        "struct.unpack(self.byteorder + (\"h\" * (self.nvar + 1)), self.path_or_buf.read(2 * (self.nvar + 1)))",
        "self.path_or_buf.read(2 * (self.nvar + 1))",
        "self.path_or_buf.seek(self._seek_formats)",
        "self._get_fmtlist()",
        "self.path_or_buf.seek(self._seek_value_label_names)",
        "self._get_lbllist()",
        "self.path_or_buf.seek(self._seek_variable_labels)",
        "self._get_variable_labels()"
      ],
      "mapped_sequence": [
        {
          "api_name": "self.path_or_buf.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        },
        {
          "api_name": "struct.unpack",
          "id": "deserialize_from_bytes",
          "description": "Deserializes Python object from bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "self.path_or_buf.seek",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        }
      ],
      "contextual_code": "def _read_new_header(self) -> None:\n    self.path_or_buf.read(27)\n    self.format_version = int(self.path_or_buf.read(3))\n    if self.format_version not in [117, 118, 119]:\n        raise ValueError(_version_error.format(version=self.format_version))\n    self._set_encoding()\n    self.path_or_buf.read(21)\n    self.byteorder = self.path_or_buf.read(3) == b\"MSF\" and \">\" or \"<\"\n    self.path_or_buf.read(15)\n    nvar_type = \"H\" if self.format_version <= 118 else \"I\"\n    nvar_size = 2 if self.format_version <= 118 else 4\n    self.nvar = struct.unpack(\n        self.byteorder + nvar_type, self.path_or_buf.read(nvar_size)\n    )[0]\n    self.path_or_buf.read(7)\n    self.nobs = self._get_nobs()\n    self.path_or_buf.read(11)\n    self._data_label = self._get_data_label()\n    self.path_or_buf.read(19)\n    self.time_stamp = self._get_time_stamp()\n    self.path_or_buf.read(26)\n    self.path_or_buf.read(8)\n    self.path_or_buf.read(8)\n    self._seek_vartypes = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 16\n    )\n    self._seek_varnames = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 10\n    )\n    self._seek_sortlist = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 10\n    )\n    self._seek_formats = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 9\n    )\n    self._seek_value_label_names = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 19\n    )\n    self._seek_variable_labels = self._get_seek_variable_labels()\n    self.path_or_buf.read(8)\n    self.data_location = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 6\n    )\n    self.seek_strls = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 7\n    )\n    self.seek_value_labels = (\n        struct.unpack(self.byteorder + \"q\", self.path_or_buf.read(8))[0] + 14\n    )\n    self.typlist, self.dtyplist = self._get_dtypes(self._seek_vartypes)\n    self.path_or_buf.seek(self._seek_varnames)\n    self.varlist = self._get_varlist()\n    self.path_or_buf.seek(self._seek_sortlist)\n    self.srtlist = struct.unpack(\n        self.byteorder + (\"h\" * (self.nvar + 1)),\n        self.path_or_buf.read(2 * (self.nvar + 1)),\n    )[:-1]\n    self.path_or_buf.seek(self._seek_formats)\n    self.fmtlist = self._get_fmtlist()\n    self.path_or_buf.seek(self._seek_value_label_names)\n    self.lbllist = self._get_lbllist()\n    self.path_or_buf.seek(self._seek_variable_labels)\n    self._variable_labels = self._get_variable_labels()"
    }
  },
  {
    "pyfile": "script.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/python/ipython/py2/IPython/core/magics/script.py",
    "line_number": "237",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "236\t        \"\"\"callback for running the script in the background\"\"\"\n237\t        p.stdin.write(cell)\n238\t        p.stdin.close()",
    "code_snippet": "def _run_script(self, p, cell):\n    \"\"\"callback for running the script in the background\"\"\"\n    p.stdin.write(cell)\n    p.stdin.close()\n    p.wait()",
    "pattern_analysis": {
      "api_sequence": [
        "p.stdin.write",
        "p.stdin.close",
        "p.wait"
      ],
      "api_sequence_with_args": [
        "p.stdin.write(cell)",
        "p.stdin.close()",
        "p.wait()"
      ],
      "mapped_sequence": [
        {
          "api_name": "p.stdin.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "p.stdin.close",
          "id": "close_file",
          "description": "Closes the opened file",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_closing"
        },
        {
          "api_name": "p.wait",
          "id": "wait_process_completion",
          "description": "Waits for process to complete execution",
          "first_id": "system_operations",
          "second_id": "process_management",
          "third_id": "process_control"
        }
      ],
      "contextual_code": "def _run_script(self, p, cell):\n    \"\"\"callback for running the script in the background\"\"\"\n    p.stdin.write(cell)\n    p.stdin.close()\n    p.wait()"
    }
  },
  {
    "pyfile": "forkedfunc.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/python/py/py/_process/forkedfunc.py",
    "line_number": "20",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "19\t        def write(self, data):\n20\t            f.write(data)\n21\t            f.flush()",
    "code_snippet": "def get_unbuffered_io(fd, filename):\n    f = open(str(filename), \"w\")\n    if fd != f.fileno():\n        os.dup2(f.fileno(), fd)\n    class AutoFlush:\n        def write(self, data):\n            f.write(data)\n            f.flush()\n        def __getattr__(self, name):\n            return getattr(f, name)\n    return AutoFlush()",
    "pattern_analysis": {
      "api_sequence": [
        "open",
        "str",
        "os.dup2",
        "f.fileno",
        "f.write",
        "f.flush",
        "getattr"
      ],
      "api_sequence_with_args": [
        "open(str(filename), \"w\")",
        "str(filename)",
        "os.dup2(f.fileno(), fd)",
        "f.fileno()",
        "f.write(data)",
        "f.flush()",
        "getattr(f, name)"
      ],
      "mapped_sequence": [
        {
          "api_name": "open",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "str",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.dup2",
          "id": "dup_socket_stdout",
          "description": "Duplicates socket file descriptor to standard output",
          "first_id": "basic_network_operations",
          "second_id": "socket_communication",
          "third_id": "connection_management"
        },
        {
          "api_name": "f.fileno",
          "id": "get_socket_fd",
          "description": "Retrieves file descriptor for socket object",
          "first_id": "basic_network_operations",
          "second_id": "socket_communication",
          "third_id": "connection_management"
        },
        {
          "api_name": "f.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "f.flush",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "getattr",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        }
      ],
      "contextual_code": "def get_unbuffered_io(fd, filename):\n    f = open(str(filename), \"w\")\n    if fd != f.fileno():\n        os.dup2(f.fileno(), fd)\n    class AutoFlush:\n        def write(self, data):\n            f.write(data)\n            f.flush()\n        def __getattr__(self, name):\n            return getattr(f, name)\n    return AutoFlush()"
    }
  },
  {
    "pyfile": "libpython.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/tools/cython/Cython/Debugger/libpython.py",
    "line_number": "1666",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "1665\t            else:\n1666\t                sys.stdout.write('#%i\\n' % self.get_index())\n1667",
    "code_snippet": "def print_summary(self):\n    if self.is_evalframe():\n        pyop = self.get_pyop()\n        if pyop:\n            line = pyop.get_truncated_repr(MAX_OUTPUT_LEN)\n            write_unicode(sys.stdout, '#%i %s\\n' % (self.get_index(), line))\n            if not pyop.is_optimized_out():\n                line = pyop.current_line()\n                if line is not None:\n                    sys.stdout.write('    %s\\n' % line.strip())\n        else:\n            sys.stdout.write('#%i (unable to read python frame information)\\n' % self.get_index())\n    else:\n        info = self.is_other_python_frame()\n        if info:\n            sys.stdout.write('#%i %s\\n' % (self.get_index(), info))\n        else:\n            sys.stdout.write('#%i\\n' % self.get_index())",
    "pattern_analysis": {
      "api_sequence": [
        "self.is_evalframe",
        "self.get_pyop",
        "pyop.get_truncated_repr",
        "self.get_index",
        "write_unicode",
        "pyop.is_optimized_out",
        "pyop.current_line",
        "sys.stdout.write",
        "self.get_index",
        "sys.stdout.write",
        "self.is_other_python_frame",
        "self.get_index",
        "sys.stdout.write",
        "self.get_index",
        "sys.stdout.write"
      ],
      "api_sequence_with_args": [
        "self.is_evalframe()",
        "self.get_pyop()",
        "pyop.get_truncated_repr(MAX_OUTPUT_LEN)",
        "self.get_index()",
        "write_unicode(sys.stdout, '#%i %s\\n' % (self.get_index(), line))",
        "pyop.is_optimized_out()",
        "pyop.current_line()",
        "sys.stdout.write('    %s\\n' % line.strip())",
        "self.get_index()",
        "sys.stdout.write('#%i (unable to read python frame information)\\n' % self.get_index())",
        "self.is_other_python_frame()",
        "self.get_index()",
        "sys.stdout.write('#%i %s\\n' % (self.get_index(), info))",
        "self.get_index()",
        "sys.stdout.write('#%i\\n' % self.get_index())"
      ],
      "mapped_sequence": [
        {
          "api_name": "sys.stdout.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        }
      ],
      "contextual_code": "def print_summary(self):\n    if self.is_evalframe():\n        pyop = self.get_pyop()\n        if pyop:\n            line = pyop.get_truncated_repr(MAX_OUTPUT_LEN)\n            write_unicode(sys.stdout, '#%i %s\\n' % (self.get_index(), line))\n            if not pyop.is_optimized_out():\n                line = pyop.current_line()\n                if line is not None:\n                    sys.stdout.write('    %s\\n' % line.strip())\n        else:\n            sys.stdout.write('#%i (unable to read python frame information)\\n' % self.get_index())\n    else:\n        info = self.is_other_python_frame()\n        if info:\n            sys.stdout.write('#%i %s\\n' % (self.get_index(), info))\n        else:\n            sys.stdout.write('#%i\\n' % self.get_index())"
    }
  },
  {
    "pyfile": "stata.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/python/pandas/py2/pandas/io/stata.py",
    "line_number": "706",
    "type_description": "B815:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "705\t        for offset in self.off:\n706\t            bio.write(struct.pack(byteorder + 'i', offset))\n707",
    "code_snippet": "def generate_value_label(self, byteorder, encoding):\n    \"\"\"\n    Parameters\n    ----------\n    byteorder : str\n        Byte order of the output\n    encoding : str\n        File encoding\n\n    Returns\n    -------\n    value_label : bytes\n        Bytes containing the formatted value label\n    \"\"\"\n\n    self._encoding = encoding\n    bio = BytesIO()\n    null_string = '\\x00'\n    null_byte = b'\\x00'\n\n    # len\n    bio.write(struct.pack(byteorder + 'i', self.len))\n\n    # labname\n    labname = self._encode(_pad_bytes(self.labname[:32], 33))\n    bio.write(labname)\n\n    # padding - 3 bytes\n    for i in range(3):\n        bio.write(struct.pack('c', null_byte))\n\n    # value_label_table\n    # n - int32\n    bio.write(struct.pack(byteorder + 'i', self.n))\n\n    # textlen  - int32\n    bio.write(struct.pack(byteorder + 'i', self.text_len))\n\n    # off - int32 array (n elements)\n    for offset in self.off:\n        bio.write(struct.pack(byteorder + 'i', offset))\n\n    # val - int32 array (n elements)\n    for value in self.val:\n        bio.write(struct.pack(byteorder + 'i', value))\n\n    # txt - Text labels, null terminated\n    for text in self.txt:\n        bio.write(self._encode(text + null_string))\n\n    bio.seek(0)\n    return bio.read()",
    "pattern_analysis": {
      "api_sequence": [
        "struct.pack",
        "io.BytesIO",
        "io.BytesIO.write",
        "io.BytesIO.seek",
        "io.BytesIO.read"
      ],
      "api_sequence_with_args": [
        "struct.pack(byteorder + 'i', self.len)",
        "io.BytesIO()",
        "io.BytesIO.write(struct.pack(byteorder + 'i', self.len))",
        "io.BytesIO.seek(0)",
        "io.BytesIO.read()"
      ],
      "mapped_sequence": [
        {
          "api_name": "struct.pack",
          "id": "pack_values",
          "description": "Packs values into bytes using specified format",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "io.BytesIO",
          "id": "create_memory_bytes",
          "description": "Creates in-memory bytes buffer from encoded string",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "io.BytesIO.write",
          "id": "save_image_buffer",
          "description": "Saves image to in-memory buffer in PNG format",
          "first_id": "information_gathering",
          "second_id": "multimedia_capture",
          "third_id": "image_processing"
        },
        {
          "api_name": "io.BytesIO.seek",
          "id": "move_buffer_pointer",
          "description": "Moves buffer pointer to start",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "io.BytesIO.read",
          "id": "get_buffer_bytes",
          "description": "Retrieves bytes value from in-memory buffer",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        }
      ],
      "contextual_code": "def generate_value_label(self, byteorder, encoding):\n    self._encoding = encoding\n    bio = BytesIO()\n    null_string = '\\x00'\n    null_byte = b'\\x00'\n\n    bio.write(struct.pack(byteorder + 'i', self.len))\n    labname = self._encode(_pad_bytes(self.labname[:32], 33))\n    bio.write(labname)\n    for i in range(3):\n        bio.write(struct.pack('c', null_byte))\n    bio.write(struct.pack(byteorder + 'i', self.n))\n    bio.write(struct.pack(byteorder + 'i', self.text_len))\n    for offset in self.off:\n        bio.write(struct.pack(byteorder + 'i', offset))\n    for value in self.val:\n        bio.write(struct.pack(byteorder + 'i', value))\n    for text in self.txt:\n        bio.write(self._encode(text + null_string))\n    bio.seek(0)\n    return bio.read()"
    }
  },
  {
    "pyfile": "misc_util.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/python/numpy/py2/numpy/distutils/misc_util.py",
    "line_number": "2039",
    "type_description": "B832:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "2038\t                    f = open(target, 'w')\n2039\t                    f.write('version = %r\\n' % (version))\n2040\t                    f.close()",
    "code_snippet": "def make_svn_version_py(self, delete=True):\n    \"\"\"Appends a data function to the data_files list that will generate\n    __svn_version__.py file to the current package directory.\n\n    Generate package __svn_version__.py file from SVN revision number,\n    it will be removed after python exits but will be available\n    when sdist, etc commands are executed.\n\n    Notes\n    -----\n    If __svn_version__.py existed before, nothing is done.\n\n    This is\n    intended for working with source directories that are in an SVN\n    repository.\n    \"\"\"\n    target = njoin(self.local_path, '__svn_version__.py')\n    revision = self._get_svn_revision(self.local_path)\n    if os.path.isfile(target) or revision is None:\n        return\n    else:\n        def generate_svn_version_py():\n            if not os.path.isfile(target):\n                version = str(revision)\n                self.info('Creating %s (version=%r)' % (target, version))\n                f = open(target, 'w')\n                f.write('version = %r\\n' % (version))\n                f.close()\n\n            def rm_file(f=target,p=self.info):\n                if delete:\n                    try: os.remove(f); p('removed '+f)\n                    except OSError: pass\n                    try: os.remove(f+'c'); p('removed '+f+'c')\n                    except OSError: pass\n\n            atexit.register(rm_file)\n\n            return target\n\n        self.add_data_files(('', generate_svn_version_py()))",
    "pattern_analysis": {
      "api_sequence": [
        "os.path.isfile",
        "self._get_svn_revision",
        "os.path.isfile",
        "open",
        "open.write",
        "open.close",
        "os.path.isfile",
        "os.remove",
        "self.info",
        "os.remove",
        "self.info",
        "atexit.register",
        "self.add_data_files"
      ],
      "api_sequence_with_args": [
        "os.path.isfile(target)",
        "self._get_svn_revision(self.local_path)",
        "os.path.isfile(target)",
        "open(target, 'w')",
        "open.write('version = %r\\n' % (version))",
        "open.close()",
        "os.path.isfile(target)",
        "os.remove(f)",
        "self.info('removed '+f)",
        "os.remove(f+'c')",
        "self.info('removed '+f+'c')",
        "atexit.register(rm_file)",
        "self.add_data_files(('', generate_svn_version_py()))"
      ],
      "mapped_sequence": [
        {
          "api_name": "os.path.isfile",
          "id": "check_file_is_file",
          "description": "Checks if specified path exists and is a file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "self._get_svn_revision",
          "id": "import_dynamic",
          "description": "Dynamically imports specified module",
          "first_id": "code_execution",
          "second_id": "module_management",
          "third_id": "module_importing"
        },
        {
          "api_name": "os.path.isfile",
          "id": "check_file_is_file",
          "description": "Checks if specified path exists and is a file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "open",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "open.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "open.close",
          "id": "close_file",
          "description": "Closes the opened file",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_closing"
        },
        {
          "api_name": "os.path.isfile",
          "id": "check_file_is_file",
          "description": "Checks if specified path exists and is a file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "os.remove",
          "id": "delete_file",
          "description": "Deletes specified file from filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "self.info",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "os.remove",
          "id": "delete_file",
          "description": "Deletes specified file from filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "self.info",
          "id": "log_info",
          "description": "Logs informational message",
          "first_id": "data_exfiltration",
          "second_id": "data_collection_operations",
          "third_id": "data_acquisition"
        },
        {
          "api_name": "atexit.register",
          "id": "register_exit_function",
          "description": "Registers function to be called at program exit",
          "first_id": "persistence_stealth",
          "second_id": "persistence_mechanisms",
          "third_id": "persistence_configuration"
        },
        {
          "api_name": "self.add_data_files",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        }
      ],
      "contextual_code": "def make_svn_version_py(self, delete=True):\n    target = njoin(self.local_path, '__svn_version__.py')\n    revision = self._get_svn_revision(self.local_path)\n    if os.path.isfile(target) or revision is None:\n        return\n    else:\n        def generate_svn_version_py():\n            if not os.path.isfile(target):\n                version = str(revision)\n                self.info('Creating %s (version=%r)' % (target, version))\n                f = open(target, 'w')\n                f.write('version = %r\\n' % (version))\n                f.close()\n\n            def rm_file(f=target,p=self.info):\n                if delete:\n                    try: os.remove(f); p('removed '+f)\n                    except OSError: pass\n                    try: os.remove(f+'c'); p('removed '+f+'c')\n                    except OSError: pass\n\n            atexit.register(rm_file)\n\n            return target\n\n        self.add_data_files(('', generate_svn_version_py()))"
    }
  },
  {
    "pyfile": "TestCyCache.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/tools/cython/Cython/Build/Tests/TestCyCache.py",
    "line_number": "66",
    "type_description": "B832:write",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "65\t        a_cache = os.path.join(self.cache_dir, os.listdir(self.cache_dir)[0])\n66\t        gzip.GzipFile(a_cache, 'wb').write('fake stuff'.encode('ascii'))\n67\t        os.unlink(a_c)",
    "code_snippet": "def test_cycache_uses_cache(self):\n    a_pyx = os.path.join(self.src_dir, 'a.pyx')\n    a_c = a_pyx[:-4] + '.c'\n    open(a_pyx, 'w').write('pass')\n    self.fresh_cythonize(a_pyx, cache=self.cache_dir)\n    a_cache = os.path.join(self.cache_dir, os.listdir(self.cache_dir)[0])\n    gzip.GzipFile(a_cache, 'wb').write('fake stuff'.encode('ascii'))\n    os.unlink(a_c)\n    self.fresh_cythonize(a_pyx, cache=self.cache_dir)\n    a_contents = open(a_c).read()\n    self.assertEqual(a_contents, 'fake stuff',\n                     'Unexpected contents: %s...' % a_contents[:100])",
    "pattern_analysis": {
      "api_sequence": [
        "os.path.join",
        "open",
        "open.write",
        "self.fresh_cythonize",
        "os.path.join",
        "os.listdir",
        "gzip.GzipFile",
        "gzip.GzipFile.write",
        "os.unlink",
        "self.fresh_cythonize",
        "open",
        "open.read",
        "self.assertEqual"
      ],
      "api_sequence_with_args": [
        "os.path.join(self.src_dir, 'a.pyx')",
        "open(a_pyx, 'w')",
        "open(a_pyx, 'w').write('pass')",
        "self.fresh_cythonize(a_pyx, cache=self.cache_dir)",
        "os.path.join(self.cache_dir, os.listdir(self.cache_dir)[0])",
        "os.listdir(self.cache_dir)",
        "gzip.GzipFile(a_cache, 'wb')",
        "gzip.GzipFile(a_cache, 'wb').write('fake stuff'.encode('ascii'))",
        "os.unlink(a_c)",
        "self.fresh_cythonize(a_pyx, cache=self.cache_dir)",
        "open(a_c)",
        "open(a_c).read()",
        "self.assertEqual(a_contents, 'fake stuff', 'Unexpected contents: %s...' % a_contents[:100])"
      ],
      "mapped_sequence": [
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "open",
          "id": "basic_write_operations",
          "description": "Basic file opening operations for writing (normal writing, binary writing)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "open.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "self.fresh_cythonize",
          "id": "import_dynamic",
          "description": "Dynamically imports specified module",
          "first_id": "code_execution",
          "second_id": "module_management",
          "third_id": "module_importing"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.listdir",
          "id": "list_files_directories",
          "description": "Lists files and directories in specified path",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "gzip.GzipFile",
          "id": "open_file_app",
          "description": "Opens file with associated application",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "gzip.GzipFile.write",
          "id": "basic_file_writing",
          "description": "Writing data to files (strings or bytes)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_writing"
        },
        {
          "api_name": "os.unlink",
          "id": "delete_file",
          "description": "Deletes specified file from filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "self.fresh_cythonize",
          "id": "import_dynamic",
          "description": "Dynamically imports specified module",
          "first_id": "code_execution",
          "second_id": "module_management",
          "third_id": "module_importing"
        },
        {
          "api_name": "open",
          "id": "basic_read_operations",
          "description": "ic file opening operations for reading (normal reading, binary reading)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "open.read",
          "id": "basic_file_reading",
          "description": "Reading content from files (by lines or entire content)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_reading"
        }
      ],
      "contextual_code": "def test_cycache_uses_cache(self):\n    a_pyx = os.path.join(self.src_dir, 'a.pyx')\n    a_c = a_pyx[:-4] + '.c'\n    open(a_pyx, 'w').write('pass')\n    self.fresh_cythonize(a_pyx, cache=self.cache_dir)\n    a_cache = os.path.join(self.cache_dir, os.listdir(self.cache_dir)[0])\n    gzip.GzipFile(a_cache, 'wb').write('fake stuff'.encode('ascii'))\n    os.unlink(a_c)\n    self.fresh_cythonize(a_pyx, cache=self.cache_dir)\n    a_contents = open(a_c).read()\n    self.assertEqual(a_contents, 'fake stuff',\n                     'Unexpected contents: %s...' % a_contents[:100])"
    }
  },
  {
    "pyfile": "ssltransport.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/python/urllib3/urllib3/util/ssltransport.py",
    "line_number": "73",
    "type_description": "B830:read",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "72\t    def read(self, len=1024, buffer=None):\n73\t        return self._wrap_ssl_read(len, buffer)\n74",
    "code_snippet": "def read(self, len=1024, buffer=None):\n    return self._wrap_ssl_read(len, buffer)\n\ndef _wrap_ssl_read(self, len, buffer=None):\n    try:\n        return self._ssl_io_loop(self.sslobj.read, len, buffer)\n    except ssl.SSLError as e:\n        if e.errno == ssl.SSL_ERROR_EOF and self.suppress_ragged_eofs:\n            return 0  # eof, return 0.\n        else:\n            raise\n\ndef _ssl_io_loop(self, func, *args):\n    \"\"\"Performs an I/O loop between incoming/outgoing and the socket.\"\"\"\n    should_loop = True\n    ret = None\n\n    while should_loop:\n        errno = None\n        try:\n            ret = func(*args)\n        except ssl.SSLError as e:\n            if e.errno not in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):\n                # WANT_READ, and WANT_WRITE are expected, others are not.\n                raise e\n            errno = e.errno\n\n        buf = self.outgoing.read()\n        self.socket.sendall(buf)\n\n        if errno is None:\n            should_loop = False\n        elif errno == ssl.SSL_ERROR_WANT_READ:\n            buf = self.socket.recv(SSL_BLOCKSIZE)\n            if buf:\n                self.incoming.write(buf)\n            else:\n                self.incoming.write_eof()\n    return ret",
    "pattern_analysis": {
      "api_sequence": [
        "self.sslobj.read",
        "self.outgoing.read",
        "self.socket.sendall",
        "self.socket.recv",
        "self.incoming.write",
        "self.incoming.write_eof"
      ],
      "api_sequence_with_args": [
        "self.sslobj.read(len, buffer)",
        "self.outgoing.read()",
        "self.socket.sendall(buf)",
        "self.socket.recv(SSL_BLOCKSIZE)",
        "self.incoming.write(buf)",
        "self.incoming.write_eof()"
      ],
      "mapped_sequence": [
        {
          "api_name": "ssl.SSLSocket.read",
          "id": "read_response_bytes",
          "description": "Reads response body as bytes",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "response_processing"
        },
        {
          "api_name": "io.BytesIO.read",
          "id": "get_buffer_bytes",
          "description": "Retrieves bytes value from in-memory buffer",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "socket.socket.sendall",
          "id": "send_socket_data",
          "description": "Sends data over socket connection",
          "first_id": "basic_network_operations",
          "second_id": "socket_communication",
          "third_id": "data_transmission"
        },
        {
          "api_name": "socket.socket.recv",
          "id": "receive_socket_data",
          "description": "Receives data from socket connection",
          "first_id": "basic_network_operations",
          "second_id": "socket_communication",
          "third_id": "data_transmission"
        },
        {
          "api_name": "io.BytesIO.write",
          "id": "copy_memory",
          "description": "Copies memory from source to destination buffer",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        },
        {
          "api_name": "io.BytesIO.write_eof",
          "id": "copy_memory",
          "description": "Copies memory from source to destination buffer",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "byte_encoding"
        }
      ],
      "contextual_code": "def read(self, len=1024, buffer=None):\n    return self._wrap_ssl_read(len, buffer)\n\ndef _wrap_ssl_read(self, len, buffer=None):\n    try:\n        return self._ssl_io_loop(self.sslobj.read, len, buffer)\n    except ssl.SSLError as e:\n        if e.errno == ssl.SSL_ERROR_EOF and self.suppress_ragged_eofs:\n            return 0  # eof, return 0.\n        else:\n            raise\n\ndef _ssl_io_loop(self, func, *args):\n    should_loop = True\n    ret = None\n    while should_loop:\n        errno = None\n        try:\n            ret = func(*args)  # self.sslobj.read(len, buffer)\n        except ssl.SSLError as e:\n            if e.errno not in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):\n                raise e\n            errno = e.errno\n        buf = self.outgoing.read()\n        self.socket.sendall(buf)\n        if errno is None:\n            should_loop = False\n        elif errno == ssl.SSL_ERROR_WANT_READ:\n            buf = self.socket.recv(SSL_BLOCKSIZE)\n            if buf:\n                self.incoming.write(buf)\n            else:\n                self.incoming.write_eof()\n    return ret"
    }
  },
  {
    "pyfile": "bccache.py",
    "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/catboost_dev-1.2rc0/catboost_dev-1.2rc0/catboost_all_src/contrib/python/Jinja2/py3/jinja2/bccache.py",
    "line_number": "251",
    "type_description": "B811:getuid",
    "severity": "High",
    "confidence": "Medium",
    "original_snippet": "250\t        if (\n251\t            actual_dir_stat.st_uid != os.getuid()\n252\t            or not stat.S_ISDIR(actual_dir_stat.st_mode)",
    "code_snippet": "def _get_default_cache_dir(self) -> str:\n    def _unsafe_dir() -> \"te.NoReturn\":\n        raise RuntimeError(\n            \"Cannot determine safe temp directory.  You \"\n            \"need to explicitly provide one.\"\n        )\n\n    tmpdir = tempfile.gettempdir()\n\n    # On windows the temporary directory is used specific unless\n    # explicitly forced otherwise.  We can just use that.\n    if os.name == \"nt\":\n        return tmpdir\n    if not hasattr(os, \"getuid\"):\n        _unsafe_dir()\n\n    dirname = f\"_jinja2-cache-{os.getuid()}\"\n    actual_dir = os.path.join(tmpdir, dirname)\n\n    try:\n        os.mkdir(actual_dir, stat.S_IRWXU)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n    try:\n        os.chmod(actual_dir, stat.S_IRWXU)\n        actual_dir_stat = os.lstat(actual_dir)\n        if (\n            actual_dir_stat.st_uid != os.getuid()\n            or not stat.S_ISDIR(actual_dir_stat.st_mode)\n            or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU\n        ):\n            _unsafe_dir()\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n\n    actual_dir_stat = os.lstat(actual_dir)\n    if (\n        actual_dir_stat.st_uid != os.getuid()\n        or not stat.S_ISDIR(actual_dir_stat.st_mode)\n        or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU\n    ):\n        _unsafe_dir()\n\n    return actual_dir",
    "pattern_analysis": {
      "api_sequence": [
        "tempfile.gettempdir",
        "os.name",
        "hasattr",
        "os.getuid",
        "os.path.join",
        "os.mkdir",
        "os.chmod",
        "os.lstat",
        "os.getuid",
        "stat.S_ISDIR",
        "stat.S_IMODE",
        "os.lstat",
        "os.getuid",
        "stat.S_ISDIR",
        "stat.S_IMODE"
      ],
      "api_sequence_with_args": [
        "tempfile.gettempdir()",
        "os.name",
        "hasattr(os, 'getuid')",
        "os.getuid()",
        "os.path.join(tmpdir, dirname)",
        "os.mkdir(actual_dir, stat.S_IRWXU)",
        "os.chmod(actual_dir, stat.S_IRWXU)",
        "os.lstat(actual_dir)",
        "os.getuid()",
        "stat.S_ISDIR(actual_dir_stat.st_mode)",
        "stat.S_IMODE(actual_dir_stat.st_mode)",
        "os.lstat(actual_dir)",
        "os.getuid()",
        "stat.S_ISDIR(actual_dir_stat.st_mode)",
        "stat.S_IMODE(actual_dir_stat.st_mode)"
      ],
      "mapped_sequence": [
        {
          "api_name": "tempfile.gettempdir",
          "id": "create_temp_dir",
          "description": "Creates temporary directory and returns its path",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "os.name",
          "id": "get_os_id",
          "description": "Retrieves operating system identifier",
          "first_id": "information_gathering",
          "second_id": "system_information_collection",
          "third_id": "os_information"
        },
        {
          "api_name": "hasattr",
          "id": "check_instance_type",
          "description": "Checks if object is instance of specified type",
          "first_id": "utility_functions",
          "second_id": "logging_exception_handling",
          "third_id": "exception_checking"
        },
        {
          "api_name": "os.getuid",
          "id": "get_username",
          "description": "Retrieves current user's login name",
          "first_id": "information_gathering",
          "second_id": "system_information_collection",
          "third_id": "user_information"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.mkdir",
          "id": "create_directory",
          "description": "Creates directory, ignoring if it already exists",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "os.chmod",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "os.lstat",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.getuid",
          "id": "get_username",
          "description": "Retrieves current user's login name",
          "first_id": "information_gathering",
          "second_id": "system_information_collection",
          "third_id": "user_information"
        },
        {
          "api_name": "stat.S_ISDIR",
          "id": "check_directory_exists",
          "description": "Checks if specified path exists and is a directory",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "stat.S_IMODE",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        },
        {
          "api_name": "os.lstat",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "os.getuid",
          "id": "get_username",
          "description": "Retrieves current user's login name",
          "first_id": "information_gathering",
          "second_id": "system_information_collection",
          "third_id": "user_information"
        },
        {
          "api_name": "stat.S_ISDIR",
          "id": "check_directory_exists",
          "description": "Checks if specified path exists and is a directory",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_checking"
        },
        {
          "api_name": "stat.S_IMODE",
          "id": "set_file_attributes",
          "description": "Sets file attributes for specified file",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_attribute_management"
        }
      ],
      "contextual_code": "def _get_default_cache_dir(self) -> str:\n    def _unsafe_dir() -> \"te.NoReturn\":\n        raise RuntimeError(\n            \"Cannot determine safe temp directory.  You \"\n            \"need to explicitly provide one.\"\n        )\n\n    tmpdir = tempfile.gettempdir()\n\n    if os.name == \"nt\":\n        return tmpdir\n    if not hasattr(os, \"getuid\"):\n        _unsafe_dir()\n\n    dirname = f\"_jinja2-cache-{os.getuid()}\"\n    actual_dir = os.path.join(tmpdir, dirname)\n\n    try:\n        os.mkdir(actual_dir, stat.S_IRWXU)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n    try:\n        os.chmod(actual_dir, stat.S_IRWXU)\n        actual_dir_stat = os.lstat(actual_dir)\n        if (\n            actual_dir_stat.st_uid != os.getuid()\n            or not stat.S_ISDIR(actual_dir_stat.st_mode)\n            or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU\n        ):\n            _unsafe_dir()\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n\n    actual_dir_stat = os.lstat(actual_dir)\n    if (\n        actual_dir_stat.st_uid != os.getuid()\n        or not stat.S_ISDIR(actual_dir_stat.st_mode)\n        or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU\n    ):\n        _unsafe_dir()\n\n    return actual_dir"
    }
  }
]