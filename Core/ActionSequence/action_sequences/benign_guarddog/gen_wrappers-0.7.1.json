[
  {
    "pyfile": "creator_cmfy.py",
    "code_snippet": "import asyncio\nimport base64\nimport json\nimport logging\nimport os\nimport urllib\nimport urllib.parse\nimport urllib.request\nfrom typing import Any, List, Optional, Union, Dict, Tuple\n\nimport httpx\nimport requests\n\nfrom creator.base.base_app import BaseApp\nfrom creator.base.base_response import ResponseDataType, ResponseData, BaseResponse\nfrom creator.base.job_status import JobStatus\nfrom creator.cmfy.request_cmfy import CmfyWorkflow, CmfyWorkflowFcus, model_load_json\nfrom creator.cmfy.response_cmfy import ResponseCmfy\n\nlogger = logging.getLogger(__name__)\n\nclass AppCmfy(BaseApp):\n    param_classes = [CmfyWorkflow, CmfyWorkflowFcus]\n    output = {}\n\n    def __init__(self):\n        super().__init__()\n        focus_port = os.environ.get(\"PORT_CMFY\", 8888)\n        if isinstance(focus_port, str):\n            focus_port = int(focus_port)\n        self.api_base_url = f\"http://0.0.0.0:{focus_port}\"\n\n    async def create(self, params: Union[CmfyWorkflow, CmfyWorkflowFcus]) -> ResponseCmfy:\n        cmfy_port = os.environ.get(\"PORT_CMFY\", 8889)\n        url = f\"http://localhost:{cmfy_port}/prompt\"\n        workflow = json.loads(params.workflow_json)\n        loaded_model, is_flux, model_type = await self.get_model_from_workflow(workflow)\n        if model_type == \"checkpoint\" and loaded_model is not None:\n            self._check_loaded_model(loaded_model)\n        logger.debug(f\"CMFY data: {workflow}\")\n        # Send a POST to cmfy_url with the workflow json\n        # The response will be JSON string with the below format\n        response_json = {}\n        try:\n            headers = {'Content-Type': 'application/json'}\n            data = {\"prompt\": workflow}\n            data = json.dumps(data).encode('utf-8')\n            response = requests.post(url, data=data, headers=headers)\n            logger.debug(f\"CMFY response: {response}, {response.text}, {response.json()}\")\n            # If we have a 422 here, print what the unprocessable entity is\n            if response.status_code == 422:\n                logger.warning(f\"Unprocessable entity: {response.text}\")\n            response.raise_for_status()\n            response_json = response.json()\n        except Exception as e:\n            logger.error(f\"Error creating prompt: {e}\")\n            return ResponseCmfy.error(f\"Error creating prompt: {e} ({response_json})\")\n        # {\"prompt_id\": \"f57c69ee-f4ed-4866-b5a4-4072c17c36a8\", \"number\": 2, \"node_errors\": {}}\n        prompt_id = response_json.get(\"prompt_id\", None)\n        logger.debug(f\"Prompt ID: {prompt_id}\")\n        if prompt_id is None:\n            return ResponseCmfy.error(f\"Error creating prompt: {response_json}\")\n        status_count = 0\n        response = await self.get_status(prompt_id)\n        status = response.status\n        while status != JobStatus.FINISHED and status != JobStatus.FAILED and status_count < 10:\n            await asyncio.sleep(1)\n            response = await self.get_status(prompt_id)\n            status = response.status\n            status_count += 1\n        if status == JobStatus.FINISHED:\n            response_data = response.output\n            logger.info(f\"Success, returning response with {len(data)} images\")\n            return ResponseCmfy.success(response_data, prompt_id)\n        return ResponseCmfy.error(\"Error creating prompt\")\n\n    async def create_async(self, params: Union[CmfyWorkflow, CmfyWorkflowFcus]) -> ResponseCmfy:\n        cmfy_port = os.environ.get(\"PORT_CMFY\", 8889)\n        url = f\"http://localhost:{cmfy_port}/prompt\"\n        workflow = json.loads(params.workflow_json)\n        loaded_model, is_flux, model_type = await self.get_model_from_workflow(workflow)\n        if model_type == \"checkpoint\" and loaded_model is not None:\n            self._check_loaded_model(loaded_model)\n        logger.debug(f\"CMFY data: {workflow}\")\n        # Send a POST to cmfy_url with the workflow json\n        # The response will be JSON string with the below format\n        response_json = {}\n        try:\n            headers = {'Content-Type': 'application/json'}\n            data = {\"prompt\": workflow}\n            data = json.dumps(data).encode('utf-8')\n            response = requests.post(url, data=data, headers=headers)\n            logger.debug(f\"CMFY response: {response}, {response.text}, {response.json()}\")\n            # If we have a 422 here, print what the unprocessable entity is\n            if response.status_code == 422:\n                logger.warning(f\"Unprocessable entity: {response.text}\")\n            response.raise_for_status()\n            response_json = response.json()\n        except Exception as e:\n            logger.error(f\"Error creating prompt: {e}\")\n            return ResponseCmfy.error(f\"Error creating prompt: {e} ({response_json})\")\n        # {\"prompt_id\": \"f57c69ee-f4ed-4866-b5a4-4072c17c36a8\", \"number\": 2, \"node_errors\": {}}\n        prompt_id = response_json.get(\"prompt_id\", None)\n        logger.debug(f\"Prompt ID: {prompt_id}\")\n        if prompt_id is None:\n            return ResponseCmfy.error(f\"Error creating prompt: {response_json}\")\n        return ResponseCmfy.running(prompt_id)\n\n    async def get_status(self, job_id) -> BaseResponse:\n        url = f\"http://localhost:{os.environ.get('PORT_CMFY', 8889)}/history/{job_id}\"\n        job_data = None\n        print(f\"Getting status for job {job_id} from url {url}\")\n        logger.debug(f\"Getting status for job {job_id}\")\n        while job_data is None:\n            history = requests.get(url)\n            if history.status_code != 200:\n                return BaseResponse.error(\"Error getting job status\", job_id)\n            #logger.info(f\"History: {history.json()}\")\n            history = history.json()\n            job = history.get(job_id, None)\n            if not job:\n                continue\n            job_data = job\n\n        status = job_data.get('status', {})\n        status_str = status.get('status_str', None)\n        completed = status.get('completed', False)\n        messages = status.get('messages', [])\n        if status_str == \"success\" and completed:\n            outputs = job_data.get('outputs', {})\n            if outputs:\n                images_output = []\n                videos_output = []\n                for node_id, node_output in job_data['outputs'].items():\n                    # TODO: Add handler here for animated images, etc.\n                    if 'images' in node_output:\n                        logger.debug(f\"Node output: {node_output}\")\n                        for image in node_output['images']:\n                            logger.debug(f\"Getting image: {image['filename']}\")\n                            print(f\"Getting image: {image['filename']}\")\n                            image_data = await self._get_image(image['filename'], image['subfolder'], image['type'])\n                            images_output.append(image_data)\n                        print(f\"We are returning {len(images_output)} images\")\n                        response_data = ResponseData(data=images_output, data_type=ResponseDataType.IMAGE,\n                                                     total_count=len(images_output))\n                        return ResponseCmfy.success(data=response_data)\n                    if 'gifs' in node_output:\n                        output_is_gif = False\n                        print(f\"Node output: {node_output}\")\n                        for gif in node_output['gifs']:\n                            print(f\"Getting gif: {gif['filename']}\")\n                            gif_data = await self._get_image(gif['filename'], gif['subfolder'], gif['type'])\n                            output_is_gif = gif['filename'].endswith(\".gif\")\n                            videos_output.append(gif_data)\n                        print(f\"We are returning {len(videos_output)} gifs/videos\")\n                        response_type = ResponseDataType.GIF if output_is_gif else ResponseDataType.VIDEO\n                        response_data = ResponseData(data=videos_output, data_type=response_type,\n                                                     total_count=len(videos_output))\n                        return ResponseCmfy.success(data=response_data)\n            else:\n                logger.warning(\"Outputs are empty despite successful execution.\")\n                # Decide whether to return success or handle as an error\n                return ResponseCmfy.success(ResponseData())\n\n        if status_str == \"error\":\n            error_message = f\"An exception occurred: {messages}\"\n            return ResponseCmfy.error(error_message, job_id)\n        if not completed:\n            return ResponseCmfy.running(job_id)\n        return ResponseCmfy.error(\"Error getting job status\", job_id)\n\n    @staticmethod\n    async def _get_image(filename: str, subfolder: str, folder_type: str) -> Optional[str]:\n        server_address = f\"localhost:{os.environ.get('PORT_CMFY', 8889)}\"\n        data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n        url_values = urllib.parse.urlencode(data)\n        req_url = f\"http://{server_address}/view?{url_values}\"\n        logger.debug(f\"Getting image from {req_url}\")\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(req_url)\n                response.raise_for_status()\n                image_data = response.content\n                # Convert the image data to a base64 string\n                base64_encoded = base64.b64encode(image_data).decode('utf-8')\n                print(f\"Image data: {base64_encoded[:100]}\")\n                return base64_encoded\n        except Exception as e:\n            logger.error(f\"Failed to retrieve or encode image: {e}\")\n            return None\n\n    def _check_loaded_model(self, model_name):\n        if model_name and model_name not in self.loaded_models:\n            self.loaded_models.append(model_name)\n\n        max_cached_models = os.environ.get(\"MAX_CACHED_MODELS\", 3)\n        if len(self.loaded_models) > max_cached_models:\n            self.loaded_models = self.loaded_models[-max_cached_models:]\n\n    async def cache_model(self, model: str = \"Juggernaut-XI-Prototype.safetensors\", model_type=\"SD\") -> bool:\n        request_json = model_load_json\n        request_json[\"1\"]['inputs']['ckpt_name'] = model\n        workflow_json_str = json.dumps(request_json)\n        data = {\"workflow_json\": workflow_json_str}\n        wf = CmfyWorkflow.model_validate(data)\n        # Print the workflow\n        print(f\"Workflow: {wf.workflow_json} {wf.__dict__}\")\n        self._check_loaded_model(model)\n        response = await self.create(wf)\n        if response.status == JobStatus.FINISHED:\n            return True\n        return False\n\n    @staticmethod\n    async def get_model_from_workflow(workflow: Dict[str, Any]) -> Optional[Tuple[Optional[str], bool, str]]:\n        # Define specific class types for each model type\n        checkpoint_loaders = [\n            \"Checkpoint Loader\",\n            \"Checkpoint Loader (Simple)\",\n            \"Checkpoint Loader w/Name (WLSH)\",\n            \"CheckpointLoaderSimpleShared //Inspire\",\n            \"StableCascade_CheckpointLoader //Inspire\",\n            \"CheckpointLoaderSimple\",\n            \"CheckpointLoaderSimpleWithNoiseSelect\"\n        ]\n\n        controlnet_loaders = [\n            \"ControlNetLoader\",\n            \"LoadFluxControlNet\"\n        ]\n\n        lora_loaders = [\n            \"LoraLoader\",\n            \"FluxLoraLoader\",\n            \"Load Lora\"\n        ]\n\n        clip_loaders = [\n            \"CLIPLoader\"\n        ]\n\n        # Iterate through nodes in the workflow\n        for node_id, node in workflow.items():\n            try:\n                class_type = node['class_type']\n\n                # Default values\n                model_name = None\n                is_flux = False\n                model_type = \"\"\n\n                # Check for Checkpoint loaders\n                if class_type in checkpoint_loaders or \"checkpointloader\" in class_type.lower():\n                    model_name = node['inputs'].get('ckpt_name', None) if \"cascade\" not in class_type.lower() else node['inputs'].get('stage_b', None)\n                    model_type = \"checkpoint\"\n                    if \"Flux\" in class_type or (model_name and 'flux' in model_name.lower()):\n                        is_flux = True\n\n                # Check for ControlNet loaders\n                elif class_type in controlnet_loaders:\n                    model_name = node['inputs'].get('control_net_name', node['inputs'].get('controlnet_path', None))\n                    model_type = \"controlnet\"\n                    if \"Flux\" in class_type:\n                        is_flux = True\n\n                # Check for LoRA loaders\n                elif class_type in lora_loaders:\n                    model_name = node['inputs'].get('lora_name', None)\n                    model_type = \"lora\"\n                    if \"Flux\" in class_type:\n                        is_flux = True\n\n                # Check for CLIP loaders\n                elif class_type in clip_loaders:\n                    model_name = node['inputs'].get('clip_name', None)\n                    model_type = \"clip\"\n\n                # Return if a model name is found\n                if model_name:\n                    print(f\"Model name: {model_name} found in workflow!\")\n                    return model_name, is_flux, model_type\n\n            except KeyError:\n                continue\n\n        # Return None if no model is found\n        print(f\"No model found in workflow: {json.dumps(workflow, indent=2)}\")\n        return None, False, \"\"\n",
    "pattern_analysis": {
      "api_sequence": [
        "os.environ.get",
        "json.loads",
        "self.get_model_from_workflow",
        "self._check_loaded_model",
        "requests.post",
        "logger.debug",
        "logger.debug",
        "logger.warning",
        "requests.Response.raise_for_status",
        "requests.Response.json",
        "logger.error",
        "ResponseCmfy.error",
        "response_json.get",
        "logger.debug",
        "ResponseCmfy.error",
        "self.get_status",
        "asyncio.sleep",
        "self.get_status",
        "ResponseCmfy.success",
        "ResponseCmfy.error",
        "os.environ.get",
        "json.loads",
        "self.get_model_from_workflow",
        "self._check_loaded_model",
        "requests.post",
        "logger.debug",
        "logger.warning",
        "requests.Response.raise_for_status",
        "requests.Response.json",
        "logger.error",
        "ResponseCmfy.error",
        "response_json.get",
        "logger.debug",
        "ResponseCmfy.error",
        "ResponseCmfy.running",
        "os.environ.get",
        "print",
        "logger.debug",
        "requests.get",
        "requests.Response.status_code",
        "BaseResponse.error",
        "requests.Response.json",
        "dict.get",
        "dict.get",
        "dict.get",
        "dict.get",
        "dict.get",
        "logger.debug",
        "print",
        "self._get_image",
        "print",
        "ResponseData",
        "ResponseCmfy.success",
        "logger.warning",
        "ResponseCmfy.success",
        "ResponseCmfy.error",
        "ResponseCmfy.running",
        "ResponseCmfy.error",
        "os.environ.get",
        "urllib.parse.urlencode",
        "logger.debug",
        "httpx.AsyncClient",
        "httpx.AsyncClient.get",
        "requests.Response.raise_for_status",
        "requests.Response.content",
        "base64.b64encode",
        "bytes.decode",
        "print",
        "logger.error",
        "os.environ.get",
        "self.loaded_models.append",
        "os.environ.get",
        "len",
        "self.loaded_models.__getitem__",
        "json.dumps",
        "CmfyWorkflow.model_validate",
        "print",
        "self._check_loaded_model",
        "self.create",
        "json.dumps"
      ],
      "api_sequence_with_args": [
        "os.environ.get(\"PORT_CMFY\", 8888)",
        "json.loads(params.workflow_json)",
        "self.get_model_from_workflow(workflow)",
        "self._check_loaded_model(loaded_model)",
        "requests.post(url, data=data, headers=headers)",
        "logger.debug(f\"CMFY data: {workflow}\")",
        "logger.debug(f\"CMFY response: {response}, {response.text}, {response.json()}\")",
        "logger.warning(f\"Unprocessable entity: {response.text}\")",
        "response.raise_for_status()",
        "response.json()",
        "logger.error(f\"Error creating prompt: {e}\")",
        "ResponseCmfy.error(f\"Error creating prompt: {e} ({response_json})\")",
        "response_json.get(\"prompt_id\", None)",
        "logger.debug(f\"Prompt ID: {prompt_id}\")",
        "ResponseCmfy.error(f\"Error creating prompt: {response_json}\")",
        "self.get_status(prompt_id)",
        "asyncio.sleep(1)",
        "self.get_status(prompt_id)",
        "ResponseCmfy.success(response_data, prompt_id)",
        "ResponseCmfy.error(\"Error creating prompt\")",
        "os.environ.get(\"PORT_CMFY\", 8889)",
        "json.loads(params.workflow_json)",
        "self.get_model_from_workflow(workflow)",
        "self._check_loaded_model(loaded_model)",
        "requests.post(url, data=data, headers=headers)",
        "logger.debug(f\"CMFY data: {workflow}\")",
        "logger.warning(f\"Unprocessable entity: {response.text}\")",
        "response.raise_for_status()",
        "response.json()",
        "logger.error(f\"Error creating prompt: {e}\")",
        "ResponseCmfy.error(f\"Error creating prompt: {e} ({response_json})\")",
        "response_json.get(\"prompt_id\", None)",
        "logger.debug(f\"Prompt ID: {prompt_id}\")",
        "ResponseCmfy.error(f\"Error creating prompt: {response_json}\")",
        "ResponseCmfy.running(prompt_id)",
        "os.environ.get('PORT_CMFY', 8889)",
        "print(f\"Getting status for job {job_id} from url {url}\")",
        "logger.debug(f\"Getting status for job {job_id}\")",
        "requests.get(url)",
        "history.status_code != 200",
        "BaseResponse.error(\"Error getting job status\", job_id)",
        "history.json()",
        "history.get(job_id, None)",
        "job_data.get('status', {})",
        "status.get('status_str', None)",
        "status.get('completed', False)",
        "status.get('messages', [])",
        "job_data.get('outputs', {})",
        "logger.debug(f\"Node output: {node_output}\")",
        "print(f\"Getting image: {image['filename']}\")",
        "self._get_image(image['filename'], image['subfolder'], image['type'])",
        "print(f\"We are returning {len(images_output)} images\")",
        "ResponseData(data=images_output, data_type=ResponseDataType.IMAGE, total_count=len(images_output))",
        "ResponseCmfy.success(data=response_data)",
        "logger.warning(\"Outputs are empty despite successful execution.\")",
        "ResponseCmfy.success(ResponseData())",
        "ResponseCmfy.error(error_message, job_id)",
        "ResponseCmfy.running(job_id)",
        "ResponseCmfy.error(\"Error getting job status\", job_id)",
        "os.environ.get('PORT_CMFY', 8889)",
        "urllib.parse.urlencode(data)",
        "logger.debug(f\"Getting image from {req_url}\")",
        "httpx.AsyncClient()",
        "client.get(req_url)",
        "response.raise_for_status()",
        "response.content",
        "base64.b64encode(image_data)",
        "base64_encoded.decode('utf-8')",
        "print(f\"Image data: {base64_encoded[:100]}\")",
        "logger.error(f\"Failed to retrieve or encode image: {e}\")",
        "os.environ.get(\"MAX_CACHED_MODELS\", 3)",
        "self.loaded_models.append(model_name)",
        "os.environ.get(\"MAX_CACHED_MODELS\", 3)",
        "len(self.loaded_models)",
        "self.loaded_models[-max_cached_models:]",
        "json.dumps(request_json)",
        "CmfyWorkflow.model_validate(data)",
        "print(f\"Workflow: {wf.workflow_json} {wf.__dict__}\")",
        "self._check_loaded_model(model)",
        "self.create(wf)",
        "json.dumps(workflow, indent=2)"
      ],
      "mapped_sequence": [
        {
          "api_name": "os.environ.get",
          "id": "get_env_var",
          "description": "Retrieves value of environment variable",
          "first_id": "system_operations",
          "second_id": "system_environment_operations",
          "third_id": "environment_information"
        },
        {
          "api_name": "json.loads",
          "id": "deserialize_from_json",
          "description": "Deserializes JSON string to Python object",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "specific_format_encoding"
        },
        {
          "api_name": "requests.post",
          "id": "send_http_post",
          "description": "Sends HTTP POST request with data and parameters",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_sending"
        },
        {
          "api_name": "requests.get",
          "id": "send_http_get",
          "description": "Sends HTTP GET request with parameters and timeout",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_sending"
        },
        {
          "api_name": "requests.Response.raise_for_status",
          "id": "raise_http_error",
          "description": "Raises HTTPError if response status code indicates error",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "response_processing"
        },
        {
          "api_name": "requests.Response.json",
          "id": "deserialize_json_response",
          "description": "Deserializes JSON response body to Python object",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "response_processing"
        },
        {
          "api_name": "urllib.parse.urlencode",
          "id": "encode_url_query",
          "description": "Encodes mapping object to URL query string",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_configuration"
        },
        {
          "api_name": "httpx.AsyncClient.get",
          "id": "send_http_get",
          "description": "Sends HTTP GET request with parameters and timeout",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_sending"
        },
        {
          "api_name": "base64.b64encode",
          "id": "encode_bytes_to_base64",
          "description": "Encodes bytes to base64-encoded bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "base_encoding"
        }
      ],
      "contextual_code": "import os\nimport json\nimport requests\nimport urllib.parse\nimport base64\nimport httpx\n\nclass AppCmfy(BaseApp):\n    def __init__(self):\n        focus_port = os.environ.get(\"PORT_CMFY\", 8888)\n        if isinstance(focus_port, str):\n            focus_port = int(focus_port)\n        self.api_base_url = f\"http://0.0.0.0:{focus_port}\"\n\n    async def create(self, params):\n        cmfy_port = os.environ.get(\"PORT_CMFY\", 8889)\n        url = f\"http://localhost:{cmfy_port}/prompt\"\n        workflow = json.loads(params.workflow_json)\n        loaded_model, is_flux, model_type = await self.get_model_from_workflow(workflow)\n        if model_type == \"checkpoint\" and loaded_model is not None:\n            self._check_loaded_model(loaded_model)\n        try:\n            headers = {'Content-Type': 'application/json'}\n            data = {\"prompt\": workflow}\n            data = json.dumps(data).encode('utf-8')\n            response = requests.post(url, data=data, headers=headers)\n            if response.status_code == 422:\n                logger.warning(f\"Unprocessable entity: {response.text}\")\n            response.raise_for_status()\n            response_json = response.json()\n        except Exception as e:\n            logger.error(f\"Error creating prompt: {e}\")\n            return ResponseCmfy.error(f\"Error creating prompt: {e} ({response_json})\")\n        prompt_id = response_json.get(\"prompt_id\", None)\n        if prompt_id is None:\n            return ResponseCmfy.error(f\"Error creating prompt: {response_json}\")\n        status_count = 0\n        response = await self.get_status(prompt_id)\n        status = response.status\n        while status != JobStatus.FINISHED and status != JobStatus.FAILED and status_count < 10:\n            await asyncio.sleep(1)\n            response = await self.get_status(prompt_id)\n            status = response.status\n            status_count += 1\n        if status == JobStatus.FINISHED:\n            response_data = response.output\n            return ResponseCmfy.success(response_data, prompt_id)\n        return ResponseCmfy.error(\"Error creating prompt\")\n\n    async def get_status(self, job_id):\n        url = f\"http://localhost:{os.environ.get('PORT_CMFY', 8889)}/history/{job_id}\"\n        job_data = None\n        while job_data is None:\n            history = requests.get(url)\n            if history.status_code != 200:\n                return BaseResponse.error(\"Error getting job status\", job_id)\n            history = history.json()\n            job = history.get(job_id, None)\n            if not job:\n                continue\n            job_data = job\n        status = job_data.get('status', {})\n        status_str = status.get('status_str', None)\n        completed = status.get('completed', False)\n        messages = status.get('messages', [])\n        if status_str == \"success\" and completed:\n            outputs = job_data.get('outputs', {})\n            if outputs:\n                images_output = []\n                for node_id, node_output in job_data['outputs'].items():\n                    if 'images' in node_output:\n                        for image in node_output['images']:\n                            image_data = await self._get_image(image['filename'], image['subfolder'], image['type'])\n                            images_output.append(image_data)\n                        response_data = ResponseData(data=images_output, data_type=ResponseDataType.IMAGE, total_count=len(images_output))\n                        return ResponseCmfy.success(data=response_data)\n        return ResponseCmfy.error(\"Error getting job status\", job_id)\n\n    @staticmethod\n    async def _get_image(filename: str, subfolder: str, folder_type: str) -> Optional[str]:\n        server_address = f\"localhost:{os.environ.get('PORT_CMFY', 8889)}\"\n        data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n        url_values = urllib.parse.urlencode(data)\n        req_url = f\"http://{server_address}/view?{url_values}\"\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(req_url)\n                response.raise_for_status()\n                image_data = response.content\n                base64_encoded = base64.b64encode(image_data).decode('utf-8')\n                return base64_encoded\n        except Exception as e:\n            logger.error(f\"Failed to retrieve or encode image: {e}\")"
    }
  },
  {
    "metadata": {
      "package_name": "gen_wrappers-0.7.1",
      "total_matches": 3
    }
  }
]