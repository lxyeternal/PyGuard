{
  "metadata": {
    "package_name": "dataengine-0",
    "original_json_path": "/home2/blue/Documents/PyPIAgent/Codes/code_contexral/codesnippets/benign_bandit4mal/dataengine-0.0.91.json",
    "dataset_type": "benign_bandit4mal"
  },
  "code_files": [
    {
      "pyfile": "redact_utils.py",
      "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/dataengine-0.0.91/dataengine-0.0.91/dataengine/utilities/redact_utils.py",
      "line_number": "600",
      "type_description": "B839:pool",
      "context_snippet": "def generate_redact_map(\n        text_list: List[str], redact_type: str,\n        find_function: Callable[[str], Set[Any]],\n        regex_function: Callable[[Any], re.Pattern]\n    ) -> Dict[str, Dict[str, Union[str, str]]]:\n    \"\"\"\n    Generate a redaction map for a list of text items based on specified find\n    and regex functions.\n\n    Args:\n        text_list (List[str]):\n            A list of text items to be processed for redaction.\n        redact_type (str):\n            A string indicating the type of redaction.\n        find_function (Callable[[str], List[str]]):\n            A function that takes a string and returns a set of matches.\n        regex_function (Callable[[str], str]):\n            A function that gives regex pattern that covers all permutations\n            of a certain type of string.\n\n    Returns:\n        Dict[str, Dict[str, Union[str, str]]]:\n            A dictionary containing the redaction mappings. Each key is a\n            redaction label and each value is another dictionary containing\n            the original match and its regex pattern.\n    \"\"\"\n    # Set processes to 1 less than cpu count\n    with Pool(\n        processes=max(1, multiprocessing.cpu_count() - 1)\n    ) as executor:\n        results = list(executor.map(find_function, text_list))\n    # Get unique matches\n    unique_matches = set(itertools.chain.from_iterable(results))\n    # Return redact map\n    return {\n        f\"[REDACTED:{redact_type}:{{}}]\".format(index + 1): {\n            \"original\": match, \"regex\": regex_function(match)\n        } for index, match in enumerate(unique_matches)}",
      "hash_value": "3e0d1560d829c4648c803395b7ec2e48",
      "severity": "High",
      "confidence": "Medium",
      "code_snippets": [
        {
          "snippet": "def generate_redact_map(\n        text_list: List[str], redact_type: str,\n        find_function: Callable[[str], Set[Any]],\n        regex_function: Callable[[Any], re.Pattern]\n    ) -> Dict[str, Dict[str, Union[str, str]]]:\n    \"\"\"\n    Generate a redaction map for a list of text items based on specified find\n    and regex functions.\n\n    Args:\n        text_list (List[str]):\n            A list of text items to be processed for redaction.\n        redact_type (str):\n            A string indicating the type of redaction.\n        find_function (Callable[[str], List[str]]):\n            A function that takes a string and returns a set of matches.\n        regex_function (Callable[[str], str]):\n            A function that gives regex pattern that covers all permutations\n            of a certain type of string.\n\n    Returns:\n        Dict[str, Dict[str, Union[str, str]]]:\n            A dictionary containing the redaction mappings. Each key is a\n            redaction label and each value is another dictionary containing\n            the original match and its regex pattern.\n    \"\"\"\n    # Set processes to 1 less than cpu count\n    with Pool(\n        processes=max(1, multiprocessing.cpu_count() - 1)\n    ) as executor:\n        results = list(executor.map(find_function, text_list))\n    # Get unique matches\n    unique_matches = set(itertools.chain.from_iterable(results))\n    # Return redact map\n    return {\n        f\"[REDACTED:{redact_type}:{{}}]\".format(index + 1): {\n            \"original\": match, \"regex\": regex_function(match)\n        } for index, match in enumerate(unique_matches)}",
          "triple_sequences": [
            {
              "action_api": "multiprocessing.cpu_count()",
              "action_description": "Retrieves operating system information",
              "action_id": "get_os_info",
              "object": "",
              "object_description": "",
              "object_id": "",
              "intention_description": "Get system info",
              "intention_id": "get_system_info"
            },
            {
              "action_api": "Pool()",
              "action_description": "Initializes thread pool executor",
              "action_id": "init_thread_pool",
              "object": "processes=max(1, multiprocessing.cpu_count() - 1)",
              "object_description": "Thread function arguments",
              "object_id": "thread_arguments",
              "intention_description": "Prepare thread pool for concurrent execution",
              "intention_id": "concurrent_execution_preparation"
            },
            {
              "action_api": "executor.map()",
              "action_description": "Submits function to thread pool",
              "action_id": "submit_thread_function",
              "object": "find_function, text_list",
              "object_description": "Function and arguments",
              "object_id": "function_with_arguments",
              "intention_description": "Run function in thread pool",
              "intention_id": "run_function_thread_pool"
            },
            {
              "action_api": "list()",
              "action_description": "Lists all currently alive threads",
              "action_id": "list_threads",
              "object": "executor.map(find_function, text_list)",
              "object_description": "Thread function arguments",
              "object_id": "thread_arguments",
              "intention_description": "Prepare data for further processing",
              "intention_id": "prepare_data_processing"
            },
            {
              "action_api": "itertools.chain.from_iterable()",
              "action_description": "Generate product of sequence",
              "action_id": "generate_sequence_product",
              "object": "results",
              "object_description": "Character code array",
              "object_id": "character_code_array",
              "intention_description": "Prepare data for further processing",
              "intention_id": "prepare_data_processing"
            },
            {
              "action_api": "set()",
              "action_description": "Generate product of sequence",
              "action_id": "generate_sequence_product",
              "object": "itertools.chain.from_iterable(results)",
              "object_description": "Character code array",
              "object_id": "character_code_array",
              "intention_description": "Prepare data for further processing",
              "intention_id": "prepare_data_processing"
            },
            {
              "action_api": "enumerate()",
              "action_description": "Generate product of sequence",
              "action_id": "generate_sequence_product",
              "object": "unique_matches",
              "object_description": "Character code array",
              "object_id": "character_code_array",
              "intention_description": "Prepare data for further processing",
              "intention_id": "prepare_data_processing"
            },
            {
              "action_api": "regex_function()",
              "action_description": "Compiles regular expression pattern",
              "action_id": "compile_regex",
              "object": "match",
              "object_description": "Regular expression pattern",
              "object_id": "regex_pattern",
              "intention_description": "Prepare character for further processing",
              "intention_id": "prepare_character_processing"
            }
          ]
        }
      ]
    }
  ]
}