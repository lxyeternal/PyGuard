{
  "metadata": {
    "package_name": "kcli-99",
    "original_json_path": "/home2/blue/Documents/PyPIAgent/Codes/code_contexral/codesnippets/benign_bandit4mal/kcli-99.0.202504101850.json",
    "dataset_type": "benign_bandit4mal"
  },
  "code_files": [
    {
      "pyfile": "__init__.py",
      "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/kcli-99.0.202504101850/kcli-99.0.202504101850/kvirt/cluster/openshift/__init__.py",
      "line_number": "1201",
      "type_description": "B815:write",
      "context_snippet": "def create(config, plandir, cluster, overrides, dnsconfig=None):\n    k = config.k\n    log_level = 'debug' if config.debug else 'info'\n    client = config.client\n    provider = config.type\n    arch = k.get_capabilities()['arch'] if provider == 'kvm' else 'x86_64'\n    pprint(f\"Deploying on client {client}\")\n    data = safe_load(open(f'{plandir}/kcli_default.yml'))\n    data.update(overrides)\n    fix_typos(data)\n    esx = config.type == 'vsphere' and k.esx\n    data['esx'] = esx\n    ctlplanes = data['ctlplanes']\n    if ctlplanes <= 0:\n        return {'result': 'failure', 'reason': f\"Invalid number of ctlplanes {ctlplanes}\"}\n    workers = data['workers']\n    if workers < 0:\n        return {'result': 'failure', 'reason': f\"Invalid number of workers {workers}\"}\n    if data['dual_api_ip'] is not None:\n        warning(\"Forcing dualstack\")\n        data['dualstack'] = True\n    http_proxy = os.environ.get('HTTP_PROXY') or os.environ.get('http_proxy')\n    if 'http_proxy' not in data and http_proxy is not None:\n        pprint(\"Using proxy settings from environment\")\n        data['http_proxy'] = http_proxy\n        https_proxy = os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy')\n        if 'https_proxy' not in data and https_proxy is not None:\n            data['https_proxy'] = https_proxy\n        no_proxy = os.environ.get('NO_PROXY') or os.environ.get('no_proxy')\n        if 'no_proxy' not in data and no_proxy is not None:\n            data['no_proxy'] = no_proxy\n    if data['ctlplanes'] == 1 and data['workers'] == 0\\\n       and 'ctlplane_memory' not in overrides and 'memory' not in overrides:\n        overrides['ctlplane_memory'] = 32768\n        warning(\"Forcing memory of single ctlplane vm to 32G\")\n    retries = data['retries']\n    data['cluster'] = cluster\n    domain = data['domain']\n    dns_k = dnsconfig.k if dnsconfig is not None else k\n    if provider in cloud_providers:\n        dns_zones = dns_k.list_dns_zones()\n        if domain not in dns_zones and f'{domain}.' not in dns_zones:\n            return {'result': 'failure', 'reason': f'domain {domain} needs to exist'}\n    original_domain = None\n    async_install = data['async']\n    okd = data['okd']\n    autoscale = data['autoscale']\n    sslip = data['sslip']\n    if 'baremetal_hosts' not in data and 'bmc_url' in data:\n        host = {'bmc_url': data['bmc_url'], 'bmc_user': data.get('bmc_user'), 'bmc_password': data.get('bmc_password')}\n        data['baremetal_hosts'] = [host]\n    baremetal_hosts = data['baremetal_hosts']\n    notify = data['notify']\n    postscripts = data['postscripts']\n    pprint(f\"Deploying cluster {cluster}\")\n    plan = cluster\n    overrides['kubetype'] = 'openshift'\n    apps = overrides.get('apps', [])\n    disks = overrides.get('disks', [30])\n    overrides['kube'] = data['cluster']\n    installparam = overrides.copy()\n    installparam['cluster'] = cluster\n    baremetal_sno = workers == 0 and len(baremetal_hosts) == 1\n    baremetal_ctlplane = data['workers'] == 0 and len(baremetal_hosts) > 1\n    sno_vm = data['sno_vm']\n    sno = sno_vm or data['sno'] or baremetal_ctlplane or baremetal_sno\n    data['sno'] = sno\n    sno_wait = overrides.get('sno_wait') or baremetal_sno or data['api_ip'] is not None or sno_vm\n    sno_disk = data['sno_disk']\n    sno_ctlplanes = data['sno_ctlplanes'] or baremetal_ctlplane\n    sno_workers = data['sno_workers']\n    ignore_hosts = data['ignore_hosts'] or sslip\n    if sno:\n        if sno_disk is None:\n            warning(\"sno_disk will be discovered\")\n        ctlplanes = 1\n        workers = 0\n        data['mdns'] = False\n        data['kubetype'] = 'openshift'\n        data['kube'] = data['cluster']\n        if data['network_type'] == 'OpenShiftSDN':\n            warning(\"Forcing network_type to OVNKubernetes\")\n            data['network_type'] = 'OVNKubernetes'\n    elif ('lvms-operator' in apps or 'localstorage' in apps or 'ocs' in apps) and 'extra_disks' not in overrides\\\n            and 'extra_ctlplane_disks' not in overrides and 'extra_worker_disks' not in overrides and len(disks) == 1:\n        warning(\"Storage apps require extra disks to be set\")\n    network = data['network']\n    post_dualstack = False\n    if data['dualstack'] and provider in cloud_providers:\n        warning(\"Dual stack will be enabled at the end of the install\")\n        data['dualstack'] = False\n        post_dualstack = True\n    ipv6 = data['ipv6']\n    disconnected_update = data['disconnected_update']\n    disconnected_reuse = data['disconnected_reuse']\n    disconnected_operators = data['disconnected_operators']\n    certified_operators = data['disconnected_certified_operators']\n    community_operators = data['disconnected_community_operators']\n    marketplace_operators = data['disconnected_marketplace_operators']\n    disconnected_url = data['disconnected_url']\n    disconnected_user = data['disconnected_user']\n    disconnected_password = data['disconnected_password']\n    operators = disconnected_operators + community_operators + certified_operators + marketplace_operators\n    disconnected = data['disconnected']\n    disconnected_vm = data['disconnected_vm'] or (disconnected_url is None and (disconnected or operators))\n    ipsec = data['ipsec']\n    ipsec_mode = data['ipsec_mode']\n    mtu = data['mtu']\n    ovn_hostrouting = data['ovn_hostrouting']\n    metal3 = data['metal3']\n    autologin = data['autologin']\n    dedicated_etcd = data['dedicated_etcd']\n    if not data['coredns']:\n        warning(\"You will need to provide DNS records for api and ingress on your own\")\n    keepalived = data['keepalived']\n    if not keepalived:\n        warning(\"You will need to provide LB for api and ingress on your own\")\n    mdns = data['mdns']\n    localhost_fix = data['localhost_fix']\n    ctlplane_localhost_fix = data['ctlplane_localhost_fix'] or localhost_fix\n    worker_localhost_fix = data['worker_localhost_fix'] or localhost_fix\n    sno_cpuset = data['sno_cpuset']\n    kubevirt_api_service, kubevirt_api_service_node_port = False, False\n    kubevirt_ignore_node_port = data['kubevirt_ignore_node_port']\n    prega = data['prega']\n    virtualization_nightly = data['virtualization_nightly']\n    version = data['version']\n    tag = data['tag']\n    version = overrides.get('version') or detect_openshift_version(tag, OPENSHIFT_TAG)\n    data['version'] = version\n    if os.path.exists('coreos-installer'):\n        pprint(\"Removing old coreos-installer\")\n        os.remove('coreos-installer')\n    if version not in ['ci', 'candidate', 'nightly', 'stable']:\n        return {'result': 'failure', 'reason': f\"Incorrect version {version}\"}\n    else:\n        pprint(f\"Using {version} version\")\n    cluster = data.get('cluster')\n    image = data['image']\n    api_ip = data['api_ip']\n    cidr = None\n    if provider in virt_providers and keepalived and not sno and api_ip is None:\n        network = data['network']\n        networkinfo = k.info_network(network)\n        if not networkinfo:\n            return {'result': 'failure', 'reason': f\"Issue getting network {network}\"}\n        if provider == 'kvm' and networkinfo['type'] == 'routed':\n            cidr = networkinfo['cidr']\n            if cidr == 'N/A':\n                return {'result': 'failure', 'reason': \"Couldnt gather an api_ip from your specified network\"}\n            api_index = 2 if ':' in cidr else -3\n            api_ip = str(get_new_vip(network, ipv6=':' in cidr) or ip_network(cidr)[api_index])\n            warning(f\"Using {api_ip} as api_ip\")\n            overrides['api_ip'] = api_ip\n            installparam['automatic_api_ip'] = True\n            installparam['api_ip'] = api_ip\n        elif provider == 'kubevirt':\n            selector = {'kcli/plan': plan, 'kcli/role': 'ctlplane'}\n            service_type = \"LoadBalancer\" if k.access_mode == 'LoadBalancer' else 'NodePort'\n            namespace = k.namespace\n            if service_type == 'NodePort':\n                kubevirt_api_service_node_port = True\n            api_ip = k.create_service(f\"{cluster}-api\", namespace, selector, _type=service_type,\n                                      ports=[6443, 22623, 22624], openshift_hack=True)\n            if api_ip is None:\n                return {'result': 'failure', 'reason': \"Couldnt gather an api_ip from your specified network\"}\n            else:\n                pprint(f\"Using api_ip {api_ip}\")\n                overrides['api_ip'] = api_ip\n                overrides['kubevirt_api_service'] = True\n                kubevirt_api_service = True\n                overrides['mdns'] = False\n                try:\n                    patch_ingress_controller_wildcard()\n                    selector = {'kcli/plan': plan, 'kcli/role': 'worker' if workers > 0 else 'ctlplane'}\n                    k.create_service(f\"{cluster}-ingress\", namespace, selector, ports=[80, 443])\n                    routecmd = f'oc -n {namespace} create route passthrough --service={cluster}-ingress '\n                    routecmd += f'--hostname=http.apps.{cluster}.{domain} --wildcard-policy=Subdomain --port=443'\n                    call(routecmd, shell=True)\n                except:\n                    pass\n        else:\n            return {'result': 'failure', 'reason': \"You need to define api_ip in your parameters file\"}\n    if api_ip is not None:\n        try:\n            ip_address(api_ip)\n        except:\n            return {'result': 'failure', 'reason': f\"Invalid api_ip {api_ip}\"}\n    if provider in virt_providers and keepalived and not sno and ':' in api_ip:\n        ipv6 = True\n    if ipv6:\n        if data['network_type'] == 'OpenShiftSDN':\n            warning(\"Forcing network_type to OVNKubernetes\")\n            data['network_type'] = 'OVNKubernetes'\n        data['ipv6'] = True\n        overrides['ipv6'] = True\n        data['disconnected_ipv6_network'] = True\n        if not disconnected_vm and disconnected_url is None:\n            warning(\"Forcing disconnected_vm to True as no disconnected_url was provided\")\n            data['disconnected_vm'] = True\n            disconnected_vm = True\n        if sno and not data['dualstack'] and 'extra_args' not in overrides:\n            warning(\"Forcing extra_args to ip=dhcp6 for sno to boot with ipv6\")\n            data['extra_args'] = 'ip=dhcp6'\n    ingress_ip = data['ingress_ip']\n    if ingress_ip is not None:\n        if api_ip is not None and ingress_ip == api_ip:\n            ingress_ip = None\n            overrides['ingress_ip'] = None\n        else:\n            try:\n                ip_address(ingress_ip)\n            except:\n                return {'result': 'failure', 'reason': f\"Invalid ingress_ip {ingress_ip}\"}\n    if sslip and provider in virt_providers:\n        if api_ip is None:\n            return {'result': 'failure', 'reason': \"Missing api_ip which is required with sslip\"}\n        original_domain = domain\n        domain = f\"{api_ip.replace('.', '-').replace(':', '-')}.sslip.io\"\n        data['domain'] = domain\n        pprint(f\"Setting domain to {domain}\")\n        ignore_hosts = False\n    public_api_ip = data['public_api_ip']\n    provider_network = False\n    network = data['network']\n    ctlplanes = data['ctlplanes']\n    workers = data['workers']\n    tag = data['tag']\n    pull_secret = pwd_path(data.get('pull_secret')) if not okd else f\"{plandir}/fake_pull.json\"\n    pull_secret = os.path.expanduser(pull_secret)\n    macosx = data['macosx']\n    if macosx and not os.path.exists('/i_am_a_container'):\n        macosx = False\n    if provider == 'openstack' and keepalived and not sno:\n        if data['flavor'] is None:\n            return {'result': 'failure', 'reason': \"Missing flavor in parameter file\"}\n        provider_network = k.provider_network(network)\n        if not provider_network:\n            if api_ip is None:\n                cidr = k.info_network(network)['cidr']\n                api_ip = str(ip_network(cidr)[-3])\n                data['api_ip'] = api_ip\n                warning(f\"Using {api_ip} as api_ip\")\n            if public_api_ip is None:\n                public_api_ip = k.create_network_port(f\"{cluster}-vip\", network, ip=api_ip, floating=True)['floating']\n    if not os.path.exists(pull_secret):\n        return {'result': 'failure', 'reason': f\"Missing pull secret file {pull_secret}\"}\n    if prega and 'quay.io/prega' not in open(os.path.expanduser(pull_secret)).read():\n        return {'result': 'failure', 'reason': \"entry for quay.io/prega missing in pull secret\"}\n    if virtualization_nightly and 'quay.io/openshift-cnv' not in open(os.path.expanduser(pull_secret)).read():\n        return {'result': 'failure', 'reason': \"entry for quay.io/openshift-cnv missing in pull secret\"}\n    if which('oc') is None:\n        get_oc(macosx=macosx)\n    pub_key = data['pub_key'] or get_ssh_pub_key()\n    keys = data['keys']\n    if pub_key is None:\n        if keys:\n            warning(\"Using first key from your keys array\")\n            pub_key = keys[0]\n        else:\n            msg = \"No usable public key found, which is required for the deployment. Create one using ssh-keygen\"\n            return {'result': 'failure', 'reason': msg}\n    pub_key = os.path.expanduser(pub_key)\n    if pub_key.startswith('ssh-'):\n        data['pub_key'] = pub_key\n    elif os.path.exists(pub_key):\n        data['pub_key'] = open(pub_key).read().strip()\n    else:\n        return {'result': 'failure', 'reason': f\"Publickey file {pub_key} not found\"}\n    clusterdir = os.path.expanduser(f\"~/.kcli/clusters/{cluster}\")\n    if os.path.exists(clusterdir):\n        if [v for v in k.list() if v.get('plan', 'kvirt') == cluster]:\n            return {'result': 'failure', 'reason': f\"Remove existing directory {clusterdir} or use --force\"}\n        else:\n            pprint(f\"Removing existing directory {clusterdir}\")\n            rmtree(clusterdir)\n    if version == 'ci':\n        if '/' not in str(tag) and str(tag).count('.') != 1:\n            if arch in ['aarch64', 'arm64']:\n                tag = f'registry.ci.openshift.org/ocp-arm64/release-arm64:{tag}'\n            else:\n                basetag = 'ocp'\n                tag = f'registry.ci.openshift.org/{basetag}/release:{tag}'\n    which_openshift = which('openshift-install')\n    openshift_dir = os.path.dirname(which_openshift) if which_openshift is not None else '.'\n    if which_openshift is not None and not has_internet():\n        pprint(\"Using existing openshift-install found in your PATH\")\n        warning(\"Not checking version\")\n    elif okd:\n        run = get_okd_installer(tag, version=version)\n    elif not same_release_images(version=version, tag=tag, pull_secret=pull_secret, path=openshift_dir):\n        if version in ['ci', 'nightly'] or '/' in str(tag):\n            nightly = version == 'nightly'\n            run = get_ci_installer(pull_secret, tag=tag, nightly=nightly)\n        elif version in ['candidate', 'stable', 'latest']:\n            run = get_downstream_installer(version=version, tag=tag, pull_secret=pull_secret)\n        else:\n            return {'result': 'failure', 'reason': f\"Invalid version {version}\"}\n        if run != 0:\n            return {'result': 'failure', 'reason': \"Couldn't download openshift-install\"}\n        pprint(\"Move downloaded openshift-install somewhere in your PATH if you want to reuse it\")\n    elif which_openshift is not None:\n        pprint(\"Using existing openshift-install found in your PATH\")\n    else:\n        pprint(\"Reusing matching openshift-install\")\n    os.environ[\"PATH\"] = f'{os.getcwd()}:{os.environ[\"PATH\"]}'\n    INSTALLER_VERSION = get_installer_version()\n    pprint(f\"Using installer version {INSTALLER_VERSION}\")\n    if disconnected_url is not None:\n        if disconnected_user is None:\n            return {'result': 'failure', 'reason': \"disconnected_user needs to be set\"}\n        if disconnected_password is None:\n            return {'result': 'failure', 'reason': \"disconnected_password needs to be set\"}\n        if disconnected_url.startswith('http'):\n            warning(f\"Removing scheme from {disconnected_url}\")\n            disconnected_url = disconnected_url.replace('http://', '').replace('https://', '')\n        update_pull_secret(pull_secret, disconnected_url, disconnected_user, disconnected_password)\n        data['ori_tag'] = tag\n        if '/' not in str(tag):\n            disconnected_prefix = data['disconnected_prefix'] or 'openshift-release-dev/ocp-release'\n            tag = f'{disconnected_url}/{disconnected_prefix}:{INSTALLER_VERSION}-{arch}'\n            os.environ['OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE'] = tag\n        if 'ca' not in data and 'quay.io' not in disconnected_url:\n            pprint(f\"Trying to gather registry ca cert from {disconnected_url}\")\n            cacmd = f\"openssl s_client -showcerts -connect {disconnected_url} </dev/null 2>/dev/null|\"\n            cacmd += \"openssl x509 -outform PEM\"\n            data['ca'] = os.popen(cacmd).read()\n    if sno:\n        pass\n    elif image is None:\n        image_type = provider\n        region = k.region if provider == 'aws' else None\n        try:\n            image_url = get_installer_rhcos(_type=image_type, region=region, arch=arch)\n        except:\n            msg = f\"Couldn't gather the {provider} image associated to this installer version\"\n            msg += \"Force an image in your parameter file\"\n            return {'result': 'failure', 'reason': msg}\n        if provider in ['aws', 'gcp']:\n            image = image_url\n        elif esx:\n            image = image_url\n            overrides['image_url'] = image\n        else:\n            if image_url.endswith('.vhd'):\n                image = os.path.basename(image_url)\n            else:\n                image = os.path.basename(os.path.splitext(image_url)[0])\n            if provider in ['ibm', 'kubevirt', 'proxmox']:\n                image = image.replace('.', '-').replace('_', '-').lower()\n            if provider == 'vsphere':\n                image = image.replace(f'.{arch}', '')\n            images = [v for v in k.volumes() if image in v]\n            if not images:\n                result = config.download_image(pool=config.pool, image=image, url=image_url,\n                                               size=data['kubevirt_disk_size'])\n                if result['result'] != 'success':\n                    return result\n        pprint(f\"Using image {image}\")\n    elif provider == 'kubevirt' and '/' in image:\n        warning(f\"Assuming image {image} is available\")\n    else:\n        pprint(f\"Checking if image {image} is available\")\n        images = [v for v in k.volumes() if image in v]\n        if not images:\n            msg = f\"Missing {image}. Indicate correct image in your parameters file...\"\n            return {'result': 'failure', 'reason': msg}\n    overrides['image'] = image\n    static_networking_ctlplane, static_networking_worker = False, False\n    macentries = []\n    custom_names = {}\n    vmrules = [] if provider == 'kvm' else overrides.get('vmrules', [])\n    for entry in vmrules:\n        if isinstance(entry, dict):\n            hostname = list(entry.keys())[0]\n            if isinstance(entry[hostname], dict):\n                rule = entry[hostname]\n                if 'name' in rule:\n                    custom_names[hostname] = rule['name']\n                if 'nets' in rule and isinstance(rule['nets'], list):\n                    netrule = rule['nets'][0]\n                    if isinstance(netrule, dict) and 'ip' in netrule and 'netmask' in netrule:\n                        mac, ip = netrule.get('mac'), netrule['ip']\n                        netmask, gateway = netrule['netmask'], netrule.get('gateway')\n                        nameserver = netrule.get('dns', gateway)\n                        if mac is not None and gateway is not None:\n                            macentries.append(f\"{mac};{hostname};{ip};{netmask};{gateway};{nameserver}\")\n                        if hostname.startswith(f\"{cluster}-ctlplane\"):\n                            static_networking_ctlplane = True\n                        elif hostname.startswith(f\"{cluster}-worker\"):\n                            static_networking_worker = True\n    if custom_names:\n        overrides['custom_names'] = custom_names\n    overrides['cluster'] = cluster\n    if not os.path.exists(clusterdir):\n        os.makedirs(clusterdir)\n    if provider in virt_providers and disconnected_vm:\n        disconnected_vm = f\"{data['disconnected_reuse_name'] or cluster}-registry\"\n        pprint(f\"Deploying disconnected vm {disconnected_vm}\")\n        data['pull_secret'] = re.sub(r\"\\s\", \"\", open(pull_secret).read())\n        disconnected_plan = f\"{plan}-reuse\" if disconnected_reuse else plan\n        disconnected_overrides = data.copy()\n        disconnected_overrides['OPENSHIFT_TAG'] = OPENSHIFT_TAG\n        disconnected_overrides['kube'] = f\"{cluster}-reuse\" if disconnected_reuse else cluster\n        disconnected_overrides['openshift_version'] = INSTALLER_VERSION\n        disconnected_overrides['disconnected_operators_version'] = f\"4.{INSTALLER_VERSION.split('.')[1]}\"\n        x_apps = ['users', 'autolabeller', 'metal3', 'nfs']\n        disconnected_operators_2 = [o['name'] for o in disconnected_operators if isinstance(o, dict) and 'name' in o]\n        for app in apps:\n            if app not in x_apps and app not in disconnected_operators and app not in disconnected_operators_2:\n                warning(f\"Adding app {app} to disconnected_operators array\")\n                disconnected_operators.append(app)\n        disconnected_overrides['disconnected_operators'] = disconnected_operators\n        result = config.plan(disconnected_plan, inputfile=f'{plandir}/disconnected.yml',\n                             overrides=disconnected_overrides)\n        if result['result'] != 'success':\n            return result\n        disconnected_ip, disconnected_vmport = _ssh_credentials(k, disconnected_vm)[1:]\n        cacmd = \"cat /opt/registry/certs/domain.crt\"\n        cacmd = ssh(disconnected_vm, ip=disconnected_ip, user='root', tunnel=config.tunnel,\n                    tunnelhost=config.tunnelhost, tunnelport=config.tunnelport, tunneluser=config.tunneluser,\n                    insecure=True, cmd=cacmd, vmport=disconnected_vmport)\n        disconnected_ca = os.popen(cacmd).read().strip()\n        if data['ca'] is not None:\n            data['ca'] += f\"\\n{disconnected_ca}\"\n        else:\n            data['ca'] = disconnected_ca\n        urlcmd = \"cat /root/url.txt\"\n        urlcmd = ssh(disconnected_vm, ip=disconnected_ip, user='root', tunnel=config.tunnel,\n                     tunnelhost=config.tunnelhost, tunnelport=config.tunnelport, tunneluser=config.tunneluser,\n                     insecure=True, cmd=urlcmd, vmport=disconnected_vmport)\n        disconnected_url = os.popen(urlcmd).read().strip()\n        overrides['disconnected_url'] = disconnected_url\n        data['disconnected_url'] = disconnected_url\n        versioncmd = \"cat /root/version.txt\"\n        versioncmd = ssh(disconnected_vm, ip=disconnected_ip, user='root', tunnel=config.tunnel,\n                         tunnelhost=config.tunnelhost, tunnelport=config.tunnelport, tunneluser=config.tunneluser,\n                         insecure=True, cmd=versioncmd, vmport=disconnected_vmport)\n        disconnected_version = os.popen(versioncmd).read().strip()\n        for source in [\"'cs-*.yaml'\", \"'i*oc-mirror.yaml'\"]:\n            scpcmd = scp(disconnected_vm, ip=disconnected_ip, user='root', source=source, destination=clusterdir,\n                         tunnel=config.tunnel, tunnelhost=config.tunnelhost, tunnelport=config.tunnelport,\n                         tunneluser=config.tunneluser, download=True, insecure=True, vmport=disconnected_vmport)\n            os.system(scpcmd)\n        patch_oc_mirror(clusterdir)\n        os.environ['OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE'] = disconnected_version\n    data['pull_secret_path'] = pull_secret\n    data['pull_secret'] = re.sub(r\"\\s\", \"\", open(pull_secret).read())\n    if disconnected_url is not None:\n        if disconnected_update and disconnected_url != 'quay.io':\n            data['release_tag'] = f'v4.{get_installer_minor(INSTALLER_VERSION)}'\n            update_registry(config, plandir, cluster, data)\n        key = f\"{disconnected_user}:{disconnected_password}\"\n        key = str(b64encode(key.encode('utf-8')), 'utf-8')\n        auths = json.loads(data['pull_secret'])['auths']\n        if disconnected_url not in auths or auths[disconnected_url]['auth'] != key:\n            auths[disconnected_url] = {'auth': key, 'email': 'jhendrix@karmalabs.corp'}\n            data['pull_secret'] = json.dumps({\"auths\": auths})\n    if provider == 'aws':\n        aws_credentials(config)\n    elif provider == 'gcp':\n        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.expanduser(config.options.get('credentials'))\n    elif provider == 'azure':\n        azure_credentials(config)\n        if '-' in network:\n            vnet = network.split('-')[0]\n            data['machine_cidr'] = k.info_network(vnet)['cidr']\n    elif provider == 'vsphere' and get_installer_minor(INSTALLER_VERSION) < 13:\n        data['vsphere_legacy'] = True\n    installconfig = config.process_inputfile(cluster, f\"{plandir}/install-config.yaml\", overrides=data)\n    with open(f\"{clusterdir}/install-config.yaml\", 'w') as f:\n        f.write(installconfig)\n    with open(f\"{clusterdir}/install-config.yaml.bck\", 'w') as f:\n        f.write(installconfig)\n    run = call(f'openshift-install --dir={clusterdir} --log-level={log_level} create manifests', shell=True)\n    if run != 0:\n        msg = \"Leaving environment for debugging purposes. \"\n        msg += f\"Delete it with kcli delete kube --yes {cluster}\"\n        return {'result': 'failure', 'reason': msg}\n    if provider == 'azure':\n        prefix = safe_load(open(f'{clusterdir}/openshift/99_cloud-creds-secret.yaml'))['data']['azure_resource_prefix']\n        new_prefix = b64encode(bytes(cluster, 'utf-8')).decode('utf-8')\n        sedcmd = f'sed -i \"s@{prefix}@{new_prefix}@\" {clusterdir}/openshift/99_cloud-creds-secret.yaml'\n        call(sedcmd, shell=True)\n        old_prefix = b64decode(bytes(prefix, 'utf-8')).decode('utf-8')\n        sedcmd = f'sed -i \"s@{old_prefix}@{cluster}@\" {clusterdir}/openshift/* {clusterdir}/manifests/*'\n        call(sedcmd, shell=True)\n    for f in glob(f\"{clusterdir}/openshift/99_openshift-cluster-api_master-machines-*.yaml\"):\n        os.remove(f)\n    for f in glob(f\"{clusterdir}/openshift/99_openshift-cluster-api_worker-machineset-*\"):\n        os.remove(f)\n    for f in glob(f\"{clusterdir}/openshift/99_openshift-machine-api_master-control-plane-machine-set.yaml\"):\n        os.remove(f)\n    ntp_server = data['ntp_server']\n    if ntp_server is not None:\n        ntp_data = config.process_inputfile(cluster, f\"{plandir}/chrony.conf\", overrides={'ntp_server': ntp_server})\n        for role in ['master', 'worker']:\n            ntp = config.process_inputfile(cluster, f\"{plandir}/99-chrony.yaml\",\n                                           overrides={'role': role, 'ntp_data': ntp_data})\n            with open(f\"{clusterdir}/manifests/99-chrony-{role}.yaml\", 'w') as f:\n                f.write(ntp)\n    baremetal_cidr = data['baremetal_cidr']\n    if baremetal_cidr is not None:\n        node_ip_hint = f\"KUBELET_NODEIP_HINT={baremetal_cidr.split('/')[0]}\"\n        for role in ['master', 'worker']:\n            hint = config.process_inputfile(cluster, f\"{plandir}/10-node-ip-hint.yaml\",\n                                            overrides={'role': role, 'node_ip_hint': node_ip_hint})\n            with open(f\"{clusterdir}/manifests/99-chrony-{role}.yaml\", 'w') as f:\n                f.write(hint)\n    manifestsdir = data.get('manifests')\n    manifestsdir = pwd_path(manifestsdir)\n    if os.path.exists(manifestsdir) and os.path.isdir(manifestsdir):\n        for f in glob(f\"{manifestsdir}/*.y*ml\"):\n            pprint(f\"Injecting manifest {f}\")\n            copy2(f, f\"{clusterdir}/openshift\")\n    elif isinstance(manifestsdir, list):\n        for manifest in manifestsdir:\n            f, content = list(manifest.keys())[0], list(manifest.values())[0]\n            if not f.endswith('.yml') and not f.endswith('.yaml'):\n                warning(f\"Skipping manifest {f}\")\n                continue\n            pprint(f\"Injecting manifest {f}\")\n            with open(f'{clusterdir}/openshift/{f}', 'w') as f:\n                f.write(content)\n    for manifest in glob(f\"{clusterdir}/*.yaml\"):\n        if os.stat(manifest).st_size == 0:\n            warning(f\"Skipping empty manifest {manifest}\")\n        elif manifest.startswith(f'{clusterdir}/cs-') or 'oc-mirror' in manifest:\n            pprint(f\"Injecting manifest {manifest}\")\n            copy2(manifest, f\"{clusterdir}/openshift\")\n    if disconnected_operators:\n        copy2(f'{plandir}/99-operatorhub.yaml', f\"{clusterdir}/openshift\")\n    network_type = data['network_type']\n    if network_type == 'Calico':\n        calico_version = data['calico_version']\n        with TemporaryDirectory() as tmpdir:\n            calico_data = {'tmpdir': tmpdir, 'clusterdir': clusterdir, 'calico_version': calico_version}\n            calico_script = config.process_inputfile('xxx', f'{plandir}/calico.sh.j2', overrides=calico_data)\n            with open(f\"{tmpdir}/calico.sh\", 'w') as f:\n                f.write(calico_script)\n            call(f'bash {tmpdir}/calico.sh', shell=True)\n    elif network_type == 'Cilium':\n        cilium_version = data['cilium_version']\n        cluster_network_ipv4 = data['cluster_network_ipv4']\n        cilium_data = {'clusterdir': clusterdir, 'cilium_version': cilium_version, 'cidr': cluster_network_ipv4}\n        cilium_script = config.process_inputfile('xxx', f'{plandir}/cilium.sh.j2', overrides=cilium_data)\n        with open(f\"{clusterdir}/cilium.sh\", 'w') as f:\n            f.write(cilium_script)\n        call(f'bash {clusterdir}/cilium.sh', shell=True)\n    if ipsec or ipsec_mode is not None or ovn_hostrouting or mtu != 1400:\n        valid_modes = ['Full', 'Disabled', 'External']\n        if ipsec_mode is not None and ipsec_mode not in valid_modes:\n            warning(f\"Incorrect ipsec_mode. Choose between {','.join(valid_modes)}\")\n            warning(\"Setting ipsec_mode to Full\")\n            ipsec_mode = 'Full'\n        ovn_data = config.process_inputfile(cluster, f\"{plandir}/99-ovn.yaml\",\n                                            overrides={'ipsec': ipsec, 'ovn_hostrouting': ovn_hostrouting,\n                                                       'mtu': mtu, 'mode': ipsec_mode})\n        with open(f\"{clusterdir}/openshift/99-ovn.yaml\", 'w') as f:\n            f.write(ovn_data)\n    if workers == 0 or not mdns or kubevirt_api_service:\n        copy2(f'{plandir}/cluster-scheduler-02-config.yml', f\"{clusterdir}/manifests\")\n    if 'sslip' in domain:\n        ingress_sslip_data = config.process_inputfile(cluster, f\"{plandir}/cluster-ingress-02-config.yml\",\n                                                      overrides={'cluster': cluster, 'domain': domain})\n        with open(f\"{clusterdir}/manifests/cluster-ingress-02-config.yml\", 'w') as f:\n            f.write(ingress_sslip_data)\n    cron_overrides = {'registry': disconnected_url or 'quay.io'}\n    cron_overrides['version'] = 'v1beta1' if get_installer_minor(INSTALLER_VERSION) < 8 else 'v1'\n    autoapproverdata = config.process_inputfile(cluster, f\"{plandir}/autoapprovercron.yml\", overrides=cron_overrides)\n    with open(f\"{clusterdir}/autoapprovercron.yml\", 'w') as f:\n        f.write(autoapproverdata)\n    for f in glob(f\"{plandir}/customisation/*.yaml\"):\n        if '99-ingress-controller.yaml' in f:\n            ingressrole = 'master' if workers == 0 or not mdns or kubevirt_api_service else 'worker'\n            default_replicas = 1 if workers == 1 else 2\n            replicas = 1 if sno or (ctlplanes == 1 and workers == 0) or len(baremetal_hosts) == 1 else default_replicas\n            bm_workers = len(baremetal_hosts) > 0 and workers > 0\n            if provider in virt_providers and (worker_localhost_fix or bm_workers):\n                replicas = ctlplanes\n                ingressrole = 'master'\n                warning(\"Forcing router pods on ctlplanes\")\n                copy2(f'{plandir}/cluster-scheduler-02-config.yml', f\"{clusterdir}/manifests\")\n            ingressconfig = config.process_inputfile(cluster, f, overrides={'replicas': replicas, 'role': ingressrole,\n                                                                            'cluster': cluster, 'domain': domain})\n            with open(f\"{clusterdir}/openshift/99-ingress-controller.yaml\", 'w') as _f:\n                _f.write(ingressconfig)\n            continue\n        if '99-iptables.yaml' in f:\n            if provider not in cloud_providers and not sno:\n                ip = ingress_ip or api_ip\n                iptables = 'ip6tables' if ':' in ip else 'iptables'\n                iptables_overrides = {'ip': ip, 'iptables': iptables}\n                iptablesdata = config.process_inputfile(cluster, f, overrides=iptables_overrides)\n                with open(f\"{clusterdir}/openshift/99-iptables.yaml\", 'w') as _f:\n                    _f.write(iptablesdata)\n            continue\n        if '99-autoapprovercron-cronjob.yaml' in f:\n            crondata = config.process_inputfile(cluster, f, overrides=cron_overrides)\n            with open(f\"{clusterdir}/openshift/99-autoapprovercron-cronjob.yaml\", 'w') as _f:\n                _f.write(crondata)\n            continue\n        if '99-monitoring.yaml' in f:\n            monitoring_retention = data['monitoring_retention']\n            monitoringfile = config.process_inputfile(cluster, f, overrides={'retention': monitoring_retention})\n            with open(f\"{clusterdir}/openshift/99-monitoring.yaml\", 'w') as _f:\n                _f.write(monitoringfile)\n            continue\n        copy2(f, f\"{clusterdir}/openshift\")\n    if virtualization_nightly:\n        pprint(\"Adding custom catalog for OpenShift Virtualization Nightly\")\n        copy2(f'{plandir}/99-openshift-virtualization-catalog.yaml', f\"{clusterdir}/openshift\")\n    if prega and not disconnected_vm and disconnected_url is None:\n        pprint(\"Adding custom catalog for Prega\")\n        pregafile = config.process_inputfile(cluster, f'{plandir}/99-prega-catalog.yaml',\n                                             overrides={'version': version})\n        with open(f\"{clusterdir}/openshift/99-prega-catalog.yaml\", 'w') as _f:\n            _f.write(pregafile)\n    registry = disconnected_url or 'quay.io'\n    if async_install or autoscale:\n        config.import_in_kube(network=network, dest=f\"{clusterdir}/openshift\", secure=True)\n        deletionfile = f\"{plandir}/99-bootstrap-deletion.yaml\"\n        deletionfile = config.process_inputfile(cluster, deletionfile, overrides={'cluster': cluster,\n                                                                                  'registry': registry,\n                                                                                  'client': config.client})\n        with open(f\"{clusterdir}/openshift/99-bootstrap-deletion.yaml\", 'w') as _f:\n            _f.write(deletionfile)\n        if not autoscale:\n            deletionfile2 = f\"{plandir}/99-bootstrap-deletion-2.yaml\"\n            deletionfile2 = config.process_inputfile(cluster, deletionfile2, overrides={'registry': registry})\n            with open(f\"{clusterdir}/openshift/99-bootstrap-deletion-2.yaml\", 'w') as _f:\n                _f.write(deletionfile2)\n    if notify and (async_install or (sno and not sno_wait)):\n        notifycmd = \"cat /shared/results.txt\"\n        notifycmds, mailcontent = config.handle_notifications(cluster, notifymethods=config.notifymethods,\n                                                              pushbullettoken=config.pushbullettoken,\n                                                              notifycmd=notifycmd, slackchannel=config.slackchannel,\n                                                              slacktoken=config.slacktoken,\n                                                              mailserver=config.mailserver,\n                                                              mailfrom=config.mailfrom, mailto=config.mailto,\n                                                              cluster=True)\n        notifyfile = f\"{plandir}/99-notifications.yaml\"\n        notifyfile = config.process_inputfile(cluster, notifyfile, overrides={'registry': registry,\n                                                                              'cluster': cluster,\n                                                                              'domain': original_domain,\n                                                                              'sno': sno,\n                                                                              'cmds': notifycmds,\n                                                                              'mailcontent': mailcontent})\n        with open(f\"{clusterdir}/openshift/99-notifications.yaml\", 'w') as _f:\n            _f.write(notifyfile)\n    if apps and (async_install or (sno and not sno_wait)):\n        registry = disconnected_url or 'quay.io'\n        appsfile = f\"{plandir}/99-apps.yaml\"\n        apps_data = {'registry': registry, 'overrides': overrides, 'overrides_string': safe_dump(overrides)}\n        appsfile = config.process_inputfile(cluster, appsfile, overrides=apps_data)\n        with open(f\"{clusterdir}/openshift/99-apps.yaml\", 'w') as _f:\n            _f.write(appsfile)\n    if ctlplane_localhost_fix:\n        localctlplane = config.process_inputfile(cluster, f\"{plandir}/20-localhost-fix.yaml\",\n                                                 overrides={'role': 'master'})\n        with open(f\"{clusterdir}/openshift/20-localhost-fix-ctlplane.yaml\", 'w') as _f:\n            _f.write(localctlplane)\n    if worker_localhost_fix:\n        localworker = config.process_inputfile(cluster, f\"{plandir}/20-localhost-fix.yaml\",\n                                               overrides={'role': 'worker'})\n        with open(f\"{clusterdir}/openshift/99-localhost-fix-worker.yaml\", 'w') as _f:\n            _f.write(localworker)\n    if metal3:\n        copy2(f\"{plandir}/99-metal3-provisioning.yaml\", f\"{clusterdir}/openshift\")\n        copy2(f\"{plandir}/99-metal3-fake-machine.yaml\", f\"{clusterdir}/openshift\")\n    if autologin:\n        for role in ['ctlplane', 'worker']:\n            autologinfile = config.process_inputfile(cluster, f\"{plandir}/99-autologin.yaml\", overrides={'role': role})\n            with open(f\"{clusterdir}/openshift/99-autologin-{role}.yaml\", 'w') as _f:\n                _f.write(autologinfile)\n    if dedicated_etcd:\n        extra_disks = data['extra_ctlplane_disks'] or data['extra_disks']\n        if not extra_disks:\n            dedicated_etcd_size = data['dedicated_etcd_size']\n            warning(f\"Adding an additional {dedicated_etcd_size}gb disk for etcd\")\n            extra_disks = [dedicated_etcd_size]\n            data['extra_ctlplane_disks'] = extra_disks\n        extra_disk = extra_disks[0]\n        if config.type == 'vsphere' or isinstance(extra_disk, dict) and extra_disk.get('interface', '') == 'scsi':\n            disk = 'sdb'\n        else:\n            disk = 'vdb'\n        etcdfile = config.process_inputfile(cluster, f\"{plandir}/98-etcd.yaml\", overrides={'disk': disk})\n        with open(f\"{clusterdir}/openshift/98-etcd.yaml\", 'w') as _f:\n            _f.write(etcdfile)\n    if provider == 'kubevirt':\n        kubevirtctlplane = config.process_inputfile(cluster, f\"{plandir}/99-kubevirt-fix.yaml\",\n                                                    overrides={'role': 'master'})\n        with open(f\"{clusterdir}/openshift/99-kubevirt-fix-ctlplane.yaml\", 'w') as _f:\n            _f.write(kubevirtctlplane)\n        kubevirtworker = config.process_inputfile(cluster, f\"{plandir}/99-kubevirt-fix.yaml\",\n                                                  overrides={'role': 'worker'})\n        with open(f\"{clusterdir}/openshift/99-kubevirt-fix-worker.yaml\", 'w') as _f:\n            _f.write(kubevirtworker)\n    # ... (rest of function omitted for brevity)\n",
      "hash_value": "5502c6b2b255d4772e33dc44a1ae1c2d",
      "severity": "High",
      "confidence": "Medium",
      "code_snippets": [
        {
          "snippet": "def create(config, plandir, cluster, overrides, dnsconfig=None):\n    k = config.k\n    log_level = 'debug' if config.debug else 'info'\n    client = config.client\n    provider = config.type\n    arch = k.get_capabilities()['arch'] if provider == 'kvm' else 'x86_64'\n    pprint(f\"Deploying on client {client}\")\n    data = safe_load(open(f'{plandir}/kcli_default.yml'))\n    data.update(overrides)\n    fix_typos(data)\n    esx = config.type == 'vsphere' and k.esx\n    data['esx'] = esx\n    ctlplanes = data['ctlplanes']\n    if ctlplanes <= 0:\n        return {'result': 'failure', 'reason': f\"Invalid number of ctlplanes {ctlplanes}\"}\n    workers = data['workers']\n    if workers < 0:\n        return {'result': 'failure', 'reason': f\"Invalid number of workers {workers}\"}\n    if data['dual_api_ip'] is not None:\n        warning(\"Forcing dualstack\")\n        data['dualstack'] = True\n    http_proxy = os.environ.get('HTTP_PROXY') or os.environ.get('http_proxy')\n    if 'http_proxy' not in data and http_proxy is not None:\n        pprint(\"Using proxy settings from environment\")\n        data['http_proxy'] = http_proxy\n        https_proxy = os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy')\n        if 'https_proxy' not in data and https_proxy is not None:\n            data['https_proxy'] = https_proxy\n        no_proxy = os.environ.get('NO_PROXY') or os.environ.get('no_proxy')\n        if 'no_proxy' not in data and no_proxy is not None:\n            data['no_proxy'] = no_proxy\n    if data['ctlplanes'] == 1 and data['workers'] == 0\\\n       and 'ctlplane_memory' not in overrides and 'memory' not in overrides:\n        overrides['ctlplane_memory'] = 32768\n        warning(\"Forcing memory of single ctlplane vm to 32G\")\n    retries = data['retries']\n    data['cluster'] = cluster\n    domain = data['domain']\n    dns_k = dnsconfig.k if dnsconfig is not None else k\n    if provider in cloud_providers:\n        dns_zones = dns_k.list_dns_zones()\n        if domain not in dns_zones and f'{domain}.' not in dns_zones:\n            return {'result': 'failure', 'reason': f'domain {domain} needs to exist'}\n    original_domain = None\n    async_install = data['async']\n    okd = data['okd']\n    autoscale = data['autoscale']\n    sslip = data['sslip']\n    if 'baremetal_hosts' not in data and 'bmc_url' in data:\n        host = {'bmc_url': data['bmc_url'], 'bmc_user': data.get('bmc_user'), 'bmc_password': data.get('bmc_password')}\n        data['baremetal_hosts'] = [host]\n    baremetal_hosts = data['baremetal_hosts']\n    notify = data['notify']\n    postscripts = data['postscripts']\n    pprint(f\"Deploying cluster {cluster}\")\n    plan = cluster\n    overrides['kubetype'] = 'openshift'\n    apps = overrides.get('apps', [])\n    disks = overrides.get('disks', [30])\n    overrides['kube'] = data['cluster']\n    installparam = overrides.copy()\n    installparam['cluster'] = cluster\n    baremetal_sno = workers == 0 and len(baremetal_hosts) == 1\n    baremetal_ctlplane = data['workers'] == 0 and len(baremetal_hosts) > 1\n    sno_vm = data['sno_vm']\n    sno = sno_vm or data['sno'] or baremetal_ctlplane or baremetal_sno\n    data['sno'] = sno\n    sno_wait = overrides.get('sno_wait') or baremetal_sno or data['api_ip'] is not None or sno_vm\n    sno_disk = data['sno_disk']\n    sno_ctlplanes = data['sno_ctlplanes'] or baremetal_ctlplane\n    sno_workers = data['sno_workers']\n    ignore_hosts = data['ignore_hosts'] or sslip\n    if sno:\n        if sno_disk is None:\n            warning(\"sno_disk will be discovered\")\n        ctlplanes = 1\n        workers = 0\n        data['mdns'] = False\n        data['kubetype'] = 'openshift'\n        data['kube'] = data['cluster']\n        if data['network_type'] == 'OpenShiftSDN':\n            warning(\"Forcing network_type to OVNKubernetes\")\n            data['network_type'] = 'OVNKubernetes'\n    elif ('lvms-operator' in apps or 'localstorage' in apps or 'ocs' in apps) and 'extra_disks' not in overrides\\\n            and 'extra_ctlplane_disks' not in overrides and 'extra_worker_disks' not in overrides and len(disks) == 1:\n        warning(\"Storage apps require extra disks to be set\")\n    network = data['network']\n    post_dualstack = False\n    if data['dualstack'] and provider in cloud_providers:\n        warning(\"Dual stack will be enabled at the end of the install\")\n        data['dualstack'] = False\n        post_dualstack = True\n    ipv6 = data['ipv6']\n    disconnected_update = data['disconnected_update']\n    disconnected_reuse = data['disconnected_reuse']\n    disconnected_operators = data['disconnected_operators']\n    certified_operators = data['disconnected_certified_operators']\n    community_operators = data['disconnected_community_operators']\n    marketplace_operators = data['disconnected_marketplace_operators']\n    disconnected_url = data['disconnected_url']\n    disconnected_user = data['disconnected_user']\n    disconnected_password = data['disconnected_password']\n    operators = disconnected_operators + community_operators + certified_operators + marketplace_operators\n    disconnected = data['disconnected']\n    disconnected_vm = data['disconnected_vm'] or (disconnected_url is None and (disconnected or operators))\n    ipsec = data['ipsec']\n    ipsec_mode = data['ipsec_mode']\n    mtu = data['mtu']\n    ovn_hostrouting = data['ovn_hostrouting']\n    metal3 = data['metal3']\n    autologin = data['autologin']\n    dedicated_etcd = data['dedicated_etcd']\n    if not data['coredns']:\n        warning(\"You will need to provide DNS records for api and ingress on your own\")\n    keepalived = data['keepalived']\n    if not keepalived:\n        warning(\"You will need to provide LB for api and ingress on your own\")\n    mdns = data['mdns']\n    localhost_fix = data['localhost_fix']\n    ctlplane_localhost_fix = data['ctlplane_localhost_fix'] or localhost_fix\n    worker_localhost_fix = data['worker_localhost_fix'] or localhost_fix\n    sno_cpuset = data['sno_cpuset']\n    kubevirt_api_service, kubevirt_api_service_node_port = False, False\n    kubevirt_ignore_node_port = data['kubevirt_ignore_node_port']\n    prega = data['prega']\n    virtualization_nightly = data['virtualization_nightly']\n    version = data['version']\n    tag = data['tag']\n    version = overrides.get('version') or detect_openshift_version(tag, OPENSHIFT_TAG)\n    data['version'] = version\n    if os.path.exists('coreos-installer'):\n        pprint(\"Removing old coreos-installer\")\n        os.remove('coreos-installer')\n    if version not in ['ci', 'candidate', 'nightly', 'stable']:\n        return {'result': 'failure', 'reason': f\"Incorrect version {version}\"}\n    else:\n        pprint(f\"Using {version} version\")\n    cluster = data.get('cluster')\n    image = data['image']\n    api_ip = data['api_ip']\n    cidr = None\n    if provider in virt_providers and keepalived and not sno and api_ip is None:\n        network = data['network']\n        networkinfo = k.info_network(network)\n        if not networkinfo:\n            return {'result': 'failure', 'reason': f\"Issue getting network {network}\"}\n        if provider == 'kvm' and networkinfo['type'] == 'routed':\n            cidr = networkinfo['cidr']\n            if cidr == 'N/A':\n                return {'result': 'failure', 'reason': \"Couldnt gather an api_ip from your specified network\"}\n            api_index = 2 if ':' in cidr else -3\n            api_ip = str(get_new_vip(network, ipv6=':' in cidr) or ip_network(cidr)[api_index])\n            warning(f\"Using {api_ip} as api_ip\")\n            overrides['api_ip'] = api_ip\n            installparam['automatic_api_ip'] = True\n            installparam['api_ip'] = api_ip\n        elif provider == 'kubevirt':\n            selector = {'kcli/plan': plan, 'kcli/role': 'ctlplane'}\n            service_type = \"LoadBalancer\" if k.access_mode == 'LoadBalancer' else 'NodePort'\n            namespace = k.namespace\n            if service_type == 'NodePort':\n                kubevirt_api_service_node_port = True\n            api_ip = k.create_service(f\"{cluster}-api\", namespace, selector, _type=service_type,\n                                      ports=[6443, 22623, 22624], openshift_hack=True)\n            if api_ip is None:\n                return {'result': 'failure', 'reason': \"Couldnt gather an api_ip from your specified network\"}\n            else:\n                pprint(f\"Using api_ip {api_ip}\")\n                overrides['api_ip'] = api_ip\n                overrides['kubevirt_api_service'] = True\n                kubevirt_api_service = True\n                overrides['mdns'] = False\n                try:\n                    patch_ingress_controller_wildcard()\n                    selector = {'kcli/plan': plan, 'kcli/role': 'worker' if workers > 0 else 'ctlplane'}\n                    k.create_service(f\"{cluster}-ingress\", namespace, selector, ports=[80, 443])\n                    routecmd = f'oc -n {namespace} create route passthrough --service={cluster}-ingress '\n                    routecmd += f'--hostname=http.apps.{cluster}.{domain} --wildcard-policy=Subdomain --port=443'\n                    call(routecmd, shell=True)\n                except:\n                    pass\n        else:\n            return {'result': 'failure', 'reason': \"You need to define api_ip in your parameters file\"}\n    if api_ip is not None:\n        try:\n            ip_address(api_ip)\n        except:\n            return {'result': 'failure', 'reason': f\"Invalid api_ip {api_ip}\"}\n    if provider in virt_providers and keepalived and not sno and ':' in api_ip:\n        ipv6 = True\n    if ipv6:\n        if data['network_type'] == 'OpenShiftSDN':\n            warning(\"Forcing network_type to OVNKubernetes\")\n            data['network_type'] = 'OVNKubernetes'\n        data['ipv6'] = True\n        overrides['ipv6'] = True\n        data['disconnected_ipv6_network'] = True\n        if not disconnected_vm and disconnected_url is None:\n            warning(\"Forcing disconnected_vm to True as no disconnected_url was provided\")\n            data['disconnected_vm'] = True\n            disconnected_vm = True\n        if sno and not data['dualstack'] and 'extra_args' not in overrides:\n            warning(\"Forcing extra_args to ip=dhcp6 for sno to boot with ipv6\")\n            data['extra_args'] = 'ip=dhcp6'\n    ingress_ip = data['ingress_ip']\n    if ingress_ip is not None:\n        if api_ip is not None and ingress_ip == api_ip:\n            ingress_ip = None\n            overrides['ingress_ip'] = None\n        else:\n            try:\n                ip_address(ingress_ip)\n            except:\n                return {'result': 'failure', 'reason': f\"Invalid ingress_ip {ingress_ip}\"}\n    if sslip and provider in virt_providers:\n        if api_ip is None:\n            return {'result': 'failure', 'reason': \"Missing api_ip which is required with sslip\"}\n        original_domain = domain\n        domain = f\"{api_ip.replace('.', '-').replace(':', '-')}.sslip.io\"\n        data['domain'] = domain\n        pprint(f\"Setting domain to {domain}\")\n        ignore_hosts = False\n    public_api_ip = data['public_api_ip']\n    provider_network = False\n    network = data['network']\n    ctlplanes = data['ctlplanes']\n    workers = data['workers']\n    tag = data['tag']\n    pull_secret = pwd_path(data.get('pull_secret')) if not okd else f\"{plandir}/fake_pull.json\"\n    pull_secret = os.path.expanduser(pull_secret)\n    macosx = data['macosx']\n    if macosx and not os.path.exists('/i_am_a_container'):\n        macosx = False\n    if provider == 'openstack' and keepalived and not sno:\n        if data['flavor'] is None:\n            return {'result': 'failure', 'reason': \"Missing flavor in parameter file\"}\n        provider_network = k.provider_network(network)\n        if not provider_network:\n            if api_ip is None:\n                cidr = k.info_network(network)['cidr']\n                api_ip = str(ip_network(cidr)[-3])\n                data['api_ip'] = api_ip\n                warning(f\"Using {api_ip} as api_ip\")\n            if public_api_ip is None:\n                public_api_ip = k.create_network_port(f\"{cluster}-vip\", network, ip=api_ip, floating=True)['floating']\n    if not os.path.exists(pull_secret):\n        return {'result': 'failure', 'reason': f\"Missing pull secret file {pull_secret}\"}\n    if prega and 'quay.io/prega' not in open(os.path.expanduser(pull_secret)).read():\n        return {'result': 'failure', 'reason': \"entry for quay.io/prega missing in pull secret\"}\n    if virtualization_nightly and 'quay.io/openshift-cnv' not in open(os.path.expanduser(pull_secret)).read():\n        return {'result': 'failure', 'reason': \"entry for quay.io/openshift-cnv missing in pull secret\"}\n    if which('oc') is None:\n        get_oc(macosx=macosx)\n    pub_key = data['pub_key'] or get_ssh_pub_key()\n    keys = data['keys']\n    if pub_key is None:\n        if keys:\n            warning(\"Using first key from your keys array\")\n            pub_key = keys[0]\n        else:\n            msg = \"No usable public key found, which is required for the deployment. Create one using ssh-keygen\"\n            return {'result': 'failure', 'reason': msg}\n    pub_key = os.path.expanduser(pub_key)\n    if pub_key.startswith('ssh-'):\n        data['pub_key'] = pub_key\n    elif os.path.exists(pub_key):\n        data['pub_key'] = open(pub_key).read().strip()\n    else:\n        return {'result': 'failure', 'reason': f\"Publickey file {pub_key} not found\"}\n    clusterdir = os.path.expanduser(f\"~/.kcli/clusters/{cluster}\")\n    if os.path.exists(clusterdir):\n        if [v for v in k.list() if v.get('plan', 'kvirt') == cluster]:\n            return {'result': 'failure', 'reason': f\"Remove existing directory {clusterdir} or use --force\"}\n        else:\n            pprint(f\"Removing existing directory {clusterdir}\")\n            rmtree(clusterdir)\n    if version == 'ci':\n        if '/' not in str(tag) and str(tag).count('.') != 1:\n            if arch in ['aarch64', 'arm64']:\n                tag = f'registry.ci.openshift.org/ocp-arm64/release-arm64:{tag}'\n            else:\n                basetag = 'ocp'\n                tag = f'registry.ci.openshift.org/{basetag}/release:{tag}'\n    which_openshift = which('openshift-install')\n    openshift_dir = os.path.dirname(which_openshift) if which_openshift is not None else '.'\n    if which_openshift is not None and not has_internet():\n        pprint(\"Using existing openshift-install found in your PATH\")\n        warning(\"Not checking version\")\n    elif okd:\n        run = get_okd_installer(tag, version=version)\n    elif not same_release_images(version=version, tag=tag, pull_secret=pull_secret, path=openshift_dir):\n        if version in ['ci', 'nightly'] or '/' in str(tag):\n            nightly = version == 'nightly'\n            run = get_ci_installer(pull_secret, tag=tag, nightly=nightly)\n        elif version in ['candidate', 'stable', 'latest']:\n            run = get_downstream_installer(version=version, tag=tag, pull_secret=pull_secret)\n        else:\n            return {'result': 'failure', 'reason': f\"Invalid version {version}\"}\n        if run != 0:\n            return {'result': 'failure', 'reason': \"Couldn't download openshift-install\"}\n        pprint(\"Move downloaded openshift-install somewhere in your PATH if you want to reuse it\")\n    elif which_openshift is not None:\n        pprint(\"Using existing openshift-install found in your PATH\")\n    else:\n        pprint(\"Reusing matching openshift-install\")\n    os.environ[\"PATH\"] = f'{os.getcwd()}:{os.environ[\"PATH\"]}'\n    INSTALLER_VERSION = get_installer_version()\n    pprint(f\"Using installer version {INSTALLER_VERSION}\")\n    if disconnected_url is not None:\n        if disconnected_user is None:\n            return {'result': 'failure', 'reason': \"disconnected_user needs to be set\"}\n        if disconnected_password is None:\n            return {'result': 'failure', 'reason': \"disconnected_password needs to be set\"}\n        if disconnected_url.startswith('http'):\n            warning(f\"Removing scheme from {disconnected_url}\")\n            disconnected_url = disconnected_url.replace('http://', '').replace('https://', '')\n        update_pull_secret(pull_secret, disconnected_url, disconnected_user, disconnected_password)\n        data['ori_tag'] = tag\n        if '/' not in str(tag):\n            disconnected_prefix = data['disconnected_prefix'] or 'openshift-release-dev/ocp-release'\n            tag = f'{disconnected_url}/{disconnected_prefix}:{INSTALLER_VERSION}-{arch}'\n            os.environ['OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE'] = tag\n        if 'ca' not in data and 'quay.io' not in disconnected_url:\n            pprint(f\"Trying to gather registry ca cert from {disconnected_url}\")\n            cacmd = f\"openssl s_client -showcerts -connect {disconnected_url} </dev/null 2>/dev/null|\"\n            cacmd += \"openssl x509 -outform PEM\"\n            data['ca'] = os.popen(cacmd).read()\n    if sno:\n        pass\n    elif image is None:\n        image_type = provider\n        region = k.region if provider == 'aws' else None\n        try:\n            image_url = get_installer_rhcos(_type=image_type, region=region, arch=arch)\n        except:\n            msg = f\"Couldn't gather the {provider} image associated to this installer version\"\n            msg += \"Force an image in your parameter file\"\n            return {'result': 'failure', 'reason': msg}\n        if provider in ['aws', 'gcp']:\n            image = image_url\n        elif esx:\n            image = image_url\n            overrides['image_url'] = image\n        else:\n            if image_url.endswith('.vhd'):\n                image = os.path.basename(image_url)\n            else:\n                image = os.path.basename(os.path.splitext(image_url)[0])\n            if provider in ['ibm', 'kubevirt', 'proxmox']:\n                image = image.replace('.', '-').replace('_', '-').lower()\n            if provider == 'vsphere':\n                image = image.replace(f'.{arch}', '')\n            images = [v for v in k.volumes() if image in v]\n            if not images:\n                result = config.download_image(pool=config.pool, image=image, url=image_url,\n                                               size=data['kubevirt_disk_size'])\n                if result['result'] != 'success':\n                    return result\n        pprint(f\"Using image {image}\")\n    elif provider == 'kubevirt' and '/' in image:\n        warning(f\"Assuming image {image} is available\")\n    else:\n        pprint(f\"Checking if image {image} is available\")\n        images = [v for v in k.volumes() if image in v]\n        if not images:\n            msg = f\"Missing {image}. Indicate correct image in your parameters file...\"\n            return {'result': 'failure', 'reason': msg}\n    overrides['image'] = image\n    static_networking_ctlplane, static_networking_worker = False, False\n    macentries = []\n    custom_names = {}\n    vmrules = [] if provider == 'kvm' else overrides.get('vmrules', [])\n    for entry in vmrules:\n        if isinstance(entry, dict):\n            hostname = list(entry.keys())[0]\n            if isinstance(entry[hostname], dict):\n                rule = entry[hostname]\n                if 'name' in rule:\n                    custom_names[hostname] = rule['name']\n                if 'nets' in rule and isinstance(rule['nets'], list):\n                    netrule = rule['nets'][0]\n                    if isinstance(netrule, dict) and 'ip' in netrule and 'netmask' in netrule:\n                        mac, ip = netrule.get('mac'), netrule['ip']\n                        netmask, gateway = netrule['netmask'], netrule.get('gateway')\n                        nameserver = netrule.get('dns', gateway)\n                        if mac is not None and gateway is not None:\n                            macentries.append(f\"{mac};{hostname};{ip};{netmask};{gateway};{nameserver}\")\n                        if hostname.startswith(f\"{cluster}-ctlplane\"):\n                            static_networking_ctlplane = True\n                        elif hostname.startswith(f\"{cluster}-worker\"):\n                            static_networking_worker = True\n    if custom_names:\n        overrides['custom_names'] = custom_names\n    overrides['cluster'] = cluster\n    if not os.path.exists(clusterdir):\n        os.makedirs(clusterdir)\n    if provider in virt_providers and disconnected_vm:\n        disconnected_vm = f\"{data['disconnected_reuse_name'] or cluster}-registry\"\n        pprint(f\"Deploying disconnected vm {disconnected_vm}\")\n        data['pull_secret'] = re.sub(r\"\\s\", \"\", open(pull_secret).read())\n        disconnected_plan = f\"{plan}-reuse\" if disconnected_reuse else plan\n        disconnected_overrides = data.copy()\n        disconnected_overrides['OPENSHIFT_TAG'] = OPENSHIFT_TAG\n        disconnected_overrides['kube'] = f\"{cluster}-reuse\" if disconnected_reuse else cluster\n        disconnected_overrides['openshift_version'] = INSTALLER_VERSION\n        disconnected_overrides['disconnected_operators_version'] = f\"4.{INSTALLER_VERSION.split('.')[1]}\"\n        x_apps = ['users', 'autolabeller', 'metal3', 'nfs']\n        disconnected_operators_2 = [o['name'] for o in disconnected_operators if isinstance(o, dict) and 'name' in o]\n        for app in apps:\n            if app not in x_apps and app not in disconnected_operators and app not in disconnected_operators_2:\n                warning(f\"Adding app {app} to disconnected_operators array\")\n                disconnected_operators.append(app)\n        disconnected_overrides['disconnected_operators'] = disconnected_operators\n        result = config.plan(disconnected_plan, inputfile=f'{plandir}/disconnected.yml',\n                             overrides=disconnected_overrides)\n        if result['result'] != 'success':\n            return result\n        disconnected_ip, disconnected_vmport = _ssh_credentials(k, disconnected_vm)[1:]\n        cacmd = \"cat /opt/registry/certs/domain.crt\"\n        cacmd = ssh(disconnected_vm, ip=disconnected_ip, user='root', tunnel=config.tunnel,\n                    tunnelhost=config.tunnelhost, tunnelport=config.tunnelport, tunneluser=config.tunneluser,\n                    insecure=True, cmd=cacmd, vmport=disconnected_vmport)\n        disconnected_ca = os.popen(cacmd).read().strip()\n        if data['ca'] is not None:\n            data['ca'] += f\"\\n{disconnected_ca}\"\n        else:\n            data['ca'] = disconnected_ca\n        urlcmd = \"cat /root/url.txt\"\n        urlcmd = ssh(disconnected_vm, ip=disconnected_ip, user='root', tunnel=config.tunnel,\n                     tunnelhost=config.tunnelhost, tunnelport=config.tunnelport, tunneluser=config.tunneluser,\n                     insecure=True, cmd=urlcmd, vmport=disconnected_vmport)\n        disconnected_url = os.popen(urlcmd).read().strip()\n        overrides['disconnected_url'] = disconnected_url\n        data['disconnected_url'] = disconnected_url\n        versioncmd = \"cat /root/version.txt\"\n        versioncmd = ssh(disconnected_vm, ip=disconnected_ip, user='root', tunnel=config.tunnel,\n                         tunnelhost=config.tunnelhost, tunnelport=config.tunnelport, tunneluser=config.tunneluser,\n                         insecure=True, cmd=versioncmd, vmport=disconnected_vmport)\n        disconnected_version = os.popen(versioncmd).read().strip()\n        for source in [\"'cs-*.yaml'\", \"'i*oc-mirror.yaml'\"]:\n            scpcmd = scp(disconnected_vm, ip=disconnected_ip, user='root', source=source, destination=clusterdir,\n                         tunnel=config.tunnel, tunnelhost=config.tunnelhost, tunnelport=config.tunnelport,\n                         tunneluser=config.tunneluser, download=True, insecure=True, vmport=disconnected_vmport)\n            os.system(scpcmd)\n        patch_oc_mirror(clusterdir)\n        os.environ['OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE'] = disconnected_version\n    data['pull_secret_path'] = pull_secret\n    data['pull_secret'] = re.sub(r\"\\s\", \"\", open(pull_secret).read())\n    if disconnected_url is not None:\n        if disconnected_update and disconnected_url != 'quay.io':\n            data['release_tag'] = f'v4.{get_installer_minor(INSTALLER_VERSION)}'\n            update_registry(config, plandir, cluster, data)\n        key = f\"{disconnected_user}:{disconnected_password}\"\n        key = str(b64encode(key.encode('utf-8')), 'utf-8')\n        auths = json.loads(data['pull_secret'])['auths']\n        if disconnected_url not in auths or auths[disconnected_url]['auth'] != key:\n            auths[disconnected_url] = {'auth': key, 'email': 'jhendrix@karmalabs.corp'}\n            data['pull_secret'] = json.dumps({\"auths\": auths})\n    if provider == 'aws':\n        aws_credentials(config)\n    elif provider == 'gcp':\n        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.expanduser(config.options.get('credentials'))\n    elif provider == 'azure':\n        azure_credentials(config)\n        if '-' in network:\n            vnet = network.split('-')[0]\n            data['machine_cidr'] = k.info_network(vnet)['cidr']\n    elif provider == 'vsphere' and get_installer_minor(INSTALLER_VERSION) < 13:\n        data['vsphere_legacy'] = True\n    installconfig = config.process_inputfile(cluster, f\"{plandir}/install-config.yaml\", overrides=data)\n    with open(f\"{clusterdir}/install-config.yaml\", 'w') as f:\n        f.write(installconfig)\n    with open(f\"{clusterdir}/install-config.yaml.bck\", 'w') as f:\n        f.write(installconfig)\n    run = call(f'openshift-install --dir={clusterdir} --log-level={log_level} create manifests', shell=True)\n    if run != 0:\n        msg = \"Leaving environment for debugging purposes. \"\n        msg += f\"Delete it with kcli delete kube --yes {cluster}\"\n        return {'result': 'failure', 'reason': msg}\n    if provider == 'azure':\n        prefix = safe_load(open(f'{clusterdir}/openshift/99_cloud-creds-secret.yaml'))['data']['azure_resource_prefix']\n        new_prefix = b64encode(bytes(cluster, 'utf-8')).decode('utf-8')\n        sedcmd = f'sed -i \"s@{prefix}@{new_prefix}@\" {clusterdir}/openshift/99_cloud-creds-secret.yaml'\n        call(sedcmd, shell=True)\n        old_prefix = b64decode(bytes(prefix, 'utf-8')).decode('utf-8')\n        sedcmd = f'sed -i \"s@{old_prefix}@{cluster}@\" {clusterdir}/openshift/* {clusterdir}/manifests/*'\n        call(sedcmd, shell=True)\n    for f in glob(f\"{clusterdir}/openshift/99_openshift-cluster-api_master-machines-*.yaml\"):\n        os.remove(f)\n    for f in glob(f\"{clusterdir}/openshift/99_openshift-cluster-api_worker-machineset-*\"):\n        os.remove(f)\n    for f in glob(f\"{clusterdir}/openshift/99_openshift-machine-api_master-control-plane-machine-set.yaml\"):\n        os.remove(f)\n    ntp_server = data['ntp_server']\n    if ntp_server is not None:\n        ntp_data = config.process_inputfile(cluster, f\"{plandir}/chrony.conf\", overrides={'ntp_server': ntp_server})\n        for role in ['master', 'worker']:\n            ntp = config.process_inputfile(cluster, f\"{plandir}/99-chrony.yaml\",\n                                           overrides={'role': role, 'ntp_data': ntp_data})\n            with open(f\"{clusterdir}/manifests/99-chrony-{role}.yaml\", 'w') as f:\n                f.write(ntp)\n    baremetal_cidr = data['baremetal_cidr']\n    if baremetal_cidr is not None:\n        node_ip_hint = f\"KUBELET_NODEIP_HINT={baremetal_cidr.split('/')[0]}\"\n        for role in ['master', 'worker']:\n            hint = config.process_inputfile(cluster, f\"{plandir}/10-node-ip-hint.yaml\",\n                                            overrides={'role': role, 'node_ip_hint': node_ip_hint})\n            with open(f\"{clusterdir}/manifests/99-chrony-{role}.yaml\", 'w') as f:\n                f.write(hint)\n    manifestsdir = data.get('manifests')\n    manifestsdir = pwd_path(manifestsdir)\n    if os.path.exists(manifestsdir) and os.path.isdir(manifestsdir):\n        for f in glob(f\"{manifestsdir}/*.y*ml\"):\n            pprint(f\"Injecting manifest {f}\")\n            copy2(f, f\"{clusterdir}/openshift\")\n    elif isinstance(manifestsdir, list):\n        for manifest in manifestsdir:\n            f, content = list(manifest.keys())[0], list(manifest.values())[0]\n            if not f.endswith('.yml') and not f.endswith('.yaml'):\n                warning(f\"Skipping manifest {f}\")\n                continue\n            pprint(f\"Injecting manifest {f}\")\n            with open(f'{clusterdir}/openshift/{f}', 'w') as f:\n                f.write(content)\n    for manifest in glob(f\"{clusterdir}/*.yaml\"):\n        if os.stat(manifest).st_size == 0:\n            warning(f\"Skipping empty manifest {manifest}\")\n        elif manifest.startswith(f'{clusterdir}/cs-') or 'oc-mirror' in manifest:\n            pprint(f\"Injecting manifest {manifest}\")\n            copy2(manifest, f\"{clusterdir}/openshift\")\n    if disconnected_operators:\n        copy2(f'{plandir}/99-operatorhub.yaml', f\"{clusterdir}/openshift\")\n    network_type = data['network_type']\n    if network_type == 'Calico':\n        calico_version = data['calico_version']\n        with TemporaryDirectory() as tmpdir:\n            calico_data = {'tmpdir': tmpdir, 'clusterdir': clusterdir, 'calico_version': calico_version}\n            calico_script = config.process_inputfile('xxx', f'{plandir}/calico.sh.j2', overrides=calico_data)\n            with open(f\"{tmpdir}/calico.sh\", 'w') as f:\n                f.write(calico_script)\n            call(f'bash {tmpdir}/calico.sh', shell=True)\n    elif network_type == 'Cilium':\n        cilium_version = data['cilium_version']\n        cluster_network_ipv4 = data['cluster_network_ipv4']\n        cilium_data = {'clusterdir': clusterdir, 'cilium_version': cilium_version, 'cidr': cluster_network_ipv4}\n        cilium_script = config.process_inputfile('xxx', f'{plandir}/cilium.sh.j2', overrides=cilium_data)\n        with open(f\"{clusterdir}/cilium.sh\", 'w') as f:\n            f.write(cilium_script)\n        call(f'bash {clusterdir}/cilium.sh', shell=True)\n    if ipsec or ipsec_mode is not None or ovn_hostrouting or mtu != 1400:\n        valid_modes = ['Full', 'Disabled', 'External']\n        if ipsec_mode is not None and ipsec_mode not in valid_modes:\n            warning(f\"Incorrect ipsec_mode. Choose between {','.join(valid_modes)}\")\n            warning(\"Setting ipsec_mode to Full\")\n            ipsec_mode = 'Full'\n        ovn_data = config.process_inputfile(cluster, f\"{plandir}/99-ovn.yaml\",\n                                            overrides={'ipsec': ipsec, 'ovn_hostrouting': ovn_hostrouting,\n                                                       'mtu': mtu, 'mode': ipsec_mode})\n        with open(f\"{clusterdir}/openshift/99-ovn.yaml\", 'w') as f:\n            f.write(ovn_data)\n    if workers == 0 or not mdns or kubevirt_api_service:\n        copy2(f'{plandir}/cluster-scheduler-02-config.yml', f\"{clusterdir}/manifests\")\n    if 'sslip' in domain:\n        ingress_sslip_data = config.process_inputfile(cluster, f\"{plandir}/cluster-ingress-02-config.yml\",\n                                                      overrides={'cluster': cluster, 'domain': domain})\n        with open(f\"{clusterdir}/manifests/cluster-ingress-02-config.yml\", 'w') as f:\n            f.write(ingress_sslip_data)\n    cron_overrides = {'registry': disconnected_url or 'quay.io'}\n    cron_overrides['version'] = 'v1beta1' if get_installer_minor(INSTALLER_VERSION) < 8 else 'v1'\n    autoapproverdata = config.process_inputfile(cluster, f\"{plandir}/autoapprovercron.yml\", overrides=cron_overrides)\n    with open(f\"{clusterdir}/autoapprovercron.yml\", 'w') as f:\n        f.write(autoapproverdata)\n    for f in glob(f\"{plandir}/customisation/*.yaml\"):\n        if '99-ingress-controller.yaml' in f:\n            ingressrole = 'master' if workers == 0 or not mdns or kubevirt_api_service else 'worker'\n            default_replicas = 1 if workers == 1 else 2\n            replicas = 1 if sno or (ctlplanes == 1 and workers == 0) or len(baremetal_hosts) == 1 else default_replicas\n            bm_workers = len(baremetal_hosts) > 0 and workers > 0\n            if provider in virt_providers and (worker_localhost_fix or bm_workers):\n                replicas = ctlplanes\n                ingressrole = 'master'\n                warning(\"Forcing router pods on ctlplanes\")\n                copy2(f'{plandir}/cluster-scheduler-02-config.yml', f\"{clusterdir}/manifests\")\n            ingressconfig = config.process_inputfile(cluster, f, overrides={'replicas': replicas, 'role': ingressrole,\n                                                                            'cluster': cluster, 'domain': domain})\n            with open(f\"{clusterdir}/openshift/99-ingress-controller.yaml\", 'w') as _f:\n                _f.write(ingressconfig)\n            continue\n        if '99-iptables.yaml' in f:\n            if provider not in cloud_providers and not sno:\n                ip = ingress_ip or api_ip\n                iptables = 'ip6tables' if ':' in ip else 'iptables'\n                iptables_overrides = {'ip': ip, 'iptables': iptables}\n                iptablesdata = config.process_inputfile(cluster, f, overrides=iptables_overrides)\n                with open(f\"{clusterdir}/openshift/99-iptables.yaml\", 'w') as _f:\n                    _f.write(iptablesdata)\n            continue\n        if '99-autoapprovercron-cronjob.yaml' in f:\n            crondata = config.process_inputfile(cluster, f, overrides=cron_overrides)\n            with open(f\"{clusterdir}/openshift/99-autoapprovercron-cronjob.yaml\", 'w') as _f:\n                _f.write(crondata)\n            continue\n        if '99-monitoring.yaml' in f:\n            monitoring_retention = data['monitoring_retention']\n            monitoringfile = config.process_inputfile(cluster, f, overrides={'retention': monitoring_retention})\n            with open(f\"{clusterdir}/openshift/99-monitoring.yaml\", 'w') as _f:\n                _f.write(monitoringfile)\n            continue\n        copy2(f, f\"{clusterdir}/openshift\")\n    if virtualization_nightly:\n        pprint(\"Adding custom catalog for OpenShift Virtualization Nightly\")\n        copy2(f'{plandir}/99-openshift-virtualization-catalog.yaml', f\"{clusterdir}/openshift\")\n    if prega and not disconnected_vm and disconnected_url is None:\n        pprint(\"Adding custom catalog for Prega\")\n        pregafile = config.process_inputfile(cluster, f'{plandir}/99-prega-catalog.yaml',\n                                             overrides={'version': version})\n        with open(f\"{clusterdir}/openshift/99-prega-catalog.yaml\", 'w') as _f:\n            _f.write(pregafile)\n    registry = disconnected_url or 'quay.io'\n    if async_install or autoscale:\n        config.import_in_kube(network=network, dest=f\"{clusterdir}/openshift\", secure=True)\n        deletionfile = f\"{plandir}/99-bootstrap-deletion.yaml\"\n        deletionfile = config.process_inputfile(cluster, deletionfile, overrides={'cluster': cluster,\n                                                                                  'registry': registry,\n                                                                                  'client': config.client})\n        with open(f\"{clusterdir}/openshift/99-bootstrap-deletion.yaml\", 'w') as _f:\n            _f.write(deletionfile)\n        if not autoscale:\n            deletionfile2 = f\"{plandir}/99-bootstrap-deletion-2.yaml\"\n            deletionfile2 = config.process_inputfile(cluster, deletionfile2, overrides={'registry': registry})\n            with open(f\"{clusterdir}/openshift/99-bootstrap-deletion-2.yaml\", 'w') as _f:\n                _f.write(deletionfile2)\n    if notify and (async_install or (sno and not sno_wait)):\n        notifycmd = \"cat /shared/results.txt\"\n        notifycmds, mailcontent = config.handle_notifications(cluster, notifymethods=config.notifymethods,\n                                                              pushbullettoken=config.pushbullettoken,\n                                                              notifycmd=notifycmd, slackchannel=config.slackchannel,\n                                                              slacktoken=config.slacktoken,\n                                                              mailserver=config.mailserver,\n                                                              mailfrom=config.mailfrom, mailto=config.mailto,\n                                                              cluster=True)\n        notifyfile = f\"{plandir}/99-notifications.yaml\"\n        notifyfile = config.process_inputfile(cluster, notifyfile, overrides={'registry': registry,\n                                                                              'cluster': cluster,\n                                                                              'domain': original_domain,\n                                                                              'sno': sno,\n                                                                              'cmds': notifycmds,\n                                                                              'mailcontent': mailcontent})\n        with open(f\"{clusterdir}/openshift/99-notifications.yaml\", 'w') as _f:\n            _f.write(notifyfile)\n    if apps and (async_install or (sno and not sno_wait)):\n        registry = disconnected_url or 'quay.io'\n        appsfile = f\"{plandir}/99-apps.yaml\"\n        apps_data = {'registry': registry, 'overrides': overrides, 'overrides_string': safe_dump(overrides)}\n        appsfile = config.process_inputfile(cluster, appsfile, overrides=apps_data)\n        with open(f\"{clusterdir}/openshift/99-apps.yaml\", 'w') as _f:\n            _f.write(appsfile)\n    if ctlplane_localhost_fix:\n        localctlplane = config.process_inputfile(cluster, f\"{plandir}/20-localhost-fix.yaml\",\n                                                 overrides={'role': 'master'})\n        with open(f\"{clusterdir}/openshift/20-localhost-fix-ctlplane.yaml\", 'w') as _f:\n            _f.write(localctlplane)\n    if worker_localhost_fix:\n        localworker = config.process_inputfile(cluster, f\"{plandir}/20-localhost-fix.yaml\",\n                                               overrides={'role': 'worker'})\n        with open(f\"{clusterdir}/openshift/99-localhost-fix-worker.yaml\", 'w') as _f:\n            _f.write(localworker)\n    if metal3:\n        copy2(f\"{plandir}/99-metal3-provisioning.yaml\", f\"{clusterdir}/openshift\")\n        copy2(f\"{plandir}/99-metal3-fake-machine.yaml\", f\"{clusterdir}/openshift\")\n    if autologin:\n        for role in ['ctlplane', 'worker']:\n            autologinfile = config.process_inputfile(cluster, f\"{plandir}/99-autologin.yaml\", overrides={'role': role})\n            with open(f\"{clusterdir}/openshift/99-autologin-{role}.yaml\", 'w') as _f:\n                _f.write(autologinfile)\n    if dedicated_etcd:\n        extra_disks = data['extra_ctlplane_disks'] or data['extra_disks']\n        if not extra_disks:\n            dedicated_etcd_size = data['dedicated_etcd_size']\n            warning(f\"Adding an additional {dedicated_etcd_size}gb disk for etcd\")\n            extra_disks = [dedicated_etcd_size]\n            data['extra_ctlplane_disks'] = extra_disks\n        extra_disk = extra_disks[0]\n        if config.type == 'vsphere' or isinstance(extra_disk, dict) and extra_disk.get('interface', '') == 'scsi':\n            disk = 'sdb'\n        else:\n            disk = 'vdb'\n        etcdfile = config.process_inputfile(cluster, f\"{plandir}/98-etcd.yaml\", overrides={'disk': disk})\n        with open(f\"{clusterdir}/openshift/98-etcd.yaml\", 'w') as _f:\n            _f.write(etcdfile)\n    if provider == 'kubevirt':\n        kubevirtctlplane = config.process_inputfile(cluster, f\"{plandir}/99-kubevirt-fix.yaml\",\n                                                    overrides={'role': 'master'})\n        with open(f\"{clusterdir}/openshift/99-kubevirt-fix-ctlplane.yaml\", 'w') as _f:\n            _f.write(kubevirtctlplane)\n        kubevirtworker = config.process_inputfile(cluster, f\"{plandir}/99-kubevirt-fix.yaml\",\n                                                  overrides={'role': 'worker'})\n        with open(f\"{clusterdir}/openshift/99-kubevirt-fix-worker.yaml\", 'w') as _f:\n            _f.write(kubevirtworker)\n    # ... (rest of function omitted for brevity)\n",
          "triple_sequences": [
            {
              "action_api": "open()",
              "action_description": "File opening operations for reading (normal reading, binary reading)",
              "action_id": "basic_read_operations",
              "object": "f'{plandir}/kcli_default.yml'",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Read file content",
              "intention_id": "read_file_content"
            },
            {
              "action_api": "safe_load()",
              "action_description": "Deserializes JSON string to Python object",
              "action_id": "deserialize_from_json",
              "object": "open(f'{plandir}/kcli_default.yml')",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Parse JSON data",
              "intention_id": "parse_json_data"
            },
            {
              "action_api": "os.environ.get()",
              "action_description": "Retrieves value of environment variable",
              "action_id": "get_env_var",
              "object": "'HTTP_PROXY'",
              "object_description": "Environment variable",
              "object_id": "environment_variable",
              "intention_description": "Collect environment variable",
              "intention_id": "collect_environment_variable"
            },
            {
              "action_api": "os.path.exists()",
              "action_description": "Checks if specified path exists in filesystem",
              "action_id": "check_path_exists",
              "object": "'coreos-installer'",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Check if file or directory exists",
              "intention_id": "check_file_existence"
            },
            {
              "action_api": "os.remove()",
              "action_description": "Deletes specified file from filesystem",
              "action_id": "delete_file",
              "object": "'coreos-installer'",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Delete file",
              "intention_id": "delete_file"
            },
            {
              "action_api": "os.path.expanduser()",
              "action_description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
              "action_id": "path_special_operations",
              "object": "pull_secret",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Prepare path for file operations",
              "intention_id": "prepare_path_file_operations"
            },
            {
              "action_api": "os.path.exists()",
              "action_description": "Checks if specified path exists in filesystem",
              "action_id": "check_path_exists",
              "object": "pull_secret",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Check if file or directory exists",
              "intention_id": "check_file_existence"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for reading (normal reading, binary reading)",
              "action_id": "basic_read_operations",
              "object": "os.path.expanduser(pull_secret)",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Read file content",
              "intention_id": "read_file_content"
            },
            {
              "action_api": "os.path.exists()",
              "action_description": "Checks if specified path exists in filesystem",
              "action_id": "check_path_exists",
              "object": "pub_key",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Determine presence of local file",
              "intention_id": "determine_local_file_presence"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for reading (normal reading, binary reading)",
              "action_id": "basic_read_operations",
              "object": "pub_key",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Read file content",
              "intention_id": "read_file_content"
            },
            {
              "action_api": "os.path.expanduser()",
              "action_description": "Special path operations (home directory expansion, temporary directory path, executable path, directory tree generation)",
              "action_id": "path_special_operations",
              "object": "f\"~/.kcli/clusters/{cluster}\"",
              "object_description": "Directory path",
              "object_id": "directory_path",
              "intention_description": "Prepare directory path",
              "intention_id": "prepare_directory_path"
            },
            {
              "action_api": "os.path.exists()",
              "action_description": "Checks if specified path exists in filesystem",
              "action_id": "check_path_exists",
              "object": "clusterdir",
              "object_description": "Directory path",
              "object_id": "directory_path",
              "intention_description": "Determine presence of directory",
              "intention_id": "determine_directory_presence"
            },
            {
              "action_api": "rmtree()",
              "action_description": "Recursively deletes directory and its contents",
              "action_id": "delete_directory",
              "object": "clusterdir",
              "object_description": "Directory path",
              "object_id": "directory_path",
              "intention_description": "Delete directory content",
              "intention_id": "delete_directory_content"
            },
            {
              "action_api": "os.path.dirname()",
              "action_description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
              "action_id": "path_string_operations",
              "object": "which_openshift",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Prepare directory path",
              "intention_id": "prepare_directory_path"
            },
            {
              "action_api": "os.getcwd()",
              "action_description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
              "action_id": "path_string_operations",
              "object": "",
              "object_description": "Current working directory",
              "object_id": "current_working_directory",
              "intention_description": "Collect working directory",
              "intention_id": "collect_working_directory"
            },
            {
              "action_api": "os.environ[\"PATH\"] = ...",
              "action_description": "Sets attribute on builtins object",
              "action_id": "set_builtin_attr",
              "object": "f'{os.getcwd()}:{os.environ[\"PATH\"]}'",
              "object_description": "Environment variable",
              "object_id": "environment_variable",
              "intention_description": "Collect environment variable",
              "intention_id": "collect_environment_variable"
            },
            {
              "action_api": "os.popen()",
              "action_description": "Executes shell command",
              "action_id": "execute_shell_command",
              "object": "cacmd",
              "object_description": "Shell command",
              "object_id": "shell_command",
              "intention_description": "Execute command",
              "intention_id": "execute_command"
            },
            {
              "action_api": "os.popen().read()",
              "action_description": "Reads all bytes from process standard output",
              "action_id": "read_process_stdout",
              "object": "",
              "object_description": "Command output",
              "object_id": "command_output",
              "intention_description": "Collect command output",
              "intention_id": "collect_command_output"
            },
            {
              "action_api": "os.popen()",
              "action_description": "Executes shell command",
              "action_id": "execute_shell_command",
              "object": "urlcmd",
              "object_description": "Shell command",
              "object_id": "shell_command",
              "intention_description": "Execute command",
              "intention_id": "execute_command"
            },
            {
              "action_api": "os.popen().read()",
              "action_description": "Reads all bytes from process standard output",
              "action_id": "read_process_stdout",
              "object": "",
              "object_description": "Command output",
              "object_id": "command_output",
              "intention_description": "Collect command output",
              "intention_id": "collect_command_output"
            },
            {
              "action_api": "os.popen()",
              "action_description": "Executes shell command",
              "action_id": "execute_shell_command",
              "object": "versioncmd",
              "object_description": "Shell command",
              "object_id": "shell_command",
              "intention_description": "Execute command",
              "intention_id": "execute_command"
            },
            {
              "action_api": "os.popen().read()",
              "action_description": "Reads all bytes from process standard output",
              "action_id": "read_process_stdout",
              "object": "",
              "object_description": "Command output",
              "object_id": "command_output",
              "intention_description": "Collect command output",
              "intention_id": "collect_command_output"
            },
            {
              "action_api": "os.system()",
              "action_description": "Executes shell command",
              "action_id": "execute_shell_command",
              "object": "scpcmd",
              "object_description": "Shell command",
              "object_id": "shell_command",
              "intention_description": "Execute command",
              "intention_id": "execute_command"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for reading (normal reading, binary reading)",
              "action_id": "basic_read_operations",
              "object": "pull_secret",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Read file content",
              "intention_id": "read_file_content"
            },
            {
              "action_api": "re.sub()",
              "action_description": "Compiles regular expression pattern",
              "action_id": "compile_regex",
              "object": "r\"\\s\", \"\", open(pull_secret).read()",
              "object_description": "File text",
              "object_id": "file_text",
              "intention_description": "Prepare data for further processing",
              "intention_id": "prepare_data_processing"
            },
            {
              "action_api": "json.loads()",
              "action_description": "Deserializes JSON string to Python object",
              "action_id": "deserialize_from_json",
              "object": "data['pull_secret']",
              "object_description": "JSON string",
              "object_id": "json_string",
              "intention_description": "Parse JSON data",
              "intention_id": "parse_json_data"
            },
            {
              "action_api": "json.dumps()",
              "action_description": "Serializes Python object to JSON string",
              "action_id": "serialize_to_json",
              "object": "{\"auths\": auths}",
              "object_description": "JSON string",
              "object_id": "json_string",
              "intention_description": "Serialize data",
              "intention_id": "serialize_data"
            },
            {
              "action_api": "os.path.exists()",
              "action_description": "Checks if specified path exists in filesystem",
              "action_id": "check_path_exists",
              "object": "clusterdir",
              "object_description": "Directory path",
              "object_id": "directory_path",
              "intention_description": "Determine presence of directory",
              "intention_id": "determine_directory_presence"
            },
            {
              "action_api": "os.makedirs()",
              "action_description": "Creates directory, ignoring if it already exists",
              "action_id": "create_directory",
              "object": "clusterdir",
              "object_description": "Directory path",
              "object_id": "directory_path",
              "intention_description": "Ensure directory exists",
              "intention_id": "ensure_directory_exists"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/install-config.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/install-config.yaml.bck\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "call()",
              "action_description": "Executes shell command",
              "action_id": "execute_shell_command",
              "object": "f'openshift-install --dir={clusterdir} --log-level={log_level} create manifests'",
              "object_description": "Shell command",
              "object_id": "shell_command",
              "intention_description": "Execute command",
              "intention_id": "execute_command"
            },
            {
              "action_api": "glob()",
              "action_description": "List directory contents",
              "action_id": "list_directory_contents",
              "object": "f\"{clusterdir}/openshift/99_openshift-cluster-api_master-machines-*.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "List files in directory",
              "intention_id": "list_directory_files"
            },
            {
              "action_api": "os.remove()",
              "action_description": "Deletes specified file from filesystem",
              "action_id": "delete_file",
              "object": "f",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Delete file",
              "intention_id": "delete_file"
            },
            {
              "action_api": "glob()",
              "action_description": "List directory contents",
              "action_id": "list_directory_contents",
              "object": "f\"{clusterdir}/openshift/99_openshift-cluster-api_worker-machineset-*\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "List files in directory",
              "intention_id": "list_directory_files"
            },
            {
              "action_api": "os.remove()",
              "action_description": "Deletes specified file from filesystem",
              "action_id": "delete_file",
              "object": "f",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Delete file",
              "intention_id": "delete_file"
            },
            {
              "action_api": "glob()",
              "action_description": "List directory contents",
              "action_id": "list_directory_contents",
              "object": "f\"{clusterdir}/openshift/99_openshift-machine-api_master-control-plane-machine-set.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "List files in directory",
              "intention_id": "list_directory_files"
            },
            {
              "action_api": "os.remove()",
              "action_description": "Deletes specified file from filesystem",
              "action_id": "delete_file",
              "object": "f",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Delete file",
              "intention_id": "delete_file"
            },
            {
              "action_api": "copy2()",
              "action_description": "Copies file to destination",
              "action_id": "copy_file",
              "object": "f, f\"{clusterdir}/openshift\"",
              "object_description": "Directory path with file",
              "object_id": "directory_path_with_file",
              "intention_description": "Copy file to temporary directory",
              "intention_id": "copy_file_temp_directory"
            },
            {
              "action_api": "TemporaryDirectory()",
              "action_description": "Creates temporary directory and returns its path",
              "action_id": "create_temp_dir",
              "object": "",
              "object_description": "Temporary directory",
              "object_id": "temporary_directory",
              "intention_description": "Create temporary directory",
              "intention_id": "create_temporary_directory"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{tmpdir}/calico.sh\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "call()",
              "action_description": "Executes shell command",
              "action_id": "execute_shell_command",
              "object": "f'bash {tmpdir}/calico.sh'",
              "object_description": "Shell command",
              "object_id": "shell_command",
              "intention_description": "Execute command",
              "intention_id": "execute_command"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/cilium.sh\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "call()",
              "action_description": "Executes shell command",
              "action_id": "execute_shell_command",
              "object": "f'bash {clusterdir}/cilium.sh'",
              "object_description": "Shell command",
              "object_id": "shell_command",
              "intention_description": "Execute command",
              "intention_id": "execute_command"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-ovn.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "copy2()",
              "action_description": "Copies file to destination",
              "action_id": "copy_file",
              "object": "f'{plandir}/cluster-scheduler-02-config.yml', f\"{clusterdir}/manifests\"",
              "object_description": "Directory path with file",
              "object_id": "directory_path_with_file",
              "intention_description": "Copy file to temporary directory",
              "intention_id": "copy_file_temp_directory"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/manifests/cluster-ingress-02-config.yml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "glob()",
              "action_description": "List directory contents",
              "action_id": "list_directory_contents",
              "object": "f\"{plandir}/customisation/*.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "List files in directory",
              "intention_id": "list_directory_files"
            },
            {
              "action_api": "copy2()",
              "action_description": "Copies file to destination",
              "action_id": "copy_file",
              "object": "f'{plandir}/cluster-scheduler-02-config.yml', f\"{clusterdir}/manifests\"",
              "object_description": "Directory path with file",
              "object_id": "directory_path_with_file",
              "intention_description": "Copy file to temporary directory",
              "intention_id": "copy_file_temp_directory"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-ingress-controller.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-iptables.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-autoapprovercron-cronjob.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-monitoring.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "copy2()",
              "action_description": "Copies file to destination",
              "action_id": "copy_file",
              "object": "f, f\"{clusterdir}/openshift\"",
              "object_description": "Directory path with file",
              "object_id": "directory_path_with_file",
              "intention_description": "Copy file to temporary directory",
              "intention_id": "copy_file_temp_directory"
            },
            {
              "action_api": "copy2()",
              "action_description": "Copies file to destination",
              "action_id": "copy_file",
              "object": "f'{plandir}/99-openshift-virtualization-catalog.yaml', f\"{clusterdir}/openshift\"",
              "object_description": "Directory path with file",
              "object_id": "directory_path_with_file",
              "intention_description": "Copy file to temporary directory",
              "intention_id": "copy_file_temp_directory"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-prega-catalog.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-bootstrap-deletion.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-bootstrap-deletion-2.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-notifications.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-apps.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/20-localhost-fix-ctlplane.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-localhost-fix-worker.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "copy2()",
              "action_description": "Copies file to destination",
              "action_id": "copy_file",
              "object": "f\"{plandir}/99-metal3-provisioning.yaml\", f\"{clusterdir}/openshift\"",
              "object_description": "Directory path with file",
              "object_id": "directory_path_with_file",
              "intention_description": "Copy file to temporary directory",
              "intention_id": "copy_file_temp_directory"
            },
            {
              "action_api": "copy2()",
              "action_description": "Copies file to destination",
              "action_id": "copy_file",
              "object": "f\"{plandir}/99-metal3-fake-machine.yaml\", f\"{clusterdir}/openshift\"",
              "object_description": "Directory path with file",
              "object_id": "directory_path_with_file",
              "intention_description": "Copy file to temporary directory",
              "intention_id": "copy_file_temp_directory"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-autologin-{role}.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/98-etcd.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-kubevirt-fix-ctlplane.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            },
            {
              "action_api": "open()",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "f\"{clusterdir}/openshift/99-kubevirt-fix-worker.yaml\"",
              "object_description": "Script file path",
              "object_id": "script_file_path",
              "intention_description": "Write file content",
              "intention_id": "write_file_content"
            }
          ]
        }
      ]
    }
  ]
}