{
  "metadata": {
    "package_name": "srt-3",
    "original_json_path": "/home2/blue/Documents/PyPIAgent/Codes/code_contexral/codesnippets/benign_bandit4mal/srt-3.5.3.json",
    "dataset_type": "benign_bandit4mal"
  },
  "code_files": [
    {
      "pyfile": "utils.py",
      "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/srt-3.5.3/srt-3.5.3/srt_tools/utils.py",
      "line_number": "172",
      "type_description": "B814:read",
      "context_snippet": "def set_basic_args(args):\n    # TODO: dedupe some of this\n    if getattr(args, \"inplace\", None):\n        if args.input == DASH_STREAM_MAP[\"input\"]:\n            raise ValueError(\"Cannot use --inplace on stdin\")\n\n        if args.output != DASH_STREAM_MAP[\"output\"]:\n            raise ValueError(\"Cannot use -o and -p together\")\n\n        args.output = args.input\n\n    for stream_name in (\"input\", \"output\"):\n        log.debug('Processing stream \"%s\"', stream_name)\n\n        try:\n            stream = getattr(args, stream_name)\n        except AttributeError:\n            # For example, in the case of no_output\n            continue\n\n        # We don't use system default encoding, because usually one runs this\n        # on files they got from elsewhere. As such, be opinionated that these\n        # files are probably UTF-8. Looking for the BOM on reading allows us to\n        # be more liberal with what we accept, without adding BOMs on write.\n        read_encoding = args.encoding or \"utf-8-sig\"\n        write_encoding = args.encoding or \"utf-8\"\n\n        r_enc = codecs.getreader(read_encoding)\n        w_enc = codecs.getwriter(write_encoding)\n\n        log.debug(\"Got %r as stream\", stream)\n        # We don't use encoding= option to open because we want to have the\n        # same universal newlines behaviour as STD{IN,OUT}_BYTESTREAM\n        if stream in DASH_STREAM_MAP.values():\n            log.debug(\"%s in DASH_STREAM_MAP\", stream_name)\n            if stream is args.input:\n                args.input = srt.parse(\n                    r_enc(args.input).read(), ignore_errors=args.ignore_parsing_errors\n                )\n            elif stream is args.output:\n                # Since args.output is not in text mode (since we didn't\n                # earlier know the encoding), we have no universal newline\n                # support and need to do it ourselves\n                args.output = w_enc(args.output)\n        else:\n            log.debug(\"%s not in DASH_STREAM_MAP\", stream_name)\n            if stream is args.input:\n                if isinstance(args.input, MutableSequence):\n                    for i, input_fn in enumerate(args.input):\n                        if input_fn in DASH_STREAM_MAP.values():\n                            if stream is args.input:\n                                args.input[i] = srt.parse(\n                                    r_enc(input_fn).read(),\n                                    ignore_errors=args.ignore_parsing_errors,\n                                )\n                        else:\n                            f = r_enc(open(input_fn, \"rb\"))\n                            with f:\n                                args.input[i] = srt.parse(\n                                    f.read(), ignore_errors=args.ignore_parsing_errors\n                                )\n                else:\n                    f = r_enc(open(stream, \"rb\"))\n                    with f:\n                        args.input = srt.parse(\n                            f.read(), ignore_errors=args.ignore_parsing_errors\n                        )\n            else:\n                args.output = w_enc(open(args.output, \"wb\"))",
      "hash_value": "5691bf38b097bcae5c052eb919eccf19",
      "severity": "High",
      "confidence": "Medium",
      "code_snippets": [
        {
          "snippet": "def set_basic_args(args):\n    # TODO: dedupe some of this\n    if getattr(args, \"inplace\", None):\n        if args.input == DASH_STREAM_MAP[\"input\"]:\n            raise ValueError(\"Cannot use --inplace on stdin\")\n\n        if args.output != DASH_STREAM_MAP[\"output\"]:\n            raise ValueError(\"Cannot use -o and -p together\")\n\n        args.output = args.input\n\n    for stream_name in (\"input\", \"output\"):\n        log.debug('Processing stream \"%s\"', stream_name)\n\n        try:\n            stream = getattr(args, stream_name)\n        except AttributeError:\n            # For example, in the case of no_output\n            continue\n\n        # We don't use system default encoding, because usually one runs this\n        # on files they got from elsewhere. As such, be opinionated that these\n        # files are probably UTF-8. Looking for the BOM on reading allows us to\n        # be more liberal with what we accept, without adding BOMs on write.\n        read_encoding = args.encoding or \"utf-8-sig\"\n        write_encoding = args.encoding or \"utf-8\"\n\n        r_enc = codecs.getreader(read_encoding)\n        w_enc = codecs.getwriter(write_encoding)\n\n        log.debug(\"Got %r as stream\", stream)\n        # We don't use encoding= option to open because we want to have the\n        # same universal newlines behaviour as STD{IN,OUT}_BYTESTREAM\n        if stream in DASH_STREAM_MAP.values():\n            log.debug(\"%s in DASH_STREAM_MAP\", stream_name)\n            if stream is args.input:\n                args.input = srt.parse(\n                    r_enc(args.input).read(), ignore_errors=args.ignore_parsing_errors\n                )\n            elif stream is args.output:\n                # Since args.output is not in text mode (since we didn't\n                # earlier know the encoding), we have no universal newline\n                # support and need to do it ourselves\n                args.output = w_enc(args.output)\n        else:\n            log.debug(\"%s not in DASH_STREAM_MAP\", stream_name)\n            if stream is args.input:\n                if isinstance(args.input, MutableSequence):\n                    for i, input_fn in enumerate(args.input):\n                        if input_fn in DASH_STREAM_MAP.values():\n                            if stream is args.input:\n                                args.input[i] = srt.parse(\n                                    r_enc(input_fn).read(),\n                                    ignore_errors=args.ignore_parsing_errors,\n                                )\n                        else:\n                            f = r_enc(open(input_fn, \"rb\"))\n                            with f:\n                                args.input[i] = srt.parse(\n                                    f.read(), ignore_errors=args.ignore_parsing_errors\n                                )\n                else:\n                    f = r_enc(open(stream, \"rb\"))\n                    with f:\n                        args.input = srt.parse(\n                            f.read(), ignore_errors=args.ignore_parsing_errors\n                        )\n            else:\n                args.output = w_enc(open(args.output, \"wb\"))",
          "triple_sequences": [
            {
              "action_api": "getattr()",
              "action_description": "Checks if specified path exists in filesystem",
              "action_id": "check_path_exists",
              "object": "args, \"inplace\", None",
              "object_description": "",
              "object_id": "",
              "intention_description": "Determine presence of required module",
              "intention_id": "determine_required_module_presence"
            },
            {
              "action_api": "getattr()",
              "action_description": "Checks if specified path exists in filesystem",
              "action_id": "check_path_exists",
              "object": "args, stream_name",
              "object_description": "",
              "object_id": "",
              "intention_description": "Determine presence of required module",
              "intention_id": "determine_required_module_presence"
            },
            {
              "action_api": "codecs.getreader()",
              "action_description": "Decodes bytes using specified codec",
              "action_id": "decode_bytes_codec",
              "object": "read_encoding",
              "object_description": "Character encoding type",
              "object_id": "character_encoding_type",
              "intention_description": "Prepare data for further processing",
              "intention_id": "prepare_data_processing"
            },
            {
              "action_api": "codecs.getwriter()",
              "action_description": "Decodes bytes using specified codec",
              "action_id": "decode_bytes_codec",
              "object": "write_encoding",
              "object_description": "Character encoding type",
              "object_id": "character_encoding_type",
              "intention_description": "Prepare data for further processing",
              "intention_id": "prepare_data_processing"
            },
            {
              "action_api": "r_enc(args.input).read()",
              "action_description": "Reads all bytes from process standard output",
              "action_id": "read_process_stdout",
              "object": "args.input",
              "object_description": "",
              "object_id": "",
              "intention_description": "Read file content",
              "intention_id": "read_file_content"
            },
            {
              "action_api": "srt.parse()",
              "action_description": "Deserializes JSON string to Python object",
              "action_id": "deserialize_from_json",
              "object": "r_enc(args.input).read(), ignore_errors=args.ignore_parsing_errors",
              "object_description": "",
              "object_id": "",
              "intention_description": "Parse JSON data",
              "intention_id": "parse_json_data"
            },
            {
              "action_api": "w_enc(args.output)",
              "action_description": "Decodes bytes using specified codec",
              "action_id": "decode_bytes_codec",
              "object": "args.output",
              "object_description": "",
              "object_id": "",
              "intention_description": "Prepare data for further processing",
              "intention_id": "prepare_data_processing"
            },
            {
              "action_api": "isinstance(args.input, MutableSequence)",
              "action_description": "Checks if object is instance of specified type",
              "action_id": "check_instance_type",
              "object": "args.input, MutableSequence",
              "object_description": "",
              "object_id": "",
              "intention_description": "Determine presence of required module",
              "intention_id": "determine_required_module_presence"
            },
            {
              "action_api": "r_enc(open(input_fn, \"rb\"))",
              "action_description": "File opening operations for reading (normal reading, binary reading)",
              "action_id": "basic_read_operations",
              "object": "input_fn, \"rb\"",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Open file for reading",
              "intention_id": "open_file_reading"
            },
            {
              "action_api": "f.read()",
              "action_description": "Reads all bytes from process standard output",
              "action_id": "read_process_stdout",
              "object": "f",
              "object_description": "",
              "object_id": "",
              "intention_description": "Read file content",
              "intention_id": "read_file_content"
            },
            {
              "action_api": "srt.parse()",
              "action_description": "Deserializes JSON string to Python object",
              "action_id": "deserialize_from_json",
              "object": "f.read(), ignore_errors=args.ignore_parsing_errors",
              "object_description": "",
              "object_id": "",
              "intention_description": "Parse JSON data",
              "intention_id": "parse_json_data"
            },
            {
              "action_api": "r_enc(open(stream, \"rb\"))",
              "action_description": "File opening operations for reading (normal reading, binary reading)",
              "action_id": "basic_read_operations",
              "object": "stream, \"rb\"",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Open file for reading",
              "intention_id": "open_file_reading"
            },
            {
              "action_api": "f.read()",
              "action_description": "Reads all bytes from process standard output",
              "action_id": "read_process_stdout",
              "object": "f",
              "object_description": "",
              "object_id": "",
              "intention_description": "Read file content",
              "intention_id": "read_file_content"
            },
            {
              "action_api": "srt.parse()",
              "action_description": "Deserializes JSON string to Python object",
              "action_id": "deserialize_from_json",
              "object": "f.read(), ignore_errors=args.ignore_parsing_errors",
              "object_description": "",
              "object_id": "",
              "intention_description": "Parse JSON data",
              "intention_id": "parse_json_data"
            },
            {
              "action_api": "w_enc(open(args.output, \"wb\"))",
              "action_description": "File opening operations for writing (normal writing, binary writing)",
              "action_id": "basic_write_operations",
              "object": "args.output, \"wb\"",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Open file for writing",
              "intention_id": "open_file_writing"
            }
          ]
        }
      ]
    }
  ]
}