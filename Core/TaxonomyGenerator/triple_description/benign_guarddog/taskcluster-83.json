{
  "metadata": {
    "package_name": "taskcluster-83",
    "original_json_path": "/home2/blue/Documents/PyPIAgent/Codes/code_contexral/codesnippets/benign/taskcluster-83.5.1.json",
    "dataset_type": "benign"
  },
  "code_files": [
    {
      "pyfile": "helper.py",
      "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/taskcluster-83.5.1/taskcluster-83.5.1/taskcluster/helper.py",
      "line_number": "179",
      "type_description": "exfiltrate-sensitive-data",
      "context_snippet": "import os\nimport datetime\nfrom datetime import timezone\nimport logging\nimport requests\nfrom taskcluster.utils import stringDate\n\ndef upload_artifact(queue_service, artifact_path, content, content_type, ttl):\n    \"\"\"\n    DEPRECATED. Do not use.\n    \"\"\"\n    task_id = os.environ.get(\"TASK_ID\")\n    run_id = os.environ.get(\"RUN_ID\")\n    proxy = os.environ.get(\"TASKCLUSTER_PROXY_URL\")\n    assert task_id and run_id and proxy, \"Can only run in Taskcluster tasks with proxy\"\n    # Contet can be str or bytes\n    assert isinstance(content, str) or isinstance(content, bytes)\n    assert isinstance(ttl, datetime.timedelta)\n\n    # Create S3 artifact on Taskcluster\n    resp = queue_service.createArtifact(\n        task_id,\n        run_id,\n        artifact_path,\n        {\n            \"storageType\": \"s3\",\n            \"expires\": stringDate(datetime.datetime.now(timezone.utc) + ttl),\n            \"contentType\": content_type,\n        },\n    )\n    assert resp[\"storageType\"] == \"s3\", \"Not an s3 storage\"\n    assert \"putUrl\" in resp, \"Missing putUrl\"\n    assert \"contentType\" in resp, \"Missing contentType\"\n\n    # Push the artifact on storage service\n    headers = {\"Content-Type\": resp[\"contentType\"]}\n    push = requests.put(url=resp[\"putUrl\"], headers=headers, data=content)\n    push.raise_for_status()\n\n    # Build the absolute url\n    return \"/api/queue/v1/task/{task_id}/runs/{run_id}/artifacts/{path}\".format(\n        task_id=task_id,\n        run_id=run_id,\n        path=artifact_path,\n    )",
      "hash_value": "ce9a823e8add67e6fa3b34131698e60d",
      "detection_index": 1,
      "code_snippets": [
        {
          "snippet": "import os\nimport datetime\nfrom datetime import timezone\nimport logging\nimport requests\nfrom taskcluster.utils import stringDate\n\ndef upload_artifact(queue_service, artifact_path, content, content_type, ttl):\n    \"\"\"\n    DEPRECATED. Do not use.\n    \"\"\"\n    task_id = os.environ.get(\"TASK_ID\")\n    run_id = os.environ.get(\"RUN_ID\")\n    proxy = os.environ.get(\"TASKCLUSTER_PROXY_URL\")\n    assert task_id and run_id and proxy, \"Can only run in Taskcluster tasks with proxy\"\n    # Contet can be str or bytes\n    assert isinstance(content, str) or isinstance(content, bytes)\n    assert isinstance(ttl, datetime.timedelta)\n\n    # Create S3 artifact on Taskcluster\n    resp = queue_service.createArtifact(\n        task_id,\n        run_id,\n        artifact_path,\n        {\n            \"storageType\": \"s3\",\n            \"expires\": stringDate(datetime.datetime.now(timezone.utc) + ttl),\n            \"contentType\": content_type,\n        },\n    )\n    assert resp[\"storageType\"] == \"s3\", \"Not an s3 storage\"\n    assert \"putUrl\" in resp, \"Missing putUrl\"\n    assert \"contentType\" in resp, \"Missing contentType\"\n\n    # Push the artifact on storage service\n    headers = {\"Content-Type\": resp[\"contentType\"]}\n    push = requests.put(url=resp[\"putUrl\"], headers=headers, data=content)\n    push.raise_for_status()\n\n    # Build the absolute url\n    return \"/api/queue/v1/task/{task_id}/runs/{run_id}/artifacts/{path}\".format(\n        task_id=task_id,\n        run_id=run_id,\n        path=artifact_path,\n    )",
          "triple_sequences": [
            {
              "action_api": "os.environ.get()",
              "action_description": "Retrieves value of environment variable",
              "action_id": "get_env_var",
              "object": "\"TASK_ID\"",
              "object_description": "Environment variable",
              "object_id": "environment_variable",
              "intention_description": "Collect environment variable",
              "intention_id": "collect_environment_variable"
            },
            {
              "action_api": "os.environ.get()",
              "action_description": "Retrieves value of environment variable",
              "action_id": "get_env_var",
              "object": "\"RUN_ID\"",
              "object_description": "Environment variable",
              "object_id": "environment_variable",
              "intention_description": "Collect environment variable",
              "intention_id": "collect_environment_variable"
            },
            {
              "action_api": "os.environ.get()",
              "action_description": "Retrieves value of environment variable",
              "action_id": "get_env_var",
              "object": "\"TASKCLUSTER_PROXY_URL\"",
              "object_description": "Environment variable",
              "object_id": "environment_variable",
              "intention_description": "Collect environment variable",
              "intention_id": "collect_environment_variable"
            },
            {
              "action_api": "queue_service.createArtifact()",
              "action_description": "Creates new ZIP archive for writing",
              "action_id": "create_zip_archive",
              "object": "task_id, run_id, artifact_path, {\"storageType\": \"s3\", \"expires\": stringDate(datetime.datetime.now(timezone.utc) + ttl), \"contentType\": content_type}",
              "object_description": "Structured file data",
              "object_id": "structured_file_data",
              "intention_description": "Create zip archive",
              "intention_id": "create_zip_archive"
            },
            {
              "action_api": "stringDate()",
              "action_description": "Parses string into datetime object",
              "action_id": "parse_datetime",
              "object": "datetime.datetime.now(timezone.utc) + ttl",
              "object_description": "Delay duration in seconds",
              "object_id": "delay_duration",
              "intention_description": "Get datetime epoch",
              "intention_id": "get_datetime_epoch"
            },
            {
              "action_api": "requests.put()",
              "action_description": "Sends HTTP request",
              "action_id": "send_http_request",
              "object": "url=resp[\"putUrl\"], headers=headers, data=content",
              "object_description": "API endpoint",
              "object_id": "api_endpoint",
              "intention_description": "Transmit file data to server",
              "intention_id": "transmit_file_data_server"
            },
            {
              "action_api": "push.raise_for_status()",
              "action_description": "Raises HTTPError if response status code indicates error",
              "action_id": "raise_http_error",
              "object": "",
              "object_description": "",
              "object_id": "",
              "intention_description": "Stop execution on invalid input",
              "intention_id": "stop_execution_invalid_input"
            },
            {
              "action_api": "str.format()",
              "action_description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
              "action_id": "path_string_operations",
              "object": "\"/api/queue/v1/task/{task_id}/runs/{run_id}/artifacts/{path}\".format(task_id=task_id, run_id=run_id, path=artifact_path)",
              "object_description": "URL string",
              "object_id": "url_string",
              "intention_description": "Construct file or directory path",
              "intention_id": "construct_file_path"
            }
          ]
        }
      ]
    }
  ]
}