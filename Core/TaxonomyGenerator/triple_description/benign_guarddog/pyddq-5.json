{
  "metadata": {
    "package_name": "pyddq-5",
    "original_json_path": "/home2/blue/Documents/PyPIAgent/Codes/code_contexral/codesnippets/benign/pyddq-5.0.0.json",
    "dataset_type": "benign"
  },
  "code_files": [
    {
      "pyfile": "setup.py",
      "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/pyddq-5.0.0/pyddq-5.0.0/setup.py",
      "line_number": "37",
      "type_description": "code-execution",
      "context_snippet": "import sys\nimport os\nimport glob\nimport subprocess\nfrom setuptools import setup, Command\n\nclass IntegrationTestCommand(Command):\n    description = \"A command to run integration tests\"\n    user_options = [(\"jar=\", None, \"Path to Drunken Data Quality jar\")]\n    jar = None\n    addopts = None\n\n    def initialize_options(self):\n        pass\n\n    def finalize_options(self):\n        if self.addopts is None:\n            exit(\"error: option addopts should be specified in setup.cfg\")\n        elif self.jar is None:\n            exit(\"error: path to Drunken Data Quality jar should be specified\")\n\n    def run(self):\n        log4j_path = os.path.abspath(\"../src/test/resources/log4j.properties\")\n        result = 0\n        try:\n            for filename in glob.glob(os.path.join(self.addopts, \"test_*.py\")):\n                result = result or subprocess.call([\n                    \"spark-submit\",\n                    \"--driver-java-options\",\n                    '\"-Dlog4j.configuration=file://{path}\"'.format(path=log4j_path),\n                    \"--driver-class-path\",\n                    self.jar,\n                    filename\n                ])\n        except OSError as e:\n            if e.errno == os.errno.ENOENT:\n                exit(\"spark-submit is not found!\")\n            else:\n                exit(str(e))\n        exit(result)",
      "hash_value": "f1c489293b8feb77a9eb2a03f85053b7",
      "detection_index": 1,
      "code_snippets": [
        {
          "snippet": "import sys\nimport os\nimport glob\nimport subprocess\nfrom setuptools import setup, Command\n\nclass IntegrationTestCommand(Command):\n    description = \"A command to run integration tests\"\n    user_options = [(\"jar=\", None, \"Path to Drunken Data Quality jar\")]\n    jar = None\n    addopts = None\n\n    def initialize_options(self):\n        pass\n\n    def finalize_options(self):\n        if self.addopts is None:\n            exit(\"error: option addopts should be specified in setup.cfg\")\n        elif self.jar is None:\n            exit(\"error: path to Drunken Data Quality jar should be specified\")\n\n    def run(self):\n        log4j_path = os.path.abspath(\"../src/test/resources/log4j.properties\")\n        result = 0\n        try:\n            for filename in glob.glob(os.path.join(self.addopts, \"test_*.py\")):\n                result = result or subprocess.call([\n                    \"spark-submit\",\n                    \"--driver-java-options\",\n                    '\"-Dlog4j.configuration=file://{path}\"'.format(path=log4j_path),\n                    \"--driver-class-path\",\n                    self.jar,\n                    filename\n                ])\n        except OSError as e:\n            if e.errno == os.errno.ENOENT:\n                exit(\"spark-submit is not found!\")\n            else:\n                exit(str(e))\n        exit(result)",
          "triple_sequences": [
            {
              "action_api": "os.path.abspath()",
              "action_description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
              "action_id": "path_string_operations",
              "object": "../src/test/resources/log4j.properties",
              "object_description": "File path",
              "object_id": "file_path",
              "intention_description": "Construct file or directory path",
              "intention_id": "construct_file_path"
            },
            {
              "action_api": "glob.glob()",
              "action_description": "List directory contents",
              "action_id": "list_directory_contents",
              "object": "os.path.join(self.addopts, \"test_*.py\")",
              "object_description": "Directory path and file name",
              "object_id": "directory_path_with_file",
              "intention_description": "List files in directory",
              "intention_id": "list_directory_files"
            },
            {
              "action_api": "os.path.join()",
              "action_description": "Basic path string operations (getting absolute path, base name, parent directory, splitting and joining paths)",
              "action_id": "path_string_operations",
              "object": "self.addopts, \"test_*.py\"",
              "object_description": "Directory path and file name",
              "object_id": "directory_path_with_file",
              "intention_description": "Construct file or directory path",
              "intention_id": "construct_file_path"
            },
            {
              "action_api": "subprocess.call()",
              "action_description": "Executes shell command",
              "action_id": "execute_shell_command",
              "object": "[\"spark-submit\", \"--driver-java-options\", '\"-Dlog4j.configuration=file://{path}\"'.format(path=log4j_path), \"--driver-class-path\", self.jar, filename]",
              "object_description": "Shell command",
              "object_id": "shell_command",
              "intention_description": "Execute command",
              "intention_id": "execute_command"
            },
            {
              "action_api": "exit()",
              "action_description": "Exits program",
              "action_id": "exit_program",
              "object": "error: option addopts should be specified in setup.cfg",
              "object_description": "Error message text",
              "object_id": "error_message",
              "intention_description": "Terminate program execution",
              "intention_id": "terminate_program_execution"
            },
            {
              "action_api": "exit()",
              "action_description": "Exits program",
              "action_id": "exit_program",
              "object": "error: path to Drunken Data Quality jar should be specified",
              "object_description": "Error message text",
              "object_id": "error_message",
              "intention_description": "Terminate program execution",
              "intention_id": "terminate_program_execution"
            },
            {
              "action_api": "exit()",
              "action_description": "Exits program",
              "action_id": "exit_program",
              "object": "spark-submit is not found!",
              "object_description": "Error message text",
              "object_id": "error_message",
              "intention_description": "Terminate program execution",
              "intention_id": "terminate_program_execution"
            },
            {
              "action_api": "exit()",
              "action_description": "Exits program",
              "action_id": "exit_program",
              "object": "str(e)",
              "object_description": "Error message text",
              "object_id": "error_message",
              "intention_description": "Terminate program execution",
              "intention_id": "terminate_program_execution"
            },
            {
              "action_api": "exit()",
              "action_description": "Exits program",
              "action_id": "exit_program",
              "object": "result",
              "object_description": "",
              "object_id": "",
              "intention_description": "Terminate program execution",
              "intention_id": "terminate_program_execution"
            }
          ]
        }
      ]
    }
  ]
}