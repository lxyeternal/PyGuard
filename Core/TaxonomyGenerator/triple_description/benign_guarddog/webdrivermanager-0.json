{
  "metadata": {
    "package_name": "webdrivermanager-0",
    "original_json_path": "/home2/blue/Documents/PyPIAgent/Codes/code_contexral/codesnippets/benign/webdrivermanager-0.10.0.json",
    "dataset_type": "benign"
  },
  "code_files": [
    {
      "pyfile": "base.py",
      "full_path": "/home2/blue/Documents/PyPIAgent/Dataset/study/unzip_benign/webdrivermanager-0.10.0/webdrivermanager-0.10.0/src/webdrivermanager/base.py",
      "line_number": "211",
      "type_description": "shady-links",
      "context_snippet": "def _parse_github_page(self, version):\n    if version == \"latest\":\n        release_url = f\"{self.fallback_url}latest\"\n        matcher = r\".*\\/releases\\/download\\/.*{}\".format(self.os_name)\n    else:\n        release_url = f\"{self.fallback_url}tag/{version}\"\n        matcher = r\".*\\/releases\\/download\\/{}/.*{}\".format(version, self.os_name)\n\n    response = requests.get(release_url)\n    if response.status_code != 200:\n        return None\n\n    tree = BeautifulSoup(response.text, \"html.parser\")\n    links = tree.find_all(\"a\", href=re.compile(matcher))\n    if len(links) == 2:\n        matcher = f\"{matcher}.*{self.bitness}\"\n        links = tree.find_all(\"a\", href=re.compile(matcher))\n\n    if links:\n        return f\"https://github.com{links[0]['href']}\"\n\n    return None",
      "hash_value": "a4e509c1666f26ce6cbd662cae32a419",
      "detection_index": 1,
      "code_snippets": [
        {
          "snippet": "def _parse_github_page(self, version):\n    if version == \"latest\":\n        release_url = f\"{self.fallback_url}latest\"\n        matcher = r\".*\\/releases\\/download\\/.*{}\".format(self.os_name)\n    else:\n        release_url = f\"{self.fallback_url}tag/{version}\"\n        matcher = r\".*\\/releases\\/download\\/{}/.*{}\".format(version, self.os_name)\n\n    response = requests.get(release_url)\n    if response.status_code != 200:\n        return None\n\n    tree = BeautifulSoup(response.text, \"html.parser\")\n    links = tree.find_all(\"a\", href=re.compile(matcher))\n    if len(links) == 2:\n        matcher = f\"{matcher}.*{self.bitness}\"\n        links = tree.find_all(\"a\", href=re.compile(matcher))\n\n    if links:\n        return f\"https://github.com{links[0]['href']}\"\n\n    return None",
          "triple_sequences": [
            {
              "action_api": "requests.get()",
              "action_description": "Sends HTTP request",
              "action_id": "send_http_request",
              "object": "release_url",
              "object_description": "External domain",
              "object_id": "external_domain",
              "intention_description": "Download remote content",
              "intention_id": "download_remote_content"
            },
            {
              "action_api": "BeautifulSoup()",
              "action_description": "Deserializes JSON response body to Python object",
              "action_id": "deserialize_json_response",
              "object": "response.text, \"html.parser\"",
              "object_description": "HTML file content",
              "object_id": "",
              "intention_description": "Parse JSON data",
              "intention_id": "parse_json_data"
            },
            {
              "action_api": "tree.find_all()",
              "action_description": "Compiles regular expression pattern",
              "action_id": "compile_regex",
              "object": "matcher",
              "object_description": "Regular expression pattern",
              "object_id": "regex_pattern",
              "intention_description": "Browser profile detection preparation",
              "intention_id": "browser_profile_detection_preparation"
            }
          ]
        }
      ]
    }
  ]
}